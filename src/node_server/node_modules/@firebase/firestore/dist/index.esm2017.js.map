{"version":3,"file":"index.esm2017.js","sources":["../src/core/version.ts","../src/auth/user.ts","../src/util/error.ts","../src/api/credentials.ts","../src/api/timestamp.ts","../src/core/snapshot_version.ts","../src/model/path.ts","../src/model/document_key.ts","../src/util/sorted_map.ts","../src/util/sorted_set.ts","../src/util/obj.ts","../src/util/byte_string.ts","../src/util/types.ts","../src/model/server_timestamps.ts","../src/model/values.ts","../src/model/transform_operation.ts","../src/model/mutation.ts","../src/model/field_value.ts","../src/model/document.ts","../src/core/target.ts","../src/core/query.ts","../src/local/target_data.ts","../src/remote/existence_filter.ts","../src/remote/rpc_error.ts","../src/model/collections.ts","../src/model/document_set.ts","../src/core/view_snapshot.ts","../src/remote/remote_event.ts","../src/remote/watch_change.ts","../src/remote/serializer.ts","../src/platform/platform.ts","../src/util/log.ts","../src/util/assert.ts","../src/util/misc.ts","../src/core/database_info.ts","../src/util/obj_map.ts","../src/model/mutation_batch.ts","../src/local/reference_set.ts","../src/local/persistence_promise.ts","../src/local/remote_document_change_buffer.ts","../src/local/persistence.ts","../src/local/local_documents_view.ts","../src/local/local_view_changes.ts","../src/core/listen_sequence.ts","../src/util/promise.ts","../src/util/async_queue.ts","../src/local/lru_garbage_collector.ts","../src/local/local_store.ts","../src/util/input_validation.ts","../src/util/api.ts","../src/api/blob.ts","../src/api/field_path.ts","../src/api/field_value.ts","../src/api/geo_point.ts","../src/api/user_data_reader.ts","../src/remote/backoff.ts","../src/remote/persistent_stream.ts","../src/remote/datastore.ts","../src/core/transaction.ts","../src/remote/online_state_tracker.ts","../src/remote/remote_store.ts","../src/local/shared_client_state_schema.ts","../src/local/shared_client_state.ts","../src/core/target_id_generator.ts","../src/core/view.ts","../src/core/transaction_runner.ts","../src/core/sync_engine.ts","../src/core/event_manager.ts","../src/local/index_free_query_engine.ts","../src/local/encoded_resource_path.ts","../src/local/simple_db.ts","../src/local/indexeddb_mutation_queue.ts","../src/local/indexeddb_target_cache.ts","../src/local/indexeddb_remote_document_cache.ts","../src/local/memory_index_manager.ts","../src/local/indexeddb_schema.ts","../src/local/indexeddb_index_manager.ts","../src/local/local_serializer.ts","../src/local/indexeddb_persistence.ts","../src/local/memory_mutation_queue.ts","../src/local/memory_remote_document_cache.ts","../src/local/memory_target_cache.ts","../src/local/memory_persistence.ts","../src/core/component_provider.ts","../src/core/firestore_client.ts","../src/util/async_observer.ts","../src/api/observer.ts","../src/api/user_data_writer.ts","../src/api/database.ts","../src/platform/config.ts","../src/remote/connectivity_monitor_noop.ts","../src/platform_browser/browser_connectivity_monitor.ts","../src/remote/stream_bridge.ts","../src/platform_browser/webchannel_connection.ts","../index.ts","../src/platform_browser/browser_init.ts","../src/platform_browser/browser_platform.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2017 Google Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport firebase from '@firebase/app';\n\n/** The semver (www.semver.org) version of the SDK. */\nexport const SDK_VERSION = firebase.SDK_VERSION;\n","/**\n * @license\n * Copyright 2017 Google Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n/**\n * Simple wrapper around a nullable UID. Mostly exists to make code more\n * readable.\n */\nexport class User {\n  /** A user with a null UID. */\n  static readonly UNAUTHENTICATED = new User(null);\n\n  // TODO(mikelehen): Look into getting a proper uid-equivalent for\n  // non-FirebaseAuth providers.\n  static readonly GOOGLE_CREDENTIALS = new User('google-credentials-uid');\n  static readonly FIRST_PARTY = new User('first-party-uid');\n\n  constructor(readonly uid: string | null) {}\n\n  isAuthenticated(): boolean {\n    return this.uid != null;\n  }\n\n  /**\n   * Returns a key representing this user, suitable for inclusion in a\n   * dictionary.\n   */\n  toKey(): string {\n    if (this.isAuthenticated()) {\n      return 'uid:' + this.uid;\n    } else {\n      return 'anonymous-user';\n    }\n  }\n\n  isEqual(otherUser: User): boolean {\n    return otherUser.uid === this.uid;\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport * as firestore from '@firebase/firestore-types';\n\n/**\n * Error Codes describing the different ways Firestore can fail. These come\n * directly from GRPC.\n */\nexport type Code = firestore.FirestoreErrorCode;\n\nexport const Code = {\n  // Causes are copied from:\n  // https://github.com/grpc/grpc/blob/bceec94ea4fc5f0085d81235d8e1c06798dc341a/include/grpc%2B%2B/impl/codegen/status_code_enum.h\n  /** Not an error; returned on success. */\n  OK: 'ok' as Code,\n\n  /** The operation was cancelled (typically by the caller). */\n  CANCELLED: 'cancelled' as Code,\n\n  /** Unknown error or an error from a different error domain. */\n  UNKNOWN: 'unknown' as Code,\n\n  /**\n   * Client specified an invalid argument. Note that this differs from\n   * FAILED_PRECONDITION. INVALID_ARGUMENT indicates arguments that are\n   * problematic regardless of the state of the system (e.g., a malformed file\n   * name).\n   */\n  INVALID_ARGUMENT: 'invalid-argument' as Code,\n\n  /**\n   * Deadline expired before operation could complete. For operations that\n   * change the state of the system, this error may be returned even if the\n   * operation has completed successfully. For example, a successful response\n   * from a server could have been delayed long enough for the deadline to\n   * expire.\n   */\n  DEADLINE_EXCEEDED: 'deadline-exceeded' as Code,\n\n  /** Some requested entity (e.g., file or directory) was not found. */\n  NOT_FOUND: 'not-found' as Code,\n\n  /**\n   * Some entity that we attempted to create (e.g., file or directory) already\n   * exists.\n   */\n  ALREADY_EXISTS: 'already-exists' as Code,\n\n  /**\n   * The caller does not have permission to execute the specified operation.\n   * PERMISSION_DENIED must not be used for rejections caused by exhausting\n   * some resource (use RESOURCE_EXHAUSTED instead for those errors).\n   * PERMISSION_DENIED must not be used if the caller can not be identified\n   * (use UNAUTHENTICATED instead for those errors).\n   */\n  PERMISSION_DENIED: 'permission-denied' as Code,\n\n  /**\n   * The request does not have valid authentication credentials for the\n   * operation.\n   */\n  UNAUTHENTICATED: 'unauthenticated' as Code,\n\n  /**\n   * Some resource has been exhausted, perhaps a per-user quota, or perhaps the\n   * entire file system is out of space.\n   */\n  RESOURCE_EXHAUSTED: 'resource-exhausted' as Code,\n\n  /**\n   * Operation was rejected because the system is not in a state required for\n   * the operation's execution. For example, directory to be deleted may be\n   * non-empty, an rmdir operation is applied to a non-directory, etc.\n   *\n   * A litmus test that may help a service implementor in deciding\n   * between FAILED_PRECONDITION, ABORTED, and UNAVAILABLE:\n   *  (a) Use UNAVAILABLE if the client can retry just the failing call.\n   *  (b) Use ABORTED if the client should retry at a higher-level\n   *      (e.g., restarting a read-modify-write sequence).\n   *  (c) Use FAILED_PRECONDITION if the client should not retry until\n   *      the system state has been explicitly fixed. E.g., if an \"rmdir\"\n   *      fails because the directory is non-empty, FAILED_PRECONDITION\n   *      should be returned since the client should not retry unless\n   *      they have first fixed up the directory by deleting files from it.\n   *  (d) Use FAILED_PRECONDITION if the client performs conditional\n   *      REST Get/Update/Delete on a resource and the resource on the\n   *      server does not match the condition. E.g., conflicting\n   *      read-modify-write on the same resource.\n   */\n  FAILED_PRECONDITION: 'failed-precondition' as Code,\n\n  /**\n   * The operation was aborted, typically due to a concurrency issue like\n   * sequencer check failures, transaction aborts, etc.\n   *\n   * See litmus test above for deciding between FAILED_PRECONDITION, ABORTED,\n   * and UNAVAILABLE.\n   */\n  ABORTED: 'aborted' as Code,\n\n  /**\n   * Operation was attempted past the valid range. E.g., seeking or reading\n   * past end of file.\n   *\n   * Unlike INVALID_ARGUMENT, this error indicates a problem that may be fixed\n   * if the system state changes. For example, a 32-bit file system will\n   * generate INVALID_ARGUMENT if asked to read at an offset that is not in the\n   * range [0,2^32-1], but it will generate OUT_OF_RANGE if asked to read from\n   * an offset past the current file size.\n   *\n   * There is a fair bit of overlap between FAILED_PRECONDITION and\n   * OUT_OF_RANGE. We recommend using OUT_OF_RANGE (the more specific error)\n   * when it applies so that callers who are iterating through a space can\n   * easily look for an OUT_OF_RANGE error to detect when they are done.\n   */\n  OUT_OF_RANGE: 'out-of-range' as Code,\n\n  /** Operation is not implemented or not supported/enabled in this service. */\n  UNIMPLEMENTED: 'unimplemented' as Code,\n\n  /**\n   * Internal errors. Means some invariants expected by underlying System has\n   * been broken. If you see one of these errors, Something is very broken.\n   */\n  INTERNAL: 'internal' as Code,\n\n  /**\n   * The service is currently unavailable. This is a most likely a transient\n   * condition and may be corrected by retrying with a backoff.\n   *\n   * See litmus test above for deciding between FAILED_PRECONDITION, ABORTED,\n   * and UNAVAILABLE.\n   */\n  UNAVAILABLE: 'unavailable' as Code,\n\n  /** Unrecoverable data loss or corruption. */\n  DATA_LOSS: 'data-loss' as Code\n};\n\n/**\n * An error class used for Firestore-generated errors. Ideally we should be\n * using FirebaseError, but integrating with it is overly arduous at the moment,\n * so we define our own compatible error class (with a `name` of 'FirebaseError'\n * and compatible `code` and `message` fields.)\n */\nexport class FirestoreError extends Error implements firestore.FirestoreError {\n  name = 'FirebaseError';\n  stack?: string;\n\n  constructor(readonly code: Code, readonly message: string) {\n    super(message);\n\n    // HACK: We write a toString property directly because Error is not a real\n    // class and so inheritance does not work correctly. We could alternatively\n    // do the same \"back-door inheritance\" trick that FirebaseError does.\n    this.toString = () => `${this.name}: [code=${this.code}]: ${this.message}`;\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { User } from '../auth/user';\nimport { hardAssert, debugAssert } from '../util/assert';\nimport { Code, FirestoreError } from '../util/error';\nimport {\n  FirebaseAuthInternal,\n  FirebaseAuthInternalName\n} from '@firebase/auth-interop-types';\nimport { Provider } from '@firebase/component';\n\n// TODO(mikelehen): This should be split into multiple files and probably\n// moved to an auth/ folder to match other platforms.\n\nexport interface FirstPartyCredentialsSettings {\n  type: 'gapi';\n  client: unknown;\n  sessionIndex: string;\n}\n\nexport interface ProviderCredentialsSettings {\n  type: 'provider';\n  client: CredentialsProvider;\n}\n\n/** Settings for private credentials */\nexport type CredentialsSettings =\n  | FirstPartyCredentialsSettings\n  | ProviderCredentialsSettings;\n\nexport type TokenType = 'OAuth' | 'FirstParty';\nexport interface Token {\n  /** Type of token. */\n  type: TokenType;\n\n  /**\n   * The user with which the token is associated (used for persisting user\n   * state on disk, etc.).\n   */\n  user: User;\n\n  /** Extra header values to be passed along with a request */\n  authHeaders: { [header: string]: string };\n}\n\nexport class OAuthToken implements Token {\n  type = 'OAuth' as TokenType;\n  authHeaders: { [header: string]: string };\n  constructor(value: string, public user: User) {\n    this.authHeaders = {};\n    // Set the headers using Object Literal notation to avoid minification\n    this.authHeaders['Authorization'] = `Bearer ${value}`;\n  }\n}\n\n/**\n * A Listener for credential change events. The listener should fetch a new\n * token and may need to invalidate other state if the current user has also\n * changed.\n */\nexport type CredentialChangeListener = (user: User) => void;\n\n/**\n * Provides methods for getting the uid and token for the current user and\n * listening for changes.\n */\nexport interface CredentialsProvider {\n  /** Requests a token for the current user. */\n  getToken(): Promise<Token | null>;\n\n  /**\n   * Marks the last retrieved token as invalid, making the next GetToken request\n   * force-refresh the token.\n   */\n  invalidateToken(): void;\n\n  /**\n   * Specifies a listener to be notified of credential changes\n   * (sign-in / sign-out, token changes). It is immediately called once with the\n   * initial user.\n   */\n  setChangeListener(changeListener: CredentialChangeListener): void;\n\n  /** Removes the previously-set change listener. */\n  removeChangeListener(): void;\n}\n\n/** A CredentialsProvider that always yields an empty token. */\nexport class EmptyCredentialsProvider implements CredentialsProvider {\n  /**\n   * Stores the listener registered with setChangeListener()\n   * This isn't actually necessary since the UID never changes, but we use this\n   * to verify the listen contract is adhered to in tests.\n   */\n  private changeListener: CredentialChangeListener | null = null;\n\n  getToken(): Promise<Token | null> {\n    return Promise.resolve<Token | null>(null);\n  }\n\n  invalidateToken(): void {}\n\n  setChangeListener(changeListener: CredentialChangeListener): void {\n    debugAssert(\n      !this.changeListener,\n      'Can only call setChangeListener() once.'\n    );\n    this.changeListener = changeListener;\n    // Fire with initial user.\n    changeListener(User.UNAUTHENTICATED);\n  }\n\n  removeChangeListener(): void {\n    debugAssert(\n      this.changeListener !== null,\n      'removeChangeListener() when no listener registered'\n    );\n    this.changeListener = null;\n  }\n}\n\nexport class FirebaseCredentialsProvider implements CredentialsProvider {\n  /**\n   * The auth token listener registered with FirebaseApp, retained here so we\n   * can unregister it.\n   */\n  private tokenListener: ((token: string | null) => void) | null = null;\n\n  /** Tracks the current User. */\n  private currentUser: User = User.UNAUTHENTICATED;\n  private receivedInitialUser: boolean = false;\n\n  /**\n   * Counter used to detect if the token changed while a getToken request was\n   * outstanding.\n   */\n  private tokenCounter = 0;\n\n  /** The listener registered with setChangeListener(). */\n  private changeListener: CredentialChangeListener | null = null;\n\n  private forceRefresh = false;\n\n  private auth: FirebaseAuthInternal | null;\n\n  constructor(authProvider: Provider<FirebaseAuthInternalName>) {\n    this.tokenListener = () => {\n      this.tokenCounter++;\n      this.currentUser = this.getUser();\n      this.receivedInitialUser = true;\n      if (this.changeListener) {\n        this.changeListener(this.currentUser);\n      }\n    };\n\n    this.tokenCounter = 0;\n\n    this.auth = authProvider.getImmediate({ optional: true });\n\n    if (this.auth) {\n      this.auth.addAuthTokenListener(this.tokenListener!);\n    } else {\n      // if auth is not available, invoke tokenListener once with null token\n      this.tokenListener(null);\n      authProvider.get().then(\n        auth => {\n          this.auth = auth;\n          if (this.tokenListener) {\n            // tokenListener can be removed by removeChangeListener()\n            this.auth.addAuthTokenListener(this.tokenListener);\n          }\n        },\n        () => {\n          /* this.authProvider.get() never rejects */\n        }\n      );\n    }\n  }\n\n  getToken(): Promise<Token | null> {\n    debugAssert(\n      this.tokenListener != null,\n      'getToken cannot be called after listener removed.'\n    );\n\n    // Take note of the current value of the tokenCounter so that this method\n    // can fail (with an ABORTED error) if there is a token change while the\n    // request is outstanding.\n    const initialTokenCounter = this.tokenCounter;\n    const forceRefresh = this.forceRefresh;\n    this.forceRefresh = false;\n\n    if (!this.auth) {\n      return Promise.resolve(null);\n    }\n\n    return this.auth.getToken(forceRefresh).then(tokenData => {\n      // Cancel the request since the token changed while the request was\n      // outstanding so the response is potentially for a previous user (which\n      // user, we can't be sure).\n      if (this.tokenCounter !== initialTokenCounter) {\n        throw new FirestoreError(\n          Code.ABORTED,\n          'getToken aborted due to token change.'\n        );\n      } else {\n        if (tokenData) {\n          hardAssert(\n            typeof tokenData.accessToken === 'string',\n            'Invalid tokenData returned from getToken():' + tokenData\n          );\n          return new OAuthToken(tokenData.accessToken, this.currentUser);\n        } else {\n          return null;\n        }\n      }\n    });\n  }\n\n  invalidateToken(): void {\n    this.forceRefresh = true;\n  }\n\n  setChangeListener(changeListener: CredentialChangeListener): void {\n    debugAssert(\n      !this.changeListener,\n      'Can only call setChangeListener() once.'\n    );\n    this.changeListener = changeListener;\n\n    // Fire the initial event\n    if (this.receivedInitialUser) {\n      changeListener(this.currentUser);\n    }\n  }\n\n  removeChangeListener(): void {\n    debugAssert(\n      this.tokenListener != null,\n      'removeChangeListener() called twice'\n    );\n    debugAssert(\n      this.changeListener !== null,\n      'removeChangeListener() called when no listener registered'\n    );\n\n    if (this.auth) {\n      this.auth.removeAuthTokenListener(this.tokenListener!);\n    }\n    this.tokenListener = null;\n    this.changeListener = null;\n  }\n\n  // Auth.getUid() can return null even with a user logged in. It is because\n  // getUid() is synchronous, but the auth code populating Uid is asynchronous.\n  // This method should only be called in the AuthTokenListener callback\n  // to guarantee to get the actual user.\n  private getUser(): User {\n    const currentUid = this.auth && this.auth.getUid();\n    hardAssert(\n      currentUid === null || typeof currentUid === 'string',\n      'Received invalid UID: ' + currentUid\n    );\n    return new User(currentUid);\n  }\n}\n\n// Manual type definition for the subset of Gapi we use.\ninterface Gapi {\n  auth: {\n    getAuthHeaderValueForFirstParty: (\n      userIdentifiers: Array<{ [key: string]: string }>\n    ) => string | null;\n  };\n}\n\n/*\n * FirstPartyToken provides a fresh token each time its value\n * is requested, because if the token is too old, requests will be rejected.\n * Technically this may no longer be necessary since the SDK should gracefully\n * recover from unauthenticated errors (see b/33147818 for context), but it's\n * safer to keep the implementation as-is.\n */\nexport class FirstPartyToken implements Token {\n  type = 'FirstParty' as TokenType;\n  user = User.FIRST_PARTY;\n\n  constructor(private gapi: Gapi, private sessionIndex: string) {}\n\n  get authHeaders(): { [header: string]: string } {\n    const headers: { [header: string]: string } = {\n      'X-Goog-AuthUser': this.sessionIndex\n    };\n    const authHeader = this.gapi.auth.getAuthHeaderValueForFirstParty([]);\n    if (authHeader) {\n      headers['Authorization'] = authHeader;\n    }\n    return headers;\n  }\n}\n\n/*\n * Provides user credentials required for the Firestore JavaScript SDK\n * to authenticate the user, using technique that is only available\n * to applications hosted by Google.\n */\nexport class FirstPartyCredentialsProvider implements CredentialsProvider {\n  constructor(private gapi: Gapi, private sessionIndex: string) {}\n\n  getToken(): Promise<Token | null> {\n    return Promise.resolve(new FirstPartyToken(this.gapi, this.sessionIndex));\n  }\n\n  setChangeListener(changeListener: CredentialChangeListener): void {\n    // Fire with initial uid.\n    changeListener(User.FIRST_PARTY);\n  }\n\n  removeChangeListener(): void {}\n\n  invalidateToken(): void {}\n}\n\n/**\n * Builds a CredentialsProvider depending on the type of\n * the credentials passed in.\n */\nexport function makeCredentialsProvider(\n  credentials?: CredentialsSettings\n): CredentialsProvider {\n  if (!credentials) {\n    return new EmptyCredentialsProvider();\n  }\n\n  switch (credentials.type) {\n    case 'gapi':\n      const client = credentials.client as Gapi;\n      // Make sure this really is a Gapi client.\n      hardAssert(\n        !!(\n          typeof client === 'object' &&\n          client !== null &&\n          client['auth'] &&\n          client['auth']['getAuthHeaderValueForFirstParty']\n        ),\n        'unexpected gapi interface'\n      );\n      return new FirstPartyCredentialsProvider(\n        client,\n        credentials.sessionIndex || '0'\n      );\n\n    case 'provider':\n      return credentials.client;\n\n    default:\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        'makeCredentialsProvider failed due to invalid credential type'\n      );\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Code, FirestoreError } from '../util/error';\nimport { primitiveComparator } from '../util/misc';\n\n// The earlist date supported by Firestore timestamps (0001-01-01T00:00:00Z).\nconst MIN_SECONDS = -62135596800;\n\nexport class Timestamp {\n  static now(): Timestamp {\n    return Timestamp.fromMillis(Date.now());\n  }\n\n  static fromDate(date: Date): Timestamp {\n    return Timestamp.fromMillis(date.getTime());\n  }\n\n  static fromMillis(milliseconds: number): Timestamp {\n    const seconds = Math.floor(milliseconds / 1000);\n    const nanos = (milliseconds - seconds * 1000) * 1e6;\n    return new Timestamp(seconds, nanos);\n  }\n\n  constructor(readonly seconds: number, readonly nanoseconds: number) {\n    if (nanoseconds < 0) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        'Timestamp nanoseconds out of range: ' + nanoseconds\n      );\n    }\n    if (nanoseconds >= 1e9) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        'Timestamp nanoseconds out of range: ' + nanoseconds\n      );\n    }\n    if (seconds < MIN_SECONDS) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        'Timestamp seconds out of range: ' + seconds\n      );\n    }\n    // This will break in the year 10,000.\n    if (seconds >= 253402300800) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        'Timestamp seconds out of range: ' + seconds\n      );\n    }\n  }\n\n  toDate(): Date {\n    return new Date(this.toMillis());\n  }\n\n  toMillis(): number {\n    return this.seconds * 1000 + this.nanoseconds / 1e6;\n  }\n\n  _compareTo(other: Timestamp): number {\n    if (this.seconds === other.seconds) {\n      return primitiveComparator(this.nanoseconds, other.nanoseconds);\n    }\n    return primitiveComparator(this.seconds, other.seconds);\n  }\n\n  isEqual(other: Timestamp): boolean {\n    return (\n      other.seconds === this.seconds && other.nanoseconds === this.nanoseconds\n    );\n  }\n\n  toString(): string {\n    return (\n      'Timestamp(seconds=' +\n      this.seconds +\n      ', nanoseconds=' +\n      this.nanoseconds +\n      ')'\n    );\n  }\n\n  valueOf(): string {\n    // This method returns a string of the form <seconds>.<nanoseconds> where <seconds> is\n    // translated to have a non-negative value and both <seconds> and <nanoseconds> are left-padded\n    // with zeroes to be a consistent length. Strings with this format then have a lexiographical\n    // ordering that matches the expected ordering. The <seconds> translation is done to avoid\n    // having a leading negative sign (i.e. a leading '-' character) in its string representation,\n    // which would affect its lexiographical ordering.\n    const adjustedSeconds = this.seconds - MIN_SECONDS;\n    // Note: Up to 12 decimal digits are required to represent all valid 'seconds' values.\n    const formattedSeconds = String(adjustedSeconds).padStart(12, '0');\n    const formattedNanoseconds = String(this.nanoseconds).padStart(9, '0');\n    return formattedSeconds + '.' + formattedNanoseconds;\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Timestamp } from '../api/timestamp';\n\n/**\n * A version of a document in Firestore. This corresponds to the version\n * timestamp, such as update_time or read_time.\n */\nexport class SnapshotVersion {\n  static readonly MIN = new SnapshotVersion(new Timestamp(0, 0));\n\n  static fromTimestamp(value: Timestamp): SnapshotVersion {\n    return new SnapshotVersion(value);\n  }\n\n  static forDeletedDoc(): SnapshotVersion {\n    return SnapshotVersion.MIN;\n  }\n\n  private constructor(private timestamp: Timestamp) {}\n\n  compareTo(other: SnapshotVersion): number {\n    return this.timestamp._compareTo(other.timestamp);\n  }\n\n  isEqual(other: SnapshotVersion): boolean {\n    return this.timestamp.isEqual(other.timestamp);\n  }\n\n  /** Returns a number representation of the version for use in spec tests. */\n  toMicroseconds(): number {\n    // Convert to microseconds.\n    return this.timestamp.seconds * 1e6 + this.timestamp.nanoseconds / 1000;\n  }\n\n  toString(): string {\n    return 'SnapshotVersion(' + this.timestamp.toString() + ')';\n  }\n\n  toTimestamp(): Timestamp {\n    return this.timestamp;\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { debugAssert, fail } from '../util/assert';\nimport { Code, FirestoreError } from '../util/error';\n\nexport const DOCUMENT_KEY_NAME = '__name__';\n\n/**\n * Path represents an ordered sequence of string segments.\n */\nabstract class BasePath<B extends BasePath<B>> {\n  private segments: string[];\n  private offset: number;\n  private len: number;\n\n  constructor(segments: string[], offset?: number, length?: number) {\n    if (offset === undefined) {\n      offset = 0;\n    } else if (offset > segments.length) {\n      fail('offset ' + offset + ' out of range ' + segments.length);\n    }\n\n    if (length === undefined) {\n      length = segments.length - offset;\n    } else if (length > segments.length - offset) {\n      fail('length ' + length + ' out of range ' + (segments.length - offset));\n    }\n    this.segments = segments;\n    this.offset = offset;\n    this.len = length;\n  }\n\n  /**\n   * Abstract constructor method to construct an instance of B with the given\n   * parameters.\n   */\n  protected abstract construct(\n    segments: string[],\n    offset?: number,\n    length?: number\n  ): B;\n\n  /**\n   * Returns a String representation.\n   *\n   * Implementing classes are required to provide deterministic implementations as\n   * the String representation is used to obtain canonical Query IDs.\n   */\n  abstract toString(): string;\n\n  get length(): number {\n    return this.len;\n  }\n\n  isEqual(other: B): boolean {\n    return BasePath.comparator(this, other) === 0;\n  }\n\n  child(nameOrPath: string | B): B {\n    const segments = this.segments.slice(this.offset, this.limit());\n    if (nameOrPath instanceof BasePath) {\n      nameOrPath.forEach(segment => {\n        segments.push(segment);\n      });\n    } else {\n      segments.push(nameOrPath);\n    }\n    return this.construct(segments);\n  }\n\n  /** The index of one past the last segment of the path. */\n  private limit(): number {\n    return this.offset + this.length;\n  }\n\n  popFirst(size?: number): B {\n    size = size === undefined ? 1 : size;\n    debugAssert(\n      this.length >= size,\n      \"Can't call popFirst() with less segments\"\n    );\n    return this.construct(\n      this.segments,\n      this.offset + size,\n      this.length - size\n    );\n  }\n\n  popLast(): B {\n    debugAssert(!this.isEmpty(), \"Can't call popLast() on empty path\");\n    return this.construct(this.segments, this.offset, this.length - 1);\n  }\n\n  firstSegment(): string {\n    debugAssert(!this.isEmpty(), \"Can't call firstSegment() on empty path\");\n    return this.segments[this.offset];\n  }\n\n  lastSegment(): string {\n    return this.get(this.length - 1);\n  }\n\n  get(index: number): string {\n    debugAssert(index < this.length, 'Index out of range');\n    return this.segments[this.offset + index];\n  }\n\n  isEmpty(): boolean {\n    return this.length === 0;\n  }\n\n  isPrefixOf(other: this): boolean {\n    if (other.length < this.length) {\n      return false;\n    }\n\n    for (let i = 0; i < this.length; i++) {\n      if (this.get(i) !== other.get(i)) {\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n  isImmediateParentOf(potentialChild: this): boolean {\n    if (this.length + 1 !== potentialChild.length) {\n      return false;\n    }\n\n    for (let i = 0; i < this.length; i++) {\n      if (this.get(i) !== potentialChild.get(i)) {\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n  forEach(fn: (segment: string) => void): void {\n    for (let i = this.offset, end = this.limit(); i < end; i++) {\n      fn(this.segments[i]);\n    }\n  }\n\n  toArray(): string[] {\n    return this.segments.slice(this.offset, this.limit());\n  }\n\n  static comparator<T extends BasePath<T>>(\n    p1: BasePath<T>,\n    p2: BasePath<T>\n  ): number {\n    const len = Math.min(p1.length, p2.length);\n    for (let i = 0; i < len; i++) {\n      const left = p1.get(i);\n      const right = p2.get(i);\n      if (left < right) {\n        return -1;\n      }\n      if (left > right) {\n        return 1;\n      }\n    }\n    if (p1.length < p2.length) {\n      return -1;\n    }\n    if (p1.length > p2.length) {\n      return 1;\n    }\n    return 0;\n  }\n}\n\n/**\n * A slash-separated path for navigating resources (documents and collections)\n * within Firestore.\n */\nexport class ResourcePath extends BasePath<ResourcePath> {\n  protected construct(\n    segments: string[],\n    offset?: number,\n    length?: number\n  ): ResourcePath {\n    return new ResourcePath(segments, offset, length);\n  }\n\n  canonicalString(): string {\n    // NOTE: The client is ignorant of any path segments containing escape\n    // sequences (e.g. __id123__) and just passes them through raw (they exist\n    // for legacy reasons and should not be used frequently).\n\n    return this.toArray().join('/');\n  }\n\n  toString(): string {\n    return this.canonicalString();\n  }\n\n  /**\n   * Creates a resource path from the given slash-delimited string.\n   */\n  static fromString(path: string): ResourcePath {\n    // NOTE: The client is ignorant of any path segments containing escape\n    // sequences (e.g. __id123__) and just passes them through raw (they exist\n    // for legacy reasons and should not be used frequently).\n\n    if (path.indexOf('//') >= 0) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        `Invalid path (${path}). Paths must not contain // in them.`\n      );\n    }\n\n    // We may still have an empty segment at the beginning or end if they had a\n    // leading or trailing slash (which we allow).\n    const segments = path.split('/').filter(segment => segment.length > 0);\n\n    return new ResourcePath(segments);\n  }\n\n  static EMPTY_PATH = new ResourcePath([]);\n}\n\nconst identifierRegExp = /^[_a-zA-Z][_a-zA-Z0-9]*$/;\n\n/** A dot-separated path for navigating sub-objects within a document. */\nexport class FieldPath extends BasePath<FieldPath> {\n  protected construct(\n    segments: string[],\n    offset?: number,\n    length?: number\n  ): FieldPath {\n    return new FieldPath(segments, offset, length);\n  }\n\n  /**\n   * Returns true if the string could be used as a segment in a field path\n   * without escaping.\n   */\n  private static isValidIdentifier(segment: string): boolean {\n    return identifierRegExp.test(segment);\n  }\n\n  canonicalString(): string {\n    return this.toArray()\n      .map(str => {\n        str = str.replace('\\\\', '\\\\\\\\').replace('`', '\\\\`');\n        if (!FieldPath.isValidIdentifier(str)) {\n          str = '`' + str + '`';\n        }\n        return str;\n      })\n      .join('.');\n  }\n\n  toString(): string {\n    return this.canonicalString();\n  }\n\n  /**\n   * Returns true if this field references the key of a document.\n   */\n  isKeyField(): boolean {\n    return this.length === 1 && this.get(0) === DOCUMENT_KEY_NAME;\n  }\n\n  /**\n   * The field designating the key of a document.\n   */\n  static keyField(): FieldPath {\n    return new FieldPath([DOCUMENT_KEY_NAME]);\n  }\n\n  /**\n   * Parses a field string from the given server-formatted string.\n   *\n   * - Splitting the empty string is not allowed (for now at least).\n   * - Empty segments within the string (e.g. if there are two consecutive\n   *   separators) are not allowed.\n   *\n   * TODO(b/37244157): we should make this more strict. Right now, it allows\n   * non-identifier path components, even if they aren't escaped.\n   */\n  static fromServerFormat(path: string): FieldPath {\n    const segments: string[] = [];\n    let current = '';\n    let i = 0;\n\n    const addCurrentSegment = (): void => {\n      if (current.length === 0) {\n        throw new FirestoreError(\n          Code.INVALID_ARGUMENT,\n          `Invalid field path (${path}). Paths must not be empty, begin ` +\n            `with '.', end with '.', or contain '..'`\n        );\n      }\n      segments.push(current);\n      current = '';\n    };\n\n    let inBackticks = false;\n\n    while (i < path.length) {\n      const c = path[i];\n      if (c === '\\\\') {\n        if (i + 1 === path.length) {\n          throw new FirestoreError(\n            Code.INVALID_ARGUMENT,\n            'Path has trailing escape character: ' + path\n          );\n        }\n        const next = path[i + 1];\n        if (!(next === '\\\\' || next === '.' || next === '`')) {\n          throw new FirestoreError(\n            Code.INVALID_ARGUMENT,\n            'Path has invalid escape sequence: ' + path\n          );\n        }\n        current += next;\n        i += 2;\n      } else if (c === '`') {\n        inBackticks = !inBackticks;\n        i++;\n      } else if (c === '.' && !inBackticks) {\n        addCurrentSegment();\n        i++;\n      } else {\n        current += c;\n        i++;\n      }\n    }\n    addCurrentSegment();\n\n    if (inBackticks) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        'Unterminated ` in path: ' + path\n      );\n    }\n\n    return new FieldPath(segments);\n  }\n\n  static EMPTY_PATH = new FieldPath([]);\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { debugAssert } from '../util/assert';\n\nimport { ResourcePath } from './path';\n\nexport class DocumentKey {\n  constructor(readonly path: ResourcePath) {\n    debugAssert(\n      DocumentKey.isDocumentKey(path),\n      'Invalid DocumentKey with an odd number of segments: ' +\n        path.toArray().join('/')\n    );\n  }\n\n  static fromName(name: string): DocumentKey {\n    return new DocumentKey(ResourcePath.fromString(name).popFirst(5));\n  }\n\n  /** Returns true if the document is in the specified collectionId. */\n  hasCollectionId(collectionId: string): boolean {\n    return (\n      this.path.length >= 2 &&\n      this.path.get(this.path.length - 2) === collectionId\n    );\n  }\n\n  isEqual(other: DocumentKey | null): boolean {\n    return (\n      other !== null && ResourcePath.comparator(this.path, other.path) === 0\n    );\n  }\n\n  toString(): string {\n    return this.path.toString();\n  }\n\n  static EMPTY = new DocumentKey(new ResourcePath([]));\n\n  static comparator(k1: DocumentKey, k2: DocumentKey): number {\n    return ResourcePath.comparator(k1.path, k2.path);\n  }\n\n  static isDocumentKey(path: ResourcePath): boolean {\n    return path.length % 2 === 0;\n  }\n\n  /**\n   * Creates and returns a new document key with the given segments.\n   *\n   * @param segments The segments of the path to the document\n   * @return A new instance of DocumentKey\n   */\n  static fromSegments(segments: string[]): DocumentKey {\n    return new DocumentKey(new ResourcePath(segments.slice()));\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { debugAssert, fail } from './assert';\n\n/*\n * Implementation of an immutable SortedMap using a Left-leaning\n * Red-Black Tree, adapted from the implementation in Mugs\n * (http://mads379.github.com/mugs/) by Mads Hartmann Jensen\n * (mads379@gmail.com).\n *\n * Original paper on Left-leaning Red-Black Trees:\n *   http://www.cs.princeton.edu/~rs/talks/LLRB/LLRB.pdf\n *\n * Invariant 1: No red node has a red child\n * Invariant 2: Every leaf path has the same number of black nodes\n * Invariant 3: Only the left child can be red (left leaning)\n */\n\nexport type Comparator<K> = (key1: K, key2: K) => number;\n\nexport interface Entry<K, V> {\n  key: K;\n  value: V;\n}\n\n// An immutable sorted map implementation, based on a Left-leaning Red-Black\n// tree.\nexport class SortedMap<K, V> {\n  // visible for testing\n  root: LLRBNode<K, V> | LLRBEmptyNode<K, V>;\n\n  constructor(\n    public comparator: Comparator<K>,\n    root?: LLRBNode<K, V> | LLRBEmptyNode<K, V>\n  ) {\n    this.root = root ? root : LLRBNode.EMPTY;\n  }\n\n  // Returns a copy of the map, with the specified key/value added or replaced.\n  insert(key: K, value: V): SortedMap<K, V> {\n    return new SortedMap<K, V>(\n      this.comparator,\n      this.root\n        .insert(key, value, this.comparator)\n        .copy(null, null, LLRBNode.BLACK, null, null)\n    );\n  }\n\n  // Returns a copy of the map, with the specified key removed.\n  remove(key: K): SortedMap<K, V> {\n    return new SortedMap<K, V>(\n      this.comparator,\n      this.root\n        .remove(key, this.comparator)\n        .copy(null, null, LLRBNode.BLACK, null, null)\n    );\n  }\n\n  // Returns the value of the node with the given key, or null.\n  get(key: K): V | null {\n    let node = this.root;\n    while (!node.isEmpty()) {\n      const cmp = this.comparator(key, node.key);\n      if (cmp === 0) {\n        return node.value;\n      } else if (cmp < 0) {\n        node = node.left;\n      } else if (cmp > 0) {\n        node = node.right;\n      }\n    }\n    return null;\n  }\n\n  // Returns the index of the element in this sorted map, or -1 if it doesn't\n  // exist.\n  indexOf(key: K): number {\n    // Number of nodes that were pruned when descending right\n    let prunedNodes = 0;\n    let node = this.root;\n    while (!node.isEmpty()) {\n      const cmp = this.comparator(key, node.key);\n      if (cmp === 0) {\n        return prunedNodes + node.left.size;\n      } else if (cmp < 0) {\n        node = node.left;\n      } else {\n        // Count all nodes left of the node plus the node itself\n        prunedNodes += node.left.size + 1;\n        node = node.right;\n      }\n    }\n    // Node not found\n    return -1;\n  }\n\n  isEmpty(): boolean {\n    return this.root.isEmpty();\n  }\n\n  // Returns the total number of nodes in the map.\n  get size(): number {\n    return this.root.size;\n  }\n\n  // Returns the minimum key in the map.\n  minKey(): K | null {\n    return this.root.minKey();\n  }\n\n  // Returns the maximum key in the map.\n  maxKey(): K | null {\n    return this.root.maxKey();\n  }\n\n  // Traverses the map in key order and calls the specified action function\n  // for each key/value pair. If action returns true, traversal is aborted.\n  // Returns the first truthy value returned by action, or the last falsey\n  // value returned by action.\n  inorderTraversal<T>(action: (k: K, v: V) => T): T {\n    return (this.root as LLRBNode<K, V>).inorderTraversal(action);\n  }\n\n  forEach(fn: (k: K, v: V) => void): void {\n    this.inorderTraversal((k, v) => {\n      fn(k, v);\n      return false;\n    });\n  }\n\n  toString(): string {\n    const descriptions: string[] = [];\n    this.inorderTraversal((k, v) => {\n      descriptions.push(`${k}:${v}`);\n      return false;\n    });\n    return `{${descriptions.join(', ')}}`;\n  }\n\n  // Traverses the map in reverse key order and calls the specified action\n  // function for each key/value pair. If action returns true, traversal is\n  // aborted.\n  // Returns the first truthy value returned by action, or the last falsey\n  // value returned by action.\n  reverseTraversal<T>(action: (k: K, v: V) => T): T {\n    return (this.root as LLRBNode<K, V>).reverseTraversal(action);\n  }\n\n  // Returns an iterator over the SortedMap.\n  getIterator(): SortedMapIterator<K, V> {\n    return new SortedMapIterator<K, V>(this.root, null, this.comparator, false);\n  }\n\n  getIteratorFrom(key: K): SortedMapIterator<K, V> {\n    return new SortedMapIterator<K, V>(this.root, key, this.comparator, false);\n  }\n\n  getReverseIterator(): SortedMapIterator<K, V> {\n    return new SortedMapIterator<K, V>(this.root, null, this.comparator, true);\n  }\n\n  getReverseIteratorFrom(key: K): SortedMapIterator<K, V> {\n    return new SortedMapIterator<K, V>(this.root, key, this.comparator, true);\n  }\n} // end SortedMap\n\n// An iterator over an LLRBNode.\nexport class SortedMapIterator<K, V> {\n  private isReverse: boolean;\n  private nodeStack: Array<LLRBNode<K, V> | LLRBEmptyNode<K, V>>;\n\n  constructor(\n    node: LLRBNode<K, V> | LLRBEmptyNode<K, V>,\n    startKey: K | null,\n    comparator: Comparator<K>,\n    isReverse: boolean\n  ) {\n    this.isReverse = isReverse;\n    this.nodeStack = [];\n\n    let cmp = 1;\n    while (!node.isEmpty()) {\n      cmp = startKey ? comparator(node.key, startKey) : 1;\n      // flip the comparison if we're going in reverse\n      if (isReverse) {\n        cmp *= -1;\n      }\n\n      if (cmp < 0) {\n        // This node is less than our start key. ignore it\n        if (this.isReverse) {\n          node = node.left;\n        } else {\n          node = node.right;\n        }\n      } else if (cmp === 0) {\n        // This node is exactly equal to our start key. Push it on the stack,\n        // but stop iterating;\n        this.nodeStack.push(node);\n        break;\n      } else {\n        // This node is greater than our start key, add it to the stack and move\n        // to the next one\n        this.nodeStack.push(node);\n        if (this.isReverse) {\n          node = node.right;\n        } else {\n          node = node.left;\n        }\n      }\n    }\n  }\n\n  getNext(): Entry<K, V> {\n    debugAssert(\n      this.nodeStack.length > 0,\n      'getNext() called on iterator when hasNext() is false.'\n    );\n\n    let node = this.nodeStack.pop()!;\n    const result = { key: node.key, value: node.value };\n\n    if (this.isReverse) {\n      node = node.left;\n      while (!node.isEmpty()) {\n        this.nodeStack.push(node);\n        node = node.right;\n      }\n    } else {\n      node = node.right;\n      while (!node.isEmpty()) {\n        this.nodeStack.push(node);\n        node = node.left;\n      }\n    }\n\n    return result;\n  }\n\n  hasNext(): boolean {\n    return this.nodeStack.length > 0;\n  }\n\n  peek(): Entry<K, V> | null {\n    if (this.nodeStack.length === 0) {\n      return null;\n    }\n\n    const node = this.nodeStack[this.nodeStack.length - 1];\n    return { key: node.key, value: node.value };\n  }\n} // end SortedMapIterator\n\n// Represents a node in a Left-leaning Red-Black tree.\nexport class LLRBNode<K, V> {\n  readonly color: boolean;\n  readonly left: LLRBNode<K, V> | LLRBEmptyNode<K, V>;\n  readonly right: LLRBNode<K, V> | LLRBEmptyNode<K, V>;\n  readonly size: number;\n\n  // Empty node is shared between all LLRB trees.\n  // eslint-disable-next-line @typescript-eslint/no-explicit-any\n  static EMPTY: LLRBEmptyNode<any, any> = null as any;\n\n  static RED = true;\n  static BLACK = false;\n\n  constructor(\n    public key: K,\n    public value: V,\n    color?: boolean,\n    left?: LLRBNode<K, V> | LLRBEmptyNode<K, V>,\n    right?: LLRBNode<K, V> | LLRBEmptyNode<K, V>\n  ) {\n    this.color = color != null ? color : LLRBNode.RED;\n    this.left = left != null ? left : LLRBNode.EMPTY;\n    this.right = right != null ? right : LLRBNode.EMPTY;\n    this.size = this.left.size + 1 + this.right.size;\n  }\n\n  // Returns a copy of the current node, optionally replacing pieces of it.\n  copy(\n    key: K | null,\n    value: V | null,\n    color: boolean | null,\n    left: LLRBNode<K, V> | LLRBEmptyNode<K, V> | null,\n    right: LLRBNode<K, V> | LLRBEmptyNode<K, V> | null\n  ): LLRBNode<K, V> {\n    return new LLRBNode<K, V>(\n      key != null ? key : this.key,\n      value != null ? value : this.value,\n      color != null ? color : this.color,\n      left != null ? left : this.left,\n      right != null ? right : this.right\n    );\n  }\n\n  isEmpty(): boolean {\n    return false;\n  }\n\n  // Traverses the tree in key order and calls the specified action function\n  // for each node. If action returns true, traversal is aborted.\n  // Returns the first truthy value returned by action, or the last falsey\n  // value returned by action.\n  inorderTraversal<T>(action: (k: K, v: V) => T): T {\n    return (\n      (this.left as LLRBNode<K, V>).inorderTraversal(action) ||\n      action(this.key, this.value) ||\n      (this.right as LLRBNode<K, V>).inorderTraversal(action)\n    );\n  }\n\n  // Traverses the tree in reverse key order and calls the specified action\n  // function for each node. If action returns true, traversal is aborted.\n  // Returns the first truthy value returned by action, or the last falsey\n  // value returned by action.\n  reverseTraversal<T>(action: (k: K, v: V) => T): T {\n    return (\n      (this.right as LLRBNode<K, V>).reverseTraversal(action) ||\n      action(this.key, this.value) ||\n      (this.left as LLRBNode<K, V>).reverseTraversal(action)\n    );\n  }\n\n  // Returns the minimum node in the tree.\n  private min(): LLRBNode<K, V> {\n    if (this.left.isEmpty()) {\n      return this;\n    } else {\n      return (this.left as LLRBNode<K, V>).min();\n    }\n  }\n\n  // Returns the maximum key in the tree.\n  minKey(): K | null {\n    return this.min().key;\n  }\n\n  // Returns the maximum key in the tree.\n  maxKey(): K | null {\n    if (this.right.isEmpty()) {\n      return this.key;\n    } else {\n      return this.right.maxKey();\n    }\n  }\n\n  // Returns new tree, with the key/value added.\n  insert(key: K, value: V, comparator: Comparator<K>): LLRBNode<K, V> {\n    let n: LLRBNode<K, V> = this;\n    const cmp = comparator(key, n.key);\n    if (cmp < 0) {\n      n = n.copy(null, null, null, n.left.insert(key, value, comparator), null);\n    } else if (cmp === 0) {\n      n = n.copy(null, value, null, null, null);\n    } else {\n      n = n.copy(\n        null,\n        null,\n        null,\n        null,\n        n.right.insert(key, value, comparator)\n      );\n    }\n    return n.fixUp();\n  }\n\n  private removeMin(): LLRBNode<K, V> | LLRBEmptyNode<K, V> {\n    if (this.left.isEmpty()) {\n      return LLRBNode.EMPTY;\n    }\n    let n: LLRBNode<K, V> = this;\n    if (!n.left.isRed() && !n.left.left.isRed()) {\n      n = n.moveRedLeft();\n    }\n    n = n.copy(null, null, null, (n.left as LLRBNode<K, V>).removeMin(), null);\n    return n.fixUp();\n  }\n\n  // Returns new tree, with the specified item removed.\n  remove(\n    key: K,\n    comparator: Comparator<K>\n  ): LLRBNode<K, V> | LLRBEmptyNode<K, V> {\n    let smallest: LLRBNode<K, V>;\n    let n: LLRBNode<K, V> = this;\n    if (comparator(key, n.key) < 0) {\n      if (!n.left.isEmpty() && !n.left.isRed() && !n.left.left.isRed()) {\n        n = n.moveRedLeft();\n      }\n      n = n.copy(null, null, null, n.left.remove(key, comparator), null);\n    } else {\n      if (n.left.isRed()) {\n        n = n.rotateRight();\n      }\n      if (!n.right.isEmpty() && !n.right.isRed() && !n.right.left.isRed()) {\n        n = n.moveRedRight();\n      }\n      if (comparator(key, n.key) === 0) {\n        if (n.right.isEmpty()) {\n          return LLRBNode.EMPTY;\n        } else {\n          smallest = (n.right as LLRBNode<K, V>).min();\n          n = n.copy(\n            smallest.key,\n            smallest.value,\n            null,\n            null,\n            (n.right as LLRBNode<K, V>).removeMin()\n          );\n        }\n      }\n      n = n.copy(null, null, null, null, n.right.remove(key, comparator));\n    }\n    return n.fixUp();\n  }\n\n  isRed(): boolean {\n    return this.color;\n  }\n\n  // Returns new tree after performing any needed rotations.\n  private fixUp(): LLRBNode<K, V> {\n    let n: LLRBNode<K, V> = this;\n    if (n.right.isRed() && !n.left.isRed()) {\n      n = n.rotateLeft();\n    }\n    if (n.left.isRed() && n.left.left.isRed()) {\n      n = n.rotateRight();\n    }\n    if (n.left.isRed() && n.right.isRed()) {\n      n = n.colorFlip();\n    }\n    return n;\n  }\n\n  private moveRedLeft(): LLRBNode<K, V> {\n    let n = this.colorFlip();\n    if (n.right.left.isRed()) {\n      n = n.copy(\n        null,\n        null,\n        null,\n        null,\n        (n.right as LLRBNode<K, V>).rotateRight()\n      );\n      n = n.rotateLeft();\n      n = n.colorFlip();\n    }\n    return n;\n  }\n\n  private moveRedRight(): LLRBNode<K, V> {\n    let n = this.colorFlip();\n    if (n.left.left.isRed()) {\n      n = n.rotateRight();\n      n = n.colorFlip();\n    }\n    return n;\n  }\n\n  private rotateLeft(): LLRBNode<K, V> {\n    const nl = this.copy(null, null, LLRBNode.RED, null, this.right.left);\n    return (this.right as LLRBNode<K, V>).copy(\n      null,\n      null,\n      this.color,\n      nl,\n      null\n    );\n  }\n\n  private rotateRight(): LLRBNode<K, V> {\n    const nr = this.copy(null, null, LLRBNode.RED, this.left.right, null);\n    return (this.left as LLRBNode<K, V>).copy(null, null, this.color, null, nr);\n  }\n\n  private colorFlip(): LLRBNode<K, V> {\n    const left = this.left.copy(null, null, !this.left.color, null, null);\n    const right = this.right.copy(null, null, !this.right.color, null, null);\n    return this.copy(null, null, !this.color, left, right);\n  }\n\n  // For testing.\n  checkMaxDepth(): boolean {\n    const blackDepth = this.check();\n    if (Math.pow(2.0, blackDepth) <= this.size + 1) {\n      return true;\n    } else {\n      return false;\n    }\n  }\n\n  // In a balanced RB tree, the black-depth (number of black nodes) from root to\n  // leaves is equal on both sides.  This function verifies that or asserts.\n  protected check(): number {\n    if (this.isRed() && this.left.isRed()) {\n      throw fail('Red node has red child(' + this.key + ',' + this.value + ')');\n    }\n    if (this.right.isRed()) {\n      throw fail('Right child of (' + this.key + ',' + this.value + ') is red');\n    }\n    const blackDepth = (this.left as LLRBNode<K, V>).check();\n    if (blackDepth !== (this.right as LLRBNode<K, V>).check()) {\n      throw fail('Black depths differ');\n    } else {\n      return blackDepth + (this.isRed() ? 0 : 1);\n    }\n  }\n} // end LLRBNode\n\n// Represents an empty node (a leaf node in the Red-Black Tree).\nexport class LLRBEmptyNode<K, V> {\n  get key(): never {\n    throw fail('LLRBEmptyNode has no key.');\n  }\n  get value(): never {\n    throw fail('LLRBEmptyNode has no value.');\n  }\n  get color(): never {\n    throw fail('LLRBEmptyNode has no color.');\n  }\n  get left(): never {\n    throw fail('LLRBEmptyNode has no left child.');\n  }\n  get right(): never {\n    throw fail('LLRBEmptyNode has no right child.');\n  }\n  size = 0;\n\n  // Returns a copy of the current node.\n  copy(\n    key: K | null,\n    value: V | null,\n    color: boolean | null,\n    left: LLRBNode<K, V> | LLRBEmptyNode<K, V> | null,\n    right: LLRBNode<K, V> | LLRBEmptyNode<K, V> | null\n  ): LLRBEmptyNode<K, V> {\n    return this;\n  }\n\n  // Returns a copy of the tree, with the specified key/value added.\n  insert(key: K, value: V, comparator: Comparator<K>): LLRBNode<K, V> {\n    return new LLRBNode<K, V>(key, value);\n  }\n\n  // Returns a copy of the tree, with the specified key removed.\n  remove(key: K, comparator: Comparator<K>): LLRBEmptyNode<K, V> {\n    return this;\n  }\n\n  isEmpty(): boolean {\n    return true;\n  }\n\n  inorderTraversal(action: (k: K, v: V) => boolean): boolean {\n    return false;\n  }\n\n  reverseTraversal(action: (k: K, v: V) => boolean): boolean {\n    return false;\n  }\n\n  minKey(): K | null {\n    return null;\n  }\n\n  maxKey(): K | null {\n    return null;\n  }\n\n  isRed(): boolean {\n    return false;\n  }\n\n  // For testing.\n  checkMaxDepth(): boolean {\n    return true;\n  }\n\n  protected check(): 0 {\n    return 0;\n  }\n} // end LLRBEmptyNode\n\nLLRBNode.EMPTY = new LLRBEmptyNode<unknown, unknown>();\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { SortedMap, SortedMapIterator } from './sorted_map';\n\n/**\n * SortedSet is an immutable (copy-on-write) collection that holds elements\n * in order specified by the provided comparator.\n *\n * NOTE: if provided comparator returns 0 for two elements, we consider them to\n * be equal!\n */\nexport class SortedSet<T> {\n  private data: SortedMap<T, boolean>;\n\n  constructor(private comparator: (left: T, right: T) => number) {\n    this.data = new SortedMap<T, boolean>(this.comparator);\n  }\n\n  has(elem: T): boolean {\n    return this.data.get(elem) !== null;\n  }\n\n  first(): T | null {\n    return this.data.minKey();\n  }\n\n  last(): T | null {\n    return this.data.maxKey();\n  }\n\n  get size(): number {\n    return this.data.size;\n  }\n\n  indexOf(elem: T): number {\n    return this.data.indexOf(elem);\n  }\n\n  /** Iterates elements in order defined by \"comparator\" */\n  forEach(cb: (elem: T) => void): void {\n    this.data.inorderTraversal((k: T, v: boolean) => {\n      cb(k);\n      return false;\n    });\n  }\n\n  /** Iterates over `elem`s such that: range[0] <= elem < range[1]. */\n  forEachInRange(range: [T, T], cb: (elem: T) => void): void {\n    const iter = this.data.getIteratorFrom(range[0]);\n    while (iter.hasNext()) {\n      const elem = iter.getNext();\n      if (this.comparator(elem.key, range[1]) >= 0) {\n        return;\n      }\n      cb(elem.key);\n    }\n  }\n\n  /**\n   * Iterates over `elem`s such that: start <= elem until false is returned.\n   */\n  forEachWhile(cb: (elem: T) => boolean, start?: T): void {\n    let iter: SortedMapIterator<T, boolean>;\n    if (start !== undefined) {\n      iter = this.data.getIteratorFrom(start);\n    } else {\n      iter = this.data.getIterator();\n    }\n    while (iter.hasNext()) {\n      const elem = iter.getNext();\n      const result = cb(elem.key);\n      if (!result) {\n        return;\n      }\n    }\n  }\n\n  /** Finds the least element greater than or equal to `elem`. */\n  firstAfterOrEqual(elem: T): T | null {\n    const iter = this.data.getIteratorFrom(elem);\n    return iter.hasNext() ? iter.getNext().key : null;\n  }\n\n  getIterator(): SortedSetIterator<T> {\n    return new SortedSetIterator<T>(this.data.getIterator());\n  }\n\n  getIteratorFrom(key: T): SortedSetIterator<T> {\n    return new SortedSetIterator<T>(this.data.getIteratorFrom(key));\n  }\n\n  /** Inserts or updates an element */\n  add(elem: T): SortedSet<T> {\n    return this.copy(this.data.remove(elem).insert(elem, true));\n  }\n\n  /** Deletes an element */\n  delete(elem: T): SortedSet<T> {\n    if (!this.has(elem)) {\n      return this;\n    }\n    return this.copy(this.data.remove(elem));\n  }\n\n  isEmpty(): boolean {\n    return this.data.isEmpty();\n  }\n\n  unionWith(other: SortedSet<T>): SortedSet<T> {\n    let result: SortedSet<T> = this;\n\n    // Make sure `result` always refers to the larger one of the two sets.\n    if (result.size < other.size) {\n      result = other;\n      other = this;\n    }\n\n    other.forEach(elem => {\n      result = result.add(elem);\n    });\n    return result;\n  }\n\n  isEqual(other: SortedSet<T>): boolean {\n    if (!(other instanceof SortedSet)) {\n      return false;\n    }\n    if (this.size !== other.size) {\n      return false;\n    }\n\n    const thisIt = this.data.getIterator();\n    const otherIt = other.data.getIterator();\n    while (thisIt.hasNext()) {\n      const thisElem = thisIt.getNext().key;\n      const otherElem = otherIt.getNext().key;\n      if (this.comparator(thisElem, otherElem) !== 0) {\n        return false;\n      }\n    }\n    return true;\n  }\n\n  toArray(): T[] {\n    const res: T[] = [];\n    this.forEach(targetId => {\n      res.push(targetId);\n    });\n    return res;\n  }\n\n  toString(): string {\n    const result: T[] = [];\n    this.forEach(elem => result.push(elem));\n    return 'SortedSet(' + result.toString() + ')';\n  }\n\n  private copy(data: SortedMap<T, boolean>): SortedSet<T> {\n    const result = new SortedSet(this.comparator);\n    result.data = data;\n    return result;\n  }\n}\n\nexport class SortedSetIterator<T> {\n  constructor(private iter: SortedMapIterator<T, boolean>) {}\n\n  getNext(): T {\n    return this.iter.getNext().key;\n  }\n\n  hasNext(): boolean {\n    return this.iter.hasNext();\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { debugAssert } from './assert';\n\nexport interface Dict<V> {\n  [stringKey: string]: V;\n}\n\nexport function objectSize<V>(obj: object): number {\n  let count = 0;\n  for (const key in obj) {\n    if (Object.prototype.hasOwnProperty.call(obj, key)) {\n      count++;\n    }\n  }\n  return count;\n}\n\nexport function forEach<V>(\n  obj: Dict<V>,\n  fn: (key: string, val: V) => void\n): void {\n  for (const key in obj) {\n    if (Object.prototype.hasOwnProperty.call(obj, key)) {\n      fn(key, obj[key]);\n    }\n  }\n}\n\nexport function isEmpty<V>(obj: Dict<V>): boolean {\n  debugAssert(\n    obj != null && typeof obj === 'object',\n    'isEmpty() expects object parameter.'\n  );\n  for (const key in obj) {\n    if (Object.prototype.hasOwnProperty.call(obj, key)) {\n      return false;\n    }\n  }\n  return true;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { PlatformSupport } from '../platform/platform';\nimport { primitiveComparator } from './misc';\n\n/**\n * Immutable class that represents a \"proto\" byte string.\n *\n * Proto byte strings can either be Base64-encoded strings or Uint8Arrays when\n * sent on the wire. This class abstracts away this differentiation by holding\n * the proto byte string in a common class that must be converted into a string\n * before being sent as a proto.\n */\nexport class ByteString {\n  static readonly EMPTY_BYTE_STRING = new ByteString('');\n\n  private constructor(private readonly binaryString: string) {}\n\n  static fromBase64String(base64: string): ByteString {\n    const binaryString = PlatformSupport.getPlatform().atob(base64);\n    return new ByteString(binaryString);\n  }\n\n  static fromUint8Array(array: Uint8Array): ByteString {\n    const binaryString = binaryStringFromUint8Array(array);\n    return new ByteString(binaryString);\n  }\n\n  toBase64(): string {\n    return PlatformSupport.getPlatform().btoa(this.binaryString);\n  }\n\n  toUint8Array(): Uint8Array {\n    return uint8ArrayFromBinaryString(this.binaryString);\n  }\n\n  approximateByteSize(): number {\n    return this.binaryString.length * 2;\n  }\n\n  compareTo(other: ByteString): number {\n    return primitiveComparator(this.binaryString, other.binaryString);\n  }\n\n  isEqual(other: ByteString): boolean {\n    return this.binaryString === other.binaryString;\n  }\n}\n\n/**\n * Helper function to convert an Uint8array to a binary string.\n */\nexport function binaryStringFromUint8Array(array: Uint8Array): string {\n  let binaryString = '';\n  for (let i = 0; i < array.length; ++i) {\n    binaryString += String.fromCharCode(array[i]);\n  }\n  return binaryString;\n}\n\n/**\n * Helper function to convert a binary string to an Uint8Array.\n */\nexport function uint8ArrayFromBinaryString(binaryString: string): Uint8Array {\n  const buffer = new Uint8Array(binaryString.length);\n  for (let i = 0; i < binaryString.length; i++) {\n    buffer[i] = binaryString.charCodeAt(i);\n  }\n  return buffer;\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n// An Object whose keys and values are strings.\nexport interface StringMap {\n  [key: string]: string;\n}\n\n/**\n * Returns whether a variable is either undefined or null.\n */\nexport function isNullOrUndefined(value: unknown): value is null | undefined {\n  return value === null || value === undefined;\n}\n\n/** Returns whether the value represents -0. */\nexport function isNegativeZero(value: number): boolean {\n  // Detect if the value is -0.0. Based on polyfill from\n  // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Object/is\n  return value === -0 && 1 / value === 1 / -0;\n}\n\n/**\n * Returns whether a value is an integer and in the safe integer range\n * @param value The value to test for being an integer and in the safe range\n */\nexport function isSafeInteger(value: unknown): boolean {\n  return (\n    typeof value === 'number' &&\n    Number.isInteger(value) &&\n    !isNegativeZero(value) &&\n    value <= Number.MAX_SAFE_INTEGER &&\n    value >= Number.MIN_SAFE_INTEGER\n  );\n}\n","/**\n * @license\n * Copyright 2020 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport * as api from '../protos/firestore_proto_api';\nimport { Timestamp } from '../api/timestamp';\nimport { normalizeTimestamp } from './values';\n\n/**\n * Represents a locally-applied ServerTimestamp.\n *\n * Server Timestamps are backed by MapValues that contain an internal field\n * `__type__` with a value of `server_timestamp`. The previous value and local\n * write time are stored in its `__previous_value__` and `__local_write_time__`\n * fields respectively.\n *\n * Notes:\n * - ServerTimestampValue instances are created as the result of applying a\n *   TransformMutation (see TransformMutation.applyTo()). They can only exist in\n *   the local view of a document. Therefore they do not need to be parsed or\n *   serialized.\n * - When evaluated locally (e.g. for snapshot.data()), they by default\n *   evaluate to `null`. This behavior can be configured by passing custom\n *   FieldValueOptions to value().\n * - With respect to other ServerTimestampValues, they sort by their\n *   localWriteTime.\n */\n\nconst SERVER_TIMESTAMP_SENTINEL = 'server_timestamp';\nconst TYPE_KEY = '__type__';\nconst PREVIOUS_VALUE_KEY = '__previous_value__';\nconst LOCAL_WRITE_TIME_KEY = '__local_write_time__';\n\nexport function isServerTimestamp(value: api.Value | null): boolean {\n  const type = (value?.mapValue?.fields || {})[TYPE_KEY]?.stringValue;\n  return type === SERVER_TIMESTAMP_SENTINEL;\n}\n\n/**\n * Creates a new ServerTimestamp proto value (using the internal format).\n */\nexport function serverTimestamp(\n  localWriteTime: Timestamp,\n  previousValue: api.Value | null\n): api.Value {\n  const mapValue: api.MapValue = {\n    fields: {\n      [TYPE_KEY]: {\n        stringValue: SERVER_TIMESTAMP_SENTINEL\n      },\n      [LOCAL_WRITE_TIME_KEY]: {\n        timestampValue: {\n          seconds: localWriteTime.seconds,\n          nanos: localWriteTime.nanoseconds\n        }\n      }\n    }\n  };\n\n  if (previousValue) {\n    mapValue.fields![PREVIOUS_VALUE_KEY] = previousValue;\n  }\n\n  return { mapValue };\n}\n\n/**\n * Returns the value of the field before this ServerTimestamp was set.\n *\n * Preserving the previous values allows the user to display the last resoled\n * value until the backend responds with the timestamp.\n */\nexport function getPreviousValue(value: api.Value): api.Value | null {\n  const previousValue = value.mapValue!.fields![PREVIOUS_VALUE_KEY];\n\n  if (isServerTimestamp(previousValue)) {\n    return getPreviousValue(previousValue);\n  }\n  return previousValue;\n}\n\n/**\n * Returns the local time at which this timestamp was first set.\n */\nexport function getLocalWriteTime(value: api.Value): Timestamp {\n  const localWriteTime = normalizeTimestamp(\n    value.mapValue!.fields![LOCAL_WRITE_TIME_KEY].timestampValue!\n  );\n  return new Timestamp(localWriteTime.seconds, localWriteTime.nanos);\n}\n","/**\n * @license\n * Copyright 2020 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport * as api from '../protos/firestore_proto_api';\n\nimport { TypeOrder } from './field_value';\nimport { fail, hardAssert } from '../util/assert';\nimport { forEach, objectSize } from '../util/obj';\nimport { ByteString } from '../util/byte_string';\nimport { isNegativeZero } from '../util/types';\nimport { DocumentKey } from './document_key';\nimport { arrayEquals, primitiveComparator } from '../util/misc';\nimport { DatabaseId } from '../core/database_info';\nimport {\n  getLocalWriteTime,\n  getPreviousValue,\n  isServerTimestamp\n} from './server_timestamps';\n\n// A RegExp matching ISO 8601 UTC timestamps with optional fraction.\nconst ISO_TIMESTAMP_REG_EXP = new RegExp(\n  /^\\d{4}-\\d\\d-\\d\\dT\\d\\d:\\d\\d:\\d\\d(?:\\.(\\d+))?Z$/\n);\n\n/** Extracts the backend's type order for the provided value. */\nexport function typeOrder(value: api.Value): TypeOrder {\n  if ('nullValue' in value) {\n    return TypeOrder.NullValue;\n  } else if ('booleanValue' in value) {\n    return TypeOrder.BooleanValue;\n  } else if ('integerValue' in value || 'doubleValue' in value) {\n    return TypeOrder.NumberValue;\n  } else if ('timestampValue' in value) {\n    return TypeOrder.TimestampValue;\n  } else if ('stringValue' in value) {\n    return TypeOrder.StringValue;\n  } else if ('bytesValue' in value) {\n    return TypeOrder.BlobValue;\n  } else if ('referenceValue' in value) {\n    return TypeOrder.RefValue;\n  } else if ('geoPointValue' in value) {\n    return TypeOrder.GeoPointValue;\n  } else if ('arrayValue' in value) {\n    return TypeOrder.ArrayValue;\n  } else if ('mapValue' in value) {\n    if (isServerTimestamp(value)) {\n      return TypeOrder.ServerTimestampValue;\n    }\n    return TypeOrder.ObjectValue;\n  } else {\n    return fail('Invalid value type: ' + JSON.stringify(value));\n  }\n}\n\n/** Tests `left` and `right` for equality based on the backend semantics. */\nexport function valueEquals(left: api.Value, right: api.Value): boolean {\n  const leftType = typeOrder(left);\n  const rightType = typeOrder(right);\n  if (leftType !== rightType) {\n    return false;\n  }\n\n  switch (leftType) {\n    case TypeOrder.NullValue:\n      return true;\n    case TypeOrder.BooleanValue:\n      return left.booleanValue === right.booleanValue;\n    case TypeOrder.ServerTimestampValue:\n      return getLocalWriteTime(left).isEqual(getLocalWriteTime(right));\n    case TypeOrder.TimestampValue:\n      return timestampEquals(left, right);\n    case TypeOrder.StringValue:\n      return left.stringValue === right.stringValue;\n    case TypeOrder.BlobValue:\n      return blobEquals(left, right);\n    case TypeOrder.RefValue:\n      return left.referenceValue === right.referenceValue;\n    case TypeOrder.GeoPointValue:\n      return geoPointEquals(left, right);\n    case TypeOrder.NumberValue:\n      return numberEquals(left, right);\n    case TypeOrder.ArrayValue:\n      return arrayEquals(\n        left.arrayValue!.values || [],\n        right.arrayValue!.values || [],\n        valueEquals\n      );\n    case TypeOrder.ObjectValue:\n      return objectEquals(left, right);\n    default:\n      return fail('Unexpected value type: ' + JSON.stringify(left));\n  }\n}\n\nfunction timestampEquals(left: api.Value, right: api.Value): boolean {\n  if (\n    typeof left.timestampValue === 'string' &&\n    typeof right.timestampValue === 'string' &&\n    left.timestampValue.length === right.timestampValue.length\n  ) {\n    // Use string equality for ISO 8601 timestamps\n    return left.timestampValue === right.timestampValue;\n  }\n\n  const leftTimestamp = normalizeTimestamp(left.timestampValue!);\n  const rightTimestamp = normalizeTimestamp(right.timestampValue!);\n  return (\n    leftTimestamp.seconds === rightTimestamp.seconds &&\n    leftTimestamp.nanos === rightTimestamp.nanos\n  );\n}\n\nfunction geoPointEquals(left: api.Value, right: api.Value): boolean {\n  return (\n    normalizeNumber(left.geoPointValue!.latitude) ===\n      normalizeNumber(right.geoPointValue!.latitude) &&\n    normalizeNumber(left.geoPointValue!.longitude) ===\n      normalizeNumber(right.geoPointValue!.longitude)\n  );\n}\n\nfunction blobEquals(left: api.Value, right: api.Value): boolean {\n  return normalizeByteString(left.bytesValue!).isEqual(\n    normalizeByteString(right.bytesValue!)\n  );\n}\n\nexport function numberEquals(left: api.Value, right: api.Value): boolean {\n  if ('integerValue' in left && 'integerValue' in right) {\n    return (\n      normalizeNumber(left.integerValue) === normalizeNumber(right.integerValue)\n    );\n  } else if ('doubleValue' in left && 'doubleValue' in right) {\n    const n1 = normalizeNumber(left.doubleValue!);\n    const n2 = normalizeNumber(right.doubleValue!);\n\n    if (n1 === n2) {\n      return isNegativeZero(n1) === isNegativeZero(n2);\n    } else {\n      return isNaN(n1) && isNaN(n2);\n    }\n  }\n\n  return false;\n}\n\nfunction objectEquals(left: api.Value, right: api.Value): boolean {\n  const leftMap = left.mapValue!.fields || {};\n  const rightMap = right.mapValue!.fields || {};\n\n  if (objectSize(leftMap) !== objectSize(rightMap)) {\n    return false;\n  }\n\n  for (const key in leftMap) {\n    if (leftMap.hasOwnProperty(key)) {\n      if (\n        rightMap[key] === undefined ||\n        !valueEquals(leftMap[key], rightMap[key])\n      ) {\n        return false;\n      }\n    }\n  }\n  return true;\n}\n\n/** Returns true if the ArrayValue contains the specified element. */\nexport function arrayValueContains(\n  haystack: api.ArrayValue,\n  needle: api.Value\n): boolean {\n  return (\n    (haystack.values || []).find(v => valueEquals(v, needle)) !== undefined\n  );\n}\n\nexport function valueCompare(left: api.Value, right: api.Value): number {\n  const leftType = typeOrder(left);\n  const rightType = typeOrder(right);\n\n  if (leftType !== rightType) {\n    return primitiveComparator(leftType, rightType);\n  }\n\n  switch (leftType) {\n    case TypeOrder.NullValue:\n      return 0;\n    case TypeOrder.BooleanValue:\n      return primitiveComparator(left.booleanValue!, right.booleanValue!);\n    case TypeOrder.NumberValue:\n      return compareNumbers(left, right);\n    case TypeOrder.TimestampValue:\n      return compareTimestamps(left.timestampValue!, right.timestampValue!);\n    case TypeOrder.ServerTimestampValue:\n      return compareTimestamps(\n        getLocalWriteTime(left),\n        getLocalWriteTime(right)\n      );\n    case TypeOrder.StringValue:\n      return primitiveComparator(left.stringValue!, right.stringValue!);\n    case TypeOrder.BlobValue:\n      return compareBlobs(left.bytesValue!, right.bytesValue!);\n    case TypeOrder.RefValue:\n      return compareReferences(left.referenceValue!, right.referenceValue!);\n    case TypeOrder.GeoPointValue:\n      return compareGeoPoints(left.geoPointValue!, right.geoPointValue!);\n    case TypeOrder.ArrayValue:\n      return compareArrays(left.arrayValue!, right.arrayValue!);\n    case TypeOrder.ObjectValue:\n      return compareMaps(left.mapValue!, right.mapValue!);\n    default:\n      throw fail('Invalid value type: ' + leftType);\n  }\n}\n\nfunction compareNumbers(left: api.Value, right: api.Value): number {\n  const leftNumber = normalizeNumber(left.integerValue || left.doubleValue);\n  const rightNumber = normalizeNumber(right.integerValue || right.doubleValue);\n\n  if (leftNumber < rightNumber) {\n    return -1;\n  } else if (leftNumber > rightNumber) {\n    return 1;\n  } else if (leftNumber === rightNumber) {\n    return 0;\n  } else {\n    // one or both are NaN.\n    if (isNaN(leftNumber)) {\n      return isNaN(rightNumber) ? 0 : -1;\n    } else {\n      return 1;\n    }\n  }\n}\n\nfunction compareTimestamps(left: api.Timestamp, right: api.Timestamp): number {\n  if (\n    typeof left === 'string' &&\n    typeof right === 'string' &&\n    left.length === right.length\n  ) {\n    return primitiveComparator(left, right);\n  }\n\n  const leftTimestamp = normalizeTimestamp(left);\n  const rightTimestamp = normalizeTimestamp(right);\n\n  const comparison = primitiveComparator(\n    leftTimestamp.seconds,\n    rightTimestamp.seconds\n  );\n  if (comparison !== 0) {\n    return comparison;\n  }\n  return primitiveComparator(leftTimestamp.nanos, rightTimestamp.nanos);\n}\n\nfunction compareReferences(leftPath: string, rightPath: string): number {\n  const leftSegments = leftPath.split('/');\n  const rightSegments = rightPath.split('/');\n  for (let i = 0; i < leftSegments.length && i < rightSegments.length; i++) {\n    const comparison = primitiveComparator(leftSegments[i], rightSegments[i]);\n    if (comparison !== 0) {\n      return comparison;\n    }\n  }\n  return primitiveComparator(leftSegments.length, rightSegments.length);\n}\n\nfunction compareGeoPoints(left: api.LatLng, right: api.LatLng): number {\n  const comparison = primitiveComparator(\n    normalizeNumber(left.latitude),\n    normalizeNumber(right.latitude)\n  );\n  if (comparison !== 0) {\n    return comparison;\n  }\n  return primitiveComparator(\n    normalizeNumber(left.longitude),\n    normalizeNumber(right.longitude)\n  );\n}\n\nfunction compareBlobs(\n  left: string | Uint8Array,\n  right: string | Uint8Array\n): number {\n  const leftBytes = normalizeByteString(left);\n  const rightBytes = normalizeByteString(right);\n  return leftBytes.compareTo(rightBytes);\n}\n\nfunction compareArrays(left: api.ArrayValue, right: api.ArrayValue): number {\n  const leftArray = left.values || [];\n  const rightArray = right.values || [];\n\n  for (let i = 0; i < leftArray.length && i < rightArray.length; ++i) {\n    const compare = valueCompare(leftArray[i], rightArray[i]);\n    if (compare) {\n      return compare;\n    }\n  }\n  return primitiveComparator(leftArray.length, rightArray.length);\n}\n\nfunction compareMaps(left: api.MapValue, right: api.MapValue): number {\n  const leftMap = left.fields || {};\n  const leftKeys = Object.keys(leftMap);\n  const rightMap = right.fields || {};\n  const rightKeys = Object.keys(rightMap);\n\n  // Even though MapValues are likely sorted correctly based on their insertion\n  // order (e.g. when received from the backend), local modifications can bring\n  // elements out of order. We need to re-sort the elements to ensure that\n  // canonical IDs are independent of insertion order.\n  leftKeys.sort();\n  rightKeys.sort();\n\n  for (let i = 0; i < leftKeys.length && i < rightKeys.length; ++i) {\n    const keyCompare = primitiveComparator(leftKeys[i], rightKeys[i]);\n    if (keyCompare !== 0) {\n      return keyCompare;\n    }\n    const compare = valueCompare(leftMap[leftKeys[i]], rightMap[rightKeys[i]]);\n    if (compare !== 0) {\n      return compare;\n    }\n  }\n\n  return primitiveComparator(leftKeys.length, rightKeys.length);\n}\n\n/**\n * Generates the canonical ID for the provided field value (as used in Target\n * serialization).\n */\nexport function canonicalId(value: api.Value): string {\n  return canonifyValue(value);\n}\n\nfunction canonifyValue(value: api.Value): string {\n  if ('nullValue' in value) {\n    return 'null';\n  } else if ('booleanValue' in value) {\n    return '' + value.booleanValue!;\n  } else if ('integerValue' in value) {\n    return '' + value.integerValue!;\n  } else if ('doubleValue' in value) {\n    return '' + value.doubleValue!;\n  } else if ('timestampValue' in value) {\n    return canonifyTimestamp(value.timestampValue!);\n  } else if ('stringValue' in value) {\n    return value.stringValue!;\n  } else if ('bytesValue' in value) {\n    return canonifyByteString(value.bytesValue!);\n  } else if ('referenceValue' in value) {\n    return canonifyReference(value.referenceValue!);\n  } else if ('geoPointValue' in value) {\n    return canonifyGeoPoint(value.geoPointValue!);\n  } else if ('arrayValue' in value) {\n    return canonifyArray(value.arrayValue!);\n  } else if ('mapValue' in value) {\n    return canonifyMap(value.mapValue!);\n  } else {\n    return fail('Invalid value type: ' + JSON.stringify(value));\n  }\n}\n\nfunction canonifyByteString(byteString: string | Uint8Array): string {\n  return normalizeByteString(byteString).toBase64();\n}\n\nfunction canonifyTimestamp(timestamp: api.Timestamp): string {\n  const normalizedTimestamp = normalizeTimestamp(timestamp);\n  return `time(${normalizedTimestamp.seconds},${normalizedTimestamp.nanos})`;\n}\n\nfunction canonifyGeoPoint(geoPoint: api.LatLng): string {\n  return `geo(${geoPoint.latitude},${geoPoint.longitude})`;\n}\n\nfunction canonifyReference(referenceValue: string): string {\n  return DocumentKey.fromName(referenceValue).toString();\n}\n\nfunction canonifyMap(mapValue: api.MapValue): string {\n  // Iteration order in JavaScript is not guaranteed. To ensure that we generate\n  // matching canonical IDs for identical maps, we need to sort the keys.\n  const sortedKeys = Object.keys(mapValue.fields || {}).sort();\n\n  let result = '{';\n  let first = true;\n  for (const key of sortedKeys) {\n    if (!first) {\n      result += ',';\n    } else {\n      first = false;\n    }\n    result += `${key}:${canonifyValue(mapValue.fields![key])}`;\n  }\n  return result + '}';\n}\n\nfunction canonifyArray(arrayValue: api.ArrayValue): string {\n  let result = '[';\n  let first = true;\n  for (const value of arrayValue.values || []) {\n    if (!first) {\n      result += ',';\n    } else {\n      first = false;\n    }\n    result += canonifyValue(value);\n  }\n  return result + ']';\n}\n\n/**\n * Returns an approximate (and wildly inaccurate) in-memory size for the field\n * value.\n *\n * The memory size takes into account only the actual user data as it resides\n * in memory and ignores object overhead.\n */\nexport function estimateByteSize(value: api.Value): number {\n  switch (typeOrder(value)) {\n    case TypeOrder.NullValue:\n      return 4;\n    case TypeOrder.BooleanValue:\n      return 4;\n    case TypeOrder.NumberValue:\n      return 8;\n    case TypeOrder.TimestampValue:\n      // Timestamps are made up of two distinct numbers (seconds + nanoseconds)\n      return 16;\n    case TypeOrder.ServerTimestampValue:\n      const previousValue = getPreviousValue(value);\n      return previousValue ? 16 + estimateByteSize(previousValue) : 16;\n    case TypeOrder.StringValue:\n      // See https://developer.mozilla.org/en-US/docs/Web/JavaScript/Data_structures:\n      // \"JavaScript's String type is [...] a set of elements of 16-bit unsigned\n      // integer values\"\n      return value.stringValue!.length * 2;\n    case TypeOrder.BlobValue:\n      return normalizeByteString(value.bytesValue!).approximateByteSize();\n    case TypeOrder.RefValue:\n      return value.referenceValue!.length;\n    case TypeOrder.GeoPointValue:\n      // GeoPoints are made up of two distinct numbers (latitude + longitude)\n      return 16;\n    case TypeOrder.ArrayValue:\n      return estimateArrayByteSize(value.arrayValue!);\n    case TypeOrder.ObjectValue:\n      return estimateMapByteSize(value.mapValue!);\n    default:\n      throw fail('Invalid value type: ' + JSON.stringify(value));\n  }\n}\n\nfunction estimateMapByteSize(mapValue: api.MapValue): number {\n  let size = 0;\n  forEach(mapValue.fields || {}, (key, val) => {\n    size += key.length + estimateByteSize(val);\n  });\n  return size;\n}\n\nfunction estimateArrayByteSize(arrayValue: api.ArrayValue): number {\n  return (arrayValue.values || []).reduce(\n    (previousSize, value) => previousSize + estimateByteSize(value),\n    0\n  );\n}\n\n/**\n * Converts the possible Proto values for a timestamp value into a \"seconds and\n * nanos\" representation.\n */\nexport function normalizeTimestamp(\n  date: api.Timestamp\n): { seconds: number; nanos: number } {\n  hardAssert(!!date, 'Cannot normalize null or undefined timestamp.');\n\n  // The json interface (for the browser) will return an iso timestamp string,\n  // while the proto js library (for node) will return a\n  // google.protobuf.Timestamp instance.\n  if (typeof date === 'string') {\n    // The date string can have higher precision (nanos) than the Date class\n    // (millis), so we do some custom parsing here.\n\n    // Parse the nanos right out of the string.\n    let nanos = 0;\n    const fraction = ISO_TIMESTAMP_REG_EXP.exec(date);\n    hardAssert(!!fraction, 'invalid timestamp: ' + date);\n    if (fraction[1]) {\n      // Pad the fraction out to 9 digits (nanos).\n      let nanoStr = fraction[1];\n      nanoStr = (nanoStr + '000000000').substr(0, 9);\n      nanos = Number(nanoStr);\n    }\n\n    // Parse the date to get the seconds.\n    const parsedDate = new Date(date);\n    const seconds = Math.floor(parsedDate.getTime() / 1000);\n\n    return { seconds, nanos };\n  } else {\n    // TODO(b/37282237): Use strings for Proto3 timestamps\n    // assert(!this.options.useProto3Json,\n    //   'The timestamp instance format requires Proto JS.');\n    const seconds = normalizeNumber(date.seconds);\n    const nanos = normalizeNumber(date.nanos);\n    return { seconds, nanos };\n  }\n}\n\n/**\n * Converts the possible Proto types for numbers into a JavaScript number.\n * Returns 0 if the value is not numeric.\n */\nexport function normalizeNumber(value: number | string | undefined): number {\n  // TODO(bjornick): Handle int64 greater than 53 bits.\n  if (typeof value === 'number') {\n    return value;\n  } else if (typeof value === 'string') {\n    return Number(value);\n  } else {\n    return 0;\n  }\n}\n\n/** Converts the possible Proto types for Blobs into a ByteString. */\nexport function normalizeByteString(blob: string | Uint8Array): ByteString {\n  if (typeof blob === 'string') {\n    return ByteString.fromBase64String(blob);\n  } else {\n    return ByteString.fromUint8Array(blob);\n  }\n}\n\n/** Returns a reference value for the provided database and key. */\nexport function refValue(databaseId: DatabaseId, key: DocumentKey): api.Value {\n  return {\n    referenceValue: `projects/${databaseId.projectId}/databases/${\n      databaseId.database\n    }/documents/${key.path.canonicalString()}`\n  };\n}\n\n/** Returns true if `value` is an IntegerValue . */\nexport function isInteger(\n  value?: api.Value | null\n): value is { integerValue: string | number } {\n  return !!value && 'integerValue' in value;\n}\n\n/** Returns true if `value` is a DoubleValue. */\nexport function isDouble(\n  value?: api.Value | null\n): value is { doubleValue: string | number } {\n  return !!value && 'doubleValue' in value;\n}\n\n/** Returns true if `value` is either an IntegerValue or a DoubleValue. */\nexport function isNumber(value?: api.Value | null): boolean {\n  return isInteger(value) || isDouble(value);\n}\n\n/** Returns true if `value` is an ArrayValue. */\nexport function isArray(\n  value?: api.Value | null\n): value is { arrayValue: api.ArrayValue } {\n  return !!value && 'arrayValue' in value;\n}\n\n/** Returns true if `value` is a ReferenceValue. */\nexport function isReferenceValue(\n  value?: api.Value | null\n): value is { referenceValue: string } {\n  return !!value && 'referenceValue' in value;\n}\n\n/** Returns true if `value` is a NullValue. */\nexport function isNullValue(\n  value?: api.Value | null\n): value is { nullValue: 'NULL_VALUE' } {\n  return !!value && 'nullValue' in value;\n}\n\n/** Returns true if `value` is NaN. */\nexport function isNanValue(\n  value?: api.Value | null\n): value is { doubleValue: 'NaN' | number } {\n  return !!value && 'doubleValue' in value && isNaN(Number(value.doubleValue));\n}\n\n/** Returns true if `value` is a MapValue. */\nexport function isMapValue(\n  value?: api.Value | null\n): value is { mapValue: api.MapValue } {\n  return !!value && 'mapValue' in value;\n}\n","/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport * as api from '../protos/firestore_proto_api';\n\nimport { Timestamp } from '../api/timestamp';\nimport { debugAssert } from '../util/assert';\nimport { JsonProtoSerializer } from '../remote/serializer';\nimport {\n  valueEquals,\n  isArray,\n  isInteger,\n  isNumber,\n  normalizeNumber\n} from './values';\nimport { serverTimestamp } from './server_timestamps';\nimport { arrayEquals } from '../util/misc';\n\n/** Represents a transform within a TransformMutation. */\nexport interface TransformOperation {\n  /**\n   * Computes the local transform result against the provided `previousValue`,\n   * optionally using the provided localWriteTime.\n   */\n  applyToLocalView(\n    previousValue: api.Value | null,\n    localWriteTime: Timestamp\n  ): api.Value;\n\n  /**\n   * Computes a final transform result after the transform has been acknowledged\n   * by the server, potentially using the server-provided transformResult.\n   */\n  applyToRemoteDocument(\n    previousValue: api.Value | null,\n    transformResult: api.Value | null\n  ): api.Value;\n\n  /**\n   * If this transform operation is not idempotent, returns the base value to\n   * persist for this transform. If a base value is returned, the transform\n   * operation is always applied to this base value, even if document has\n   * already been updated.\n   *\n   * Base values provide consistent behavior for non-idempotent transforms and\n   * allow us to return the same latency-compensated value even if the backend\n   * has already applied the transform operation. The base value is null for\n   * idempotent transforms, as they can be re-played even if the backend has\n   * already applied them.\n   *\n   * @return a base value to store along with the mutation, or null for\n   * idempotent transforms.\n   */\n  computeBaseValue(previousValue: api.Value | null): api.Value | null;\n\n  isEqual(other: TransformOperation): boolean;\n}\n\n/** Transforms a value into a server-generated timestamp. */\nexport class ServerTimestampTransform implements TransformOperation {\n  private constructor() {}\n  static instance = new ServerTimestampTransform();\n\n  applyToLocalView(\n    previousValue: api.Value | null,\n    localWriteTime: Timestamp\n  ): api.Value {\n    return serverTimestamp(localWriteTime!, previousValue);\n  }\n\n  applyToRemoteDocument(\n    previousValue: api.Value | null,\n    transformResult: api.Value | null\n  ): api.Value {\n    return transformResult!;\n  }\n\n  computeBaseValue(previousValue: api.Value | null): api.Value | null {\n    return null; // Server timestamps are idempotent and don't require a base value.\n  }\n\n  isEqual(other: TransformOperation): boolean {\n    return other instanceof ServerTimestampTransform;\n  }\n}\n\n/** Transforms an array value via a union operation. */\nexport class ArrayUnionTransformOperation implements TransformOperation {\n  constructor(readonly elements: api.Value[]) {}\n\n  applyToLocalView(\n    previousValue: api.Value | null,\n    localWriteTime: Timestamp\n  ): api.Value {\n    return this.apply(previousValue);\n  }\n\n  applyToRemoteDocument(\n    previousValue: api.Value | null,\n    transformResult: api.Value | null\n  ): api.Value {\n    // The server just sends null as the transform result for array operations,\n    // so we have to calculate a result the same as we do for local\n    // applications.\n    return this.apply(previousValue);\n  }\n\n  private apply(previousValue: api.Value | null): api.Value {\n    const values = coercedFieldValuesArray(previousValue);\n    for (const toUnion of this.elements) {\n      if (!values.some(element => valueEquals(element, toUnion))) {\n        values.push(toUnion);\n      }\n    }\n    return { arrayValue: { values } };\n  }\n\n  computeBaseValue(previousValue: api.Value | null): api.Value | null {\n    return null; // Array transforms are idempotent and don't require a base value.\n  }\n\n  isEqual(other: TransformOperation): boolean {\n    return (\n      other instanceof ArrayUnionTransformOperation &&\n      arrayEquals(this.elements, other.elements, valueEquals)\n    );\n  }\n}\n\n/** Transforms an array value via a remove operation. */\nexport class ArrayRemoveTransformOperation implements TransformOperation {\n  constructor(readonly elements: api.Value[]) {}\n\n  applyToLocalView(\n    previousValue: api.Value | null,\n    localWriteTime: Timestamp\n  ): api.Value {\n    return this.apply(previousValue);\n  }\n\n  applyToRemoteDocument(\n    previousValue: api.Value | null,\n    transformResult: api.Value | null\n  ): api.Value {\n    // The server just sends null as the transform result for array operations,\n    // so we have to calculate a result the same as we do for local\n    // applications.\n    return this.apply(previousValue);\n  }\n\n  private apply(previousValue: api.Value | null): api.Value {\n    let values = coercedFieldValuesArray(previousValue);\n    for (const toRemove of this.elements) {\n      values = values.filter(element => !valueEquals(element, toRemove));\n    }\n    return { arrayValue: { values } };\n  }\n\n  computeBaseValue(previousValue: api.Value | null): api.Value | null {\n    return null; // Array transforms are idempotent and don't require a base value.\n  }\n\n  isEqual(other: TransformOperation): boolean {\n    return (\n      other instanceof ArrayRemoveTransformOperation &&\n      arrayEquals(this.elements, other.elements, valueEquals)\n    );\n  }\n}\n\n/**\n * Implements the backend semantics for locally computed NUMERIC_ADD (increment)\n * transforms. Converts all field values to integers or doubles, but unlike the\n * backend does not cap integer values at 2^63. Instead, JavaScript number\n * arithmetic is used and precision loss can occur for values greater than 2^53.\n */\nexport class NumericIncrementTransformOperation implements TransformOperation {\n  constructor(\n    private readonly serializer: JsonProtoSerializer,\n    readonly operand: api.Value\n  ) {\n    debugAssert(\n      isNumber(operand),\n      'NumericIncrementTransform transform requires a NumberValue'\n    );\n  }\n\n  applyToLocalView(\n    previousValue: api.Value | null,\n    localWriteTime: Timestamp\n  ): api.Value {\n    // PORTING NOTE: Since JavaScript's integer arithmetic is limited to 53 bit\n    // precision and resolves overflows by reducing precision, we do not\n    // manually cap overflows at 2^63.\n    const baseValue = this.computeBaseValue(previousValue);\n    const sum = this.asNumber(baseValue) + this.asNumber(this.operand);\n    if (isInteger(baseValue) && isInteger(this.operand)) {\n      return this.serializer.toInteger(sum);\n    } else {\n      return this.serializer.toDouble(sum);\n    }\n  }\n\n  applyToRemoteDocument(\n    previousValue: api.Value | null,\n    transformResult: api.Value | null\n  ): api.Value {\n    debugAssert(\n      transformResult !== null,\n      \"Didn't receive transformResult for NUMERIC_ADD transform\"\n    );\n    return transformResult;\n  }\n\n  /**\n   * Inspects the provided value, returning the provided value if it is already\n   * a NumberValue, otherwise returning a coerced value of 0.\n   */\n  computeBaseValue(previousValue: api.Value | null): api.Value {\n    return isNumber(previousValue) ? previousValue! : { integerValue: 0 };\n  }\n\n  isEqual(other: TransformOperation): boolean {\n    return (\n      other instanceof NumericIncrementTransformOperation &&\n      valueEquals(this.operand, other.operand)\n    );\n  }\n\n  private asNumber(value: api.Value): number {\n    return normalizeNumber(value.integerValue || value.doubleValue);\n  }\n}\n\nfunction coercedFieldValuesArray(value: api.Value | null): api.Value[] {\n  return isArray(value) && value.arrayValue.values\n    ? value.arrayValue.values.slice()\n    : [];\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport * as api from '../protos/firestore_proto_api';\n\nimport { Timestamp } from '../api/timestamp';\nimport { SnapshotVersion } from '../core/snapshot_version';\nimport { debugAssert, fail, hardAssert } from '../util/assert';\nimport { SortedSet } from '../util/sorted_set';\n\nimport {\n  Document,\n  MaybeDocument,\n  NoDocument,\n  UnknownDocument\n} from './document';\nimport { DocumentKey } from './document_key';\nimport { ObjectValue, ObjectValueBuilder } from './field_value';\nimport { FieldPath } from './path';\nimport { TransformOperation } from './transform_operation';\nimport { arrayEquals } from '../util/misc';\n\n/**\n * Provides a set of fields that can be used to partially patch a document.\n * FieldMask is used in conjunction with ObjectValue.\n * Examples:\n *   foo - Overwrites foo entirely with the provided value. If foo is not\n *         present in the companion ObjectValue, the field is deleted.\n *   foo.bar - Overwrites only the field bar of the object foo.\n *             If foo is not an object, foo is replaced with an object\n *             containing foo\n */\nexport class FieldMask {\n  constructor(readonly fields: SortedSet<FieldPath>) {\n    // TODO(dimond): validation of FieldMask\n  }\n\n  static fromSet(fields: SortedSet<FieldPath>): FieldMask {\n    return new FieldMask(fields);\n  }\n\n  static fromArray(fields: FieldPath[]): FieldMask {\n    let fieldsAsSet = new SortedSet<FieldPath>(FieldPath.comparator);\n    fields.forEach(fieldPath => (fieldsAsSet = fieldsAsSet.add(fieldPath)));\n    return new FieldMask(fieldsAsSet);\n  }\n\n  /**\n   * Verifies that `fieldPath` is included by at least one field in this field\n   * mask.\n   *\n   * This is an O(n) operation, where `n` is the size of the field mask.\n   */\n  covers(fieldPath: FieldPath): boolean {\n    let found = false;\n    this.fields.forEach(fieldMaskPath => {\n      if (fieldMaskPath.isPrefixOf(fieldPath)) {\n        found = true;\n      }\n    });\n    return found;\n  }\n\n  isEqual(other: FieldMask): boolean {\n    return this.fields.isEqual(other.fields);\n  }\n}\n\n/** A field path and the TransformOperation to perform upon it. */\nexport class FieldTransform {\n  constructor(\n    readonly field: FieldPath,\n    readonly transform: TransformOperation\n  ) {}\n\n  isEqual(other: FieldTransform): boolean {\n    return (\n      this.field.isEqual(other.field) && this.transform.isEqual(other.transform)\n    );\n  }\n}\n\n/** The result of successfully applying a mutation to the backend. */\nexport class MutationResult {\n  constructor(\n    /**\n     * The version at which the mutation was committed:\n     *\n     * - For most operations, this is the updateTime in the WriteResult.\n     * - For deletes, the commitTime of the WriteResponse (because deletes are\n     *   not stored and have no updateTime).\n     *\n     * Note that these versions can be different: No-op writes will not change\n     * the updateTime even though the commitTime advances.\n     */\n    readonly version: SnapshotVersion,\n    /**\n     * The resulting fields returned from the backend after a\n     * TransformMutation has been committed. Contains one FieldValue for each\n     * FieldTransform that was in the mutation.\n     *\n     * Will be null if the mutation was not a TransformMutation.\n     */\n    readonly transformResults: Array<api.Value | null> | null\n  ) {}\n}\n\nexport const enum MutationType {\n  Set,\n  Patch,\n  Transform,\n  Delete,\n  Verify\n}\n\n/**\n * Encodes a precondition for a mutation. This follows the model that the\n * backend accepts with the special case of an explicit \"empty\" precondition\n * (meaning no precondition).\n */\nexport class Precondition {\n  static readonly NONE = new Precondition();\n\n  private constructor(\n    readonly updateTime?: SnapshotVersion,\n    readonly exists?: boolean\n  ) {\n    debugAssert(\n      updateTime === undefined || exists === undefined,\n      'Precondition can specify \"exists\" or \"updateTime\" but not both'\n    );\n  }\n\n  /** Creates a new Precondition with an exists flag. */\n  static exists(exists: boolean): Precondition {\n    return new Precondition(undefined, exists);\n  }\n\n  /** Creates a new Precondition based on a version a document exists at. */\n  static updateTime(version: SnapshotVersion): Precondition {\n    return new Precondition(version);\n  }\n\n  /** Returns whether this Precondition is empty. */\n  get isNone(): boolean {\n    return this.updateTime === undefined && this.exists === undefined;\n  }\n\n  /**\n   * Returns true if the preconditions is valid for the given document\n   * (or null if no document is available).\n   */\n  isValidFor(maybeDoc: MaybeDocument | null): boolean {\n    if (this.updateTime !== undefined) {\n      return (\n        maybeDoc instanceof Document &&\n        maybeDoc.version.isEqual(this.updateTime)\n      );\n    } else if (this.exists !== undefined) {\n      return this.exists === maybeDoc instanceof Document;\n    } else {\n      debugAssert(this.isNone, 'Precondition should be empty');\n      return true;\n    }\n  }\n\n  isEqual(other: Precondition): boolean {\n    return (\n      this.exists === other.exists &&\n      (this.updateTime\n        ? !!other.updateTime && this.updateTime.isEqual(other.updateTime)\n        : !other.updateTime)\n    );\n  }\n}\n\n/**\n * A mutation describes a self-contained change to a document. Mutations can\n * create, replace, delete, and update subsets of documents.\n *\n * Mutations not only act on the value of the document but also its version.\n *\n * For local mutations (mutations that haven't been committed yet), we preserve\n * the existing version for Set, Patch, and Transform mutations. For Delete\n * mutations, we reset the version to 0.\n *\n * Here's the expected transition table.\n *\n * MUTATION           APPLIED TO            RESULTS IN\n *\n * SetMutation        Document(v3)          Document(v3)\n * SetMutation        NoDocument(v3)        Document(v0)\n * SetMutation        null                  Document(v0)\n * PatchMutation      Document(v3)          Document(v3)\n * PatchMutation      NoDocument(v3)        NoDocument(v3)\n * PatchMutation      null                  null\n * TransformMutation  Document(v3)          Document(v3)\n * TransformMutation  NoDocument(v3)        NoDocument(v3)\n * TransformMutation  null                  null\n * DeleteMutation     Document(v3)          NoDocument(v0)\n * DeleteMutation     NoDocument(v3)        NoDocument(v0)\n * DeleteMutation     null                  NoDocument(v0)\n *\n * For acknowledged mutations, we use the updateTime of the WriteResponse as\n * the resulting version for Set, Patch, and Transform mutations. As deletes\n * have no explicit update time, we use the commitTime of the WriteResponse for\n * Delete mutations.\n *\n * If a mutation is acknowledged by the backend but fails the precondition check\n * locally, we return an `UnknownDocument` and rely on Watch to send us the\n * updated version.\n *\n * Note that TransformMutations don't create Documents (in the case of being\n * applied to a NoDocument), even though they would on the backend. This is\n * because the client always combines the TransformMutation with a SetMutation\n * or PatchMutation and we only want to apply the transform if the prior\n * mutation resulted in a Document (always true for a SetMutation, but not\n * necessarily for a PatchMutation).\n *\n * ## Subclassing Notes\n *\n * Subclasses of Mutation need to implement applyToRemoteDocument() and\n * applyToLocalView() to implement the actual behavior of applying the mutation\n * to some source document.\n */\nexport abstract class Mutation {\n  abstract readonly type: MutationType;\n  abstract readonly key: DocumentKey;\n  abstract readonly precondition: Precondition;\n\n  /**\n   * Applies this mutation to the given MaybeDocument or null for the purposes\n   * of computing a new remote document. If the input document doesn't match the\n   * expected state (e.g. it is null or outdated), an `UnknownDocument` can be\n   * returned.\n   *\n   * @param maybeDoc The document to mutate. The input document can be null if\n   *     the client has no knowledge of the pre-mutation state of the document.\n   * @param mutationResult The result of applying the mutation from the backend.\n   * @return The mutated document. The returned document may be an\n   *     UnknownDocument if the mutation could not be applied to the locally\n   *     cached base document.\n   */\n  abstract applyToRemoteDocument(\n    maybeDoc: MaybeDocument | null,\n    mutationResult: MutationResult\n  ): MaybeDocument;\n\n  /**\n   * Applies this mutation to the given MaybeDocument or null for the purposes\n   * of computing the new local view of a document. Both the input and returned\n   * documents can be null.\n   *\n   * @param maybeDoc The document to mutate. The input document can be null if\n   *     the client has no knowledge of the pre-mutation state of the document.\n   * @param baseDoc The state of the document prior to this mutation batch. The\n   *     input document can be null if the client has no knowledge of the\n   *     pre-mutation state of the document.\n   * @param localWriteTime A timestamp indicating the local write time of the\n   *     batch this mutation is a part of.\n   * @return The mutated document. The returned document may be null, but only\n   *     if maybeDoc was null and the mutation would not create a new document.\n   */\n  abstract applyToLocalView(\n    maybeDoc: MaybeDocument | null,\n    baseDoc: MaybeDocument | null,\n    localWriteTime: Timestamp\n  ): MaybeDocument | null;\n\n  /**\n   * If this mutation is not idempotent, returns the base value to persist with\n   * this mutation. If a base value is returned, the mutation is always applied\n   * to this base value, even if document has already been updated.\n   *\n   * The base value is a sparse object that consists of only the document\n   * fields for which this mutation contains a non-idempotent transformation\n   * (e.g. a numeric increment). The provided value guarantees consistent\n   * behavior for non-idempotent transforms and allow us to return the same\n   * latency-compensated value even if the backend has already applied the\n   * mutation. The base value is null for idempotent mutations, as they can be\n   * re-played even if the backend has already applied them.\n   *\n   * @return a base value to store along with the mutation, or null for\n   * idempotent mutations.\n   */\n  abstract extractBaseValue(maybeDoc: MaybeDocument | null): ObjectValue | null;\n\n  abstract isEqual(other: Mutation): boolean;\n\n  protected verifyKeyMatches(maybeDoc: MaybeDocument | null): void {\n    if (maybeDoc != null) {\n      debugAssert(\n        maybeDoc.key.isEqual(this.key),\n        'Can only apply a mutation to a document with the same key'\n      );\n    }\n  }\n\n  /**\n   * Returns the version from the given document for use as the result of a\n   * mutation. Mutations are defined to return the version of the base document\n   * only if it is an existing document. Deleted and unknown documents have a\n   * post-mutation version of SnapshotVersion.MIN.\n   */\n  protected static getPostMutationVersion(\n    maybeDoc: MaybeDocument | null\n  ): SnapshotVersion {\n    if (maybeDoc instanceof Document) {\n      return maybeDoc.version;\n    } else {\n      return SnapshotVersion.MIN;\n    }\n  }\n}\n\n/**\n * A mutation that creates or replaces the document at the given key with the\n * object value contents.\n */\nexport class SetMutation extends Mutation {\n  constructor(\n    readonly key: DocumentKey,\n    readonly value: ObjectValue,\n    readonly precondition: Precondition\n  ) {\n    super();\n  }\n\n  readonly type: MutationType = MutationType.Set;\n\n  applyToRemoteDocument(\n    maybeDoc: MaybeDocument | null,\n    mutationResult: MutationResult\n  ): MaybeDocument {\n    this.verifyKeyMatches(maybeDoc);\n\n    debugAssert(\n      mutationResult.transformResults == null,\n      'Transform results received by SetMutation.'\n    );\n\n    // Unlike applyToLocalView, if we're applying a mutation to a remote\n    // document the server has accepted the mutation so the precondition must\n    // have held.\n\n    const version = mutationResult.version;\n    return new Document(this.key, version, this.value, {\n      hasCommittedMutations: true\n    });\n  }\n\n  applyToLocalView(\n    maybeDoc: MaybeDocument | null,\n    baseDoc: MaybeDocument | null,\n    localWriteTime: Timestamp\n  ): MaybeDocument | null {\n    this.verifyKeyMatches(maybeDoc);\n\n    if (!this.precondition.isValidFor(maybeDoc)) {\n      return maybeDoc;\n    }\n\n    const version = Mutation.getPostMutationVersion(maybeDoc);\n    return new Document(this.key, version, this.value, {\n      hasLocalMutations: true\n    });\n  }\n\n  extractBaseValue(maybeDoc: MaybeDocument | null): null {\n    return null;\n  }\n\n  isEqual(other: Mutation): boolean {\n    return (\n      other instanceof SetMutation &&\n      this.key.isEqual(other.key) &&\n      this.value.isEqual(other.value) &&\n      this.precondition.isEqual(other.precondition)\n    );\n  }\n}\n\n/**\n * A mutation that modifies fields of the document at the given key with the\n * given values. The values are applied through a field mask:\n *\n *  * When a field is in both the mask and the values, the corresponding field\n *    is updated.\n *  * When a field is in neither the mask nor the values, the corresponding\n *    field is unmodified.\n *  * When a field is in the mask but not in the values, the corresponding field\n *    is deleted.\n *  * When a field is not in the mask but is in the values, the values map is\n *    ignored.\n */\nexport class PatchMutation extends Mutation {\n  constructor(\n    readonly key: DocumentKey,\n    readonly data: ObjectValue,\n    readonly fieldMask: FieldMask,\n    readonly precondition: Precondition\n  ) {\n    super();\n  }\n\n  readonly type: MutationType = MutationType.Patch;\n\n  applyToRemoteDocument(\n    maybeDoc: MaybeDocument | null,\n    mutationResult: MutationResult\n  ): MaybeDocument {\n    this.verifyKeyMatches(maybeDoc);\n\n    debugAssert(\n      mutationResult.transformResults == null,\n      'Transform results received by PatchMutation.'\n    );\n\n    if (!this.precondition.isValidFor(maybeDoc)) {\n      // Since the mutation was not rejected, we know that the  precondition\n      // matched on the backend. We therefore must not have the expected version\n      // of the document in our cache and return an UnknownDocument with the\n      // known updateTime.\n      return new UnknownDocument(this.key, mutationResult.version);\n    }\n\n    const newData = this.patchDocument(maybeDoc);\n    return new Document(this.key, mutationResult.version, newData, {\n      hasCommittedMutations: true\n    });\n  }\n\n  applyToLocalView(\n    maybeDoc: MaybeDocument | null,\n    baseDoc: MaybeDocument | null,\n    localWriteTime: Timestamp\n  ): MaybeDocument | null {\n    this.verifyKeyMatches(maybeDoc);\n\n    if (!this.precondition.isValidFor(maybeDoc)) {\n      return maybeDoc;\n    }\n\n    const version = Mutation.getPostMutationVersion(maybeDoc);\n    const newData = this.patchDocument(maybeDoc);\n    return new Document(this.key, version, newData, {\n      hasLocalMutations: true\n    });\n  }\n\n  extractBaseValue(maybeDoc: MaybeDocument | null): null {\n    return null;\n  }\n\n  isEqual(other: Mutation): boolean {\n    return (\n      other instanceof PatchMutation &&\n      this.key.isEqual(other.key) &&\n      this.fieldMask.isEqual(other.fieldMask) &&\n      this.precondition.isEqual(other.precondition)\n    );\n  }\n\n  /**\n   * Patches the data of document if available or creates a new document. Note\n   * that this does not check whether or not the precondition of this patch\n   * holds.\n   */\n  private patchDocument(maybeDoc: MaybeDocument | null): ObjectValue {\n    let data: ObjectValue;\n    if (maybeDoc instanceof Document) {\n      data = maybeDoc.data();\n    } else {\n      data = ObjectValue.EMPTY;\n    }\n    return this.patchObject(data);\n  }\n\n  private patchObject(data: ObjectValue): ObjectValue {\n    const builder = data.toBuilder();\n    this.fieldMask.fields.forEach(fieldPath => {\n      if (!fieldPath.isEmpty()) {\n        const newValue = this.data.field(fieldPath);\n        if (newValue !== null) {\n          builder.set(fieldPath, newValue);\n        } else {\n          builder.delete(fieldPath);\n        }\n      }\n    });\n    return builder.build();\n  }\n}\n\n/**\n * A mutation that modifies specific fields of the document with transform\n * operations. Currently the only supported transform is a server timestamp, but\n * IP Address, increment(n), etc. could be supported in the future.\n *\n * It is somewhat similar to a PatchMutation in that it patches specific fields\n * and has no effect when applied to a null or NoDocument (see comment on\n * Mutation for rationale).\n */\nexport class TransformMutation extends Mutation {\n  readonly type: MutationType = MutationType.Transform;\n\n  // NOTE: We set a precondition of exists: true as a safety-check, since we\n  // always combine TransformMutations with a SetMutation or PatchMutation which\n  // (if successful) should end up with an existing document.\n  readonly precondition = Precondition.exists(true);\n\n  constructor(\n    readonly key: DocumentKey,\n    readonly fieldTransforms: FieldTransform[]\n  ) {\n    super();\n  }\n\n  applyToRemoteDocument(\n    maybeDoc: MaybeDocument | null,\n    mutationResult: MutationResult\n  ): MaybeDocument {\n    this.verifyKeyMatches(maybeDoc);\n\n    hardAssert(\n      mutationResult.transformResults != null,\n      'Transform results missing for TransformMutation.'\n    );\n\n    if (!this.precondition.isValidFor(maybeDoc)) {\n      // Since the mutation was not rejected, we know that the  precondition\n      // matched on the backend. We therefore must not have the expected version\n      // of the document in our cache and return an UnknownDocument with the\n      // known updateTime.\n      return new UnknownDocument(this.key, mutationResult.version);\n    }\n\n    const doc = this.requireDocument(maybeDoc);\n    const transformResults = this.serverTransformResults(\n      maybeDoc,\n      mutationResult.transformResults!\n    );\n\n    const version = mutationResult.version;\n    const newData = this.transformObject(doc.data(), transformResults);\n    return new Document(this.key, version, newData, {\n      hasCommittedMutations: true\n    });\n  }\n\n  applyToLocalView(\n    maybeDoc: MaybeDocument | null,\n    baseDoc: MaybeDocument | null,\n    localWriteTime: Timestamp\n  ): MaybeDocument | null {\n    this.verifyKeyMatches(maybeDoc);\n\n    if (!this.precondition.isValidFor(maybeDoc)) {\n      return maybeDoc;\n    }\n\n    const doc = this.requireDocument(maybeDoc);\n    const transformResults = this.localTransformResults(\n      localWriteTime,\n      maybeDoc,\n      baseDoc\n    );\n    const newData = this.transformObject(doc.data(), transformResults);\n    return new Document(this.key, doc.version, newData, {\n      hasLocalMutations: true\n    });\n  }\n\n  extractBaseValue(maybeDoc: MaybeDocument | null): ObjectValue | null {\n    let baseObject: ObjectValueBuilder | null = null;\n    for (const fieldTransform of this.fieldTransforms) {\n      const existingValue =\n        maybeDoc instanceof Document\n          ? maybeDoc.field(fieldTransform.field)\n          : undefined;\n      const coercedValue = fieldTransform.transform.computeBaseValue(\n        existingValue || null\n      );\n\n      if (coercedValue != null) {\n        if (baseObject == null) {\n          baseObject = ObjectValue.newBuilder().set(\n            fieldTransform.field,\n            coercedValue\n          );\n        } else {\n          baseObject = baseObject.set(fieldTransform.field, coercedValue);\n        }\n      }\n    }\n    return baseObject ? baseObject.build() : null;\n  }\n\n  isEqual(other: Mutation): boolean {\n    return (\n      other instanceof TransformMutation &&\n      this.key.isEqual(other.key) &&\n      arrayEquals(this.fieldTransforms, other.fieldTransforms, (l, r) =>\n        l.isEqual(r)\n      ) &&\n      this.precondition.isEqual(other.precondition)\n    );\n  }\n\n  /**\n   * Asserts that the given MaybeDocument is actually a Document and verifies\n   * that it matches the key for this mutation. Since we only support\n   * transformations with precondition exists this method is guaranteed to be\n   * safe.\n   */\n  private requireDocument(maybeDoc: MaybeDocument | null): Document {\n    debugAssert(\n      maybeDoc instanceof Document,\n      'Unknown MaybeDocument type ' + maybeDoc\n    );\n    debugAssert(\n      maybeDoc.key.isEqual(this.key),\n      'Can only transform a document with the same key'\n    );\n    return maybeDoc;\n  }\n\n  /**\n   * Creates a list of \"transform results\" (a transform result is a field value\n   * representing the result of applying a transform) for use after a\n   * TransformMutation has been acknowledged by the server.\n   *\n   * @param baseDoc The document prior to applying this mutation batch.\n   * @param serverTransformResults The transform results received by the server.\n   * @return The transform results list.\n   */\n  private serverTransformResults(\n    baseDoc: MaybeDocument | null,\n    serverTransformResults: Array<api.Value | null>\n  ): api.Value[] {\n    const transformResults: api.Value[] = [];\n    hardAssert(\n      this.fieldTransforms.length === serverTransformResults.length,\n      `server transform result count (${serverTransformResults.length}) ` +\n        `should match field transform count (${this.fieldTransforms.length})`\n    );\n\n    for (let i = 0; i < serverTransformResults.length; i++) {\n      const fieldTransform = this.fieldTransforms[i];\n      const transform = fieldTransform.transform;\n      let previousValue: api.Value | null = null;\n      if (baseDoc instanceof Document) {\n        previousValue = baseDoc.field(fieldTransform.field);\n      }\n      transformResults.push(\n        transform.applyToRemoteDocument(\n          previousValue,\n          serverTransformResults[i]\n        )\n      );\n    }\n    return transformResults;\n  }\n\n  /**\n   * Creates a list of \"transform results\" (a transform result is a field value\n   * representing the result of applying a transform) for use when applying a\n   * TransformMutation locally.\n   *\n   * @param localWriteTime The local time of the transform mutation (used to\n   *     generate ServerTimestampValues).\n   * @param maybeDoc The current state of the document after applying all\n   *     previous mutations.\n   * @param baseDoc The document prior to applying this mutation batch.\n   * @return The transform results list.\n   */\n  private localTransformResults(\n    localWriteTime: Timestamp,\n    maybeDoc: MaybeDocument | null,\n    baseDoc: MaybeDocument | null\n  ): api.Value[] {\n    const transformResults: api.Value[] = [];\n    for (const fieldTransform of this.fieldTransforms) {\n      const transform = fieldTransform.transform;\n\n      let previousValue: api.Value | null = null;\n      if (maybeDoc instanceof Document) {\n        previousValue = maybeDoc.field(fieldTransform.field);\n      }\n\n      if (previousValue === null && baseDoc instanceof Document) {\n        // If the current document does not contain a value for the mutated\n        // field, use the value that existed before applying this mutation\n        // batch. This solves an edge case where a PatchMutation clears the\n        // values in a nested map before the TransformMutation is applied.\n        previousValue = baseDoc.field(fieldTransform.field);\n      }\n\n      transformResults.push(\n        transform.applyToLocalView(previousValue, localWriteTime)\n      );\n    }\n    return transformResults;\n  }\n\n  private transformObject(\n    data: ObjectValue,\n    transformResults: api.Value[]\n  ): ObjectValue {\n    debugAssert(\n      transformResults.length === this.fieldTransforms.length,\n      'TransformResults length mismatch.'\n    );\n\n    const builder = data.toBuilder();\n    for (let i = 0; i < this.fieldTransforms.length; i++) {\n      const fieldTransform = this.fieldTransforms[i];\n      const fieldPath = fieldTransform.field;\n      builder.set(fieldPath, transformResults[i]);\n    }\n    return builder.build();\n  }\n}\n\n/** A mutation that deletes the document at the given key. */\nexport class DeleteMutation extends Mutation {\n  constructor(readonly key: DocumentKey, readonly precondition: Precondition) {\n    super();\n  }\n\n  readonly type: MutationType = MutationType.Delete;\n\n  applyToRemoteDocument(\n    maybeDoc: MaybeDocument | null,\n    mutationResult: MutationResult\n  ): MaybeDocument {\n    this.verifyKeyMatches(maybeDoc);\n\n    debugAssert(\n      mutationResult.transformResults == null,\n      'Transform results received by DeleteMutation.'\n    );\n\n    // Unlike applyToLocalView, if we're applying a mutation to a remote\n    // document the server has accepted the mutation so the precondition must\n    // have held.\n\n    return new NoDocument(this.key, mutationResult.version, {\n      hasCommittedMutations: true\n    });\n  }\n\n  applyToLocalView(\n    maybeDoc: MaybeDocument | null,\n    baseDoc: MaybeDocument | null,\n    localWriteTime: Timestamp\n  ): MaybeDocument | null {\n    this.verifyKeyMatches(maybeDoc);\n\n    if (!this.precondition.isValidFor(maybeDoc)) {\n      return maybeDoc;\n    }\n\n    if (maybeDoc) {\n      debugAssert(\n        maybeDoc.key.isEqual(this.key),\n        'Can only apply mutation to document with same key'\n      );\n    }\n    return new NoDocument(this.key, SnapshotVersion.forDeletedDoc());\n  }\n\n  extractBaseValue(maybeDoc: MaybeDocument | null): null {\n    return null;\n  }\n\n  isEqual(other: Mutation): boolean {\n    return (\n      other instanceof DeleteMutation &&\n      this.key.isEqual(other.key) &&\n      this.precondition.isEqual(other.precondition)\n    );\n  }\n}\n\n/**\n * A mutation that verifies the existence of the document at the given key with\n * the provided precondition.\n *\n * The `verify` operation is only used in Transactions, and this class serves\n * primarily to facilitate serialization into protos.\n */\nexport class VerifyMutation extends Mutation {\n  constructor(readonly key: DocumentKey, readonly precondition: Precondition) {\n    super();\n  }\n\n  readonly type: MutationType = MutationType.Verify;\n\n  applyToRemoteDocument(\n    maybeDoc: MaybeDocument | null,\n    mutationResult: MutationResult\n  ): MaybeDocument {\n    fail('VerifyMutation should only be used in Transactions.');\n  }\n\n  applyToLocalView(\n    maybeDoc: MaybeDocument | null,\n    baseDoc: MaybeDocument | null,\n    localWriteTime: Timestamp\n  ): MaybeDocument | null {\n    fail('VerifyMutation should only be used in Transactions.');\n  }\n\n  extractBaseValue(maybeDoc: MaybeDocument | null): null {\n    fail('VerifyMutation should only be used in Transactions.');\n  }\n\n  isEqual(other: Mutation): boolean {\n    return (\n      other instanceof VerifyMutation &&\n      this.key.isEqual(other.key) &&\n      this.precondition.isEqual(other.precondition)\n    );\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport * as api from '../protos/firestore_proto_api';\n\nimport { debugAssert } from '../util/assert';\nimport { FieldMask } from './mutation';\nimport { FieldPath } from './path';\nimport { isServerTimestamp } from './server_timestamps';\nimport { valueEquals, isMapValue, typeOrder } from './values';\nimport { forEach } from '../util/obj';\nimport { SortedSet } from '../util/sorted_set';\n\nexport interface JsonObject<T> {\n  [name: string]: T;\n}\n\nexport const enum TypeOrder {\n  // This order is based on the backend's ordering, but modified to support\n  // server timestamps.\n  NullValue = 0,\n  BooleanValue = 1,\n  NumberValue = 2,\n  TimestampValue = 3,\n  ServerTimestampValue = 4,\n  StringValue = 5,\n  BlobValue = 6,\n  RefValue = 7,\n  GeoPointValue = 8,\n  ArrayValue = 9,\n  ObjectValue = 10\n}\n\n/**\n * An ObjectValue represents a MapValue in the Firestore Proto and offers the\n * ability to add and remove fields (via the ObjectValueBuilder).\n */\nexport class ObjectValue {\n  static EMPTY = new ObjectValue({ mapValue: {} });\n\n  constructor(public readonly proto: { mapValue: api.MapValue }) {\n    debugAssert(\n      !isServerTimestamp(proto),\n      'ServerTimestamps should be converted to ServerTimestampValue'\n    );\n  }\n\n  /** Returns a new Builder instance that is based on an empty object. */\n  static newBuilder(): ObjectValueBuilder {\n    return ObjectValue.EMPTY.toBuilder();\n  }\n\n  /**\n   * Returns the value at the given path or null.\n   *\n   * @param path the path to search\n   * @return The value at the path or if there it doesn't exist.\n   */\n  field(path: FieldPath): api.Value | null {\n    if (path.isEmpty()) {\n      return this.proto;\n    } else {\n      let value: api.Value = this.proto;\n      for (let i = 0; i < path.length - 1; ++i) {\n        if (!value.mapValue!.fields) {\n          return null;\n        }\n        value = value.mapValue!.fields[path.get(i)];\n        if (!isMapValue(value)) {\n          return null;\n        }\n      }\n\n      value = (value.mapValue!.fields || {})[path.lastSegment()];\n      return value || null;\n    }\n  }\n\n  /**\n   * Returns a FieldMask built from all FieldPaths starting from this\n   * ObjectValue, including paths from nested objects.\n   */\n  fieldMask(): FieldMask {\n    return this.extractFieldMask(this.proto.mapValue!);\n  }\n\n  private extractFieldMask(value: api.MapValue): FieldMask {\n    let fields = new SortedSet<FieldPath>(FieldPath.comparator);\n    forEach(value.fields || {}, (key, value) => {\n      const currentPath = new FieldPath([key]);\n      if (typeOrder(value) === TypeOrder.ObjectValue) {\n        const nestedMask = this.extractFieldMask(value.mapValue!);\n        const nestedFields = nestedMask.fields;\n        if (nestedFields.isEmpty()) {\n          // Preserve the empty map by adding it to the FieldMask.\n          fields = fields.add(currentPath);\n        } else {\n          // For nested and non-empty ObjectValues, add the FieldPath of the\n          // leaf nodes.\n          nestedFields.forEach(nestedPath => {\n            fields = fields.add(currentPath.child(nestedPath));\n          });\n        }\n      } else {\n        // For nested and non-empty ObjectValues, add the FieldPath of the leaf\n        // nodes.\n        fields = fields.add(currentPath);\n      }\n    });\n    return FieldMask.fromSet(fields);\n  }\n\n  isEqual(other: ObjectValue): boolean {\n    return valueEquals(this.proto, other.proto);\n  }\n\n  /** Creates a ObjectValueBuilder instance that is based on the current value. */\n  toBuilder(): ObjectValueBuilder {\n    return new ObjectValueBuilder(this);\n  }\n}\n\n/**\n * An Overlay, which contains an update to apply. Can either be Value proto, a\n * map of Overlay values (to represent additional nesting at the given key) or\n * `null` (to represent field deletes).\n */\ntype Overlay = Map<string, Overlay> | api.Value | null;\n\n/**\n * An ObjectValueBuilder provides APIs to set and delete fields from an\n * ObjectValue.\n */\nexport class ObjectValueBuilder {\n  /** A map that contains the accumulated changes in this builder. */\n  private overlayMap = new Map<string, Overlay>();\n\n  /**\n   * @param baseObject The object to mutate.\n   */\n  constructor(private readonly baseObject: ObjectValue) {}\n\n  /**\n   * Sets the field to the provided value.\n   *\n   * @param path The field path to set.\n   * @param value The value to set.\n   * @return The current Builder instance.\n   */\n  set(path: FieldPath, value: api.Value): ObjectValueBuilder {\n    debugAssert(\n      !path.isEmpty(),\n      'Cannot set field for empty path on ObjectValue'\n    );\n    this.setOverlay(path, value);\n    return this;\n  }\n\n  /**\n   * Removes the field at the specified path. If there is no field at the\n   * specified path, nothing is changed.\n   *\n   * @param path The field path to remove.\n   * @return The current Builder instance.\n   */\n  delete(path: FieldPath): ObjectValueBuilder {\n    debugAssert(\n      !path.isEmpty(),\n      'Cannot delete field for empty path on ObjectValue'\n    );\n    this.setOverlay(path, null);\n    return this;\n  }\n\n  /**\n   * Adds `value` to the overlay map at `path`. Creates nested map entries if\n   * needed.\n   */\n  private setOverlay(path: FieldPath, value: api.Value | null): void {\n    let currentLevel = this.overlayMap;\n\n    for (let i = 0; i < path.length - 1; ++i) {\n      const currentSegment = path.get(i);\n      let currentValue = currentLevel.get(currentSegment);\n\n      if (currentValue instanceof Map) {\n        // Re-use a previously created map\n        currentLevel = currentValue;\n      } else if (\n        currentValue &&\n        typeOrder(currentValue) === TypeOrder.ObjectValue\n      ) {\n        // Convert the existing Protobuf MapValue into a map\n        currentValue = new Map<string, Overlay>(\n          Object.entries(currentValue.mapValue!.fields || {})\n        );\n        currentLevel.set(currentSegment, currentValue);\n        currentLevel = currentValue;\n      } else {\n        // Create an empty map to represent the current nesting level\n        currentValue = new Map<string, Overlay>();\n        currentLevel.set(currentSegment, currentValue);\n        currentLevel = currentValue;\n      }\n    }\n\n    currentLevel.set(path.lastSegment(), value);\n  }\n\n  /** Returns an ObjectValue with all mutations applied. */\n  build(): ObjectValue {\n    const mergedResult = this.applyOverlay(\n      FieldPath.EMPTY_PATH,\n      this.overlayMap\n    );\n    if (mergedResult != null) {\n      return new ObjectValue(mergedResult);\n    } else {\n      return this.baseObject;\n    }\n  }\n\n  /**\n   * Applies any overlays from `currentOverlays` that exist at `currentPath`\n   * and returns the merged data at `currentPath` (or null if there were no\n   * changes).\n   *\n   * @param currentPath The path at the current nesting level. Can be set to\n   * FieldValue.EMPTY_PATH to represent the root.\n   * @param currentOverlays The overlays at the current nesting level in the\n   * same format as `overlayMap`.\n   * @return The merged data at `currentPath` or null if no modifications\n   * were applied.\n   */\n  private applyOverlay(\n    currentPath: FieldPath,\n    currentOverlays: Map<string, Overlay>\n  ): { mapValue: api.MapValue } | null {\n    let modified = false;\n\n    const existingValue = this.baseObject.field(currentPath);\n    const resultAtPath = isMapValue(existingValue)\n      ? // If there is already data at the current path, base our\n        // modifications on top of the existing data.\n        { ...existingValue.mapValue.fields }\n      : {};\n\n    currentOverlays.forEach((value, pathSegment) => {\n      if (value instanceof Map) {\n        const nested = this.applyOverlay(currentPath.child(pathSegment), value);\n        if (nested != null) {\n          resultAtPath[pathSegment] = nested;\n          modified = true;\n        }\n      } else if (value !== null) {\n        resultAtPath[pathSegment] = value;\n        modified = true;\n      } else if (resultAtPath.hasOwnProperty(pathSegment)) {\n        delete resultAtPath[pathSegment];\n        modified = true;\n      }\n    });\n\n    return modified ? { mapValue: { fields: resultAtPath } } : null;\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport * as api from '../protos/firestore_proto_api';\n\nimport { SnapshotVersion } from '../core/snapshot_version';\nimport { fail } from '../util/assert';\n\nimport { DocumentKey } from './document_key';\nimport { ObjectValue } from './field_value';\nimport { FieldPath } from './path';\nimport { valueCompare } from './values';\n\nexport interface DocumentOptions {\n  hasLocalMutations?: boolean;\n  hasCommittedMutations?: boolean;\n}\n\n/**\n * The result of a lookup for a given path may be an existing document or a\n * marker that this document does not exist at a given version.\n */\nexport abstract class MaybeDocument {\n  constructor(readonly key: DocumentKey, readonly version: SnapshotVersion) {}\n\n  static compareByKey(d1: MaybeDocument, d2: MaybeDocument): number {\n    return DocumentKey.comparator(d1.key, d2.key);\n  }\n\n  /**\n   * Whether this document had a local mutation applied that has not yet been\n   * acknowledged by Watch.\n   */\n  abstract get hasPendingWrites(): boolean;\n\n  abstract isEqual(other: MaybeDocument | null | undefined): boolean;\n\n  abstract toString(): string;\n}\n\n/**\n * Represents a document in Firestore with a key, version, data and whether the\n * data has local mutations applied to it.\n */\nexport class Document extends MaybeDocument {\n  readonly hasLocalMutations: boolean;\n  readonly hasCommittedMutations: boolean;\n\n  constructor(\n    key: DocumentKey,\n    version: SnapshotVersion,\n    private readonly objectValue: ObjectValue,\n    options: DocumentOptions\n  ) {\n    super(key, version);\n    this.hasLocalMutations = !!options.hasLocalMutations;\n    this.hasCommittedMutations = !!options.hasCommittedMutations;\n  }\n\n  field(path: FieldPath): api.Value | null {\n    return this.objectValue.field(path);\n  }\n\n  data(): ObjectValue {\n    return this.objectValue;\n  }\n\n  toProto(): { mapValue: api.MapValue } {\n    return this.objectValue.proto;\n  }\n\n  isEqual(other: MaybeDocument | null | undefined): boolean {\n    return (\n      other instanceof Document &&\n      this.key.isEqual(other.key) &&\n      this.version.isEqual(other.version) &&\n      this.hasLocalMutations === other.hasLocalMutations &&\n      this.hasCommittedMutations === other.hasCommittedMutations &&\n      this.objectValue.isEqual(other.objectValue)\n    );\n  }\n\n  toString(): string {\n    return (\n      `Document(${this.key}, ${\n        this.version\n      }, ${this.objectValue.toString()}, ` +\n      `{hasLocalMutations: ${this.hasLocalMutations}}), ` +\n      `{hasCommittedMutations: ${this.hasCommittedMutations}})`\n    );\n  }\n\n  get hasPendingWrites(): boolean {\n    return this.hasLocalMutations || this.hasCommittedMutations;\n  }\n\n  static compareByField(field: FieldPath, d1: Document, d2: Document): number {\n    const v1 = d1.field(field);\n    const v2 = d2.field(field);\n    if (v1 !== null && v2 !== null) {\n      return valueCompare(v1, v2);\n    } else {\n      return fail(\"Trying to compare documents on fields that don't exist\");\n    }\n  }\n}\n\n/**\n * A class representing a deleted document.\n * Version is set to 0 if we don't point to any specific time, otherwise it\n * denotes time we know it didn't exist at.\n */\nexport class NoDocument extends MaybeDocument {\n  readonly hasCommittedMutations: boolean;\n\n  constructor(\n    key: DocumentKey,\n    version: SnapshotVersion,\n    options?: DocumentOptions\n  ) {\n    super(key, version);\n    this.hasCommittedMutations = !!(options && options.hasCommittedMutations);\n  }\n\n  toString(): string {\n    return `NoDocument(${this.key}, ${this.version})`;\n  }\n\n  get hasPendingWrites(): boolean {\n    return this.hasCommittedMutations;\n  }\n\n  isEqual(other: MaybeDocument | null | undefined): boolean {\n    return (\n      other instanceof NoDocument &&\n      other.hasCommittedMutations === this.hasCommittedMutations &&\n      other.version.isEqual(this.version) &&\n      other.key.isEqual(this.key)\n    );\n  }\n}\n\n/**\n * A class representing an existing document whose data is unknown (e.g. a\n * document that was updated without a known base document).\n */\nexport class UnknownDocument extends MaybeDocument {\n  toString(): string {\n    return `UnknownDocument(${this.key}, ${this.version})`;\n  }\n\n  get hasPendingWrites(): boolean {\n    return true;\n  }\n\n  isEqual(other: MaybeDocument | null | undefined): boolean {\n    return (\n      other instanceof UnknownDocument &&\n      other.version.isEqual(this.version) &&\n      other.key.isEqual(this.key)\n    );\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { DocumentKey } from '../model/document_key';\nimport { ResourcePath } from '../model/path';\nimport { isNullOrUndefined } from '../util/types';\nimport { Bound, Filter, OrderBy } from './query';\n\n/**\n * A Target represents the WatchTarget representation of a Query, which is used\n * by the LocalStore and the RemoteStore to keep track of and to execute\n * backend queries. While a Query can represent multiple Targets, each Targets\n * maps to a single WatchTarget in RemoteStore and a single TargetData entry\n * in persistence.\n */\nexport class Target {\n  private memoizedCanonicalId: string | null = null;\n\n  /**\n   * Initializes a Target with a path and optional additional query constraints.\n   * Path must currently be empty if this is a collection group query.\n   *\n   * NOTE: you should always construct `Target` from `Query.toTarget` instead of\n   * using this constructor, because `Query` provides an implicit `orderBy`\n   * property.\n   */\n  constructor(\n    readonly path: ResourcePath,\n    readonly collectionGroup: string | null = null,\n    readonly orderBy: OrderBy[] = [],\n    readonly filters: Filter[] = [],\n    readonly limit: number | null = null,\n    readonly startAt: Bound | null = null,\n    readonly endAt: Bound | null = null\n  ) {}\n\n  canonicalId(): string {\n    if (this.memoizedCanonicalId === null) {\n      let canonicalId = this.path.canonicalString();\n      if (this.collectionGroup !== null) {\n        canonicalId += '|cg:' + this.collectionGroup;\n      }\n      canonicalId += '|f:';\n      canonicalId += this.filters.map(f => f.canonicalId()).join(',');\n      canonicalId += '|ob:';\n      canonicalId += this.orderBy.map(o => o.canonicalId()).join(',');\n\n      if (!isNullOrUndefined(this.limit)) {\n        canonicalId += '|l:';\n        canonicalId += this.limit!;\n      }\n      if (this.startAt) {\n        canonicalId += '|lb:';\n        canonicalId += this.startAt.canonicalId();\n      }\n      if (this.endAt) {\n        canonicalId += '|ub:';\n        canonicalId += this.endAt.canonicalId();\n      }\n      this.memoizedCanonicalId = canonicalId;\n    }\n    return this.memoizedCanonicalId;\n  }\n\n  toString(): string {\n    let str = this.path.canonicalString();\n    if (this.collectionGroup !== null) {\n      str += ' collectionGroup=' + this.collectionGroup;\n    }\n    if (this.filters.length > 0) {\n      str += `, filters: [${this.filters.join(', ')}]`;\n    }\n    if (!isNullOrUndefined(this.limit)) {\n      str += ', limit: ' + this.limit;\n    }\n    if (this.orderBy.length > 0) {\n      str += `, orderBy: [${this.orderBy.join(', ')}]`;\n    }\n    if (this.startAt) {\n      str += ', startAt: ' + this.startAt.canonicalId();\n    }\n    if (this.endAt) {\n      str += ', endAt: ' + this.endAt.canonicalId();\n    }\n    return `Target(${str})`;\n  }\n\n  isEqual(other: Target): boolean {\n    if (this.limit !== other.limit) {\n      return false;\n    }\n\n    if (this.orderBy.length !== other.orderBy.length) {\n      return false;\n    }\n\n    for (let i = 0; i < this.orderBy.length; i++) {\n      if (!this.orderBy[i].isEqual(other.orderBy[i])) {\n        return false;\n      }\n    }\n\n    if (this.filters.length !== other.filters.length) {\n      return false;\n    }\n\n    for (let i = 0; i < this.filters.length; i++) {\n      if (!this.filters[i].isEqual(other.filters[i])) {\n        return false;\n      }\n    }\n\n    if (this.collectionGroup !== other.collectionGroup) {\n      return false;\n    }\n\n    if (!this.path.isEqual(other.path)) {\n      return false;\n    }\n\n    if (\n      this.startAt !== null\n        ? !this.startAt.isEqual(other.startAt)\n        : other.startAt !== null\n    ) {\n      return false;\n    }\n\n    return this.endAt !== null\n      ? this.endAt.isEqual(other.endAt)\n      : other.endAt === null;\n  }\n\n  isDocumentQuery(): boolean {\n    return (\n      DocumentKey.isDocumentKey(this.path) &&\n      this.collectionGroup === null &&\n      this.filters.length === 0\n    );\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport * as api from '../protos/firestore_proto_api';\n\nimport { Document } from '../model/document';\nimport { DocumentKey } from '../model/document_key';\nimport {\n  canonicalId,\n  valueCompare,\n  arrayValueContains,\n  valueEquals,\n  isArray,\n  isNanValue,\n  isNullValue,\n  isReferenceValue,\n  typeOrder\n} from '../model/values';\nimport { FieldPath, ResourcePath } from '../model/path';\nimport { debugAssert, fail } from '../util/assert';\nimport { Code, FirestoreError } from '../util/error';\nimport { isNullOrUndefined } from '../util/types';\nimport { Target } from './target';\n\nexport const enum LimitType {\n  First = 'F',\n  Last = 'L'\n}\n\n/**\n * Query encapsulates all the query attributes we support in the SDK. It can\n * be run against the LocalStore, as well as be converted to a `Target` to\n * query the RemoteStore results.\n */\nexport class Query {\n  static atPath(path: ResourcePath): Query {\n    return new Query(path);\n  }\n\n  private memoizedOrderBy: OrderBy[] | null = null;\n\n  // The corresponding `Target` of this `Query` instance.\n  private memoizedTarget: Target | null = null;\n\n  /**\n   * Initializes a Query with a path and optional additional query constraints.\n   * Path must currently be empty if this is a collection group query.\n   */\n  constructor(\n    readonly path: ResourcePath,\n    readonly collectionGroup: string | null = null,\n    readonly explicitOrderBy: OrderBy[] = [],\n    readonly filters: Filter[] = [],\n    readonly limit: number | null = null,\n    readonly limitType: LimitType = LimitType.First,\n    readonly startAt: Bound | null = null,\n    readonly endAt: Bound | null = null\n  ) {\n    if (this.startAt) {\n      this.assertValidBound(this.startAt);\n    }\n    if (this.endAt) {\n      this.assertValidBound(this.endAt);\n    }\n  }\n\n  get orderBy(): OrderBy[] {\n    if (this.memoizedOrderBy === null) {\n      const inequalityField = this.getInequalityFilterField();\n      const firstOrderByField = this.getFirstOrderByField();\n      if (inequalityField !== null && firstOrderByField === null) {\n        // In order to implicitly add key ordering, we must also add the\n        // inequality filter field for it to be a valid query.\n        // Note that the default inequality field and key ordering is ascending.\n        if (inequalityField.isKeyField()) {\n          this.memoizedOrderBy = [KEY_ORDERING_ASC];\n        } else {\n          this.memoizedOrderBy = [\n            new OrderBy(inequalityField),\n            KEY_ORDERING_ASC\n          ];\n        }\n      } else {\n        debugAssert(\n          inequalityField === null ||\n            (firstOrderByField !== null &&\n              inequalityField.isEqual(firstOrderByField)),\n          'First orderBy should match inequality field.'\n        );\n        this.memoizedOrderBy = [];\n        let foundKeyOrdering = false;\n        for (const orderBy of this.explicitOrderBy) {\n          this.memoizedOrderBy.push(orderBy);\n          if (orderBy.field.isKeyField()) {\n            foundKeyOrdering = true;\n          }\n        }\n        if (!foundKeyOrdering) {\n          // The order of the implicit key ordering always matches the last\n          // explicit order by\n          const lastDirection =\n            this.explicitOrderBy.length > 0\n              ? this.explicitOrderBy[this.explicitOrderBy.length - 1].dir\n              : Direction.ASCENDING;\n          this.memoizedOrderBy.push(\n            lastDirection === Direction.ASCENDING\n              ? KEY_ORDERING_ASC\n              : KEY_ORDERING_DESC\n          );\n        }\n      }\n    }\n    return this.memoizedOrderBy;\n  }\n\n  addFilter(filter: Filter): Query {\n    debugAssert(\n      this.getInequalityFilterField() == null ||\n        !(filter instanceof FieldFilter) ||\n        !filter.isInequality() ||\n        filter.field.isEqual(this.getInequalityFilterField()!),\n      'Query must only have one inequality field.'\n    );\n\n    debugAssert(\n      !this.isDocumentQuery(),\n      'No filtering allowed for document query'\n    );\n\n    const newFilters = this.filters.concat([filter]);\n    return new Query(\n      this.path,\n      this.collectionGroup,\n      this.explicitOrderBy.slice(),\n      newFilters,\n      this.limit,\n      this.limitType,\n      this.startAt,\n      this.endAt\n    );\n  }\n\n  addOrderBy(orderBy: OrderBy): Query {\n    debugAssert(\n      !this.startAt && !this.endAt,\n      'Bounds must be set after orderBy'\n    );\n    // TODO(dimond): validate that orderBy does not list the same key twice.\n    const newOrderBy = this.explicitOrderBy.concat([orderBy]);\n    return new Query(\n      this.path,\n      this.collectionGroup,\n      newOrderBy,\n      this.filters.slice(),\n      this.limit,\n      this.limitType,\n      this.startAt,\n      this.endAt\n    );\n  }\n\n  withLimitToFirst(limit: number | null): Query {\n    return new Query(\n      this.path,\n      this.collectionGroup,\n      this.explicitOrderBy.slice(),\n      this.filters.slice(),\n      limit,\n      LimitType.First,\n      this.startAt,\n      this.endAt\n    );\n  }\n\n  withLimitToLast(limit: number | null): Query {\n    return new Query(\n      this.path,\n      this.collectionGroup,\n      this.explicitOrderBy.slice(),\n      this.filters.slice(),\n      limit,\n      LimitType.Last,\n      this.startAt,\n      this.endAt\n    );\n  }\n\n  withStartAt(bound: Bound): Query {\n    return new Query(\n      this.path,\n      this.collectionGroup,\n      this.explicitOrderBy.slice(),\n      this.filters.slice(),\n      this.limit,\n      this.limitType,\n      bound,\n      this.endAt\n    );\n  }\n\n  withEndAt(bound: Bound): Query {\n    return new Query(\n      this.path,\n      this.collectionGroup,\n      this.explicitOrderBy.slice(),\n      this.filters.slice(),\n      this.limit,\n      this.limitType,\n      this.startAt,\n      bound\n    );\n  }\n\n  /**\n   * Helper to convert a collection group query into a collection query at a\n   * specific path. This is used when executing collection group queries, since\n   * we have to split the query into a set of collection queries at multiple\n   * paths.\n   */\n  asCollectionQueryAtPath(path: ResourcePath): Query {\n    return new Query(\n      path,\n      /*collectionGroup=*/ null,\n      this.explicitOrderBy.slice(),\n      this.filters.slice(),\n      this.limit,\n      this.limitType,\n      this.startAt,\n      this.endAt\n    );\n  }\n\n  /**\n   * Returns true if this query does not specify any query constraints that\n   * could remove results.\n   */\n  matchesAllDocuments(): boolean {\n    return (\n      this.filters.length === 0 &&\n      this.limit === null &&\n      this.startAt == null &&\n      this.endAt == null &&\n      (this.explicitOrderBy.length === 0 ||\n        (this.explicitOrderBy.length === 1 &&\n          this.explicitOrderBy[0].field.isKeyField()))\n    );\n  }\n\n  // TODO(b/29183165): This is used to get a unique string from a query to, for\n  // example, use as a dictionary key, but the implementation is subject to\n  // collisions. Make it collision-free.\n  canonicalId(): string {\n    return `${this.toTarget().canonicalId()}|lt:${this.limitType}`;\n  }\n\n  toString(): string {\n    return `Query(target=${this.toTarget().toString()}; limitType=${\n      this.limitType\n    })`;\n  }\n\n  isEqual(other: Query): boolean {\n    return (\n      this.toTarget().isEqual(other.toTarget()) &&\n      this.limitType === other.limitType\n    );\n  }\n\n  docComparator(d1: Document, d2: Document): number {\n    let comparedOnKeyField = false;\n    for (const orderBy of this.orderBy) {\n      const comp = orderBy.compare(d1, d2);\n      if (comp !== 0) {\n        return comp;\n      }\n      comparedOnKeyField = comparedOnKeyField || orderBy.field.isKeyField();\n    }\n    // Assert that we actually compared by key\n    debugAssert(\n      comparedOnKeyField,\n      \"orderBy used that doesn't compare on key field\"\n    );\n    return 0;\n  }\n\n  matches(doc: Document): boolean {\n    return (\n      this.matchesPathAndCollectionGroup(doc) &&\n      this.matchesOrderBy(doc) &&\n      this.matchesFilters(doc) &&\n      this.matchesBounds(doc)\n    );\n  }\n\n  hasLimitToFirst(): boolean {\n    return !isNullOrUndefined(this.limit) && this.limitType === LimitType.First;\n  }\n\n  hasLimitToLast(): boolean {\n    return !isNullOrUndefined(this.limit) && this.limitType === LimitType.Last;\n  }\n\n  getFirstOrderByField(): FieldPath | null {\n    return this.explicitOrderBy.length > 0\n      ? this.explicitOrderBy[0].field\n      : null;\n  }\n\n  getInequalityFilterField(): FieldPath | null {\n    for (const filter of this.filters) {\n      if (filter instanceof FieldFilter && filter.isInequality()) {\n        return filter.field;\n      }\n    }\n    return null;\n  }\n\n  // Checks if any of the provided Operators are included in the query and\n  // returns the first one that is, or null if none are.\n  findFilterOperator(operators: Operator[]): Operator | null {\n    for (const filter of this.filters) {\n      if (filter instanceof FieldFilter) {\n        if (operators.indexOf(filter.op) >= 0) {\n          return filter.op;\n        }\n      }\n    }\n    return null;\n  }\n\n  isDocumentQuery(): boolean {\n    return this.toTarget().isDocumentQuery();\n  }\n\n  isCollectionGroupQuery(): boolean {\n    return this.collectionGroup !== null;\n  }\n\n  /**\n   * Converts this `Query` instance to it's corresponding `Target`\n   * representation.\n   */\n  toTarget(): Target {\n    if (!this.memoizedTarget) {\n      if (this.limitType === LimitType.First) {\n        this.memoizedTarget = new Target(\n          this.path,\n          this.collectionGroup,\n          this.orderBy,\n          this.filters,\n          this.limit,\n          this.startAt,\n          this.endAt\n        );\n      } else {\n        // Flip the orderBy directions since we want the last results\n        const orderBys = [] as OrderBy[];\n        for (const orderBy of this.orderBy) {\n          const dir =\n            orderBy.dir === Direction.DESCENDING\n              ? Direction.ASCENDING\n              : Direction.DESCENDING;\n          orderBys.push(new OrderBy(orderBy.field, dir));\n        }\n\n        // We need to swap the cursors to match the now-flipped query ordering.\n        const startAt = this.endAt\n          ? new Bound(this.endAt.position, !this.endAt.before)\n          : null;\n        const endAt = this.startAt\n          ? new Bound(this.startAt.position, !this.startAt.before)\n          : null;\n\n        // Now return as a LimitType.First query.\n        this.memoizedTarget = new Target(\n          this.path,\n          this.collectionGroup,\n          orderBys,\n          this.filters,\n          this.limit,\n          startAt,\n          endAt\n        );\n      }\n    }\n    return this.memoizedTarget!;\n  }\n\n  private matchesPathAndCollectionGroup(doc: Document): boolean {\n    const docPath = doc.key.path;\n    if (this.collectionGroup !== null) {\n      // NOTE: this.path is currently always empty since we don't expose Collection\n      // Group queries rooted at a document path yet.\n      return (\n        doc.key.hasCollectionId(this.collectionGroup) &&\n        this.path.isPrefixOf(docPath)\n      );\n    } else if (DocumentKey.isDocumentKey(this.path)) {\n      // exact match for document queries\n      return this.path.isEqual(docPath);\n    } else {\n      // shallow ancestor queries by default\n      return this.path.isImmediateParentOf(docPath);\n    }\n  }\n\n  /**\n   * A document must have a value for every ordering clause in order to show up\n   * in the results.\n   */\n  private matchesOrderBy(doc: Document): boolean {\n    for (const orderBy of this.explicitOrderBy) {\n      // order by key always matches\n      if (!orderBy.field.isKeyField() && doc.field(orderBy.field) === null) {\n        return false;\n      }\n    }\n    return true;\n  }\n\n  private matchesFilters(doc: Document): boolean {\n    for (const filter of this.filters) {\n      if (!filter.matches(doc)) {\n        return false;\n      }\n    }\n    return true;\n  }\n\n  /**\n   * Makes sure a document is within the bounds, if provided.\n   */\n  private matchesBounds(doc: Document): boolean {\n    if (this.startAt && !this.startAt.sortsBeforeDocument(this.orderBy, doc)) {\n      return false;\n    }\n    if (this.endAt && this.endAt.sortsBeforeDocument(this.orderBy, doc)) {\n      return false;\n    }\n    return true;\n  }\n\n  private assertValidBound(bound: Bound): void {\n    debugAssert(\n      bound.position.length <= this.orderBy.length,\n      'Bound is longer than orderBy'\n    );\n  }\n}\n\nexport abstract class Filter {\n  abstract matches(doc: Document): boolean;\n  abstract canonicalId(): string;\n  abstract isEqual(filter: Filter): boolean;\n}\n\nexport class Operator {\n  static LESS_THAN = new Operator('<');\n  static LESS_THAN_OR_EQUAL = new Operator('<=');\n  static EQUAL = new Operator('==');\n  static GREATER_THAN = new Operator('>');\n  static GREATER_THAN_OR_EQUAL = new Operator('>=');\n  static ARRAY_CONTAINS = new Operator('array-contains');\n  static IN = new Operator('in');\n  static ARRAY_CONTAINS_ANY = new Operator('array-contains-any');\n\n  static fromString(op: string): Operator {\n    switch (op) {\n      case '<':\n        return Operator.LESS_THAN;\n      case '<=':\n        return Operator.LESS_THAN_OR_EQUAL;\n      case '==':\n        return Operator.EQUAL;\n      case '>=':\n        return Operator.GREATER_THAN_OR_EQUAL;\n      case '>':\n        return Operator.GREATER_THAN;\n      case 'array-contains':\n        return Operator.ARRAY_CONTAINS;\n      case 'in':\n        return Operator.IN;\n      case 'array-contains-any':\n        return Operator.ARRAY_CONTAINS_ANY;\n      default:\n        return fail('Unknown FieldFilter operator: ' + op);\n    }\n  }\n\n  constructor(public name: string) {}\n\n  toString(): string {\n    return this.name;\n  }\n\n  isEqual(other: Operator): boolean {\n    return this.name === other.name;\n  }\n}\n\nexport class FieldFilter extends Filter {\n  protected constructor(\n    public field: FieldPath,\n    public op: Operator,\n    public value: api.Value\n  ) {\n    super();\n  }\n\n  /**\n   * Creates a filter based on the provided arguments.\n   */\n  static create(field: FieldPath, op: Operator, value: api.Value): FieldFilter {\n    if (field.isKeyField()) {\n      if (op === Operator.IN) {\n        debugAssert(\n          isArray(value),\n          'Comparing on key with IN, but filter value not an ArrayValue'\n        );\n        debugAssert(\n          (value.arrayValue.values || []).every(elem => isReferenceValue(elem)),\n          'Comparing on key with IN, but an array value was not a RefValue'\n        );\n        return new KeyFieldInFilter(field, value);\n      } else {\n        debugAssert(\n          isReferenceValue(value),\n          'Comparing on key, but filter value not a RefValue'\n        );\n        debugAssert(\n          op !== Operator.ARRAY_CONTAINS && op !== Operator.ARRAY_CONTAINS_ANY,\n          `'${op.toString()}' queries don't make sense on document keys.`\n        );\n        return new KeyFieldFilter(field, op, value);\n      }\n    } else if (isNullValue(value)) {\n      if (op !== Operator.EQUAL) {\n        throw new FirestoreError(\n          Code.INVALID_ARGUMENT,\n          'Invalid query. Null supports only equality comparisons.'\n        );\n      }\n      return new FieldFilter(field, op, value);\n    } else if (isNanValue(value)) {\n      if (op !== Operator.EQUAL) {\n        throw new FirestoreError(\n          Code.INVALID_ARGUMENT,\n          'Invalid query. NaN supports only equality comparisons.'\n        );\n      }\n      return new FieldFilter(field, op, value);\n    } else if (op === Operator.ARRAY_CONTAINS) {\n      return new ArrayContainsFilter(field, value);\n    } else if (op === Operator.IN) {\n      debugAssert(\n        isArray(value),\n        'IN filter has invalid value: ' + value.toString()\n      );\n      return new InFilter(field, value);\n    } else if (op === Operator.ARRAY_CONTAINS_ANY) {\n      debugAssert(\n        isArray(value),\n        'ARRAY_CONTAINS_ANY filter has invalid value: ' + value.toString()\n      );\n      return new ArrayContainsAnyFilter(field, value);\n    } else {\n      return new FieldFilter(field, op, value);\n    }\n  }\n\n  matches(doc: Document): boolean {\n    const other = doc.field(this.field);\n\n    // Only compare types with matching backend order (such as double and int).\n    return (\n      other !== null &&\n      typeOrder(this.value) === typeOrder(other) &&\n      this.matchesComparison(valueCompare(other, this.value))\n    );\n  }\n\n  protected matchesComparison(comparison: number): boolean {\n    switch (this.op) {\n      case Operator.LESS_THAN:\n        return comparison < 0;\n      case Operator.LESS_THAN_OR_EQUAL:\n        return comparison <= 0;\n      case Operator.EQUAL:\n        return comparison === 0;\n      case Operator.GREATER_THAN:\n        return comparison > 0;\n      case Operator.GREATER_THAN_OR_EQUAL:\n        return comparison >= 0;\n      default:\n        return fail('Unknown FieldFilter operator: ' + this.op);\n    }\n  }\n\n  isInequality(): boolean {\n    return (\n      [\n        Operator.LESS_THAN,\n        Operator.LESS_THAN_OR_EQUAL,\n        Operator.GREATER_THAN,\n        Operator.GREATER_THAN_OR_EQUAL\n      ].indexOf(this.op) >= 0\n    );\n  }\n\n  canonicalId(): string {\n    // TODO(b/29183165): Technically, this won't be unique if two values have\n    // the same description, such as the int 3 and the string \"3\". So we should\n    // add the types in here somehow, too.\n    return (\n      this.field.canonicalString() +\n      this.op.toString() +\n      canonicalId(this.value)\n    );\n  }\n\n  isEqual(other: Filter): boolean {\n    if (other instanceof FieldFilter) {\n      return (\n        this.op.isEqual(other.op) &&\n        this.field.isEqual(other.field) &&\n        valueEquals(this.value, other.value)\n      );\n    } else {\n      return false;\n    }\n  }\n\n  toString(): string {\n    return `${this.field.canonicalString()} ${this.op} ${canonicalId(\n      this.value\n    )}`;\n  }\n}\n\n/** Filter that matches on key fields (i.e. '__name__'). */\nexport class KeyFieldFilter extends FieldFilter {\n  private readonly key: DocumentKey;\n\n  constructor(field: FieldPath, op: Operator, value: api.Value) {\n    super(field, op, value);\n    debugAssert(\n      isReferenceValue(value),\n      'KeyFieldFilter expects a ReferenceValue'\n    );\n    this.key = DocumentKey.fromName(value.referenceValue);\n  }\n\n  matches(doc: Document): boolean {\n    const comparison = DocumentKey.comparator(doc.key, this.key);\n    return this.matchesComparison(comparison);\n  }\n}\n\n/** Filter that matches on key fields within an array. */\nexport class KeyFieldInFilter extends FieldFilter {\n  private readonly keys: DocumentKey[];\n\n  constructor(field: FieldPath, value: api.Value) {\n    super(field, Operator.IN, value);\n    debugAssert(isArray(value), 'KeyFieldInFilter expects an ArrayValue');\n    this.keys = (value.arrayValue.values || []).map(v => {\n      debugAssert(\n        isReferenceValue(v),\n        'Comparing on key with IN, but an array value was not a ReferenceValue'\n      );\n      return DocumentKey.fromName(v.referenceValue);\n    });\n  }\n\n  matches(doc: Document): boolean {\n    return this.keys.some(key => key.isEqual(doc.key));\n  }\n}\n\n/** A Filter that implements the array-contains operator. */\nexport class ArrayContainsFilter extends FieldFilter {\n  constructor(field: FieldPath, value: api.Value) {\n    super(field, Operator.ARRAY_CONTAINS, value);\n  }\n\n  matches(doc: Document): boolean {\n    const other = doc.field(this.field);\n    return isArray(other) && arrayValueContains(other.arrayValue, this.value);\n  }\n}\n\n/** A Filter that implements the IN operator. */\nexport class InFilter extends FieldFilter {\n  constructor(field: FieldPath, value: api.Value) {\n    super(field, Operator.IN, value);\n    debugAssert(isArray(value), 'InFilter expects an ArrayValue');\n  }\n\n  matches(doc: Document): boolean {\n    const other = doc.field(this.field);\n    return other !== null && arrayValueContains(this.value.arrayValue!, other);\n  }\n}\n\n/** A Filter that implements the array-contains-any operator. */\nexport class ArrayContainsAnyFilter extends FieldFilter {\n  constructor(field: FieldPath, value: api.Value) {\n    super(field, Operator.ARRAY_CONTAINS_ANY, value);\n    debugAssert(isArray(value), 'ArrayContainsAnyFilter expects an ArrayValue');\n  }\n\n  matches(doc: Document): boolean {\n    const other = doc.field(this.field);\n    if (!isArray(other) || !other.arrayValue.values) {\n      return false;\n    }\n    return other.arrayValue.values.some(val =>\n      arrayValueContains(this.value.arrayValue!, val)\n    );\n  }\n}\n\n/**\n * The direction of sorting in an order by.\n */\nexport class Direction {\n  static ASCENDING = new Direction('asc');\n  static DESCENDING = new Direction('desc');\n\n  private constructor(public name: string) {}\n\n  toString(): string {\n    return this.name;\n  }\n}\n\n/**\n * Represents a bound of a query.\n *\n * The bound is specified with the given components representing a position and\n * whether it's just before or just after the position (relative to whatever the\n * query order is).\n *\n * The position represents a logical index position for a query. It's a prefix\n * of values for the (potentially implicit) order by clauses of a query.\n *\n * Bound provides a function to determine whether a document comes before or\n * after a bound. This is influenced by whether the position is just before or\n * just after the provided values.\n */\nexport class Bound {\n  constructor(readonly position: api.Value[], readonly before: boolean) {}\n\n  canonicalId(): string {\n    // TODO(b/29183165): Make this collision robust.\n    return `${this.before ? 'b' : 'a'}:${this.position\n      .map(p => canonicalId(p))\n      .join(',')}`;\n  }\n\n  /**\n   * Returns true if a document sorts before a bound using the provided sort\n   * order.\n   */\n  sortsBeforeDocument(orderBy: OrderBy[], doc: Document): boolean {\n    debugAssert(\n      this.position.length <= orderBy.length,\n      \"Bound has more components than query's orderBy\"\n    );\n    let comparison = 0;\n    for (let i = 0; i < this.position.length; i++) {\n      const orderByComponent = orderBy[i];\n      const component = this.position[i];\n      if (orderByComponent.field.isKeyField()) {\n        debugAssert(\n          isReferenceValue(component),\n          'Bound has a non-key value where the key path is being used.'\n        );\n        comparison = DocumentKey.comparator(\n          DocumentKey.fromName(component.referenceValue),\n          doc.key\n        );\n      } else {\n        const docValue = doc.field(orderByComponent.field);\n        debugAssert(\n          docValue !== null,\n          'Field should exist since document matched the orderBy already.'\n        );\n        comparison = valueCompare(component, docValue);\n      }\n      if (orderByComponent.dir === Direction.DESCENDING) {\n        comparison = comparison * -1;\n      }\n      if (comparison !== 0) {\n        break;\n      }\n    }\n    return this.before ? comparison <= 0 : comparison < 0;\n  }\n\n  isEqual(other: Bound | null): boolean {\n    if (other === null) {\n      return false;\n    }\n    if (\n      this.before !== other.before ||\n      this.position.length !== other.position.length\n    ) {\n      return false;\n    }\n    for (let i = 0; i < this.position.length; i++) {\n      const thisPosition = this.position[i];\n      const otherPosition = other.position[i];\n      if (!valueEquals(thisPosition, otherPosition)) {\n        return false;\n      }\n    }\n    return true;\n  }\n}\n\n/**\n * An ordering on a field, in some Direction. Direction defaults to ASCENDING.\n */\nexport class OrderBy {\n  readonly dir: Direction;\n  private readonly isKeyOrderBy: boolean;\n\n  constructor(readonly field: FieldPath, dir?: Direction) {\n    if (dir === undefined) {\n      dir = Direction.ASCENDING;\n    }\n    this.dir = dir;\n    this.isKeyOrderBy = field.isKeyField();\n  }\n\n  compare(d1: Document, d2: Document): number {\n    const comparison = this.isKeyOrderBy\n      ? Document.compareByKey(d1, d2)\n      : Document.compareByField(this.field, d1, d2);\n    switch (this.dir) {\n      case Direction.ASCENDING:\n        return comparison;\n      case Direction.DESCENDING:\n        return -1 * comparison;\n      default:\n        return fail('Unknown direction: ' + this.dir);\n    }\n  }\n\n  canonicalId(): string {\n    // TODO(b/29183165): Make this collision robust.\n    return this.field.canonicalString() + this.dir.toString();\n  }\n\n  toString(): string {\n    return `${this.field.canonicalString()} (${this.dir})`;\n  }\n\n  isEqual(other: OrderBy): boolean {\n    return this.dir === other.dir && this.field.isEqual(other.field);\n  }\n}\n\nconst KEY_ORDERING_ASC = new OrderBy(FieldPath.keyField(), Direction.ASCENDING);\nconst KEY_ORDERING_DESC = new OrderBy(\n  FieldPath.keyField(),\n  Direction.DESCENDING\n);\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { SnapshotVersion } from '../core/snapshot_version';\nimport { Target } from '../core/target';\nimport { ListenSequenceNumber, TargetId } from '../core/types';\nimport { ByteString } from '../util/byte_string';\n\n/** An enumeration of the different purposes we have for targets. */\nexport const enum TargetPurpose {\n  /** A regular, normal query target. */\n  Listen,\n\n  /**\n   * The query target was used to refill a query after an existence filter mismatch.\n   */\n  ExistenceFilterMismatch,\n\n  /** The query target was used to resolve a limbo document. */\n  LimboResolution\n}\n\n/**\n * An immutable set of metadata that the local store tracks for each target.\n */\nexport class TargetData {\n  constructor(\n    /** The target being listened to. */\n    readonly target: Target,\n    /**\n     * The target ID to which the target corresponds; Assigned by the\n     * LocalStore for user listens and by the SyncEngine for limbo watches.\n     */\n    readonly targetId: TargetId,\n    /** The purpose of the target. */\n    readonly purpose: TargetPurpose,\n    /**\n     * The sequence number of the last transaction during which this target data\n     * was modified.\n     */\n    readonly sequenceNumber: ListenSequenceNumber,\n    /** The latest snapshot version seen for this target. */\n    readonly snapshotVersion: SnapshotVersion = SnapshotVersion.MIN,\n    /**\n     * The maximum snapshot version at which the associated view\n     * contained no limbo documents.\n     */\n    readonly lastLimboFreeSnapshotVersion: SnapshotVersion = SnapshotVersion.MIN,\n    /**\n     * An opaque, server-assigned token that allows watching a target to be\n     * resumed after disconnecting without retransmitting all the data that\n     * matches the target. The resume token essentially identifies a point in\n     * time from which the server should resume sending results.\n     */\n    readonly resumeToken: ByteString = ByteString.EMPTY_BYTE_STRING\n  ) {}\n\n  /** Creates a new target data instance with an updated sequence number. */\n  withSequenceNumber(sequenceNumber: number): TargetData {\n    return new TargetData(\n      this.target,\n      this.targetId,\n      this.purpose,\n      sequenceNumber,\n      this.snapshotVersion,\n      this.lastLimboFreeSnapshotVersion,\n      this.resumeToken\n    );\n  }\n\n  /**\n   * Creates a new target data instance with an updated resume token and\n   * snapshot version.\n   */\n  withResumeToken(\n    resumeToken: ByteString,\n    snapshotVersion: SnapshotVersion\n  ): TargetData {\n    return new TargetData(\n      this.target,\n      this.targetId,\n      this.purpose,\n      this.sequenceNumber,\n      snapshotVersion,\n      this.lastLimboFreeSnapshotVersion,\n      resumeToken\n    );\n  }\n\n  /**\n   * Creates a new target data instance with an updated last limbo free\n   * snapshot version number.\n   */\n  withLastLimboFreeSnapshotVersion(\n    lastLimboFreeSnapshotVersion: SnapshotVersion\n  ): TargetData {\n    return new TargetData(\n      this.target,\n      this.targetId,\n      this.purpose,\n      this.sequenceNumber,\n      this.snapshotVersion,\n      lastLimboFreeSnapshotVersion,\n      this.resumeToken\n    );\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nexport class ExistenceFilter {\n  // TODO(b/33078163): just use simplest form of existence filter for now\n  constructor(public count: number) {}\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { fail } from '../util/assert';\nimport { Code } from '../util/error';\nimport { logError } from '../util/log';\n\n/**\n * Error Codes describing the different ways GRPC can fail. These are copied\n * directly from GRPC's sources here:\n *\n * https://github.com/grpc/grpc/blob/bceec94ea4fc5f0085d81235d8e1c06798dc341a/include/grpc%2B%2B/impl/codegen/status_code_enum.h\n *\n * Important! The names of these identifiers matter because the string forms\n * are used for reverse lookups from the webchannel stream. Do NOT change the\n * names of these identifiers or change this into a const enum.\n */\nenum RpcCode {\n  OK = 0,\n  CANCELLED = 1,\n  UNKNOWN = 2,\n  INVALID_ARGUMENT = 3,\n  DEADLINE_EXCEEDED = 4,\n  NOT_FOUND = 5,\n  ALREADY_EXISTS = 6,\n  PERMISSION_DENIED = 7,\n  UNAUTHENTICATED = 16,\n  RESOURCE_EXHAUSTED = 8,\n  FAILED_PRECONDITION = 9,\n  ABORTED = 10,\n  OUT_OF_RANGE = 11,\n  UNIMPLEMENTED = 12,\n  INTERNAL = 13,\n  UNAVAILABLE = 14,\n  DATA_LOSS = 15\n}\n\n/**\n * Determines whether an error code represents a permanent error when received\n * in response to a non-write operation.\n *\n * See isPermanentWriteError for classifying write errors.\n */\nexport function isPermanentError(code: Code): boolean {\n  switch (code) {\n    case Code.OK:\n      return fail('Treated status OK as error');\n    case Code.CANCELLED:\n    case Code.UNKNOWN:\n    case Code.DEADLINE_EXCEEDED:\n    case Code.RESOURCE_EXHAUSTED:\n    case Code.INTERNAL:\n    case Code.UNAVAILABLE:\n    // Unauthenticated means something went wrong with our token and we need\n    // to retry with new credentials which will happen automatically.\n    case Code.UNAUTHENTICATED:\n      return false;\n    case Code.INVALID_ARGUMENT:\n    case Code.NOT_FOUND:\n    case Code.ALREADY_EXISTS:\n    case Code.PERMISSION_DENIED:\n    case Code.FAILED_PRECONDITION:\n    // Aborted might be retried in some scenarios, but that is dependant on\n    // the context and should handled individually by the calling code.\n    // See https://cloud.google.com/apis/design/errors.\n    case Code.ABORTED:\n    case Code.OUT_OF_RANGE:\n    case Code.UNIMPLEMENTED:\n    case Code.DATA_LOSS:\n      return true;\n    default:\n      return fail('Unknown status code: ' + code);\n  }\n}\n\n/**\n * Determines whether an error code represents a permanent error when received\n * in response to a write operation.\n *\n * Write operations must be handled specially because as of b/119437764, ABORTED\n * errors on the write stream should be retried too (even though ABORTED errors\n * are not generally retryable).\n *\n * Note that during the initial handshake on the write stream an ABORTED error\n * signals that we should discard our stream token (i.e. it is permanent). This\n * means a handshake error should be classified with isPermanentError, above.\n */\nexport function isPermanentWriteError(code: Code): boolean {\n  return isPermanentError(code) && code !== Code.ABORTED;\n}\n\n/**\n * Maps an error Code from a GRPC status identifier like 'NOT_FOUND'.\n *\n * @returns The Code equivalent to the given status string or undefined if\n *     there is no match.\n */\nexport function mapCodeFromRpcStatus(status: string): Code | undefined {\n  // lookup by string\n  // eslint-disable-next-line @typescript-eslint/no-explicit-any\n  const code: RpcCode = RpcCode[status as any] as any;\n  if (code === undefined) {\n    return undefined;\n  }\n\n  return mapCodeFromRpcCode(code);\n}\n\n/**\n * Maps an error Code from GRPC status code number, like 0, 1, or 14. These\n * are not the same as HTTP status codes.\n *\n * @returns The Code equivalent to the given GRPC status code. Fails if there\n *     is no match.\n */\nexport function mapCodeFromRpcCode(code: number | undefined): Code {\n  if (code === undefined) {\n    // This shouldn't normally happen, but in certain error cases (like trying\n    // to send invalid proto messages) we may get an error with no GRPC code.\n    logError('GRPC error has no .code');\n    return Code.UNKNOWN;\n  }\n\n  switch (code) {\n    case RpcCode.OK:\n      return Code.OK;\n    case RpcCode.CANCELLED:\n      return Code.CANCELLED;\n    case RpcCode.UNKNOWN:\n      return Code.UNKNOWN;\n    case RpcCode.DEADLINE_EXCEEDED:\n      return Code.DEADLINE_EXCEEDED;\n    case RpcCode.RESOURCE_EXHAUSTED:\n      return Code.RESOURCE_EXHAUSTED;\n    case RpcCode.INTERNAL:\n      return Code.INTERNAL;\n    case RpcCode.UNAVAILABLE:\n      return Code.UNAVAILABLE;\n    case RpcCode.UNAUTHENTICATED:\n      return Code.UNAUTHENTICATED;\n    case RpcCode.INVALID_ARGUMENT:\n      return Code.INVALID_ARGUMENT;\n    case RpcCode.NOT_FOUND:\n      return Code.NOT_FOUND;\n    case RpcCode.ALREADY_EXISTS:\n      return Code.ALREADY_EXISTS;\n    case RpcCode.PERMISSION_DENIED:\n      return Code.PERMISSION_DENIED;\n    case RpcCode.FAILED_PRECONDITION:\n      return Code.FAILED_PRECONDITION;\n    case RpcCode.ABORTED:\n      return Code.ABORTED;\n    case RpcCode.OUT_OF_RANGE:\n      return Code.OUT_OF_RANGE;\n    case RpcCode.UNIMPLEMENTED:\n      return Code.UNIMPLEMENTED;\n    case RpcCode.DATA_LOSS:\n      return Code.DATA_LOSS;\n    default:\n      return fail('Unknown status code: ' + code);\n  }\n}\n\n/**\n * Maps an RPC code from a Code. This is the reverse operation from\n * mapCodeFromRpcCode and should really only be used in tests.\n */\nexport function mapRpcCodeFromCode(code: Code | undefined): number {\n  if (code === undefined) {\n    return RpcCode.OK;\n  }\n\n  switch (code) {\n    case Code.OK:\n      return RpcCode.OK;\n    case Code.CANCELLED:\n      return RpcCode.CANCELLED;\n    case Code.UNKNOWN:\n      return RpcCode.UNKNOWN;\n    case Code.DEADLINE_EXCEEDED:\n      return RpcCode.DEADLINE_EXCEEDED;\n    case Code.RESOURCE_EXHAUSTED:\n      return RpcCode.RESOURCE_EXHAUSTED;\n    case Code.INTERNAL:\n      return RpcCode.INTERNAL;\n    case Code.UNAVAILABLE:\n      return RpcCode.UNAVAILABLE;\n    case Code.UNAUTHENTICATED:\n      return RpcCode.UNAUTHENTICATED;\n    case Code.INVALID_ARGUMENT:\n      return RpcCode.INVALID_ARGUMENT;\n    case Code.NOT_FOUND:\n      return RpcCode.NOT_FOUND;\n    case Code.ALREADY_EXISTS:\n      return RpcCode.ALREADY_EXISTS;\n    case Code.PERMISSION_DENIED:\n      return RpcCode.PERMISSION_DENIED;\n    case Code.FAILED_PRECONDITION:\n      return RpcCode.FAILED_PRECONDITION;\n    case Code.ABORTED:\n      return RpcCode.ABORTED;\n    case Code.OUT_OF_RANGE:\n      return RpcCode.OUT_OF_RANGE;\n    case Code.UNIMPLEMENTED:\n      return RpcCode.UNIMPLEMENTED;\n    case Code.DATA_LOSS:\n      return RpcCode.DATA_LOSS;\n    default:\n      return fail('Unknown status code: ' + code);\n  }\n}\n\n/**\n * Converts an HTTP Status Code to the equivalent error code.\n *\n * @param status An HTTP Status Code, like 200, 404, 503, etc.\n * @returns The equivalent Code. Unknown status codes are mapped to\n *     Code.UNKNOWN.\n */\nexport function mapCodeFromHttpStatus(status: number): Code {\n  // The canonical error codes for Google APIs [1] specify mapping onto HTTP\n  // status codes but the mapping is not bijective. In each case of ambiguity\n  // this function chooses a primary error.\n  //\n  // [1]\n  // https://github.com/googleapis/googleapis/blob/master/google/rpc/code.proto\n  switch (status) {\n    case 200: // OK\n      return Code.OK;\n\n    case 400: // Bad Request\n      return Code.INVALID_ARGUMENT;\n    // Other possibilities based on the forward mapping\n    // return Code.FAILED_PRECONDITION;\n    // return Code.OUT_OF_RANGE;\n\n    case 401: // Unauthorized\n      return Code.UNAUTHENTICATED;\n\n    case 403: // Forbidden\n      return Code.PERMISSION_DENIED;\n\n    case 404: // Not Found\n      return Code.NOT_FOUND;\n\n    case 409: // Conflict\n      return Code.ABORTED;\n    // Other possibilities:\n    // return Code.ALREADY_EXISTS;\n\n    case 416: // Range Not Satisfiable\n      return Code.OUT_OF_RANGE;\n\n    case 429: // Too Many Requests\n      return Code.RESOURCE_EXHAUSTED;\n\n    case 499: // Client Closed Request\n      return Code.CANCELLED;\n\n    case 500: // Internal Server Error\n      return Code.UNKNOWN;\n    // Other possibilities:\n    // return Code.INTERNAL;\n    // return Code.DATA_LOSS;\n\n    case 501: // Unimplemented\n      return Code.UNIMPLEMENTED;\n\n    case 503: // Service Unavailable\n      return Code.UNAVAILABLE;\n\n    case 504: // Gateway Timeout\n      return Code.DEADLINE_EXCEEDED;\n\n    default:\n      if (status >= 200 && status < 300) {\n        return Code.OK;\n      }\n      if (status >= 400 && status < 500) {\n        return Code.FAILED_PRECONDITION;\n      }\n      if (status >= 500 && status < 600) {\n        return Code.INTERNAL;\n      }\n      return Code.UNKNOWN;\n  }\n}\n\n/**\n * Converts an HTTP response's error status to the equivalent error code.\n *\n * @param status An HTTP error response status (\"FAILED_PRECONDITION\",\n * \"UNKNOWN\", etc.)\n * @returns The equivalent Code. Non-matching responses are mapped to\n *     Code.UNKNOWN.\n */\nexport function mapCodeFromHttpResponseErrorStatus(status: string): Code {\n  const serverError = status.toLowerCase().replace('_', '-');\n  return Object.values(Code).indexOf(serverError as Code) >= 0\n    ? (serverError as Code)\n    : Code.UNKNOWN;\n}\n","/**\n * @license\n * Copyright 2017 Google Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { SnapshotVersion } from '../core/snapshot_version';\nimport { SortedMap } from '../util/sorted_map';\nimport { SortedSet } from '../util/sorted_set';\n\nimport { TargetId } from '../core/types';\nimport { primitiveComparator } from '../util/misc';\nimport { Document, MaybeDocument } from './document';\nimport { DocumentKey } from './document_key';\n\n/** Miscellaneous collection types / constants. */\nexport interface DocumentSizeEntry {\n  maybeDocument: MaybeDocument;\n  size: number;\n}\n\nexport type MaybeDocumentMap = SortedMap<DocumentKey, MaybeDocument>;\nconst EMPTY_MAYBE_DOCUMENT_MAP = new SortedMap<DocumentKey, MaybeDocument>(\n  DocumentKey.comparator\n);\nexport function maybeDocumentMap(): MaybeDocumentMap {\n  return EMPTY_MAYBE_DOCUMENT_MAP;\n}\n\nexport type NullableMaybeDocumentMap = SortedMap<\n  DocumentKey,\n  MaybeDocument | null\n>;\n\nexport function nullableMaybeDocumentMap(): NullableMaybeDocumentMap {\n  return maybeDocumentMap();\n}\n\nexport interface DocumentSizeEntries {\n  maybeDocuments: NullableMaybeDocumentMap;\n  sizeMap: SortedMap<DocumentKey, number>;\n}\n\nexport type DocumentMap = SortedMap<DocumentKey, Document>;\nconst EMPTY_DOCUMENT_MAP = new SortedMap<DocumentKey, Document>(\n  DocumentKey.comparator\n);\nexport function documentMap(): DocumentMap {\n  return EMPTY_DOCUMENT_MAP;\n}\n\nexport type DocumentVersionMap = SortedMap<DocumentKey, SnapshotVersion>;\nconst EMPTY_DOCUMENT_VERSION_MAP = new SortedMap<DocumentKey, SnapshotVersion>(\n  DocumentKey.comparator\n);\nexport function documentVersionMap(): DocumentVersionMap {\n  return EMPTY_DOCUMENT_VERSION_MAP;\n}\n\nexport type DocumentKeySet = SortedSet<DocumentKey>;\nconst EMPTY_DOCUMENT_KEY_SET = new SortedSet(DocumentKey.comparator);\nexport function documentKeySet(...keys: DocumentKey[]): DocumentKeySet {\n  let set = EMPTY_DOCUMENT_KEY_SET;\n  for (const key of keys) {\n    set = set.add(key);\n  }\n  return set;\n}\n\nexport type TargetIdSet = SortedSet<TargetId>;\nconst EMPTY_TARGET_ID_SET = new SortedSet<TargetId>(primitiveComparator);\nexport function targetIdSet(): SortedSet<TargetId> {\n  return EMPTY_TARGET_ID_SET;\n}\n","/**\n * @license\n * Copyright 2017 Google Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { SortedMap } from '../util/sorted_map';\n\nimport { documentMap } from './collections';\nimport { Document } from './document';\nimport { DocumentComparator } from './document_comparator';\nimport { DocumentKey } from './document_key';\n\n/**\n * DocumentSet is an immutable (copy-on-write) collection that holds documents\n * in order specified by the provided comparator. We always add a document key\n * comparator on top of what is provided to guarantee document equality based on\n * the key.\n */\n\nexport class DocumentSet {\n  /**\n   * Returns an empty copy of the existing DocumentSet, using the same\n   * comparator.\n   */\n  static emptySet(oldSet: DocumentSet): DocumentSet {\n    return new DocumentSet(oldSet.comparator);\n  }\n\n  private comparator: DocumentComparator;\n  private keyedMap: SortedMap<DocumentKey, Document>;\n  private sortedSet: SortedMap<Document, null>;\n\n  /** The default ordering is by key if the comparator is omitted */\n  constructor(comp?: DocumentComparator) {\n    // We are adding document key comparator to the end as it's the only\n    // guaranteed unique property of a document.\n    if (comp) {\n      this.comparator = (d1: Document, d2: Document) =>\n        comp(d1, d2) || DocumentKey.comparator(d1.key, d2.key);\n    } else {\n      this.comparator = (d1: Document, d2: Document) =>\n        DocumentKey.comparator(d1.key, d2.key);\n    }\n\n    this.keyedMap = documentMap();\n    this.sortedSet = new SortedMap<Document, null>(this.comparator);\n  }\n\n  has(key: DocumentKey): boolean {\n    return this.keyedMap.get(key) != null;\n  }\n\n  get(key: DocumentKey): Document | null {\n    return this.keyedMap.get(key);\n  }\n\n  first(): Document | null {\n    return this.sortedSet.minKey();\n  }\n\n  last(): Document | null {\n    return this.sortedSet.maxKey();\n  }\n\n  isEmpty(): boolean {\n    return this.sortedSet.isEmpty();\n  }\n\n  /**\n   * Returns the index of the provided key in the document set, or -1 if the\n   * document key is not present in the set;\n   */\n  indexOf(key: DocumentKey): number {\n    const doc = this.keyedMap.get(key);\n    return doc ? this.sortedSet.indexOf(doc) : -1;\n  }\n\n  get size(): number {\n    return this.sortedSet.size;\n  }\n\n  /** Iterates documents in order defined by \"comparator\" */\n  forEach(cb: (doc: Document) => void): void {\n    this.sortedSet.inorderTraversal((k, v) => {\n      cb(k);\n      return false;\n    });\n  }\n\n  /** Inserts or updates a document with the same key */\n  add(doc: Document): DocumentSet {\n    // First remove the element if we have it.\n    const set = this.delete(doc.key);\n    return set.copy(\n      set.keyedMap.insert(doc.key, doc),\n      set.sortedSet.insert(doc, null)\n    );\n  }\n\n  /** Deletes a document with a given key */\n  delete(key: DocumentKey): DocumentSet {\n    const doc = this.get(key);\n    if (!doc) {\n      return this;\n    }\n\n    return this.copy(this.keyedMap.remove(key), this.sortedSet.remove(doc));\n  }\n\n  isEqual(other: DocumentSet | null | undefined): boolean {\n    if (!(other instanceof DocumentSet)) {\n      return false;\n    }\n    if (this.size !== other.size) {\n      return false;\n    }\n\n    const thisIt = this.sortedSet.getIterator();\n    const otherIt = other.sortedSet.getIterator();\n    while (thisIt.hasNext()) {\n      const thisDoc = thisIt.getNext().key;\n      const otherDoc = otherIt.getNext().key;\n      if (!thisDoc.isEqual(otherDoc)) {\n        return false;\n      }\n    }\n    return true;\n  }\n\n  toString(): string {\n    const docStrings: string[] = [];\n    this.forEach(doc => {\n      docStrings.push(doc.toString());\n    });\n    if (docStrings.length === 0) {\n      return 'DocumentSet ()';\n    } else {\n      return 'DocumentSet (\\n  ' + docStrings.join('  \\n') + '\\n)';\n    }\n  }\n\n  private copy(\n    keyedMap: SortedMap<DocumentKey, Document>,\n    sortedSet: SortedMap<Document, null>\n  ): DocumentSet {\n    const newSet = new DocumentSet();\n    newSet.comparator = this.comparator;\n    newSet.keyedMap = keyedMap;\n    newSet.sortedSet = sortedSet;\n    return newSet;\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Document } from '../model/document';\nimport { DocumentKey } from '../model/document_key';\nimport { DocumentSet } from '../model/document_set';\nimport { fail } from '../util/assert';\nimport { SortedMap } from '../util/sorted_map';\n\nimport { DocumentKeySet } from '../model/collections';\nimport { Query } from './query';\n\nexport const enum ChangeType {\n  Added,\n  Removed,\n  Modified,\n  Metadata\n}\n\nexport interface DocumentViewChange {\n  type: ChangeType;\n  doc: Document;\n}\n\nexport const enum SyncState {\n  Local,\n  Synced\n}\n\n/**\n * DocumentChangeSet keeps track of a set of changes to docs in a query, merging\n * duplicate events for the same doc.\n */\nexport class DocumentChangeSet {\n  private changeMap = new SortedMap<DocumentKey, DocumentViewChange>(\n    DocumentKey.comparator\n  );\n\n  track(change: DocumentViewChange): void {\n    const key = change.doc.key;\n    const oldChange = this.changeMap.get(key);\n    if (!oldChange) {\n      this.changeMap = this.changeMap.insert(key, change);\n      return;\n    }\n\n    // Merge the new change with the existing change.\n    if (\n      change.type !== ChangeType.Added &&\n      oldChange.type === ChangeType.Metadata\n    ) {\n      this.changeMap = this.changeMap.insert(key, change);\n    } else if (\n      change.type === ChangeType.Metadata &&\n      oldChange.type !== ChangeType.Removed\n    ) {\n      this.changeMap = this.changeMap.insert(key, {\n        type: oldChange.type,\n        doc: change.doc\n      });\n    } else if (\n      change.type === ChangeType.Modified &&\n      oldChange.type === ChangeType.Modified\n    ) {\n      this.changeMap = this.changeMap.insert(key, {\n        type: ChangeType.Modified,\n        doc: change.doc\n      });\n    } else if (\n      change.type === ChangeType.Modified &&\n      oldChange.type === ChangeType.Added\n    ) {\n      this.changeMap = this.changeMap.insert(key, {\n        type: ChangeType.Added,\n        doc: change.doc\n      });\n    } else if (\n      change.type === ChangeType.Removed &&\n      oldChange.type === ChangeType.Added\n    ) {\n      this.changeMap = this.changeMap.remove(key);\n    } else if (\n      change.type === ChangeType.Removed &&\n      oldChange.type === ChangeType.Modified\n    ) {\n      this.changeMap = this.changeMap.insert(key, {\n        type: ChangeType.Removed,\n        doc: oldChange.doc\n      });\n    } else if (\n      change.type === ChangeType.Added &&\n      oldChange.type === ChangeType.Removed\n    ) {\n      this.changeMap = this.changeMap.insert(key, {\n        type: ChangeType.Modified,\n        doc: change.doc\n      });\n    } else {\n      // This includes these cases, which don't make sense:\n      // Added->Added\n      // Removed->Removed\n      // Modified->Added\n      // Removed->Modified\n      // Metadata->Added\n      // Removed->Metadata\n      fail(\n        'unsupported combination of changes: ' +\n          JSON.stringify(change) +\n          ' after ' +\n          JSON.stringify(oldChange)\n      );\n    }\n  }\n\n  getChanges(): DocumentViewChange[] {\n    const changes: DocumentViewChange[] = [];\n    this.changeMap.inorderTraversal(\n      (key: DocumentKey, change: DocumentViewChange) => {\n        changes.push(change);\n      }\n    );\n    return changes;\n  }\n}\n\nexport class ViewSnapshot {\n  constructor(\n    readonly query: Query,\n    readonly docs: DocumentSet,\n    readonly oldDocs: DocumentSet,\n    readonly docChanges: DocumentViewChange[],\n    readonly mutatedKeys: DocumentKeySet,\n    readonly fromCache: boolean,\n    readonly syncStateChanged: boolean,\n    readonly excludesMetadataChanges: boolean\n  ) {}\n\n  /** Returns a view snapshot as if all documents in the snapshot were added. */\n  static fromInitialDocuments(\n    query: Query,\n    documents: DocumentSet,\n    mutatedKeys: DocumentKeySet,\n    fromCache: boolean\n  ): ViewSnapshot {\n    const changes: DocumentViewChange[] = [];\n    documents.forEach(doc => {\n      changes.push({ type: ChangeType.Added, doc });\n    });\n\n    return new ViewSnapshot(\n      query,\n      documents,\n      DocumentSet.emptySet(documents),\n      changes,\n      mutatedKeys,\n      fromCache,\n      /* syncStateChanged= */ true,\n      /* excludesMetadataChanges= */ false\n    );\n  }\n\n  get hasPendingWrites(): boolean {\n    return !this.mutatedKeys.isEmpty();\n  }\n\n  isEqual(other: ViewSnapshot): boolean {\n    if (\n      this.fromCache !== other.fromCache ||\n      this.syncStateChanged !== other.syncStateChanged ||\n      !this.mutatedKeys.isEqual(other.mutatedKeys) ||\n      !this.query.isEqual(other.query) ||\n      !this.docs.isEqual(other.docs) ||\n      !this.oldDocs.isEqual(other.oldDocs)\n    ) {\n      return false;\n    }\n    const changes: DocumentViewChange[] = this.docChanges;\n    const otherChanges: DocumentViewChange[] = other.docChanges;\n    if (changes.length !== otherChanges.length) {\n      return false;\n    }\n    for (let i = 0; i < changes.length; i++) {\n      if (\n        changes[i].type !== otherChanges[i].type ||\n        !changes[i].doc.isEqual(otherChanges[i].doc)\n      ) {\n        return false;\n      }\n    }\n    return true;\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { SnapshotVersion } from '../core/snapshot_version';\nimport { TargetId } from '../core/types';\nimport {\n  documentKeySet,\n  DocumentKeySet,\n  maybeDocumentMap,\n  MaybeDocumentMap,\n  targetIdSet\n} from '../model/collections';\nimport { SortedSet } from '../util/sorted_set';\nimport { ByteString } from '../util/byte_string';\n\n/**\n * An event from the RemoteStore. It is split into targetChanges (changes to the\n * state or the set of documents in our watched targets) and documentUpdates\n * (changes to the actual documents).\n */\nexport class RemoteEvent {\n  constructor(\n    /**\n     * The snapshot version this event brings us up to, or MIN if not set.\n     */\n    readonly snapshotVersion: SnapshotVersion,\n    /**\n     * A map from target to changes to the target. See TargetChange.\n     */\n    readonly targetChanges: Map<TargetId, TargetChange>,\n    /**\n     * A set of targets that is known to be inconsistent. Listens for these\n     * targets should be re-established without resume tokens.\n     */\n    readonly targetMismatches: SortedSet<TargetId>,\n    /**\n     * A set of which documents have changed or been deleted, along with the\n     * doc's new values (if not deleted).\n     */\n    readonly documentUpdates: MaybeDocumentMap,\n    /**\n     * A set of which document updates are due only to limbo resolution targets.\n     */\n    readonly resolvedLimboDocuments: DocumentKeySet\n  ) {}\n\n  /**\n   * HACK: Views require RemoteEvents in order to determine whether the view is\n   * CURRENT, but secondary tabs don't receive remote events. So this method is\n   * used to create a synthesized RemoteEvent that can be used to apply a\n   * CURRENT status change to a View, for queries executed in a different tab.\n   */\n  // PORTING NOTE: Multi-tab only\n  static createSynthesizedRemoteEventForCurrentChange(\n    targetId: TargetId,\n    current: boolean\n  ): RemoteEvent {\n    const targetChanges = new Map<TargetId, TargetChange>();\n    targetChanges.set(\n      targetId,\n      TargetChange.createSynthesizedTargetChangeForCurrentChange(\n        targetId,\n        current\n      )\n    );\n    return new RemoteEvent(\n      SnapshotVersion.MIN,\n      targetChanges,\n      targetIdSet(),\n      maybeDocumentMap(),\n      documentKeySet()\n    );\n  }\n}\n\n/**\n * A TargetChange specifies the set of changes for a specific target as part of\n * a RemoteEvent. These changes track which documents are added, modified or\n * removed, as well as the target's resume token and whether the target is\n * marked CURRENT.\n * The actual changes *to* documents are not part of the TargetChange since\n * documents may be part of multiple targets.\n */\nexport class TargetChange {\n  constructor(\n    /**\n     * An opaque, server-assigned token that allows watching a query to be resumed\n     * after disconnecting without retransmitting all the data that matches the\n     * query. The resume token essentially identifies a point in time from which\n     * the server should resume sending results.\n     */\n    readonly resumeToken: ByteString,\n    /**\n     * The \"current\" (synced) status of this target. Note that \"current\"\n     * has special meaning in the RPC protocol that implies that a target is\n     * both up-to-date and consistent with the rest of the watch stream.\n     */\n    readonly current: boolean,\n    /**\n     * The set of documents that were newly assigned to this target as part of\n     * this remote event.\n     */\n    readonly addedDocuments: DocumentKeySet,\n    /**\n     * The set of documents that were already assigned to this target but received\n     * an update during this remote event.\n     */\n    readonly modifiedDocuments: DocumentKeySet,\n    /**\n     * The set of documents that were removed from this target as part of this\n     * remote event.\n     */\n    readonly removedDocuments: DocumentKeySet\n  ) {}\n\n  /**\n   * This method is used to create a synthesized TargetChanges that can be used to\n   * apply a CURRENT status change to a View (for queries executed in a different\n   * tab) or for new queries (to raise snapshots with correct CURRENT status).\n   */\n  static createSynthesizedTargetChangeForCurrentChange(\n    targetId: TargetId,\n    current: boolean\n  ): TargetChange {\n    return new TargetChange(\n      ByteString.EMPTY_BYTE_STRING,\n      current,\n      documentKeySet(),\n      documentKeySet(),\n      documentKeySet()\n    );\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { SnapshotVersion } from '../core/snapshot_version';\nimport { TargetId } from '../core/types';\nimport { ChangeType } from '../core/view_snapshot';\nimport { TargetData, TargetPurpose } from '../local/target_data';\nimport {\n  documentKeySet,\n  DocumentKeySet,\n  maybeDocumentMap\n} from '../model/collections';\nimport { Document, MaybeDocument, NoDocument } from '../model/document';\nimport { DocumentKey } from '../model/document_key';\nimport { debugAssert, fail, hardAssert } from '../util/assert';\nimport { FirestoreError } from '../util/error';\nimport { logDebug } from '../util/log';\nimport { primitiveComparator } from '../util/misc';\nimport { SortedMap } from '../util/sorted_map';\nimport { SortedSet } from '../util/sorted_set';\nimport { ExistenceFilter } from './existence_filter';\nimport { RemoteEvent, TargetChange } from './remote_event';\nimport { ByteString } from '../util/byte_string';\n\n/**\n * Internal representation of the watcher API protocol buffers.\n */\nexport type WatchChange =\n  | DocumentWatchChange\n  | WatchTargetChange\n  | ExistenceFilterChange;\n\n/**\n * Represents a changed document and a list of target ids to which this change\n * applies.\n *\n * If document has been deleted NoDocument will be provided.\n */\nexport class DocumentWatchChange {\n  constructor(\n    /** The new document applies to all of these targets. */\n    public updatedTargetIds: TargetId[],\n    /** The new document is removed from all of these targets. */\n    public removedTargetIds: TargetId[],\n    /** The key of the document for this change. */\n    public key: DocumentKey,\n    /**\n     * The new document or NoDocument if it was deleted. Is null if the\n     * document went out of view without the server sending a new document.\n     */\n    public newDoc: MaybeDocument | null\n  ) {}\n}\n\nexport class ExistenceFilterChange {\n  constructor(\n    public targetId: TargetId,\n    public existenceFilter: ExistenceFilter\n  ) {}\n}\n\nexport const enum WatchTargetChangeState {\n  NoChange,\n  Added,\n  Removed,\n  Current,\n  Reset\n}\n\nexport class WatchTargetChange {\n  constructor(\n    /** What kind of change occurred to the watch target. */\n    public state: WatchTargetChangeState,\n    /** The target IDs that were added/removed/set. */\n    public targetIds: TargetId[],\n    /**\n     * An opaque, server-assigned token that allows watching a target to be\n     * resumed after disconnecting without retransmitting all the data that\n     * matches the target. The resume token essentially identifies a point in\n     * time from which the server should resume sending results.\n     */\n    public resumeToken: ByteString = ByteString.EMPTY_BYTE_STRING,\n    /** An RPC error indicating why the watch failed. */\n    public cause: FirestoreError | null = null\n  ) {}\n}\n\n/** Tracks the internal state of a Watch target. */\nclass TargetState {\n  /**\n   * The number of pending responses (adds or removes) that we are waiting on.\n   * We only consider targets active that have no pending responses.\n   */\n  private pendingResponses = 0;\n\n  /**\n   * Keeps track of the document changes since the last raised snapshot.\n   *\n   * These changes are continuously updated as we receive document updates and\n   * always reflect the current set of changes against the last issued snapshot.\n   */\n  private documentChanges: SortedMap<\n    DocumentKey,\n    ChangeType\n  > = snapshotChangesMap();\n\n  /** See public getters for explanations of these fields. */\n  private _resumeToken: ByteString = ByteString.EMPTY_BYTE_STRING;\n  private _current = false;\n\n  /**\n   * Whether this target state should be included in the next snapshot. We\n   * initialize to true so that newly-added targets are included in the next\n   * RemoteEvent.\n   */\n  private _hasPendingChanges = true;\n\n  /**\n   * Whether this target has been marked 'current'.\n   *\n   * 'Current' has special meaning in the RPC protocol: It implies that the\n   * Watch backend has sent us all changes up to the point at which the target\n   * was added and that the target is consistent with the rest of the watch\n   * stream.\n   */\n  get current(): boolean {\n    return this._current;\n  }\n\n  /** The last resume token sent to us for this target. */\n  get resumeToken(): ByteString {\n    return this._resumeToken;\n  }\n\n  /** Whether this target has pending target adds or target removes. */\n  get isPending(): boolean {\n    return this.pendingResponses !== 0;\n  }\n\n  /** Whether we have modified any state that should trigger a snapshot. */\n  get hasPendingChanges(): boolean {\n    return this._hasPendingChanges;\n  }\n\n  /**\n   * Applies the resume token to the TargetChange, but only when it has a new\n   * value. Empty resumeTokens are discarded.\n   */\n  updateResumeToken(resumeToken: ByteString): void {\n    if (resumeToken.approximateByteSize() > 0) {\n      this._hasPendingChanges = true;\n      this._resumeToken = resumeToken;\n    }\n  }\n\n  /**\n   * Creates a target change from the current set of changes.\n   *\n   * To reset the document changes after raising this snapshot, call\n   * `clearPendingChanges()`.\n   */\n  toTargetChange(): TargetChange {\n    let addedDocuments = documentKeySet();\n    let modifiedDocuments = documentKeySet();\n    let removedDocuments = documentKeySet();\n\n    this.documentChanges.forEach((key, changeType) => {\n      switch (changeType) {\n        case ChangeType.Added:\n          addedDocuments = addedDocuments.add(key);\n          break;\n        case ChangeType.Modified:\n          modifiedDocuments = modifiedDocuments.add(key);\n          break;\n        case ChangeType.Removed:\n          removedDocuments = removedDocuments.add(key);\n          break;\n        default:\n          fail('Encountered invalid change type: ' + changeType);\n      }\n    });\n\n    return new TargetChange(\n      this._resumeToken,\n      this._current,\n      addedDocuments,\n      modifiedDocuments,\n      removedDocuments\n    );\n  }\n\n  /**\n   * Resets the document changes and sets `hasPendingChanges` to false.\n   */\n  clearPendingChanges(): void {\n    this._hasPendingChanges = false;\n    this.documentChanges = snapshotChangesMap();\n  }\n\n  addDocumentChange(key: DocumentKey, changeType: ChangeType): void {\n    this._hasPendingChanges = true;\n    this.documentChanges = this.documentChanges.insert(key, changeType);\n  }\n\n  removeDocumentChange(key: DocumentKey): void {\n    this._hasPendingChanges = true;\n    this.documentChanges = this.documentChanges.remove(key);\n  }\n\n  recordPendingTargetRequest(): void {\n    this.pendingResponses += 1;\n  }\n\n  recordTargetResponse(): void {\n    this.pendingResponses -= 1;\n  }\n\n  markCurrent(): void {\n    this._hasPendingChanges = true;\n    this._current = true;\n  }\n}\n\n/**\n * Interface implemented by RemoteStore to expose target metadata to the\n * WatchChangeAggregator.\n */\nexport interface TargetMetadataProvider {\n  /**\n   * Returns the set of remote document keys for the given target ID as of the\n   * last raised snapshot.\n   */\n  getRemoteKeysForTarget(targetId: TargetId): DocumentKeySet;\n\n  /**\n   * Returns the TargetData for an active target ID or 'null' if this target\n   * has become inactive\n   */\n  getTargetDataForTarget(targetId: TargetId): TargetData | null;\n}\n\nconst LOG_TAG = 'WatchChangeAggregator';\n\n/**\n * A helper class to accumulate watch changes into a RemoteEvent.\n */\nexport class WatchChangeAggregator {\n  constructor(private metadataProvider: TargetMetadataProvider) {}\n\n  /** The internal state of all tracked targets. */\n  private targetStates = new Map<TargetId, TargetState>();\n\n  /** Keeps track of the documents to update since the last raised snapshot. */\n  private pendingDocumentUpdates = maybeDocumentMap();\n\n  /** A mapping of document keys to their set of target IDs. */\n  private pendingDocumentTargetMapping = documentTargetMap();\n\n  /**\n   * A list of targets with existence filter mismatches. These targets are\n   * known to be inconsistent and their listens needs to be re-established by\n   * RemoteStore.\n   */\n  private pendingTargetResets = new SortedSet<TargetId>(primitiveComparator);\n\n  /**\n   * Processes and adds the DocumentWatchChange to the current set of changes.\n   */\n  handleDocumentChange(docChange: DocumentWatchChange): void {\n    for (const targetId of docChange.updatedTargetIds) {\n      if (docChange.newDoc instanceof Document) {\n        this.addDocumentToTarget(targetId, docChange.newDoc);\n      } else if (docChange.newDoc instanceof NoDocument) {\n        this.removeDocumentFromTarget(\n          targetId,\n          docChange.key,\n          docChange.newDoc\n        );\n      }\n    }\n\n    for (const targetId of docChange.removedTargetIds) {\n      this.removeDocumentFromTarget(targetId, docChange.key, docChange.newDoc);\n    }\n  }\n\n  /** Processes and adds the WatchTargetChange to the current set of changes. */\n  handleTargetChange(targetChange: WatchTargetChange): void {\n    this.forEachTarget(targetChange, targetId => {\n      const targetState = this.ensureTargetState(targetId);\n      switch (targetChange.state) {\n        case WatchTargetChangeState.NoChange:\n          if (this.isActiveTarget(targetId)) {\n            targetState.updateResumeToken(targetChange.resumeToken);\n          }\n          break;\n        case WatchTargetChangeState.Added:\n          // We need to decrement the number of pending acks needed from watch\n          // for this targetId.\n          targetState.recordTargetResponse();\n          if (!targetState.isPending) {\n            // We have a freshly added target, so we need to reset any state\n            // that we had previously. This can happen e.g. when remove and add\n            // back a target for existence filter mismatches.\n            targetState.clearPendingChanges();\n          }\n          targetState.updateResumeToken(targetChange.resumeToken);\n          break;\n        case WatchTargetChangeState.Removed:\n          // We need to keep track of removed targets to we can post-filter and\n          // remove any target changes.\n          // We need to decrement the number of pending acks needed from watch\n          // for this targetId.\n          targetState.recordTargetResponse();\n          if (!targetState.isPending) {\n            this.removeTarget(targetId);\n          }\n          debugAssert(\n            !targetChange.cause,\n            'WatchChangeAggregator does not handle errored targets'\n          );\n          break;\n        case WatchTargetChangeState.Current:\n          if (this.isActiveTarget(targetId)) {\n            targetState.markCurrent();\n            targetState.updateResumeToken(targetChange.resumeToken);\n          }\n          break;\n        case WatchTargetChangeState.Reset:\n          if (this.isActiveTarget(targetId)) {\n            // Reset the target and synthesizes removes for all existing\n            // documents. The backend will re-add any documents that still\n            // match the target before it sends the next global snapshot.\n            this.resetTarget(targetId);\n            targetState.updateResumeToken(targetChange.resumeToken);\n          }\n          break;\n        default:\n          fail('Unknown target watch change state: ' + targetChange.state);\n      }\n    });\n  }\n\n  /**\n   * Iterates over all targetIds that the watch change applies to: either the\n   * targetIds explicitly listed in the change or the targetIds of all currently\n   * active targets.\n   */\n  forEachTarget(\n    targetChange: WatchTargetChange,\n    fn: (targetId: TargetId) => void\n  ): void {\n    if (targetChange.targetIds.length > 0) {\n      targetChange.targetIds.forEach(fn);\n    } else {\n      this.targetStates.forEach((_, targetId) => {\n        if (this.isActiveTarget(targetId)) {\n          fn(targetId);\n        }\n      });\n    }\n  }\n\n  /**\n   * Handles existence filters and synthesizes deletes for filter mismatches.\n   * Targets that are invalidated by filter mismatches are added to\n   * `pendingTargetResets`.\n   */\n  handleExistenceFilter(watchChange: ExistenceFilterChange): void {\n    const targetId = watchChange.targetId;\n    const expectedCount = watchChange.existenceFilter.count;\n\n    const targetData = this.targetDataForActiveTarget(targetId);\n    if (targetData) {\n      const target = targetData.target;\n      if (target.isDocumentQuery()) {\n        if (expectedCount === 0) {\n          // The existence filter told us the document does not exist. We deduce\n          // that this document does not exist and apply a deleted document to\n          // our updates. Without applying this deleted document there might be\n          // another query that will raise this document as part of a snapshot\n          // until it is resolved, essentially exposing inconsistency between\n          // queries.\n          const key = new DocumentKey(target.path);\n          this.removeDocumentFromTarget(\n            targetId,\n            key,\n            new NoDocument(key, SnapshotVersion.forDeletedDoc())\n          );\n        } else {\n          hardAssert(\n            expectedCount === 1,\n            'Single document existence filter with count: ' + expectedCount\n          );\n        }\n      } else {\n        const currentSize = this.getCurrentDocumentCountForTarget(targetId);\n        if (currentSize !== expectedCount) {\n          // Existence filter mismatch: We reset the mapping and raise a new\n          // snapshot with `isFromCache:true`.\n          this.resetTarget(targetId);\n          this.pendingTargetResets = this.pendingTargetResets.add(targetId);\n        }\n      }\n    }\n  }\n\n  /**\n   * Converts the currently accumulated state into a remote event at the\n   * provided snapshot version. Resets the accumulated changes before returning.\n   */\n  createRemoteEvent(snapshotVersion: SnapshotVersion): RemoteEvent {\n    const targetChanges = new Map<TargetId, TargetChange>();\n\n    this.targetStates.forEach((targetState, targetId) => {\n      const targetData = this.targetDataForActiveTarget(targetId);\n      if (targetData) {\n        if (targetState.current && targetData.target.isDocumentQuery()) {\n          // Document queries for document that don't exist can produce an empty\n          // result set. To update our local cache, we synthesize a document\n          // delete if we have not previously received the document. This\n          // resolves the limbo state of the document, removing it from\n          // limboDocumentRefs.\n          //\n          // TODO(dimond): Ideally we would have an explicit lookup target\n          // instead resulting in an explicit delete message and we could\n          // remove this special logic.\n          const key = new DocumentKey(targetData.target.path);\n          if (\n            this.pendingDocumentUpdates.get(key) === null &&\n            !this.targetContainsDocument(targetId, key)\n          ) {\n            this.removeDocumentFromTarget(\n              targetId,\n              key,\n              new NoDocument(key, snapshotVersion)\n            );\n          }\n        }\n\n        if (targetState.hasPendingChanges) {\n          targetChanges.set(targetId, targetState.toTargetChange());\n          targetState.clearPendingChanges();\n        }\n      }\n    });\n\n    let resolvedLimboDocuments = documentKeySet();\n\n    // We extract the set of limbo-only document updates as the GC logic\n    // special-cases documents that do not appear in the target cache.\n    //\n    // TODO(gsoltis): Expand on this comment once GC is available in the JS\n    // client.\n    this.pendingDocumentTargetMapping.forEach((key, targets) => {\n      let isOnlyLimboTarget = true;\n\n      targets.forEachWhile(targetId => {\n        const targetData = this.targetDataForActiveTarget(targetId);\n        if (\n          targetData &&\n          targetData.purpose !== TargetPurpose.LimboResolution\n        ) {\n          isOnlyLimboTarget = false;\n          return false;\n        }\n\n        return true;\n      });\n\n      if (isOnlyLimboTarget) {\n        resolvedLimboDocuments = resolvedLimboDocuments.add(key);\n      }\n    });\n\n    const remoteEvent = new RemoteEvent(\n      snapshotVersion,\n      targetChanges,\n      this.pendingTargetResets,\n      this.pendingDocumentUpdates,\n      resolvedLimboDocuments\n    );\n\n    this.pendingDocumentUpdates = maybeDocumentMap();\n    this.pendingDocumentTargetMapping = documentTargetMap();\n    this.pendingTargetResets = new SortedSet<TargetId>(primitiveComparator);\n\n    return remoteEvent;\n  }\n\n  /**\n   * Adds the provided document to the internal list of document updates and\n   * its document key to the given target's mapping.\n   */\n  // Visible for testing.\n  addDocumentToTarget(targetId: TargetId, document: MaybeDocument): void {\n    if (!this.isActiveTarget(targetId)) {\n      return;\n    }\n\n    const changeType = this.targetContainsDocument(targetId, document.key)\n      ? ChangeType.Modified\n      : ChangeType.Added;\n\n    const targetState = this.ensureTargetState(targetId);\n    targetState.addDocumentChange(document.key, changeType);\n\n    this.pendingDocumentUpdates = this.pendingDocumentUpdates.insert(\n      document.key,\n      document\n    );\n\n    this.pendingDocumentTargetMapping = this.pendingDocumentTargetMapping.insert(\n      document.key,\n      this.ensureDocumentTargetMapping(document.key).add(targetId)\n    );\n  }\n\n  /**\n   * Removes the provided document from the target mapping. If the\n   * document no longer matches the target, but the document's state is still\n   * known (e.g. we know that the document was deleted or we received the change\n   * that caused the filter mismatch), the new document can be provided\n   * to update the remote document cache.\n   */\n  // Visible for testing.\n  removeDocumentFromTarget(\n    targetId: TargetId,\n    key: DocumentKey,\n    updatedDocument: MaybeDocument | null\n  ): void {\n    if (!this.isActiveTarget(targetId)) {\n      return;\n    }\n\n    const targetState = this.ensureTargetState(targetId);\n    if (this.targetContainsDocument(targetId, key)) {\n      targetState.addDocumentChange(key, ChangeType.Removed);\n    } else {\n      // The document may have entered and left the target before we raised a\n      // snapshot, so we can just ignore the change.\n      targetState.removeDocumentChange(key);\n    }\n\n    this.pendingDocumentTargetMapping = this.pendingDocumentTargetMapping.insert(\n      key,\n      this.ensureDocumentTargetMapping(key).delete(targetId)\n    );\n\n    if (updatedDocument) {\n      this.pendingDocumentUpdates = this.pendingDocumentUpdates.insert(\n        key,\n        updatedDocument\n      );\n    }\n  }\n\n  removeTarget(targetId: TargetId): void {\n    this.targetStates.delete(targetId);\n  }\n\n  /**\n   * Returns the current count of documents in the target. This includes both\n   * the number of documents that the LocalStore considers to be part of the\n   * target as well as any accumulated changes.\n   */\n  private getCurrentDocumentCountForTarget(targetId: TargetId): number {\n    const targetState = this.ensureTargetState(targetId);\n    const targetChange = targetState.toTargetChange();\n    return (\n      this.metadataProvider.getRemoteKeysForTarget(targetId).size +\n      targetChange.addedDocuments.size -\n      targetChange.removedDocuments.size\n    );\n  }\n\n  /**\n   * Increment the number of acks needed from watch before we can consider the\n   * server to be 'in-sync' with the client's active targets.\n   */\n  recordPendingTargetRequest(targetId: TargetId): void {\n    // For each request we get we need to record we need a response for it.\n    const targetState = this.ensureTargetState(targetId);\n    targetState.recordPendingTargetRequest();\n  }\n\n  private ensureTargetState(targetId: TargetId): TargetState {\n    let result = this.targetStates.get(targetId);\n    if (!result) {\n      result = new TargetState();\n      this.targetStates.set(targetId, result);\n    }\n    return result;\n  }\n\n  private ensureDocumentTargetMapping(key: DocumentKey): SortedSet<TargetId> {\n    let targetMapping = this.pendingDocumentTargetMapping.get(key);\n\n    if (!targetMapping) {\n      targetMapping = new SortedSet<TargetId>(primitiveComparator);\n      this.pendingDocumentTargetMapping = this.pendingDocumentTargetMapping.insert(\n        key,\n        targetMapping\n      );\n    }\n\n    return targetMapping;\n  }\n\n  /**\n   * Verifies that the user is still interested in this target (by calling\n   * `getTargetDataForTarget()`) and that we are not waiting for pending ADDs\n   * from watch.\n   */\n  protected isActiveTarget(targetId: TargetId): boolean {\n    const targetActive = this.targetDataForActiveTarget(targetId) !== null;\n    if (!targetActive) {\n      logDebug(LOG_TAG, 'Detected inactive target', targetId);\n    }\n    return targetActive;\n  }\n\n  /**\n   * Returns the TargetData for an active target (i.e. a target that the user\n   * is still interested in that has no outstanding target change requests).\n   */\n  protected targetDataForActiveTarget(targetId: TargetId): TargetData | null {\n    const targetState = this.targetStates.get(targetId);\n    return targetState && targetState.isPending\n      ? null\n      : this.metadataProvider.getTargetDataForTarget(targetId);\n  }\n\n  /**\n   * Resets the state of a Watch target to its initial state (e.g. sets\n   * 'current' to false, clears the resume token and removes its target mapping\n   * from all documents).\n   */\n  private resetTarget(targetId: TargetId): void {\n    debugAssert(\n      !this.targetStates.get(targetId)!.isPending,\n      'Should only reset active targets'\n    );\n    this.targetStates.set(targetId, new TargetState());\n\n    // Trigger removal for any documents currently mapped to this target.\n    // These removals will be part of the initial snapshot if Watch does not\n    // resend these documents.\n    const existingKeys = this.metadataProvider.getRemoteKeysForTarget(targetId);\n    existingKeys.forEach(key => {\n      this.removeDocumentFromTarget(targetId, key, /*updatedDocument=*/ null);\n    });\n  }\n  /**\n   * Returns whether the LocalStore considers the document to be part of the\n   * specified target.\n   */\n  private targetContainsDocument(\n    targetId: TargetId,\n    key: DocumentKey\n  ): boolean {\n    const existingKeys = this.metadataProvider.getRemoteKeysForTarget(targetId);\n    return existingKeys.has(key);\n  }\n}\n\nfunction documentTargetMap(): SortedMap<DocumentKey, SortedSet<TargetId>> {\n  return new SortedMap<DocumentKey, SortedSet<TargetId>>(\n    DocumentKey.comparator\n  );\n}\n\nfunction snapshotChangesMap(): SortedMap<DocumentKey, ChangeType> {\n  return new SortedMap<DocumentKey, ChangeType>(DocumentKey.comparator);\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Blob } from '../api/blob';\nimport { Timestamp } from '../api/timestamp';\nimport { DatabaseId } from '../core/database_info';\nimport {\n  Bound,\n  Direction,\n  FieldFilter,\n  Filter,\n  LimitType,\n  Operator,\n  OrderBy,\n  Query\n} from '../core/query';\nimport { SnapshotVersion } from '../core/snapshot_version';\nimport { Target } from '../core/target';\nimport { TargetId } from '../core/types';\nimport { TargetData, TargetPurpose } from '../local/target_data';\nimport { Document, MaybeDocument, NoDocument } from '../model/document';\nimport { DocumentKey } from '../model/document_key';\nimport { ObjectValue } from '../model/field_value';\nimport {\n  DeleteMutation,\n  FieldMask,\n  FieldTransform,\n  Mutation,\n  MutationResult,\n  PatchMutation,\n  Precondition,\n  SetMutation,\n  TransformMutation,\n  VerifyMutation\n} from '../model/mutation';\nimport { FieldPath, ResourcePath } from '../model/path';\nimport * as api from '../protos/firestore_proto_api';\nimport { debugAssert, fail, hardAssert } from '../util/assert';\nimport { Code, FirestoreError } from '../util/error';\nimport { ByteString } from '../util/byte_string';\nimport {\n  isNegativeZero,\n  isNullOrUndefined,\n  isSafeInteger\n} from '../util/types';\nimport {\n  ArrayRemoveTransformOperation,\n  ArrayUnionTransformOperation,\n  NumericIncrementTransformOperation,\n  ServerTimestampTransform,\n  TransformOperation\n} from '../model/transform_operation';\nimport { ExistenceFilter } from './existence_filter';\nimport { mapCodeFromRpcCode } from './rpc_error';\nimport {\n  DocumentWatchChange,\n  ExistenceFilterChange,\n  WatchChange,\n  WatchTargetChange,\n  WatchTargetChangeState\n} from './watch_change';\nimport { isNanValue, isNullValue, normalizeTimestamp } from '../model/values';\n\nconst DIRECTIONS = (() => {\n  const dirs: { [dir: string]: api.OrderDirection } = {};\n  dirs[Direction.ASCENDING.name] = 'ASCENDING';\n  dirs[Direction.DESCENDING.name] = 'DESCENDING';\n  return dirs;\n})();\n\nconst OPERATORS = (() => {\n  const ops: { [op: string]: api.FieldFilterOp } = {};\n  ops[Operator.LESS_THAN.name] = 'LESS_THAN';\n  ops[Operator.LESS_THAN_OR_EQUAL.name] = 'LESS_THAN_OR_EQUAL';\n  ops[Operator.GREATER_THAN.name] = 'GREATER_THAN';\n  ops[Operator.GREATER_THAN_OR_EQUAL.name] = 'GREATER_THAN_OR_EQUAL';\n  ops[Operator.EQUAL.name] = 'EQUAL';\n  ops[Operator.ARRAY_CONTAINS.name] = 'ARRAY_CONTAINS';\n  ops[Operator.IN.name] = 'IN';\n  ops[Operator.ARRAY_CONTAINS_ANY.name] = 'ARRAY_CONTAINS_ANY';\n  return ops;\n})();\n\nfunction assertPresent(value: unknown, description: string): asserts value {\n  debugAssert(!isNullOrUndefined(value), description + ' is missing');\n}\n\nexport interface SerializerOptions {\n  /**\n   * The serializer supports both Protobuf.js and Proto3 JSON formats. By\n   * setting this flag to true, the serializer will use the Proto3 JSON format.\n   *\n   * For a description of the Proto3 JSON format check\n   * https://developers.google.com/protocol-buffers/docs/proto3#json\n   */\n  useProto3Json: boolean;\n}\n\n/**\n * Generates JsonObject values for the Datastore API suitable for sending to\n * either GRPC stub methods or via the JSON/HTTP REST API.\n * TODO(klimt): We can remove the databaseId argument if we keep the full\n * resource name in documents.\n */\nexport class JsonProtoSerializer {\n  constructor(\n    private databaseId: DatabaseId,\n    private options: SerializerOptions\n  ) {}\n\n  fromRpcStatus(status: api.Status): FirestoreError {\n    const code =\n      status.code === undefined\n        ? Code.UNKNOWN\n        : mapCodeFromRpcCode(status.code);\n    return new FirestoreError(code, status.message || '');\n  }\n\n  /**\n   * Returns a value for a number (or null) that's appropriate to put into\n   * a google.protobuf.Int32Value proto.\n   * DO NOT USE THIS FOR ANYTHING ELSE.\n   * This method cheats. It's typed as returning \"number\" because that's what\n   * our generated proto interfaces say Int32Value must be. But GRPC actually\n   * expects a { value: <number> } struct.\n   */\n  private toInt32Proto(val: number | null): number | { value: number } | null {\n    if (this.options.useProto3Json || isNullOrUndefined(val)) {\n      return val;\n    } else {\n      return { value: val };\n    }\n  }\n\n  /**\n   * Returns a number (or null) from a google.protobuf.Int32Value proto.\n   */\n  private fromInt32Proto(\n    val: number | { value: number } | undefined\n  ): number | null {\n    let result;\n    if (typeof val === 'object') {\n      result = val.value;\n    } else {\n      result = val;\n    }\n    return isNullOrUndefined(result) ? null : result;\n  }\n\n  /**\n   * Returns an IntegerValue for `value`.\n   */\n  toInteger(value: number): api.Value {\n    return { integerValue: '' + value };\n  }\n\n  /**\n   * Returns an DoubleValue for `value` that is encoded based the serializer's\n   * `useProto3Json` setting.\n   */\n  toDouble(value: number): api.Value {\n    if (this.options.useProto3Json) {\n      if (isNaN(value)) {\n        return { doubleValue: 'NaN' };\n      } else if (value === Infinity) {\n        return { doubleValue: 'Infinity' };\n      } else if (value === -Infinity) {\n        return { doubleValue: '-Infinity' };\n      }\n    }\n    return { doubleValue: isNegativeZero(value) ? '-0' : value };\n  }\n\n  /**\n   * Returns a value for a number that's appropriate to put into a proto.\n   * The return value is an IntegerValue if it can safely represent the value,\n   * otherwise a DoubleValue is returned.\n   */\n  toNumber(value: number): api.Value {\n    return isSafeInteger(value) ? this.toInteger(value) : this.toDouble(value);\n  }\n\n  /**\n   * Returns a value for a Date that's appropriate to put into a proto.\n   */\n  toTimestamp(timestamp: Timestamp): api.Timestamp {\n    if (this.options.useProto3Json) {\n      // Serialize to ISO-8601 date format, but with full nano resolution.\n      // Since JS Date has only millis, let's only use it for the seconds and\n      // then manually add the fractions to the end.\n      const jsDateStr = new Date(timestamp.seconds * 1000).toISOString();\n      // Remove .xxx frac part and Z in the end.\n      const strUntilSeconds = jsDateStr.replace(/\\.\\d*/, '').replace('Z', '');\n      // Pad the fraction out to 9 digits (nanos).\n      const nanoStr = ('000000000' + timestamp.nanoseconds).slice(-9);\n\n      return `${strUntilSeconds}.${nanoStr}Z`;\n    } else {\n      return {\n        seconds: '' + timestamp.seconds,\n        nanos: timestamp.nanoseconds\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any\n      } as any;\n    }\n  }\n\n  private fromTimestamp(date: api.Timestamp): Timestamp {\n    const timestamp = normalizeTimestamp(date);\n    return new Timestamp(timestamp.seconds, timestamp.nanos);\n  }\n\n  /**\n   * Returns a value for bytes that's appropriate to put in a proto.\n   *\n   * Visible for testing.\n   */\n  toBytes(bytes: Blob | ByteString): string | Uint8Array {\n    if (this.options.useProto3Json) {\n      return bytes.toBase64();\n    } else {\n      return bytes.toUint8Array();\n    }\n  }\n\n  /**\n   * Returns a ByteString based on the proto string value.\n   */\n  fromBytes(value: string | Uint8Array | undefined): ByteString {\n    if (this.options.useProto3Json) {\n      hardAssert(\n        value === undefined || typeof value === 'string',\n        'value must be undefined or a string when using proto3 Json'\n      );\n      return ByteString.fromBase64String(value ? value : '');\n    } else {\n      hardAssert(\n        value === undefined || value instanceof Uint8Array,\n        'value must be undefined or Uint8Array'\n      );\n      return ByteString.fromUint8Array(value ? value : new Uint8Array());\n    }\n  }\n\n  toVersion(version: SnapshotVersion): api.Timestamp {\n    return this.toTimestamp(version.toTimestamp());\n  }\n\n  fromVersion(version: api.Timestamp): SnapshotVersion {\n    hardAssert(!!version, \"Trying to deserialize version that isn't set\");\n    return SnapshotVersion.fromTimestamp(this.fromTimestamp(version));\n  }\n\n  toResourceName(path: ResourcePath, databaseId?: DatabaseId): string {\n    return this.fullyQualifiedPrefixPath(databaseId || this.databaseId)\n      .child('documents')\n      .child(path)\n      .canonicalString();\n  }\n\n  fromResourceName(name: string): ResourcePath {\n    const resource = ResourcePath.fromString(name);\n    hardAssert(\n      isValidResourceName(resource),\n      'Tried to deserialize invalid key ' + resource.toString()\n    );\n    return resource;\n  }\n\n  toName(key: DocumentKey): string {\n    return this.toResourceName(key.path);\n  }\n\n  fromName(name: string): DocumentKey {\n    const resource = this.fromResourceName(name);\n    hardAssert(\n      resource.get(1) === this.databaseId.projectId,\n      'Tried to deserialize key from different project: ' +\n        resource.get(1) +\n        ' vs ' +\n        this.databaseId.projectId\n    );\n    hardAssert(\n      (!resource.get(3) && !this.databaseId.database) ||\n        resource.get(3) === this.databaseId.database,\n      'Tried to deserialize key from different database: ' +\n        resource.get(3) +\n        ' vs ' +\n        this.databaseId.database\n    );\n    return new DocumentKey(this.extractLocalPathFromResourceName(resource));\n  }\n\n  toQueryPath(path: ResourcePath): string {\n    return this.toResourceName(path);\n  }\n\n  fromQueryPath(name: string): ResourcePath {\n    const resourceName = this.fromResourceName(name);\n    // In v1beta1 queries for collections at the root did not have a trailing\n    // \"/documents\". In v1 all resource paths contain \"/documents\". Preserve the\n    // ability to read the v1beta1 form for compatibility with queries persisted\n    // in the local target cache.\n    if (resourceName.length === 4) {\n      return ResourcePath.EMPTY_PATH;\n    }\n    return this.extractLocalPathFromResourceName(resourceName);\n  }\n\n  get encodedDatabaseId(): string {\n    const path = new ResourcePath([\n      'projects',\n      this.databaseId.projectId,\n      'databases',\n      this.databaseId.database\n    ]);\n    return path.canonicalString();\n  }\n\n  private fullyQualifiedPrefixPath(databaseId: DatabaseId): ResourcePath {\n    return new ResourcePath([\n      'projects',\n      databaseId.projectId,\n      'databases',\n      databaseId.database\n    ]);\n  }\n\n  private extractLocalPathFromResourceName(\n    resourceName: ResourcePath\n  ): ResourcePath {\n    hardAssert(\n      resourceName.length > 4 && resourceName.get(4) === 'documents',\n      'tried to deserialize invalid key ' + resourceName.toString()\n    );\n    return resourceName.popFirst(5);\n  }\n\n  /** Creates an api.Document from key and fields (but no create/update time) */\n  toMutationDocument(key: DocumentKey, fields: ObjectValue): api.Document {\n    return {\n      name: this.toName(key),\n      fields: fields.proto.mapValue.fields\n    };\n  }\n\n  toDocument(document: Document): api.Document {\n    debugAssert(\n      !document.hasLocalMutations,\n      \"Can't serialize documents with mutations.\"\n    );\n    return {\n      name: this.toName(document.key),\n      fields: document.toProto().mapValue.fields,\n      updateTime: this.toTimestamp(document.version.toTimestamp())\n    };\n  }\n\n  fromDocument(\n    document: api.Document,\n    hasCommittedMutations?: boolean\n  ): Document {\n    const key = this.fromName(document.name!);\n    const version = this.fromVersion(document.updateTime!);\n    const data = new ObjectValue({ mapValue: { fields: document.fields } });\n    return new Document(key, version, data, {\n      hasCommittedMutations: !!hasCommittedMutations\n    });\n  }\n\n  private fromFound(doc: api.BatchGetDocumentsResponse): Document {\n    hardAssert(\n      !!doc.found,\n      'Tried to deserialize a found document from a missing document.'\n    );\n    assertPresent(doc.found.name, 'doc.found.name');\n    assertPresent(doc.found.updateTime, 'doc.found.updateTime');\n    const key = this.fromName(doc.found.name);\n    const version = this.fromVersion(doc.found.updateTime);\n    const data = new ObjectValue({ mapValue: { fields: doc.found.fields } });\n    return new Document(key, version, data, {});\n  }\n\n  private fromMissing(result: api.BatchGetDocumentsResponse): NoDocument {\n    hardAssert(\n      !!result.missing,\n      'Tried to deserialize a missing document from a found document.'\n    );\n    hardAssert(\n      !!result.readTime,\n      'Tried to deserialize a missing document without a read time.'\n    );\n    const key = this.fromName(result.missing);\n    const version = this.fromVersion(result.readTime);\n    return new NoDocument(key, version);\n  }\n\n  fromMaybeDocument(result: api.BatchGetDocumentsResponse): MaybeDocument {\n    if ('found' in result) {\n      return this.fromFound(result);\n    } else if ('missing' in result) {\n      return this.fromMissing(result);\n    }\n    return fail('invalid batch get response: ' + JSON.stringify(result));\n  }\n\n  fromWatchChange(change: api.ListenResponse): WatchChange {\n    let watchChange: WatchChange;\n    if ('targetChange' in change) {\n      assertPresent(change.targetChange, 'targetChange');\n      // proto3 default value is unset in JSON (undefined), so use 'NO_CHANGE'\n      // if unset\n      const state = this.fromWatchTargetChangeState(\n        change.targetChange.targetChangeType || 'NO_CHANGE'\n      );\n      const targetIds: TargetId[] = change.targetChange.targetIds || [];\n\n      const resumeToken = this.fromBytes(change.targetChange.resumeToken);\n      const causeProto = change.targetChange!.cause;\n      const cause = causeProto && this.fromRpcStatus(causeProto);\n      watchChange = new WatchTargetChange(\n        state,\n        targetIds,\n        resumeToken,\n        cause || null\n      );\n    } else if ('documentChange' in change) {\n      assertPresent(change.documentChange, 'documentChange');\n      const entityChange = change.documentChange;\n      assertPresent(entityChange.document, 'documentChange.name');\n      assertPresent(entityChange.document.name, 'documentChange.document.name');\n      assertPresent(\n        entityChange.document.updateTime,\n        'documentChange.document.updateTime'\n      );\n      const key = this.fromName(entityChange.document.name);\n      const version = this.fromVersion(entityChange.document.updateTime);\n      const data = new ObjectValue({\n        mapValue: { fields: entityChange.document.fields }\n      });\n      const doc = new Document(key, version, data, {});\n      const updatedTargetIds = entityChange.targetIds || [];\n      const removedTargetIds = entityChange.removedTargetIds || [];\n      watchChange = new DocumentWatchChange(\n        updatedTargetIds,\n        removedTargetIds,\n        doc.key,\n        doc\n      );\n    } else if ('documentDelete' in change) {\n      assertPresent(change.documentDelete, 'documentDelete');\n      const docDelete = change.documentDelete;\n      assertPresent(docDelete.document, 'documentDelete.document');\n      const key = this.fromName(docDelete.document);\n      const version = docDelete.readTime\n        ? this.fromVersion(docDelete.readTime)\n        : SnapshotVersion.forDeletedDoc();\n      const doc = new NoDocument(key, version);\n      const removedTargetIds = docDelete.removedTargetIds || [];\n      watchChange = new DocumentWatchChange([], removedTargetIds, doc.key, doc);\n    } else if ('documentRemove' in change) {\n      assertPresent(change.documentRemove, 'documentRemove');\n      const docRemove = change.documentRemove;\n      assertPresent(docRemove.document, 'documentRemove');\n      const key = this.fromName(docRemove.document);\n      const removedTargetIds = docRemove.removedTargetIds || [];\n      watchChange = new DocumentWatchChange([], removedTargetIds, key, null);\n    } else if ('filter' in change) {\n      // TODO(dimond): implement existence filter parsing with strategy.\n      assertPresent(change.filter, 'filter');\n      const filter = change.filter;\n      assertPresent(filter.targetId, 'filter.targetId');\n      const count = filter.count || 0;\n      const existenceFilter = new ExistenceFilter(count);\n      const targetId = filter.targetId;\n      watchChange = new ExistenceFilterChange(targetId, existenceFilter);\n    } else {\n      return fail('Unknown change type ' + JSON.stringify(change));\n    }\n    return watchChange;\n  }\n\n  fromWatchTargetChangeState(\n    state: api.TargetChangeTargetChangeType\n  ): WatchTargetChangeState {\n    if (state === 'NO_CHANGE') {\n      return WatchTargetChangeState.NoChange;\n    } else if (state === 'ADD') {\n      return WatchTargetChangeState.Added;\n    } else if (state === 'REMOVE') {\n      return WatchTargetChangeState.Removed;\n    } else if (state === 'CURRENT') {\n      return WatchTargetChangeState.Current;\n    } else if (state === 'RESET') {\n      return WatchTargetChangeState.Reset;\n    } else {\n      return fail('Got unexpected TargetChange.state: ' + state);\n    }\n  }\n\n  versionFromListenResponse(change: api.ListenResponse): SnapshotVersion {\n    // We have only reached a consistent snapshot for the entire stream if there\n    // is a read_time set and it applies to all targets (i.e. the list of\n    // targets is empty). The backend is guaranteed to send such responses.\n    if (!('targetChange' in change)) {\n      return SnapshotVersion.MIN;\n    }\n    const targetChange = change.targetChange!;\n    if (targetChange.targetIds && targetChange.targetIds.length) {\n      return SnapshotVersion.MIN;\n    }\n    if (!targetChange.readTime) {\n      return SnapshotVersion.MIN;\n    }\n    return this.fromVersion(targetChange.readTime);\n  }\n\n  toMutation(mutation: Mutation): api.Write {\n    let result: api.Write;\n    if (mutation instanceof SetMutation) {\n      result = {\n        update: this.toMutationDocument(mutation.key, mutation.value)\n      };\n    } else if (mutation instanceof DeleteMutation) {\n      result = { delete: this.toName(mutation.key) };\n    } else if (mutation instanceof PatchMutation) {\n      result = {\n        update: this.toMutationDocument(mutation.key, mutation.data),\n        updateMask: this.toDocumentMask(mutation.fieldMask)\n      };\n    } else if (mutation instanceof TransformMutation) {\n      result = {\n        transform: {\n          document: this.toName(mutation.key),\n          fieldTransforms: mutation.fieldTransforms.map(transform =>\n            this.toFieldTransform(transform)\n          )\n        }\n      };\n    } else if (mutation instanceof VerifyMutation) {\n      result = {\n        verify: this.toName(mutation.key)\n      };\n    } else {\n      return fail('Unknown mutation type ' + mutation.type);\n    }\n\n    if (!mutation.precondition.isNone) {\n      result.currentDocument = this.toPrecondition(mutation.precondition);\n    }\n\n    return result;\n  }\n\n  fromMutation(proto: api.Write): Mutation {\n    const precondition = proto.currentDocument\n      ? this.fromPrecondition(proto.currentDocument)\n      : Precondition.NONE;\n\n    if (proto.update) {\n      assertPresent(proto.update.name, 'name');\n      const key = this.fromName(proto.update.name);\n      const value = new ObjectValue({\n        mapValue: { fields: proto.update.fields }\n      });\n      if (proto.updateMask) {\n        const fieldMask = this.fromDocumentMask(proto.updateMask);\n        return new PatchMutation(key, value, fieldMask, precondition);\n      } else {\n        return new SetMutation(key, value, precondition);\n      }\n    } else if (proto.delete) {\n      const key = this.fromName(proto.delete);\n      return new DeleteMutation(key, precondition);\n    } else if (proto.transform) {\n      const key = this.fromName(proto.transform.document!);\n      const fieldTransforms = proto.transform.fieldTransforms!.map(transform =>\n        this.fromFieldTransform(transform)\n      );\n      hardAssert(\n        precondition.exists === true,\n        'Transforms only support precondition \"exists == true\"'\n      );\n      return new TransformMutation(key, fieldTransforms);\n    } else if (proto.verify) {\n      const key = this.fromName(proto.verify);\n      return new VerifyMutation(key, precondition);\n    } else {\n      return fail('unknown mutation proto: ' + JSON.stringify(proto));\n    }\n  }\n\n  private toPrecondition(precondition: Precondition): api.Precondition {\n    debugAssert(!precondition.isNone, \"Can't serialize an empty precondition\");\n    if (precondition.updateTime !== undefined) {\n      return {\n        updateTime: this.toVersion(precondition.updateTime)\n      };\n    } else if (precondition.exists !== undefined) {\n      return { exists: precondition.exists };\n    } else {\n      return fail('Unknown precondition');\n    }\n  }\n\n  private fromPrecondition(precondition: api.Precondition): Precondition {\n    if (precondition.updateTime !== undefined) {\n      return Precondition.updateTime(this.fromVersion(precondition.updateTime));\n    } else if (precondition.exists !== undefined) {\n      return Precondition.exists(precondition.exists);\n    } else {\n      return Precondition.NONE;\n    }\n  }\n\n  private fromWriteResult(\n    proto: api.WriteResult,\n    commitTime: api.Timestamp\n  ): MutationResult {\n    // NOTE: Deletes don't have an updateTime.\n    let version = proto.updateTime\n      ? this.fromVersion(proto.updateTime)\n      : this.fromVersion(commitTime);\n\n    if (version.isEqual(SnapshotVersion.MIN)) {\n      // The Firestore Emulator currently returns an update time of 0 for\n      // deletes of non-existing documents (rather than null). This breaks the\n      // test \"get deleted doc while offline with source=cache\" as NoDocuments\n      // with version 0 are filtered by IndexedDb's RemoteDocumentCache.\n      // TODO(#2149): Remove this when Emulator is fixed\n      version = this.fromVersion(commitTime);\n    }\n\n    let transformResults: api.Value[] | null = null;\n    if (proto.transformResults && proto.transformResults.length > 0) {\n      transformResults = proto.transformResults;\n    }\n    return new MutationResult(version, transformResults);\n  }\n\n  fromWriteResults(\n    protos: api.WriteResult[] | undefined,\n    commitTime?: api.Timestamp\n  ): MutationResult[] {\n    if (protos && protos.length > 0) {\n      hardAssert(\n        commitTime !== undefined,\n        'Received a write result without a commit time'\n      );\n      return protos.map(proto => this.fromWriteResult(proto, commitTime));\n    } else {\n      return [];\n    }\n  }\n\n  private toFieldTransform(fieldTransform: FieldTransform): api.FieldTransform {\n    const transform = fieldTransform.transform;\n    if (transform instanceof ServerTimestampTransform) {\n      return {\n        fieldPath: fieldTransform.field.canonicalString(),\n        setToServerValue: 'REQUEST_TIME'\n      };\n    } else if (transform instanceof ArrayUnionTransformOperation) {\n      return {\n        fieldPath: fieldTransform.field.canonicalString(),\n        appendMissingElements: {\n          values: transform.elements\n        }\n      };\n    } else if (transform instanceof ArrayRemoveTransformOperation) {\n      return {\n        fieldPath: fieldTransform.field.canonicalString(),\n        removeAllFromArray: {\n          values: transform.elements\n        }\n      };\n    } else if (transform instanceof NumericIncrementTransformOperation) {\n      return {\n        fieldPath: fieldTransform.field.canonicalString(),\n        increment: transform.operand\n      };\n    } else {\n      throw fail('Unknown transform: ' + fieldTransform.transform);\n    }\n  }\n\n  private fromFieldTransform(proto: api.FieldTransform): FieldTransform {\n    let transform: TransformOperation | null = null;\n    if ('setToServerValue' in proto) {\n      hardAssert(\n        proto.setToServerValue === 'REQUEST_TIME',\n        'Unknown server value transform proto: ' + JSON.stringify(proto)\n      );\n      transform = ServerTimestampTransform.instance;\n    } else if ('appendMissingElements' in proto) {\n      const values = proto.appendMissingElements!.values || [];\n      transform = new ArrayUnionTransformOperation(values);\n    } else if ('removeAllFromArray' in proto) {\n      const values = proto.removeAllFromArray!.values || [];\n      transform = new ArrayRemoveTransformOperation(values);\n    } else if ('increment' in proto) {\n      transform = new NumericIncrementTransformOperation(\n        this,\n        proto.increment!\n      );\n    } else {\n      fail('Unknown transform proto: ' + JSON.stringify(proto));\n    }\n    const fieldPath = FieldPath.fromServerFormat(proto.fieldPath!);\n    return new FieldTransform(fieldPath, transform!);\n  }\n\n  toDocumentsTarget(target: Target): api.DocumentsTarget {\n    return { documents: [this.toQueryPath(target.path)] };\n  }\n\n  fromDocumentsTarget(documentsTarget: api.DocumentsTarget): Target {\n    const count = documentsTarget.documents!.length;\n    hardAssert(\n      count === 1,\n      'DocumentsTarget contained other than 1 document: ' + count\n    );\n    const name = documentsTarget.documents![0];\n    return Query.atPath(this.fromQueryPath(name)).toTarget();\n  }\n\n  toQueryTarget(target: Target): api.QueryTarget {\n    // Dissect the path into parent, collectionId, and optional key filter.\n    const result: api.QueryTarget = { structuredQuery: {} };\n    const path = target.path;\n    if (target.collectionGroup !== null) {\n      debugAssert(\n        path.length % 2 === 0,\n        'Collection Group queries should be within a document path or root.'\n      );\n      result.parent = this.toQueryPath(path);\n      result.structuredQuery!.from = [\n        {\n          collectionId: target.collectionGroup,\n          allDescendants: true\n        }\n      ];\n    } else {\n      debugAssert(\n        path.length % 2 !== 0,\n        'Document queries with filters are not supported.'\n      );\n      result.parent = this.toQueryPath(path.popLast());\n      result.structuredQuery!.from = [{ collectionId: path.lastSegment() }];\n    }\n\n    const where = this.toFilter(target.filters);\n    if (where) {\n      result.structuredQuery!.where = where;\n    }\n\n    const orderBy = this.toOrder(target.orderBy);\n    if (orderBy) {\n      result.structuredQuery!.orderBy = orderBy;\n    }\n\n    const limit = this.toInt32Proto(target.limit);\n    if (limit !== null) {\n      result.structuredQuery!.limit = limit;\n    }\n\n    if (target.startAt) {\n      result.structuredQuery!.startAt = this.toCursor(target.startAt);\n    }\n    if (target.endAt) {\n      result.structuredQuery!.endAt = this.toCursor(target.endAt);\n    }\n\n    return result;\n  }\n\n  fromQueryTarget(target: api.QueryTarget): Target {\n    let path = this.fromQueryPath(target.parent!);\n\n    const query = target.structuredQuery!;\n    const fromCount = query.from ? query.from.length : 0;\n    let collectionGroup: string | null = null;\n    if (fromCount > 0) {\n      hardAssert(\n        fromCount === 1,\n        'StructuredQuery.from with more than one collection is not supported.'\n      );\n      const from = query.from![0];\n      if (from.allDescendants) {\n        collectionGroup = from.collectionId!;\n      } else {\n        path = path.child(from.collectionId!);\n      }\n    }\n\n    let filterBy: Filter[] = [];\n    if (query.where) {\n      filterBy = this.fromFilter(query.where);\n    }\n\n    let orderBy: OrderBy[] = [];\n    if (query.orderBy) {\n      orderBy = this.fromOrder(query.orderBy);\n    }\n\n    let limit: number | null = null;\n    if (query.limit) {\n      limit = this.fromInt32Proto(query.limit);\n    }\n\n    let startAt: Bound | null = null;\n    if (query.startAt) {\n      startAt = this.fromCursor(query.startAt);\n    }\n\n    let endAt: Bound | null = null;\n    if (query.endAt) {\n      endAt = this.fromCursor(query.endAt);\n    }\n\n    return new Query(\n      path,\n      collectionGroup,\n      orderBy,\n      filterBy,\n      limit,\n      LimitType.First,\n      startAt,\n      endAt\n    ).toTarget();\n  }\n\n  toListenRequestLabels(\n    targetData: TargetData\n  ): api.ApiClientObjectMap<string> | null {\n    const value = this.toLabel(targetData.purpose);\n    if (value == null) {\n      return null;\n    } else {\n      return {\n        'goog-listen-tags': value\n      };\n    }\n  }\n\n  private toLabel(purpose: TargetPurpose): string | null {\n    switch (purpose) {\n      case TargetPurpose.Listen:\n        return null;\n      case TargetPurpose.ExistenceFilterMismatch:\n        return 'existence-filter-mismatch';\n      case TargetPurpose.LimboResolution:\n        return 'limbo-document';\n      default:\n        return fail('Unrecognized query purpose: ' + purpose);\n    }\n  }\n\n  toTarget(targetData: TargetData): api.Target {\n    let result: api.Target;\n    const target = targetData.target;\n\n    if (target.isDocumentQuery()) {\n      result = { documents: this.toDocumentsTarget(target) };\n    } else {\n      result = { query: this.toQueryTarget(target) };\n    }\n\n    result.targetId = targetData.targetId;\n\n    if (targetData.resumeToken.approximateByteSize() > 0) {\n      result.resumeToken = this.toBytes(targetData.resumeToken);\n    }\n\n    return result;\n  }\n\n  private toFilter(filters: Filter[]): api.Filter | undefined {\n    if (filters.length === 0) {\n      return;\n    }\n    const protos = filters.map(filter => {\n      if (filter instanceof FieldFilter) {\n        return this.toUnaryOrFieldFilter(filter);\n      } else {\n        return fail('Unrecognized filter: ' + JSON.stringify(filter));\n      }\n    });\n    if (protos.length === 1) {\n      return protos[0];\n    }\n    return { compositeFilter: { op: 'AND', filters: protos } };\n  }\n\n  private fromFilter(filter: api.Filter | undefined): Filter[] {\n    if (!filter) {\n      return [];\n    } else if (filter.unaryFilter !== undefined) {\n      return [this.fromUnaryFilter(filter)];\n    } else if (filter.fieldFilter !== undefined) {\n      return [this.fromFieldFilter(filter)];\n    } else if (filter.compositeFilter !== undefined) {\n      return filter.compositeFilter\n        .filters!.map(f => this.fromFilter(f))\n        .reduce((accum, current) => accum.concat(current));\n    } else {\n      return fail('Unknown filter: ' + JSON.stringify(filter));\n    }\n  }\n\n  private toOrder(orderBys: OrderBy[]): api.Order[] | undefined {\n    if (orderBys.length === 0) {\n      return;\n    }\n    return orderBys.map(order => this.toPropertyOrder(order));\n  }\n\n  private fromOrder(orderBys: api.Order[]): OrderBy[] {\n    return orderBys.map(order => this.fromPropertyOrder(order));\n  }\n\n  private toCursor(cursor: Bound): api.Cursor {\n    return {\n      before: cursor.before,\n      values: cursor.position\n    };\n  }\n\n  private fromCursor(cursor: api.Cursor): Bound {\n    const before = !!cursor.before;\n    const position = cursor.values || [];\n    return new Bound(position, before);\n  }\n\n  // visible for testing\n  toDirection(dir: Direction): api.OrderDirection {\n    return DIRECTIONS[dir.name];\n  }\n\n  // visible for testing\n  fromDirection(dir: api.OrderDirection | undefined): Direction | undefined {\n    switch (dir) {\n      case 'ASCENDING':\n        return Direction.ASCENDING;\n      case 'DESCENDING':\n        return Direction.DESCENDING;\n      default:\n        return undefined;\n    }\n  }\n\n  // visible for testing\n  toOperatorName(op: Operator): api.FieldFilterOp {\n    return OPERATORS[op.name];\n  }\n\n  fromOperatorName(op: api.FieldFilterOp): Operator {\n    switch (op) {\n      case 'EQUAL':\n        return Operator.EQUAL;\n      case 'GREATER_THAN':\n        return Operator.GREATER_THAN;\n      case 'GREATER_THAN_OR_EQUAL':\n        return Operator.GREATER_THAN_OR_EQUAL;\n      case 'LESS_THAN':\n        return Operator.LESS_THAN;\n      case 'LESS_THAN_OR_EQUAL':\n        return Operator.LESS_THAN_OR_EQUAL;\n      case 'ARRAY_CONTAINS':\n        return Operator.ARRAY_CONTAINS;\n      case 'IN':\n        return Operator.IN;\n      case 'ARRAY_CONTAINS_ANY':\n        return Operator.ARRAY_CONTAINS_ANY;\n      case 'OPERATOR_UNSPECIFIED':\n        return fail('Unspecified operator');\n      default:\n        return fail('Unknown operator');\n    }\n  }\n\n  toFieldPathReference(path: FieldPath): api.FieldReference {\n    return { fieldPath: path.canonicalString() };\n  }\n\n  fromFieldPathReference(fieldReference: api.FieldReference): FieldPath {\n    return FieldPath.fromServerFormat(fieldReference.fieldPath!);\n  }\n\n  // visible for testing\n  toPropertyOrder(orderBy: OrderBy): api.Order {\n    return {\n      field: this.toFieldPathReference(orderBy.field),\n      direction: this.toDirection(orderBy.dir)\n    };\n  }\n\n  fromPropertyOrder(orderBy: api.Order): OrderBy {\n    return new OrderBy(\n      this.fromFieldPathReference(orderBy.field!),\n      this.fromDirection(orderBy.direction)\n    );\n  }\n\n  fromFieldFilter(filter: api.Filter): Filter {\n    return FieldFilter.create(\n      this.fromFieldPathReference(filter.fieldFilter!.field!),\n      this.fromOperatorName(filter.fieldFilter!.op!),\n      filter.fieldFilter!.value!\n    );\n  }\n\n  // visible for testing\n  toUnaryOrFieldFilter(filter: FieldFilter): api.Filter {\n    if (filter.op === Operator.EQUAL) {\n      if (isNanValue(filter.value)) {\n        return {\n          unaryFilter: {\n            field: this.toFieldPathReference(filter.field),\n            op: 'IS_NAN'\n          }\n        };\n      } else if (isNullValue(filter.value)) {\n        return {\n          unaryFilter: {\n            field: this.toFieldPathReference(filter.field),\n            op: 'IS_NULL'\n          }\n        };\n      }\n    }\n    return {\n      fieldFilter: {\n        field: this.toFieldPathReference(filter.field),\n        op: this.toOperatorName(filter.op),\n        value: filter.value\n      }\n    };\n  }\n\n  fromUnaryFilter(filter: api.Filter): Filter {\n    switch (filter.unaryFilter!.op!) {\n      case 'IS_NAN':\n        const nanField = this.fromFieldPathReference(\n          filter.unaryFilter!.field!\n        );\n        return FieldFilter.create(nanField, Operator.EQUAL, {\n          doubleValue: NaN\n        });\n      case 'IS_NULL':\n        const nullField = this.fromFieldPathReference(\n          filter.unaryFilter!.field!\n        );\n        return FieldFilter.create(nullField, Operator.EQUAL, {\n          nullValue: 'NULL_VALUE'\n        });\n      case 'OPERATOR_UNSPECIFIED':\n        return fail('Unspecified filter');\n      default:\n        return fail('Unknown filter');\n    }\n  }\n\n  toDocumentMask(fieldMask: FieldMask): api.DocumentMask {\n    const canonicalFields: string[] = [];\n    fieldMask.fields.forEach(field =>\n      canonicalFields.push(field.canonicalString())\n    );\n    return {\n      fieldPaths: canonicalFields\n    };\n  }\n\n  fromDocumentMask(proto: api.DocumentMask): FieldMask {\n    const paths = proto.fieldPaths || [];\n    const fields = paths.map(path => FieldPath.fromServerFormat(path));\n    return FieldMask.fromArray(fields);\n  }\n}\n\nexport function isValidResourceName(path: ResourcePath): boolean {\n  // Resource names have at least 4 components (project ID, database ID)\n  return (\n    path.length >= 4 &&\n    path.get(0) === 'projects' &&\n    path.get(2) === 'databases'\n  );\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { DatabaseId, DatabaseInfo } from '../core/database_info';\nimport { Connection } from '../remote/connection';\nimport { JsonProtoSerializer } from '../remote/serializer';\nimport { fail } from '../util/assert';\nimport { ConnectivityMonitor } from './../remote/connectivity_monitor';\n\n/**\n * Provides a common interface to load anything platform dependent, e.g.\n * the connection implementation.\n *\n * An implementation of this must be provided at compile time for the platform.\n */\n// TODO: Consider only exposing the APIs of 'document' and 'window' that we\n// use in our client.\nexport interface Platform {\n  loadConnection(databaseInfo: DatabaseInfo): Promise<Connection>;\n  newConnectivityMonitor(): ConnectivityMonitor;\n  newSerializer(databaseId: DatabaseId): JsonProtoSerializer;\n\n  /** Formats an object as a JSON string, suitable for logging. */\n  formatJSON(value: unknown): string;\n\n  /** Converts a Base64 encoded string to a binary string. */\n  atob(encoded: string): string;\n\n  /** Converts a binary string to a Base64 encoded string. */\n  btoa(raw: string): string;\n\n  /** The Platform's 'window' implementation or null if not available. */\n  readonly window: Window | null;\n\n  /** The Platform's 'document' implementation or null if not available. */\n  readonly document: Document | null;\n\n  /** True if and only if the Base64 conversion functions are available. */\n  readonly base64Available: boolean;\n\n  /**\n   * True if timestamps, bytes and numbers are represented in Proto3 JSON\n   * format (in-memory and on the wire)\n   */\n  readonly useProto3Json: boolean;\n}\n\n/**\n * Provides singleton helpers where setup code can inject a platform at runtime.\n * setPlatform needs to be set before Firestore is used and must be set exactly\n * once.\n */\nexport class PlatformSupport {\n  private static platform: Platform;\n  static setPlatform(platform: Platform): void {\n    if (PlatformSupport.platform) {\n      fail('Platform already defined');\n    }\n    PlatformSupport.platform = platform;\n  }\n\n  static getPlatform(): Platform {\n    if (!PlatformSupport.platform) {\n      fail('Platform not set');\n    }\n    return PlatformSupport.platform;\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Logger, LogLevel } from '@firebase/logger';\nimport { SDK_VERSION } from '../core/version';\nimport { PlatformSupport } from '../platform/platform';\n\nexport { LogLevel };\n\nconst logClient = new Logger('@firebase/firestore');\n\n// Helper methods are needed because variables can't be exported as read/write\nexport function getLogLevel(): LogLevel {\n  return logClient.logLevel;\n}\n\nexport function setLogLevel(newLevel: LogLevel): void {\n  logClient.logLevel = newLevel;\n}\n\nexport function logDebug(msg: string, ...obj: unknown[]): void {\n  if (logClient.logLevel <= LogLevel.DEBUG) {\n    const args = obj.map(argToString);\n    logClient.debug(`Firestore (${SDK_VERSION}): ${msg}`, ...args);\n  }\n}\n\nexport function logError(msg: string, ...obj: unknown[]): void {\n  if (logClient.logLevel <= LogLevel.ERROR) {\n    const args = obj.map(argToString);\n    logClient.error(`Firestore (${SDK_VERSION}): ${msg}`, ...args);\n  }\n}\n\n/**\n * Converts an additional log parameter to a string representation.\n */\nfunction argToString(obj: unknown): string | unknown {\n  if (typeof obj === 'string') {\n    return obj;\n  } else {\n    const platform = PlatformSupport.getPlatform();\n    try {\n      return platform.formatJSON(obj);\n    } catch (e) {\n      // Converting to JSON failed, just log the object directly\n      return obj;\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { SDK_VERSION } from '../core/version';\nimport { logError } from './log';\n\n/**\n * Unconditionally fails, throwing an Error with the given message.\n *\n * Returns `never` and can be used in expressions:\n * @example\n * let futureVar = fail('not implemented yet');\n */\nexport function fail(failure: string): never {\n  // Log the failure in addition to throw an exception, just in case the\n  // exception is swallowed.\n  const message =\n    `FIRESTORE (${SDK_VERSION}) INTERNAL ASSERTION FAILED: ` + failure;\n  logError(message);\n\n  // NOTE: We don't use FirestoreError here because these are internal failures\n  // that cannot be handled by the user. (Also it would create a circular\n  // dependency between the error and assert modules which doesn't work.)\n  throw new Error(message);\n}\n\n/**\n * Fails if the given assertion condition is false, throwing an Error with the\n * given message if it did.\n */\nexport function hardAssert(\n  assertion: boolean,\n  message: string\n): asserts assertion {\n  if (!assertion) {\n    fail(message);\n  }\n}\n\n\n/**\n * Fails if the given assertion condition is false, throwing an Error with the\n * given message if it did.\n *\n * The code of callsites invoking this function are stripped out in production\n * builds. Any side-effects of code within the debugAssert() invocation will not\n * happen in this case.\n */\nexport function debugAssert(\n  assertion: boolean,\n  message: string\n): asserts assertion {\n  if (!assertion) {\n    fail(message);\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { debugAssert } from './assert';\n\nexport type EventHandler<E> = (value: E) => void;\nexport interface Indexable {\n  [k: string]: unknown;\n}\n\nexport class AutoId {\n  static newId(): string {\n    // Alphanumeric characters\n    const chars =\n      'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789';\n    let autoId = '';\n    for (let i = 0; i < 20; i++) {\n      autoId += chars.charAt(Math.floor(Math.random() * chars.length));\n    }\n    debugAssert(autoId.length === 20, 'Invalid auto ID: ' + autoId);\n    return autoId;\n  }\n}\n\nexport function primitiveComparator<T>(left: T, right: T): number {\n  if (left < right) {\n    return -1;\n  }\n  if (left > right) {\n    return 1;\n  }\n  return 0;\n}\n\nexport interface Equatable<T> {\n  isEqual(other: T): boolean;\n}\n\n/** Helper to compare arrays using isEqual(). */\nexport function arrayEquals<T>(\n  left: T[],\n  right: T[],\n  comparator: (l: T, r: T) => boolean\n): boolean {\n  if (left.length !== right.length) {\n    return false;\n  }\n  return left.every((value, index) => comparator(value, right[index]));\n}\n/**\n * Returns the immediate lexicographically-following string. This is useful to\n * construct an inclusive range for indexeddb iterators.\n */\nexport function immediateSuccessor(s: string): string {\n  // Return the input string, with an additional NUL byte appended.\n  return s + '\\0';\n}\n","/**\n * @license\n * Copyright 2017 Google Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { primitiveComparator } from '../util/misc';\n\nexport class DatabaseInfo {\n  /**\n   * Constructs a DatabaseInfo using the provided host, databaseId and\n   * persistenceKey.\n   *\n   * @param databaseId The database to use.\n   * @param persistenceKey A unique identifier for this Firestore's local\n   * storage (used in conjunction with the databaseId).\n   * @param host The Firestore backend host to connect to.\n   * @param ssl Whether to use SSL when connecting.\n   * @param forceLongPolling Whether to use the forceLongPolling option\n   * when using WebChannel as the network transport.\n   */\n  constructor(\n    readonly databaseId: DatabaseId,\n    readonly persistenceKey: string,\n    readonly host: string,\n    readonly ssl: boolean,\n    readonly forceLongPolling: boolean\n  ) {}\n}\n\n/** The default database name for a project. */\nconst DEFAULT_DATABASE_NAME = '(default)';\n\n/** Represents the database ID a Firestore client is associated with. */\nexport class DatabaseId {\n  readonly database: string;\n  constructor(readonly projectId: string, database?: string) {\n    this.database = database ? database : DEFAULT_DATABASE_NAME;\n  }\n\n  get isDefaultDatabase(): boolean {\n    return this.database === DEFAULT_DATABASE_NAME;\n  }\n\n  isEqual(other: {}): boolean {\n    return (\n      other instanceof DatabaseId &&\n      other.projectId === this.projectId &&\n      other.database === this.database\n    );\n  }\n\n  compareTo(other: DatabaseId): number {\n    return (\n      primitiveComparator(this.projectId, other.projectId) ||\n      primitiveComparator(this.database, other.database)\n    );\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Equatable } from './misc';\nimport { forEach, isEmpty } from './obj';\n\ntype Entry<K, V> = [K, V];\n\n/**\n * A map implementation that uses objects as keys. Objects must implement the\n * Equatable interface and must be immutable. Entries in the map are stored\n * together with the key being produced from the mapKeyFn. This map\n * automatically handles collisions of keys.\n */\nexport class ObjectMap<KeyType extends Equatable<KeyType>, ValueType> {\n  /**\n   * The inner map for a key -> value pair. Due to the possibility of\n   * collisions we keep a list of entries that we do a linear search through\n   * to find an actual match. Note that collisions should be rare, so we still\n   * expect near constant time lookups in practice.\n   */\n  private inner: {\n    [canonicalId: string]: Array<Entry<KeyType, ValueType>>;\n  } = {};\n\n  constructor(private mapKeyFn: (key: KeyType) => string) {}\n\n  /** Get a value for this key, or undefined if it does not exist. */\n  get(key: KeyType): ValueType | undefined {\n    const id = this.mapKeyFn(key);\n    const matches = this.inner[id];\n    if (matches === undefined) {\n      return undefined;\n    }\n    for (const [otherKey, value] of matches) {\n      if (otherKey.isEqual(key)) {\n        return value;\n      }\n    }\n    return undefined;\n  }\n\n  has(key: KeyType): boolean {\n    return this.get(key) !== undefined;\n  }\n\n  /** Put this key and value in the map. */\n  set(key: KeyType, value: ValueType): void {\n    const id = this.mapKeyFn(key);\n    const matches = this.inner[id];\n    if (matches === undefined) {\n      this.inner[id] = [[key, value]];\n      return;\n    }\n    for (let i = 0; i < matches.length; i++) {\n      if (matches[i][0].isEqual(key)) {\n        matches[i] = [key, value];\n        return;\n      }\n    }\n    matches.push([key, value]);\n  }\n\n  /**\n   * Remove this key from the map. Returns a boolean if anything was deleted.\n   */\n  delete(key: KeyType): boolean {\n    const id = this.mapKeyFn(key);\n    const matches = this.inner[id];\n    if (matches === undefined) {\n      return false;\n    }\n    for (let i = 0; i < matches.length; i++) {\n      if (matches[i][0].isEqual(key)) {\n        if (matches.length === 1) {\n          delete this.inner[id];\n        } else {\n          matches.splice(i, 1);\n        }\n        return true;\n      }\n    }\n    return false;\n  }\n\n  forEach(fn: (key: KeyType, val: ValueType) => void): void {\n    forEach(this.inner, (_, entries) => {\n      for (const [k, v] of entries) {\n        fn(k, v);\n      }\n    });\n  }\n\n  isEmpty(): boolean {\n    return isEmpty(this.inner);\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Timestamp } from '../api/timestamp';\nimport { SnapshotVersion } from '../core/snapshot_version';\nimport { BatchId } from '../core/types';\nimport { hardAssert, debugAssert } from '../util/assert';\nimport { arrayEquals } from '../util/misc';\nimport { ByteString } from '../util/byte_string';\nimport {\n  documentKeySet,\n  DocumentKeySet,\n  DocumentVersionMap,\n  documentVersionMap,\n  MaybeDocumentMap\n} from './collections';\nimport { MaybeDocument } from './document';\nimport { DocumentKey } from './document_key';\nimport { Mutation, MutationResult } from './mutation';\n\nexport const BATCHID_UNKNOWN = -1;\n\n/**\n * A batch of mutations that will be sent as one unit to the backend.\n */\nexport class MutationBatch {\n  /**\n   * @param batchId The unique ID of this mutation batch.\n   * @param localWriteTime The original write time of this mutation.\n   * @param baseMutations Mutations that are used to populate the base\n   * values when this mutation is applied locally. This can be used to locally\n   * overwrite values that are persisted in the remote document cache. Base\n   * mutations are never sent to the backend.\n   * @param mutations The user-provided mutations in this mutation batch.\n   * User-provided mutations are applied both locally and remotely on the\n   * backend.\n   */\n  constructor(\n    public batchId: BatchId,\n    public localWriteTime: Timestamp,\n    public baseMutations: Mutation[],\n    public mutations: Mutation[]\n  ) {\n    debugAssert(mutations.length > 0, 'Cannot create an empty mutation batch');\n  }\n\n  /**\n   * Applies all the mutations in this MutationBatch to the specified document\n   * to create a new remote document\n   *\n   * @param docKey The key of the document to apply mutations to.\n   * @param maybeDoc The document to apply mutations to.\n   * @param batchResult The result of applying the MutationBatch to the\n   * backend.\n   */\n  applyToRemoteDocument(\n    docKey: DocumentKey,\n    maybeDoc: MaybeDocument | null,\n    batchResult: MutationBatchResult\n  ): MaybeDocument | null {\n    if (maybeDoc) {\n      debugAssert(\n        maybeDoc.key.isEqual(docKey),\n        `applyToRemoteDocument: key ${docKey} should match maybeDoc key\n        ${maybeDoc.key}`\n      );\n    }\n\n    const mutationResults = batchResult.mutationResults;\n    debugAssert(\n      mutationResults.length === this.mutations.length,\n      `Mismatch between mutations length\n      (${this.mutations.length}) and mutation results length\n      (${mutationResults.length}).`\n    );\n\n    for (let i = 0; i < this.mutations.length; i++) {\n      const mutation = this.mutations[i];\n      if (mutation.key.isEqual(docKey)) {\n        const mutationResult = mutationResults[i];\n        maybeDoc = mutation.applyToRemoteDocument(maybeDoc, mutationResult);\n      }\n    }\n    return maybeDoc;\n  }\n\n  /**\n   * Computes the local view of a document given all the mutations in this\n   * batch.\n   *\n   * @param docKey The key of the document to apply mutations to.\n   * @param maybeDoc The document to apply mutations to.\n   */\n  applyToLocalView(\n    docKey: DocumentKey,\n    maybeDoc: MaybeDocument | null\n  ): MaybeDocument | null {\n    if (maybeDoc) {\n      debugAssert(\n        maybeDoc.key.isEqual(docKey),\n        `applyToLocalDocument: key ${docKey} should match maybeDoc key\n        ${maybeDoc.key}`\n      );\n    }\n\n    // First, apply the base state. This allows us to apply non-idempotent\n    // transform against a consistent set of values.\n    for (const mutation of this.baseMutations) {\n      if (mutation.key.isEqual(docKey)) {\n        maybeDoc = mutation.applyToLocalView(\n          maybeDoc,\n          maybeDoc,\n          this.localWriteTime\n        );\n      }\n    }\n\n    const baseDoc = maybeDoc;\n\n    // Second, apply all user-provided mutations.\n    for (const mutation of this.mutations) {\n      if (mutation.key.isEqual(docKey)) {\n        maybeDoc = mutation.applyToLocalView(\n          maybeDoc,\n          baseDoc,\n          this.localWriteTime\n        );\n      }\n    }\n    return maybeDoc;\n  }\n\n  /**\n   * Computes the local view for all provided documents given the mutations in\n   * this batch.\n   */\n  applyToLocalDocumentSet(maybeDocs: MaybeDocumentMap): MaybeDocumentMap {\n    // TODO(mrschmidt): This implementation is O(n^2). If we apply the mutations\n    // directly (as done in `applyToLocalView()`), we can reduce the complexity\n    // to O(n).\n    let mutatedDocuments = maybeDocs;\n    this.mutations.forEach(m => {\n      const mutatedDocument = this.applyToLocalView(\n        m.key,\n        maybeDocs.get(m.key)\n      );\n      if (mutatedDocument) {\n        mutatedDocuments = mutatedDocuments.insert(m.key, mutatedDocument);\n      }\n    });\n    return mutatedDocuments;\n  }\n\n  keys(): DocumentKeySet {\n    return this.mutations.reduce(\n      (keys, m) => keys.add(m.key),\n      documentKeySet()\n    );\n  }\n\n  isEqual(other: MutationBatch): boolean {\n    return (\n      this.batchId === other.batchId &&\n      arrayEquals(this.mutations, other.mutations, (l, r) => l.isEqual(r)) &&\n      arrayEquals(this.baseMutations, other.baseMutations, (l, r) =>\n        l.isEqual(r)\n      )\n    );\n  }\n}\n\n/** The result of applying a mutation batch to the backend. */\nexport class MutationBatchResult {\n  private constructor(\n    readonly batch: MutationBatch,\n    readonly commitVersion: SnapshotVersion,\n    readonly mutationResults: MutationResult[],\n    readonly streamToken: ByteString,\n    /**\n     * A pre-computed mapping from each mutated document to the resulting\n     * version.\n     */\n    readonly docVersions: DocumentVersionMap\n  ) {}\n\n  /**\n   * Creates a new MutationBatchResult for the given batch and results. There\n   * must be one result for each mutation in the batch. This static factory\n   * caches a document=>version mapping (docVersions).\n   */\n  static from(\n    batch: MutationBatch,\n    commitVersion: SnapshotVersion,\n    results: MutationResult[],\n    streamToken: ByteString\n  ): MutationBatchResult {\n    hardAssert(\n      batch.mutations.length === results.length,\n      'Mutations sent ' +\n        batch.mutations.length +\n        ' must equal results received ' +\n        results.length\n    );\n\n    let versionMap = documentVersionMap();\n    const mutations = batch.mutations;\n    for (let i = 0; i < mutations.length; i++) {\n      versionMap = versionMap.insert(mutations[i].key, results[i].version);\n    }\n\n    return new MutationBatchResult(\n      batch,\n      commitVersion,\n      results,\n      streamToken,\n      versionMap\n    );\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { BatchId, TargetId } from '../core/types';\nimport { documentKeySet, DocumentKeySet } from '../model/collections';\nimport { DocumentKey } from '../model/document_key';\nimport { primitiveComparator } from '../util/misc';\nimport { SortedSet } from '../util/sorted_set';\n\n/**\n * A collection of references to a document from some kind of numbered entity\n * (either a target ID or batch ID). As references are added to or removed from\n * the set corresponding events are emitted to a registered garbage collector.\n *\n * Each reference is represented by a DocumentReference object. Each of them\n * contains enough information to uniquely identify the reference. They are all\n * stored primarily in a set sorted by key. A document is considered garbage if\n * there's no references in that set (this can be efficiently checked thanks to\n * sorting by key).\n *\n * ReferenceSet also keeps a secondary set that contains references sorted by\n * IDs. This one is used to efficiently implement removal of all references by\n * some target ID.\n */\nexport class ReferenceSet {\n  // A set of outstanding references to a document sorted by key.\n  private refsByKey = new SortedSet(DocReference.compareByKey);\n\n  // A set of outstanding references to a document sorted by target id.\n  private refsByTarget = new SortedSet(DocReference.compareByTargetId);\n\n  /** Returns true if the reference set contains no references. */\n  isEmpty(): boolean {\n    return this.refsByKey.isEmpty();\n  }\n\n  /** Adds a reference to the given document key for the given ID. */\n  addReference(key: DocumentKey, id: TargetId | BatchId): void {\n    const ref = new DocReference(key, id);\n    this.refsByKey = this.refsByKey.add(ref);\n    this.refsByTarget = this.refsByTarget.add(ref);\n  }\n\n  /** Add references to the given document keys for the given ID. */\n  addReferences(keys: DocumentKeySet, id: TargetId | BatchId): void {\n    keys.forEach(key => this.addReference(key, id));\n  }\n\n  /**\n   * Removes a reference to the given document key for the given\n   * ID.\n   */\n  removeReference(key: DocumentKey, id: TargetId | BatchId): void {\n    this.removeRef(new DocReference(key, id));\n  }\n\n  removeReferences(keys: DocumentKeySet, id: TargetId | BatchId): void {\n    keys.forEach(key => this.removeReference(key, id));\n  }\n\n  /**\n   * Clears all references with a given ID. Calls removeRef() for each key\n   * removed.\n   */\n  removeReferencesForId(id: TargetId | BatchId): DocumentKey[] {\n    const emptyKey = DocumentKey.EMPTY;\n    const startRef = new DocReference(emptyKey, id);\n    const endRef = new DocReference(emptyKey, id + 1);\n    const keys: DocumentKey[] = [];\n    this.refsByTarget.forEachInRange([startRef, endRef], ref => {\n      this.removeRef(ref);\n      keys.push(ref.key);\n    });\n    return keys;\n  }\n\n  removeAllReferences(): void {\n    this.refsByKey.forEach(ref => this.removeRef(ref));\n  }\n\n  private removeRef(ref: DocReference): void {\n    this.refsByKey = this.refsByKey.delete(ref);\n    this.refsByTarget = this.refsByTarget.delete(ref);\n  }\n\n  referencesForId(id: TargetId | BatchId): DocumentKeySet {\n    const emptyKey = DocumentKey.EMPTY;\n    const startRef = new DocReference(emptyKey, id);\n    const endRef = new DocReference(emptyKey, id + 1);\n    let keys = documentKeySet();\n    this.refsByTarget.forEachInRange([startRef, endRef], ref => {\n      keys = keys.add(ref.key);\n    });\n    return keys;\n  }\n\n  containsKey(key: DocumentKey): boolean {\n    const ref = new DocReference(key, 0);\n    const firstRef = this.refsByKey.firstAfterOrEqual(ref);\n    return firstRef !== null && key.isEqual(firstRef.key);\n  }\n}\n\nexport class DocReference {\n  constructor(\n    public key: DocumentKey,\n    public targetOrBatchId: TargetId | BatchId\n  ) {}\n\n  /** Compare by key then by ID */\n  static compareByKey(left: DocReference, right: DocReference): number {\n    return (\n      DocumentKey.comparator(left.key, right.key) ||\n      primitiveComparator(left.targetOrBatchId, right.targetOrBatchId)\n    );\n  }\n\n  /** Compare by ID then by key */\n  static compareByTargetId(left: DocReference, right: DocReference): number {\n    return (\n      primitiveComparator(left.targetOrBatchId, right.targetOrBatchId) ||\n      DocumentKey.comparator(left.key, right.key)\n    );\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { fail } from '../util/assert';\n\nexport type FulfilledHandler<T, R> =\n  | ((result: T) => R | PersistencePromise<R>)\n  | null;\nexport type RejectedHandler<R> =\n  | ((reason: Error) => R | PersistencePromise<R>)\n  | null;\nexport type Resolver<T> = (value?: T) => void;\nexport type Rejector = (error: Error) => void;\n\n/**\n * PersistencePromise<> is essentially a re-implementation of Promise<> except\n * it has a .next() method instead of .then() and .next() and .catch() callbacks\n * are executed synchronously when a PersistencePromise resolves rather than\n * asynchronously (Promise<> implementations use setImmediate() or similar).\n *\n * This is necessary to interoperate with IndexedDB which will automatically\n * commit transactions if control is returned to the event loop without\n * synchronously initiating another operation on the transaction.\n *\n * NOTE: .then() and .catch() only allow a single consumer, unlike normal\n * Promises.\n */\nexport class PersistencePromise<T> {\n  // NOTE: next/catchCallback will always point to our own wrapper functions,\n  // not the user's raw next() or catch() callbacks.\n  private nextCallback: FulfilledHandler<T, unknown> = null;\n  private catchCallback: RejectedHandler<unknown> = null;\n\n  // When the operation resolves, we'll set result or error and mark isDone.\n  private result: T | undefined = undefined;\n  private error: Error | undefined = undefined;\n  private isDone = false;\n\n  // Set to true when .then() or .catch() are called and prevents additional\n  // chaining.\n  private callbackAttached = false;\n\n  constructor(callback: (resolve: Resolver<T>, reject: Rejector) => void) {\n    callback(\n      value => {\n        this.isDone = true;\n        this.result = value;\n        if (this.nextCallback) {\n          // value should be defined unless T is Void, but we can't express\n          // that in the type system.\n          this.nextCallback(value!);\n        }\n      },\n      error => {\n        this.isDone = true;\n        this.error = error;\n        if (this.catchCallback) {\n          this.catchCallback(error);\n        }\n      }\n    );\n  }\n\n  catch<R>(\n    fn: (error: Error) => R | PersistencePromise<R>\n  ): PersistencePromise<R> {\n    return this.next(undefined, fn);\n  }\n\n  next<R>(\n    nextFn?: FulfilledHandler<T, R>,\n    catchFn?: RejectedHandler<R>\n  ): PersistencePromise<R> {\n    if (this.callbackAttached) {\n      fail('Called next() or catch() twice for PersistencePromise');\n    }\n    this.callbackAttached = true;\n    if (this.isDone) {\n      if (!this.error) {\n        return this.wrapSuccess(nextFn, this.result!);\n      } else {\n        return this.wrapFailure(catchFn, this.error);\n      }\n    } else {\n      return new PersistencePromise<R>((resolve, reject) => {\n        this.nextCallback = (value: T) => {\n          this.wrapSuccess(nextFn, value).next(resolve, reject);\n        };\n        this.catchCallback = (error: Error) => {\n          this.wrapFailure(catchFn, error).next(resolve, reject);\n        };\n      });\n    }\n  }\n\n  toPromise(): Promise<T> {\n    return new Promise((resolve, reject) => {\n      this.next(resolve, reject);\n    });\n  }\n\n  private wrapUserFunction<R>(\n    fn: () => R | PersistencePromise<R>\n  ): PersistencePromise<R> {\n    try {\n      const result = fn();\n      if (result instanceof PersistencePromise) {\n        return result;\n      } else {\n        return PersistencePromise.resolve(result);\n      }\n    } catch (e) {\n      return PersistencePromise.reject<R>(e);\n    }\n  }\n\n  private wrapSuccess<R>(\n    nextFn: FulfilledHandler<T, R> | undefined,\n    value: T\n  ): PersistencePromise<R> {\n    if (nextFn) {\n      return this.wrapUserFunction(() => nextFn(value));\n    } else {\n      // If there's no nextFn, then R must be the same as T\n      return PersistencePromise.resolve<R>((value as unknown) as R);\n    }\n  }\n\n  private wrapFailure<R>(\n    catchFn: RejectedHandler<R> | undefined,\n    error: Error\n  ): PersistencePromise<R> {\n    if (catchFn) {\n      return this.wrapUserFunction(() => catchFn(error));\n    } else {\n      return PersistencePromise.reject<R>(error);\n    }\n  }\n\n  static resolve(): PersistencePromise<void>;\n  static resolve<R>(result: R): PersistencePromise<R>;\n  static resolve<R>(result?: R): PersistencePromise<R | void> {\n    return new PersistencePromise<R | void>((resolve, reject) => {\n      resolve(result);\n    });\n  }\n\n  static reject<R>(error: Error): PersistencePromise<R> {\n    return new PersistencePromise<R>((resolve, reject) => {\n      reject(error);\n    });\n  }\n\n  static waitFor(\n    // Accept all Promise types in waitFor().\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    all: { forEach: (cb: (el: PersistencePromise<any>) => void) => void }\n  ): PersistencePromise<void> {\n    return new PersistencePromise<void>((resolve, reject) => {\n      let expectedCount = 0;\n      let resolvedCount = 0;\n      let done = false;\n\n      all.forEach(element => {\n        ++expectedCount;\n        element.next(\n          () => {\n            ++resolvedCount;\n            if (done && resolvedCount === expectedCount) {\n              resolve();\n            }\n          },\n          err => reject(err)\n        );\n      });\n\n      done = true;\n      if (resolvedCount === expectedCount) {\n        resolve();\n      }\n    });\n  }\n\n  /**\n   * Given an array of predicate functions that asynchronously evaluate to a\n   * boolean, implements a short-circuiting `or` between the results. Predicates\n   * will be evaluated until one of them returns `true`, then stop. The final\n   * result will be whether any of them returned `true`.\n   */\n  static or(\n    predicates: Array<() => PersistencePromise<boolean>>\n  ): PersistencePromise<boolean> {\n    let p: PersistencePromise<boolean> = PersistencePromise.resolve<boolean>(\n      false\n    );\n    for (const predicate of predicates) {\n      p = p.next(isTrue => {\n        if (isTrue) {\n          return PersistencePromise.resolve<boolean>(isTrue);\n        } else {\n          return predicate();\n        }\n      });\n    }\n    return p;\n  }\n\n  /**\n   * Given an iterable, call the given function on each element in the\n   * collection and wait for all of the resulting concurrent PersistencePromises\n   * to resolve.\n   */\n  static forEach<R, S>(\n    collection: { forEach: (cb: (r: R, s: S) => void) => void },\n    f:\n      | ((r: R, s: S) => PersistencePromise<void>)\n      | ((r: R) => PersistencePromise<void>)\n  ): PersistencePromise<void>;\n  static forEach<R>(\n    collection: { forEach: (cb: (r: R) => void) => void },\n    f: (r: R) => PersistencePromise<void>\n  ): PersistencePromise<void>;\n  static forEach<R, S>(\n    collection: { forEach: (cb: (r: R, s?: S) => void) => void },\n    f: (r: R, s?: S) => PersistencePromise<void>\n  ): PersistencePromise<void> {\n    const promises: Array<PersistencePromise<void>> = [];\n    collection.forEach((r, s) => {\n      promises.push(f.call(this, r, s));\n    });\n    return this.waitFor(promises);\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { DocumentKeySet, NullableMaybeDocumentMap } from '../model/collections';\nimport { MaybeDocument } from '../model/document';\nimport { DocumentKey } from '../model/document_key';\nimport { debugAssert } from '../util/assert';\nimport { ObjectMap } from '../util/obj_map';\n\nimport { PersistenceTransaction } from './persistence';\nimport { PersistencePromise } from './persistence_promise';\nimport { SnapshotVersion } from '../core/snapshot_version';\n\n/**\n * An in-memory buffer of entries to be written to a RemoteDocumentCache.\n * It can be used to batch up a set of changes to be written to the cache, but\n * additionally supports reading entries back with the `getEntry()` method,\n * falling back to the underlying RemoteDocumentCache if no entry is\n * buffered.\n *\n * Entries added to the cache *must* be read first. This is to facilitate\n * calculating the size delta of the pending changes.\n *\n * PORTING NOTE: This class was implemented then removed from other platforms.\n * If byte-counting ends up being needed on the other platforms, consider\n * porting this class as part of that implementation work.\n */\nexport abstract class RemoteDocumentChangeBuffer {\n  // A mapping of document key to the new cache entry that should be written (or null if any\n  // existing cache entry should be removed).\n  protected changes: ObjectMap<\n    DocumentKey,\n    MaybeDocument | null\n  > = new ObjectMap(key => key.toString());\n\n  // The read time to use for all added documents in this change buffer.\n  private _readTime: SnapshotVersion | undefined;\n\n  private changesApplied = false;\n\n  protected abstract getFromCache(\n    transaction: PersistenceTransaction,\n    documentKey: DocumentKey\n  ): PersistencePromise<MaybeDocument | null>;\n\n  protected abstract getAllFromCache(\n    transaction: PersistenceTransaction,\n    documentKeys: DocumentKeySet\n  ): PersistencePromise<NullableMaybeDocumentMap>;\n\n  protected abstract applyChanges(\n    transaction: PersistenceTransaction\n  ): PersistencePromise<void>;\n\n  protected set readTime(value: SnapshotVersion) {\n    // Right now (for simplicity) we just track a single readTime for all the\n    // added entries since we expect them to all be the same, but we could\n    // rework to store per-entry readTimes if necessary.\n    debugAssert(\n      this._readTime === undefined || this._readTime.isEqual(value),\n      'All changes in a RemoteDocumentChangeBuffer must have the same read time'\n    );\n    this._readTime = value;\n  }\n\n  protected get readTime(): SnapshotVersion {\n    debugAssert(\n      this._readTime !== undefined,\n      'Read time is not set. All removeEntry() calls must include a readTime if `trackRemovals` is used.'\n    );\n    return this._readTime;\n  }\n\n  /**\n   * Buffers a `RemoteDocumentCache.addEntry()` call.\n   *\n   * You can only modify documents that have already been retrieved via\n   * `getEntry()/getEntries()` (enforced via IndexedDbs `apply()`).\n   */\n  addEntry(maybeDocument: MaybeDocument, readTime: SnapshotVersion): void {\n    this.assertNotApplied();\n    this.readTime = readTime;\n    this.changes.set(maybeDocument.key, maybeDocument);\n  }\n\n  /**\n   * Buffers a `RemoteDocumentCache.removeEntry()` call.\n   *\n   * You can only remove documents that have already been retrieved via\n   * `getEntry()/getEntries()` (enforced via IndexedDbs `apply()`).\n   */\n  removeEntry(key: DocumentKey, readTime?: SnapshotVersion): void {\n    this.assertNotApplied();\n    if (readTime) {\n      this.readTime = readTime;\n    }\n    this.changes.set(key, null);\n  }\n\n  /**\n   * Looks up an entry in the cache. The buffered changes will first be checked,\n   * and if no buffered change applies, this will forward to\n   * `RemoteDocumentCache.getEntry()`.\n   *\n   * @param transaction The transaction in which to perform any persistence\n   *     operations.\n   * @param documentKey The key of the entry to look up.\n   * @return The cached Document or NoDocument entry, or null if we have nothing\n   * cached.\n   */\n  getEntry(\n    transaction: PersistenceTransaction,\n    documentKey: DocumentKey\n  ): PersistencePromise<MaybeDocument | null> {\n    this.assertNotApplied();\n    const bufferedEntry = this.changes.get(documentKey);\n    if (bufferedEntry !== undefined) {\n      return PersistencePromise.resolve<MaybeDocument | null>(bufferedEntry);\n    } else {\n      return this.getFromCache(transaction, documentKey);\n    }\n  }\n\n  /**\n   * Looks up several entries in the cache, forwarding to\n   * `RemoteDocumentCache.getEntry()`.\n   *\n   * @param transaction The transaction in which to perform any persistence\n   *     operations.\n   * @param documentKeys The keys of the entries to look up.\n   * @return A map of cached `Document`s or `NoDocument`s, indexed by key. If an\n   *     entry cannot be found, the corresponding key will be mapped to a null\n   *     value.\n   */\n  getEntries(\n    transaction: PersistenceTransaction,\n    documentKeys: DocumentKeySet\n  ): PersistencePromise<NullableMaybeDocumentMap> {\n    return this.getAllFromCache(transaction, documentKeys);\n  }\n\n  /**\n   * Applies buffered changes to the underlying RemoteDocumentCache, using\n   * the provided transaction.\n   */\n  apply(transaction: PersistenceTransaction): PersistencePromise<void> {\n    this.assertNotApplied();\n    this.changesApplied = true;\n    return this.applyChanges(transaction);\n  }\n\n  /** Helper to assert this.changes is not null  */\n  protected assertNotApplied(): void {\n    debugAssert(!this.changesApplied, 'Changes have already been applied.');\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { User } from '../auth/user';\nimport { ListenSequenceNumber } from '../core/types';\nimport { DocumentKey } from '../model/document_key';\nimport { IndexManager } from './index_manager';\nimport { LocalStore } from './local_store';\nimport { MutationQueue } from './mutation_queue';\nimport { PersistencePromise } from './persistence_promise';\nimport { TargetCache } from './target_cache';\nimport { ReferenceSet } from './reference_set';\nimport { RemoteDocumentCache } from './remote_document_cache';\nimport { TargetData } from './target_data';\nimport { ClientId } from './shared_client_state';\n\nexport const PRIMARY_LEASE_LOST_ERROR_MSG =\n  'The current tab is not in the required state to perform this operation. ' +\n  'It might be necessary to refresh the browser tab.';\n\n/**\n * A base class representing a persistence transaction, encapsulating both the\n * transaction's sequence numbers as well as a list of onCommitted listeners.\n *\n * When you call Persistence.runTransaction(), it will create a transaction and\n * pass it to your callback. You then pass it to any method that operates\n * on persistence.\n */\nexport abstract class PersistenceTransaction {\n  private readonly onCommittedListeners: Array<() => void> = [];\n\n  abstract readonly currentSequenceNumber: ListenSequenceNumber;\n\n  addOnCommittedListener(listener: () => void): void {\n    this.onCommittedListeners.push(listener);\n  }\n\n  raiseOnCommittedEvent(): void {\n    this.onCommittedListeners.forEach(listener => listener());\n  }\n}\n\n/** The different modes supported by `IndexedDbPersistence.runTransaction()`. */\nexport type PersistenceTransactionMode =\n  | 'readonly'\n  | 'readwrite'\n  | 'readwrite-primary';\n\n/**\n * Callback type for primary state notifications. This callback can be\n * registered with the persistence layer to get notified when we transition from\n * primary to secondary state and vice versa.\n *\n * Note: Instances can only toggle between Primary and Secondary state if\n * IndexedDB persistence is enabled and multiple clients are active. If this\n * listener is registered with MemoryPersistence, the callback will be called\n * exactly once marking the current instance as Primary.\n */\nexport type PrimaryStateListener = (isPrimary: boolean) => Promise<void>;\n\n/**\n * A ReferenceDelegate instance handles all of the hooks into the document-reference lifecycle. This\n * includes being added to a target, being removed from a target, being subject to mutation, and\n * being mutated by the user.\n *\n * Different implementations may do different things with each of these events. Not every\n * implementation needs to do something with every lifecycle hook.\n *\n * PORTING NOTE: since sequence numbers are attached to transactions in this\n * client, the ReferenceDelegate does not need to deal in transactional\n * semantics (onTransactionStarted/Committed()), nor does it need to track and\n * generate sequence numbers (getCurrentSequenceNumber()).\n */\nexport interface ReferenceDelegate {\n  /**\n   * Registers a ReferenceSet of documents that should be considered 'referenced' and not eligible\n   * for removal during garbage collection.\n   */\n  setInMemoryPins(pins: ReferenceSet): void;\n\n  /** Notify the delegate that the given document was added to a target. */\n  addReference(\n    txn: PersistenceTransaction,\n    doc: DocumentKey\n  ): PersistencePromise<void>;\n\n  /** Notify the delegate that the given document was removed from a target. */\n  removeReference(\n    txn: PersistenceTransaction,\n    doc: DocumentKey\n  ): PersistencePromise<void>;\n\n  /**\n   * Notify the delegate that a target was removed. The delegate may, but is not obligated to,\n   * actually delete the target and associated data.\n   */\n  removeTarget(\n    txn: PersistenceTransaction,\n    targetData: TargetData\n  ): PersistencePromise<void>;\n\n  /** Notify the delegate that a document is no longer being mutated by the user. */\n  removeMutationReference(\n    txn: PersistenceTransaction,\n    doc: DocumentKey\n  ): PersistencePromise<void>;\n\n  /** Notify the delegate that a limbo document was updated. */\n  updateLimboDocument(\n    txn: PersistenceTransaction,\n    doc: DocumentKey\n  ): PersistencePromise<void>;\n}\n\n/**\n * Persistence is the lowest-level shared interface to persistent storage in\n * Firestore.\n *\n * Persistence is used to create MutationQueue and RemoteDocumentCache\n * instances backed by persistence (which might be in-memory or LevelDB).\n *\n * Persistence also exposes an API to create and run PersistenceTransactions\n * against persistence. All read / write operations must be wrapped in a\n * transaction. Implementations of PersistenceTransaction / Persistence only\n * need to guarantee that writes made against the transaction are not made to\n * durable storage until the transaction resolves its PersistencePromise.\n * Since memory-only storage components do not alter durable storage, they are\n * free to ignore the transaction.\n *\n * This contract is enough to allow the LocalStore be be written\n * independently of whether or not the stored state actually is durably\n * persisted. If persistent storage is enabled, writes are grouped together to\n * avoid inconsistent state that could cause crashes.\n *\n * Concretely, when persistent storage is enabled, the persistent versions of\n * MutationQueue, RemoteDocumentCache, and others (the mutators) will\n * defer their writes into a transaction. Once the local store has completed\n * one logical operation, it commits the transaction.\n *\n * When persistent storage is disabled, the non-persistent versions of the\n * mutators ignore the transaction. This short-cut is allowed because\n * memory-only storage leaves no state so it cannot be inconsistent.\n *\n * This simplifies the implementations of the mutators and allows memory-only\n * implementations to supplement the persistent ones without requiring any\n * special dual-store implementation of Persistence. The cost is that the\n * LocalStore needs to be slightly careful about the order of its reads and\n * writes in order to avoid relying on being able to read back uncommitted\n * writes.\n */\nexport interface Persistence {\n  /**\n   * Whether or not this persistence instance has been started.\n   */\n  readonly started: boolean;\n\n  readonly referenceDelegate: ReferenceDelegate;\n\n  /**\n   * Releases any resources held during eager shutdown.\n   */\n  shutdown(): Promise<void>;\n\n  /**\n   * Registers a listener that gets called when the primary state of the\n   * instance changes. Upon registering, this listener is invoked immediately\n   * with the current primary state.\n   *\n   * PORTING NOTE: This is only used for Web multi-tab.\n   */\n  setPrimaryStateListener(\n    primaryStateListener: PrimaryStateListener\n  ): Promise<void>;\n\n  /**\n   * Registers a listener that gets called when the database receives a\n   * version change event indicating that it has deleted.\n   *\n   * PORTING NOTE: This is only used for Web multi-tab.\n   */\n  setDatabaseDeletedListener(\n    databaseDeletedListener: () => Promise<void>\n  ): void;\n\n  /**\n   * Adjusts the current network state in the client's metadata, potentially\n   * affecting the primary lease.\n   *\n   * PORTING NOTE: This is only used for Web multi-tab.\n   */\n  setNetworkEnabled(networkEnabled: boolean): void;\n\n  /**\n   * Returns the IDs of the clients that are currently active. If multi-tab\n   * is not supported, returns an array that only contains the local client's\n   * ID.\n   *\n   * PORTING NOTE: This is only used for Web multi-tab.\n   */\n  getActiveClients(): Promise<ClientId[]>;\n\n  /**\n   * Returns a MutationQueue representing the persisted mutations for the\n   * given user.\n   *\n   * Note: The implementation is free to return the same instance every time\n   * this is called for a given user. In particular, the memory-backed\n   * implementation does this to emulate the persisted implementation to the\n   * extent possible (e.g. in the case of uid switching from\n   * sally=>jack=>sally, sally's mutation queue will be preserved).\n   */\n  getMutationQueue(user: User): MutationQueue;\n\n  /**\n   * Returns a TargetCache representing the persisted cache of targets.\n   *\n   * Note: The implementation is free to return the same instance every time\n   * this is called. In particular, the memory-backed implementation does this\n   * to emulate the persisted implementation to the extent possible.\n   */\n  getTargetCache(): TargetCache;\n\n  /**\n   * Returns a RemoteDocumentCache representing the persisted cache of remote\n   * documents.\n   *\n   * Note: The implementation is free to return the same instance every time\n   * this is called. In particular, the memory-backed implementation does this\n   * to emulate the persisted implementation to the extent possible.\n   */\n  getRemoteDocumentCache(): RemoteDocumentCache;\n\n  /**\n   * Returns an IndexManager instance that manages our persisted query indexes.\n   *\n   * Note: The implementation is free to return the same instance every time\n   * this is called. In particular, the memory-backed implementation does this\n   * to emulate the persisted implementation to the extent possible.\n   */\n  getIndexManager(): IndexManager;\n\n  /**\n   * Performs an operation inside a persistence transaction. Any reads or writes\n   * against persistence must be performed within a transaction. Writes will be\n   * committed atomically once the transaction completes.\n   *\n   * Persistence operations are asynchronous and therefore the provided\n   * transactionOperation must return a PersistencePromise. When it is resolved,\n   * the transaction will be committed and the Promise returned by this method\n   * will resolve.\n   *\n   * @param action A description of the action performed by this transaction,\n   * used for logging.\n   * @param mode The underlying mode of the IndexedDb transaction. Can be\n   * 'readonly`, 'readwrite' or 'readwrite-primary'. Transactions marked\n   * 'readwrite-primary' can only be executed by the primary client. In this\n   * mode, the transactionOperation will not be run if the primary lease cannot\n   * be acquired and the returned promise will be rejected with a\n   * FAILED_PRECONDITION error.\n   * @param transactionOperation The operation to run inside a transaction.\n   * @return A promise that is resolved once the transaction completes.\n   */\n  runTransaction<T>(\n    action: string,\n    mode: PersistenceTransactionMode,\n    transactionOperation: (\n      transaction: PersistenceTransaction\n    ) => PersistencePromise<T>\n  ): Promise<T>;\n}\n\n/**\n * Interface implemented by the LRU scheduler to start(), stop() and restart\n * garbage collection.\n */\nexport interface GarbageCollectionScheduler {\n  readonly started: boolean;\n  start(localStore: LocalStore): void;\n  stop(): void;\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Query } from '../core/query';\nimport { SnapshotVersion } from '../core/snapshot_version';\nimport {\n  DocumentKeySet,\n  documentKeySet,\n  DocumentMap,\n  documentMap,\n  MaybeDocumentMap,\n  maybeDocumentMap,\n  NullableMaybeDocumentMap,\n  nullableMaybeDocumentMap\n} from '../model/collections';\nimport { Document, MaybeDocument, NoDocument } from '../model/document';\nimport { DocumentKey } from '../model/document_key';\nimport { MutationBatch } from '../model/mutation_batch';\nimport { ResourcePath } from '../model/path';\n\nimport { debugAssert } from '../util/assert';\nimport { IndexManager } from './index_manager';\nimport { MutationQueue } from './mutation_queue';\nimport { PatchMutation } from '../model/mutation';\nimport { PersistenceTransaction } from './persistence';\nimport { PersistencePromise } from './persistence_promise';\nimport { RemoteDocumentCache } from './remote_document_cache';\n\n/**\n * A readonly view of the local state of all documents we're tracking (i.e. we\n * have a cached version in remoteDocumentCache or local mutations for the\n * document). The view is computed by applying the mutations in the\n * MutationQueue to the RemoteDocumentCache.\n */\nexport class LocalDocumentsView {\n  constructor(\n    readonly remoteDocumentCache: RemoteDocumentCache,\n    readonly mutationQueue: MutationQueue,\n    readonly indexManager: IndexManager\n  ) {}\n\n  /**\n   * Get the local view of the document identified by `key`.\n   *\n   * @return Local view of the document or null if we don't have any cached\n   * state for it.\n   */\n  getDocument(\n    transaction: PersistenceTransaction,\n    key: DocumentKey\n  ): PersistencePromise<MaybeDocument | null> {\n    return this.mutationQueue\n      .getAllMutationBatchesAffectingDocumentKey(transaction, key)\n      .next(batches => this.getDocumentInternal(transaction, key, batches));\n  }\n\n  /** Internal version of `getDocument` that allows reusing batches. */\n  private getDocumentInternal(\n    transaction: PersistenceTransaction,\n    key: DocumentKey,\n    inBatches: MutationBatch[]\n  ): PersistencePromise<MaybeDocument | null> {\n    return this.remoteDocumentCache.getEntry(transaction, key).next(doc => {\n      for (const batch of inBatches) {\n        doc = batch.applyToLocalView(key, doc);\n      }\n      return doc;\n    });\n  }\n\n  // Returns the view of the given `docs` as they would appear after applying\n  // all mutations in the given `batches`.\n  private applyLocalMutationsToDocuments(\n    transaction: PersistenceTransaction,\n    docs: NullableMaybeDocumentMap,\n    batches: MutationBatch[]\n  ): NullableMaybeDocumentMap {\n    let results = nullableMaybeDocumentMap();\n    docs.forEach((key, localView) => {\n      for (const batch of batches) {\n        localView = batch.applyToLocalView(key, localView);\n      }\n      results = results.insert(key, localView);\n    });\n    return results;\n  }\n\n  /**\n   * Gets the local view of the documents identified by `keys`.\n   *\n   * If we don't have cached state for a document in `keys`, a NoDocument will\n   * be stored for that key in the resulting set.\n   */\n  getDocuments(\n    transaction: PersistenceTransaction,\n    keys: DocumentKeySet\n  ): PersistencePromise<MaybeDocumentMap> {\n    return this.remoteDocumentCache\n      .getEntries(transaction, keys)\n      .next(docs => this.getLocalViewOfDocuments(transaction, docs));\n  }\n\n  /**\n   * Similar to `getDocuments`, but creates the local view from the given\n   * `baseDocs` without retrieving documents from the local store.\n   */\n  getLocalViewOfDocuments(\n    transaction: PersistenceTransaction,\n    baseDocs: NullableMaybeDocumentMap\n  ): PersistencePromise<MaybeDocumentMap> {\n    return this.mutationQueue\n      .getAllMutationBatchesAffectingDocumentKeys(transaction, baseDocs)\n      .next(batches => {\n        const docs = this.applyLocalMutationsToDocuments(\n          transaction,\n          baseDocs,\n          batches\n        );\n        let results = maybeDocumentMap();\n        docs.forEach((key, maybeDoc) => {\n          // TODO(http://b/32275378): Don't conflate missing / deleted.\n          if (!maybeDoc) {\n            maybeDoc = new NoDocument(key, SnapshotVersion.forDeletedDoc());\n          }\n          results = results.insert(key, maybeDoc);\n        });\n\n        return results;\n      });\n  }\n\n  /**\n   * Performs a query against the local view of all documents.\n   *\n   * @param transaction The persistence transaction.\n   * @param query The query to match documents against.\n   * @param sinceReadTime If not set to SnapshotVersion.MIN, return only\n   *     documents that have been read since this snapshot version (exclusive).\n   */\n  getDocumentsMatchingQuery(\n    transaction: PersistenceTransaction,\n    query: Query,\n    sinceReadTime: SnapshotVersion\n  ): PersistencePromise<DocumentMap> {\n    if (query.isDocumentQuery()) {\n      return this.getDocumentsMatchingDocumentQuery(transaction, query.path);\n    } else if (query.isCollectionGroupQuery()) {\n      return this.getDocumentsMatchingCollectionGroupQuery(\n        transaction,\n        query,\n        sinceReadTime\n      );\n    } else {\n      return this.getDocumentsMatchingCollectionQuery(\n        transaction,\n        query,\n        sinceReadTime\n      );\n    }\n  }\n\n  private getDocumentsMatchingDocumentQuery(\n    transaction: PersistenceTransaction,\n    docPath: ResourcePath\n  ): PersistencePromise<DocumentMap> {\n    // Just do a simple document lookup.\n    return this.getDocument(transaction, new DocumentKey(docPath)).next(\n      maybeDoc => {\n        let result = documentMap();\n        if (maybeDoc instanceof Document) {\n          result = result.insert(maybeDoc.key, maybeDoc);\n        }\n        return result;\n      }\n    );\n  }\n\n  private getDocumentsMatchingCollectionGroupQuery(\n    transaction: PersistenceTransaction,\n    query: Query,\n    sinceReadTime: SnapshotVersion\n  ): PersistencePromise<DocumentMap> {\n    debugAssert(\n      query.path.isEmpty(),\n      'Currently we only support collection group queries at the root.'\n    );\n    const collectionId = query.collectionGroup!;\n    let results = documentMap();\n    return this.indexManager\n      .getCollectionParents(transaction, collectionId)\n      .next(parents => {\n        // Perform a collection query against each parent that contains the\n        // collectionId and aggregate the results.\n        return PersistencePromise.forEach(parents, (parent: ResourcePath) => {\n          const collectionQuery = query.asCollectionQueryAtPath(\n            parent.child(collectionId)\n          );\n          return this.getDocumentsMatchingCollectionQuery(\n            transaction,\n            collectionQuery,\n            sinceReadTime\n          ).next(r => {\n            r.forEach((key, doc) => {\n              results = results.insert(key, doc);\n            });\n          });\n        }).next(() => results);\n      });\n  }\n\n  private getDocumentsMatchingCollectionQuery(\n    transaction: PersistenceTransaction,\n    query: Query,\n    sinceReadTime: SnapshotVersion\n  ): PersistencePromise<DocumentMap> {\n    // Query the remote documents and overlay mutations.\n    let results: DocumentMap;\n    let mutationBatches: MutationBatch[];\n    return this.remoteDocumentCache\n      .getDocumentsMatchingQuery(transaction, query, sinceReadTime)\n      .next(queryResults => {\n        results = queryResults;\n        return this.mutationQueue.getAllMutationBatchesAffectingQuery(\n          transaction,\n          query\n        );\n      })\n      .next(matchingMutationBatches => {\n        mutationBatches = matchingMutationBatches;\n        // It is possible that a PatchMutation can make a document match a query, even if\n        // the version in the RemoteDocumentCache is not a match yet (waiting for server\n        // to ack). To handle this, we find all document keys affected by the PatchMutations\n        // that are not in `result` yet, and back fill them via `remoteDocumentCache.getEntries`,\n        // otherwise those `PatchMutations` will be ignored because no base document can be found,\n        // and lead to missing result for the query.\n        return this.addMissingBaseDocuments(\n          transaction,\n          mutationBatches,\n          results\n        ).next(mergedDocuments => {\n          results = mergedDocuments;\n\n          for (const batch of mutationBatches) {\n            for (const mutation of batch.mutations) {\n              const key = mutation.key;\n              const baseDoc = results.get(key);\n              const mutatedDoc = mutation.applyToLocalView(\n                baseDoc,\n                baseDoc,\n                batch.localWriteTime\n              );\n              if (mutatedDoc instanceof Document) {\n                results = results.insert(key, mutatedDoc);\n              } else {\n                results = results.remove(key);\n              }\n            }\n          }\n        });\n      })\n      .next(() => {\n        // Finally, filter out any documents that don't actually match\n        // the query.\n        results.forEach((key, doc) => {\n          if (!query.matches(doc)) {\n            results = results.remove(key);\n          }\n        });\n\n        return results;\n      });\n  }\n\n  private addMissingBaseDocuments(\n    transaction: PersistenceTransaction,\n    matchingMutationBatches: MutationBatch[],\n    existingDocuments: DocumentMap\n  ): PersistencePromise<DocumentMap> {\n    let missingBaseDocEntriesForPatching = documentKeySet();\n    for (const batch of matchingMutationBatches) {\n      for (const mutation of batch.mutations) {\n        if (\n          mutation instanceof PatchMutation &&\n          existingDocuments.get(mutation.key) === null\n        ) {\n          missingBaseDocEntriesForPatching = missingBaseDocEntriesForPatching.add(\n            mutation.key\n          );\n        }\n      }\n    }\n\n    let mergedDocuments = existingDocuments;\n    return this.remoteDocumentCache\n      .getEntries(transaction, missingBaseDocEntriesForPatching)\n      .next(missingBaseDocs => {\n        missingBaseDocs.forEach((key, doc) => {\n          if (doc !== null && doc instanceof Document) {\n            mergedDocuments = mergedDocuments.insert(key, doc);\n          }\n        });\n        return mergedDocuments;\n      });\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { TargetId } from '../core/types';\nimport { ChangeType, ViewSnapshot } from '../core/view_snapshot';\nimport { documentKeySet, DocumentKeySet } from '../model/collections';\n\n/**\n * A set of changes to what documents are currently in view and out of view for\n * a given query. These changes are sent to the LocalStore by the View (via\n * the SyncEngine) and are used to pin / unpin documents as appropriate.\n */\nexport class LocalViewChanges {\n  constructor(\n    readonly targetId: TargetId,\n    readonly fromCache: boolean,\n    readonly addedKeys: DocumentKeySet,\n    readonly removedKeys: DocumentKeySet\n  ) {}\n\n  static fromSnapshot(\n    targetId: TargetId,\n    viewSnapshot: ViewSnapshot\n  ): LocalViewChanges {\n    let addedKeys = documentKeySet();\n    let removedKeys = documentKeySet();\n\n    for (const docChange of viewSnapshot.docChanges) {\n      switch (docChange.type) {\n        case ChangeType.Added:\n          addedKeys = addedKeys.add(docChange.doc.key);\n          break;\n        case ChangeType.Removed:\n          removedKeys = removedKeys.add(docChange.doc.key);\n          break;\n        default:\n        // do nothing\n      }\n    }\n\n    return new LocalViewChanges(\n      targetId,\n      viewSnapshot.fromCache,\n      addedKeys,\n      removedKeys\n    );\n  }\n}\n","/**\n * @license\n * Copyright 2018 Google Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { ListenSequenceNumber } from './types';\n\n/**\n * `SequenceNumberSyncer` defines the methods required to keep multiple instances of a\n * `ListenSequence` in sync.\n */\nexport interface SequenceNumberSyncer {\n  // Notify the syncer that a new sequence number has been used.\n  writeSequenceNumber(sequenceNumber: ListenSequenceNumber): void;\n  // Setting this property allows the syncer to notify when a sequence number has been used, and\n  // and lets the ListenSequence adjust its internal previous value accordingly.\n  sequenceNumberHandler:\n    | ((sequenceNumber: ListenSequenceNumber) => void)\n    | null;\n}\n\n/**\n * `ListenSequence` is a monotonic sequence. It is initialized with a minimum value to\n * exceed. All subsequent calls to next will return increasing values. If provided with a\n * `SequenceNumberSyncer`, it will additionally bump its next value when told of a new value, as\n * well as write out sequence numbers that it produces via `next()`.\n */\nexport class ListenSequence {\n  static readonly INVALID: ListenSequenceNumber = -1;\n\n  private writeNewSequenceNumber?: (\n    newSequenceNumber: ListenSequenceNumber\n  ) => void;\n\n  constructor(\n    private previousValue: ListenSequenceNumber,\n    sequenceNumberSyncer?: SequenceNumberSyncer\n  ) {\n    if (sequenceNumberSyncer) {\n      sequenceNumberSyncer.sequenceNumberHandler = sequenceNumber =>\n        this.setPreviousValue(sequenceNumber);\n      this.writeNewSequenceNumber = sequenceNumber =>\n        sequenceNumberSyncer.writeSequenceNumber(sequenceNumber);\n    }\n  }\n\n  private setPreviousValue(\n    externalPreviousValue: ListenSequenceNumber\n  ): ListenSequenceNumber {\n    this.previousValue = Math.max(externalPreviousValue, this.previousValue);\n    return this.previousValue;\n  }\n\n  next(): ListenSequenceNumber {\n    const nextValue = ++this.previousValue;\n    if (this.writeNewSequenceNumber) {\n      this.writeNewSequenceNumber(nextValue);\n    }\n    return nextValue;\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nexport interface Resolver<R> {\n  (value?: R | Promise<R>): void;\n}\n\nexport interface Rejecter {\n  (reason?: Error): void;\n}\n\nexport interface CancelablePromise<T> {\n  // We are not extending Promise, since Node's Promise API require us to\n  // implement 'finally', which is not fully supported on Web.\n  then<TResult1 = T, TResult2 = never>(\n    onfulfilled?:\n      | ((value: T) => TResult1 | PromiseLike<TResult1>)\n      | undefined\n      | null,\n    onrejected?: // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    ((reason: any) => TResult2 | PromiseLike<TResult2>) | undefined | null\n  ): Promise<TResult1 | TResult2>;\n  catch<TResult = never>(\n    onrejected?: // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    ((reason: any) => TResult | PromiseLike<TResult>) | undefined | null\n  ): Promise<T | TResult>;\n  cancel(): void;\n}\n\nexport class Deferred<R> {\n  promise: Promise<R>;\n  // Assigned synchronously in constructor by Promise constructor callback.\n  resolve!: Resolver<R>;\n  reject!: Rejecter;\n\n  constructor() {\n    this.promise = new Promise((resolve: Resolver<R>, reject: Rejecter) => {\n      this.resolve = resolve;\n      this.reject = reject;\n    });\n  }\n}\n\n/**\n * Takes an array of values and a function from a value to a Promise. The function is run on each\n * value sequentially, waiting for the previous promise to resolve before starting the next one.\n * The returned promise resolves once the function has been run on all values.\n */\nexport function sequence<T>(\n  values: T[],\n  fn: (value: T) => Promise<void>\n): Promise<void> {\n  let p = Promise.resolve();\n  for (const value of values) {\n    p = p.then(() => fn(value));\n  }\n  return p;\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { debugAssert, fail } from './assert';\nimport { Code, FirestoreError } from './error';\nimport { logError } from './log';\nimport { CancelablePromise, Deferred } from './promise';\n\n// Accept any return type from setTimeout().\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\ntype TimerHandle = any;\n\n/**\n * Wellknown \"timer\" IDs used when scheduling delayed operations on the\n * AsyncQueue. These IDs can then be used from tests to check for the presence\n * of operations or to run them early.\n *\n * The string values are used when encoding these timer IDs in JSON spec tests.\n */\nexport const enum TimerId {\n  /** All can be used with runDelayedOperationsEarly() to run all timers. */\n  All = 'all',\n\n  /**\n   * The following 4 timers are used in persistent_stream.ts for the listen and\n   * write streams. The \"Idle\" timer is used to close the stream due to\n   * inactivity. The \"ConnectionBackoff\" timer is used to restart a stream once\n   * the appropriate backoff delay has elapsed.\n   */\n  ListenStreamIdle = 'listen_stream_idle',\n  ListenStreamConnectionBackoff = 'listen_stream_connection_backoff',\n  WriteStreamIdle = 'write_stream_idle',\n  WriteStreamConnectionBackoff = 'write_stream_connection_backoff',\n\n  /**\n   * A timer used in online_state_tracker.ts to transition from\n   * OnlineState.Unknown to Offline after a set timeout, rather than waiting\n   * indefinitely for success or failure.\n   */\n  OnlineStateTimeout = 'online_state_timeout',\n\n  /**\n   * A timer used to update the client metadata in IndexedDb, which is used\n   * to determine the primary leaseholder.\n   */\n  ClientMetadataRefresh = 'client_metadata_refresh',\n\n  /** A timer used to periodically attempt LRU Garbage collection */\n  LruGarbageCollection = 'lru_garbage_collection',\n\n  /**\n   * A timer used to retry transactions. Since there can be multiple concurrent\n   * transactions, multiple of these may be in the queue at a given time.\n   */\n  RetryTransaction = 'retry_transaction'\n}\n\n/**\n * Represents an operation scheduled to be run in the future on an AsyncQueue.\n *\n * It is created via DelayedOperation.createAndSchedule().\n *\n * Supports cancellation (via cancel()) and early execution (via skipDelay()).\n */\nclass DelayedOperation<T extends unknown> implements CancelablePromise<T> {\n  // handle for use with clearTimeout(), or null if the operation has been\n  // executed or canceled already.\n  private timerHandle: TimerHandle | null;\n\n  private readonly deferred = new Deferred<T>();\n\n  private constructor(\n    private readonly asyncQueue: AsyncQueue,\n    readonly timerId: TimerId,\n    readonly targetTimeMs: number,\n    private readonly op: () => Promise<T>,\n    private readonly removalCallback: (op: DelayedOperation<T>) => void\n  ) {\n    // It's normal for the deferred promise to be canceled (due to cancellation)\n    // and so we attach a dummy catch callback to avoid\n    // 'UnhandledPromiseRejectionWarning' log spam.\n    this.deferred.promise.catch(err => {});\n  }\n\n  /**\n   * Creates and returns a DelayedOperation that has been scheduled to be\n   * executed on the provided asyncQueue after the provided delayMs.\n   *\n   * @param asyncQueue The queue to schedule the operation on.\n   * @param id A Timer ID identifying the type of operation this is.\n   * @param delayMs The delay (ms) before the operation should be scheduled.\n   * @param op The operation to run.\n   * @param removalCallback A callback to be called synchronously once the\n   *   operation is executed or canceled, notifying the AsyncQueue to remove it\n   *   from its delayedOperations list.\n   *   PORTING NOTE: This exists to prevent making removeDelayedOperation() and\n   *   the DelayedOperation class public.\n   */\n  static createAndSchedule<R extends unknown>(\n    asyncQueue: AsyncQueue,\n    timerId: TimerId,\n    delayMs: number,\n    op: () => Promise<R>,\n    removalCallback: (op: DelayedOperation<R>) => void\n  ): DelayedOperation<R> {\n    const targetTime = Date.now() + delayMs;\n    const delayedOp = new DelayedOperation(\n      asyncQueue,\n      timerId,\n      targetTime,\n      op,\n      removalCallback\n    );\n    delayedOp.start(delayMs);\n    return delayedOp;\n  }\n\n  /**\n   * Starts the timer. This is called immediately after construction by\n   * createAndSchedule().\n   */\n  private start(delayMs: number): void {\n    this.timerHandle = setTimeout(() => this.handleDelayElapsed(), delayMs);\n  }\n\n  /**\n   * Queues the operation to run immediately (if it hasn't already been run or\n   * canceled).\n   */\n  skipDelay(): void {\n    return this.handleDelayElapsed();\n  }\n\n  /**\n   * Cancels the operation if it hasn't already been executed or canceled. The\n   * promise will be rejected.\n   *\n   * As long as the operation has not yet been run, calling cancel() provides a\n   * guarantee that the operation will not be run.\n   */\n  cancel(reason?: string): void {\n    if (this.timerHandle !== null) {\n      this.clearTimeout();\n      this.deferred.reject(\n        new FirestoreError(\n          Code.CANCELLED,\n          'Operation cancelled' + (reason ? ': ' + reason : '')\n        )\n      );\n    }\n  }\n\n  // Promise implementation.\n  readonly [Symbol.toStringTag]: 'Promise';\n  then = this.deferred.promise.then.bind(this.deferred.promise);\n  catch = this.deferred.promise.catch.bind(this.deferred.promise);\n\n  private handleDelayElapsed(): void {\n    this.asyncQueue.enqueueAndForget(() => {\n      if (this.timerHandle !== null) {\n        this.clearTimeout();\n        return this.op().then(result => {\n          return this.deferred.resolve(result);\n        });\n      } else {\n        return Promise.resolve();\n      }\n    });\n  }\n\n  private clearTimeout(): void {\n    if (this.timerHandle !== null) {\n      this.removalCallback(this);\n      clearTimeout(this.timerHandle);\n      this.timerHandle = null;\n    }\n  }\n}\n\nexport class AsyncQueue {\n  // The last promise in the queue.\n  private tail: Promise<unknown> = Promise.resolve();\n\n  // Is this AsyncQueue being shut down? Once it is set to true, it will not\n  // be changed again.\n  private _isShuttingDown: boolean = false;\n\n  // Operations scheduled to be queued in the future. Operations are\n  // automatically removed after they are run or canceled.\n  private delayedOperations: Array<DelayedOperation<unknown>> = [];\n\n  // visible for testing\n  failure: Error | null = null;\n\n  // Flag set while there's an outstanding AsyncQueue operation, used for\n  // assertion sanity-checks.\n  private operationInProgress = false;\n\n  // List of TimerIds to fast-forward delays for.\n  private timerIdsToSkip: TimerId[] = [];\n\n  // Is this AsyncQueue being shut down? If true, this instance will not enqueue\n  // any new operations, Promises from enqueue requests will not resolve.\n  get isShuttingDown(): boolean {\n    return this._isShuttingDown;\n  }\n\n  /**\n   * Adds a new operation to the queue without waiting for it to complete (i.e.\n   * we ignore the Promise result).\n   */\n  enqueueAndForget<T extends unknown>(op: () => Promise<T>): void {\n    // eslint-disable-next-line @typescript-eslint/no-floating-promises\n    this.enqueue(op);\n  }\n\n  /**\n   * Regardless if the queue has initialized shutdown, adds a new operation to the\n   * queue without waiting for it to complete (i.e. we ignore the Promise result).\n   */\n  enqueueAndForgetEvenAfterShutdown<T extends unknown>(\n    op: () => Promise<T>\n  ): void {\n    this.verifyNotFailed();\n    // eslint-disable-next-line @typescript-eslint/no-floating-promises\n    this.enqueueInternal(op);\n  }\n\n  /**\n   * Regardless if the queue has initialized shutdown, adds a new operation to the\n   * queue.\n   */\n  private enqueueEvenAfterShutdown<T extends unknown>(\n    op: () => Promise<T>\n  ): Promise<T> {\n    this.verifyNotFailed();\n    return this.enqueueInternal(op);\n  }\n\n  /**\n   * Adds a new operation to the queue and initialize the shut down of this queue.\n   * Returns a promise that will be resolved when the promise returned by the new\n   * operation is (with its value).\n   * Once this method is called, the only possible way to request running an operation\n   * is through `enqueueAndForgetEvenAfterShutdown`.\n   */\n  async enqueueAndInitiateShutdown(op: () => Promise<void>): Promise<void> {\n    this.verifyNotFailed();\n    if (!this._isShuttingDown) {\n      this._isShuttingDown = true;\n      await this.enqueueEvenAfterShutdown(op);\n    }\n  }\n\n  /**\n   * Adds a new operation to the queue. Returns a promise that will be resolved\n   * when the promise returned by the new operation is (with its value).\n   */\n  enqueue<T extends unknown>(op: () => Promise<T>): Promise<T> {\n    this.verifyNotFailed();\n    if (this._isShuttingDown) {\n      // Return a Promise which never resolves.\n      return new Promise<T>(resolve => {});\n    }\n    return this.enqueueInternal(op);\n  }\n\n  private enqueueInternal<T extends unknown>(op: () => Promise<T>): Promise<T> {\n    const newTail = this.tail.then(() => {\n      this.operationInProgress = true;\n      return op()\n        .catch((error: FirestoreError) => {\n          this.failure = error;\n          this.operationInProgress = false;\n          const message = error.stack || error.message || '';\n          logError('INTERNAL UNHANDLED ERROR: ', message);\n\n          // Re-throw the error so that this.tail becomes a rejected Promise and\n          // all further attempts to chain (via .then) will just short-circuit\n          // and return the rejected Promise.\n          throw error;\n        })\n        .then(result => {\n          this.operationInProgress = false;\n          return result;\n        });\n    });\n    this.tail = newTail;\n    return newTail;\n  }\n\n  /**\n   * Schedules an operation to be queued on the AsyncQueue once the specified\n   * `delayMs` has elapsed. The returned CancelablePromise can be used to cancel\n   * the operation prior to its running.\n   */\n  enqueueAfterDelay<T extends unknown>(\n    timerId: TimerId,\n    delayMs: number,\n    op: () => Promise<T>\n  ): CancelablePromise<T> {\n    this.verifyNotFailed();\n\n    debugAssert(\n      delayMs >= 0,\n      `Attempted to schedule an operation with a negative delay of ${delayMs}`\n    );\n\n    // Fast-forward delays for timerIds that have been overriden.\n    if (this.timerIdsToSkip.indexOf(timerId) > -1) {\n      delayMs = 0;\n    }\n\n    const delayedOp = DelayedOperation.createAndSchedule<T>(\n      this,\n      timerId,\n      delayMs,\n      op,\n      removedOp =>\n        this.removeDelayedOperation(removedOp as DelayedOperation<unknown>)\n    );\n    this.delayedOperations.push(delayedOp as DelayedOperation<unknown>);\n    return delayedOp;\n  }\n\n  private verifyNotFailed(): void {\n    if (this.failure) {\n      fail(\n        'AsyncQueue is already failed: ' +\n          (this.failure.stack || this.failure.message)\n      );\n    }\n  }\n\n  /**\n   * Verifies there's an operation currently in-progress on the AsyncQueue.\n   * Unfortunately we can't verify that the running code is in the promise chain\n   * of that operation, so this isn't a foolproof check, but it should be enough\n   * to catch some bugs.\n   */\n  verifyOperationInProgress(): void {\n    debugAssert(\n      this.operationInProgress,\n      'verifyOpInProgress() called when no op in progress on this queue.'\n    );\n  }\n\n  /**\n   * Waits until all currently queued tasks are finished executing. Delayed\n   * operations are not run.\n   */\n  async drain(): Promise<void> {\n    // Operations in the queue prior to draining may have enqueued additional\n    // operations. Keep draining the queue until the tail is no longer advanced,\n    // which indicates that no more new operations were enqueued and that all\n    // operations were executed.\n    let currentTail: Promise<unknown>;\n    do {\n      currentTail = this.tail;\n      await currentTail;\n    } while (currentTail !== this.tail);\n  }\n\n  /**\n   * For Tests: Determine if a delayed operation with a particular TimerId\n   * exists.\n   */\n  containsDelayedOperation(timerId: TimerId): boolean {\n    for (const op of this.delayedOperations) {\n      if (op.timerId === timerId) {\n        return true;\n      }\n    }\n    return false;\n  }\n\n  /**\n   * For Tests: Runs some or all delayed operations early.\n   *\n   * @param lastTimerId Delayed operations up to and including this TimerId will\n   *  be drained. Throws if no such operation exists. Pass TimerId.All to run\n   *  all delayed operations.\n   * @returns a Promise that resolves once all operations have been run.\n   */\n  runDelayedOperationsEarly(lastTimerId: TimerId): Promise<void> {\n    // Note that draining may generate more delayed ops, so we do that first.\n    return this.drain().then(() => {\n      debugAssert(\n        lastTimerId === TimerId.All ||\n          this.containsDelayedOperation(lastTimerId),\n        `Attempted to drain to missing operation ${lastTimerId}`\n      );\n\n      // Run ops in the same order they'd run if they ran naturally.\n      this.delayedOperations.sort((a, b) => a.targetTimeMs - b.targetTimeMs);\n\n      for (const op of this.delayedOperations) {\n        op.skipDelay();\n        if (lastTimerId !== TimerId.All && op.timerId === lastTimerId) {\n          break;\n        }\n      }\n\n      return this.drain();\n    });\n  }\n\n  /**\n   * For Tests: Skip all subsequent delays for a timer id.\n   */\n  skipDelaysForTimerId(timerId: TimerId): void {\n    this.timerIdsToSkip.push(timerId);\n  }\n\n  /** Called once a DelayedOperation is run or canceled. */\n  private removeDelayedOperation(op: DelayedOperation<unknown>): void {\n    // NOTE: indexOf / slice are O(n), but delayedOperations is expected to be small.\n    const index = this.delayedOperations.indexOf(op);\n    debugAssert(index >= 0, 'Delayed operation not found.');\n    this.delayedOperations.splice(index, 1);\n  }\n}\n","/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { ListenSequence } from '../core/listen_sequence';\nimport { ListenSequenceNumber, TargetId } from '../core/types';\nimport { debugAssert } from '../util/assert';\nimport { AsyncQueue, TimerId } from '../util/async_queue';\nimport { getLogLevel, logDebug, LogLevel } from '../util/log';\nimport { primitiveComparator } from '../util/misc';\nimport { CancelablePromise } from '../util/promise';\nimport { SortedMap } from '../util/sorted_map';\nimport { SortedSet } from '../util/sorted_set';\nimport { ignoreIfPrimaryLeaseLoss, LocalStore } from './local_store';\nimport {\n  GarbageCollectionScheduler,\n  PersistenceTransaction\n} from './persistence';\nimport { PersistencePromise } from './persistence_promise';\nimport { TargetData } from './target_data';\n\n/**\n * Persistence layers intending to use LRU Garbage collection should have reference delegates that\n * implement this interface. This interface defines the operations that the LRU garbage collector\n * needs from the persistence layer.\n */\nexport interface LruDelegate {\n  readonly garbageCollector: LruGarbageCollector;\n\n  /** Enumerates all the targets in the TargetCache. */\n  forEachTarget(\n    txn: PersistenceTransaction,\n    f: (target: TargetData) => void\n  ): PersistencePromise<void>;\n\n  getSequenceNumberCount(\n    txn: PersistenceTransaction\n  ): PersistencePromise<number>;\n\n  /**\n   * Enumerates sequence numbers for documents not associated with a target.\n   * Note that this may include duplicate sequence numbers.\n   */\n  forEachOrphanedDocumentSequenceNumber(\n    txn: PersistenceTransaction,\n    f: (sequenceNumber: ListenSequenceNumber) => void\n  ): PersistencePromise<void>;\n\n  /**\n   * Removes all targets that have a sequence number less than or equal to `upperBound`, and are not\n   * present in the `activeTargetIds` set.\n   *\n   * @return the number of targets removed.\n   */\n  removeTargets(\n    txn: PersistenceTransaction,\n    upperBound: ListenSequenceNumber,\n    activeTargetIds: ActiveTargets\n  ): PersistencePromise<number>;\n\n  /**\n   * Removes all unreferenced documents from the cache that have a sequence number less than or\n   * equal to the given `upperBound`.\n   *\n   * @return the number of documents removed.\n   */\n  removeOrphanedDocuments(\n    txn: PersistenceTransaction,\n    upperBound: ListenSequenceNumber\n  ): PersistencePromise<number>;\n\n  getCacheSize(txn: PersistenceTransaction): PersistencePromise<number>;\n}\n\n/**\n * Describes a map whose keys are active target ids. We do not care about the type of the\n * values.\n */\nexport type ActiveTargets = SortedMap<TargetId, unknown>;\n\n// The type and comparator for the items contained in the SortedSet used in\n// place of a priority queue for the RollingSequenceNumberBuffer.\ntype BufferEntry = [ListenSequenceNumber, number];\nfunction bufferEntryComparator(\n  [aSequence, aIndex]: BufferEntry,\n  [bSequence, bIndex]: BufferEntry\n): number {\n  const seqCmp = primitiveComparator(aSequence, bSequence);\n  if (seqCmp === 0) {\n    // This order doesn't matter, but we can bias against churn by sorting\n    // entries created earlier as less than newer entries.\n    return primitiveComparator(aIndex, bIndex);\n  } else {\n    return seqCmp;\n  }\n}\n\n/**\n * Used to calculate the nth sequence number. Keeps a rolling buffer of the\n * lowest n values passed to `addElement`, and finally reports the largest of\n * them in `maxValue`.\n */\nclass RollingSequenceNumberBuffer {\n  private buffer: SortedSet<BufferEntry> = new SortedSet<BufferEntry>(\n    bufferEntryComparator\n  );\n\n  private previousIndex = 0;\n\n  constructor(private readonly maxElements: number) {}\n\n  private nextIndex(): number {\n    return ++this.previousIndex;\n  }\n\n  addElement(sequenceNumber: ListenSequenceNumber): void {\n    const entry: BufferEntry = [sequenceNumber, this.nextIndex()];\n    if (this.buffer.size < this.maxElements) {\n      this.buffer = this.buffer.add(entry);\n    } else {\n      const highestValue = this.buffer.last()!;\n      if (bufferEntryComparator(entry, highestValue) < 0) {\n        this.buffer = this.buffer.delete(highestValue).add(entry);\n      }\n    }\n  }\n\n  get maxValue(): ListenSequenceNumber {\n    // Guaranteed to be non-empty. If we decide we are not collecting any\n    // sequence numbers, nthSequenceNumber below short-circuits. If we have\n    // decided that we are collecting n sequence numbers, it's because n is some\n    // percentage of the existing sequence numbers. That means we should never\n    // be in a situation where we are collecting sequence numbers but don't\n    // actually have any.\n    return this.buffer.last()![0];\n  }\n}\n\n/**\n * Describes the results of a garbage collection run. `didRun` will be set to\n * `false` if collection was skipped (either it is disabled or the cache size\n * has not hit the threshold). If collection ran, the other fields will be\n * filled in with the details of the results.\n */\nexport interface LruResults {\n  readonly didRun: boolean;\n  readonly sequenceNumbersCollected: number;\n  readonly targetsRemoved: number;\n  readonly documentsRemoved: number;\n}\n\nconst GC_DID_NOT_RUN: LruResults = {\n  didRun: false,\n  sequenceNumbersCollected: 0,\n  targetsRemoved: 0,\n  documentsRemoved: 0\n};\n\nexport class LruParams {\n  static readonly COLLECTION_DISABLED = -1;\n  static readonly MINIMUM_CACHE_SIZE_BYTES = 1 * 1024 * 1024;\n  static readonly DEFAULT_CACHE_SIZE_BYTES = 40 * 1024 * 1024;\n  private static readonly DEFAULT_COLLECTION_PERCENTILE = 10;\n  private static readonly DEFAULT_MAX_SEQUENCE_NUMBERS_TO_COLLECT = 1000;\n\n  static withCacheSize(cacheSize: number): LruParams {\n    return new LruParams(\n      cacheSize,\n      LruParams.DEFAULT_COLLECTION_PERCENTILE,\n      LruParams.DEFAULT_MAX_SEQUENCE_NUMBERS_TO_COLLECT\n    );\n  }\n\n  static readonly DEFAULT: LruParams = new LruParams(\n    LruParams.DEFAULT_CACHE_SIZE_BYTES,\n    LruParams.DEFAULT_COLLECTION_PERCENTILE,\n    LruParams.DEFAULT_MAX_SEQUENCE_NUMBERS_TO_COLLECT\n  );\n\n  static readonly DISABLED: LruParams = new LruParams(\n    LruParams.COLLECTION_DISABLED,\n    0,\n    0\n  );\n\n  constructor(\n    // When we attempt to collect, we will only do so if the cache size is greater than this\n    // threshold. Passing `COLLECTION_DISABLED` here will cause collection to always be skipped.\n    readonly cacheSizeCollectionThreshold: number,\n    // The percentage of sequence numbers that we will attempt to collect\n    readonly percentileToCollect: number,\n    // A cap on the total number of sequence numbers that will be collected. This prevents\n    // us from collecting a huge number of sequence numbers if the cache has grown very large.\n    readonly maximumSequenceNumbersToCollect: number\n  ) {}\n}\n\n/** How long we wait to try running LRU GC after SDK initialization. */\nconst INITIAL_GC_DELAY_MS = 1 * 60 * 1000;\n/** Minimum amount of time between GC checks, after the first one. */\nconst REGULAR_GC_DELAY_MS = 5 * 60 * 1000;\n\n/**\n * This class is responsible for the scheduling of LRU garbage collection. It handles checking\n * whether or not GC is enabled, as well as which delay to use before the next run.\n */\nexport class LruScheduler implements GarbageCollectionScheduler {\n  private hasRun: boolean = false;\n  private gcTask: CancelablePromise<void> | null;\n\n  constructor(\n    private readonly garbageCollector: LruGarbageCollector,\n    private readonly asyncQueue: AsyncQueue\n  ) {\n    this.gcTask = null;\n  }\n\n  start(localStore: LocalStore): void {\n    debugAssert(\n      this.gcTask === null,\n      'Cannot start an already started LruScheduler'\n    );\n    if (\n      this.garbageCollector.params.cacheSizeCollectionThreshold !==\n      LruParams.COLLECTION_DISABLED\n    ) {\n      this.scheduleGC(localStore);\n    }\n  }\n\n  stop(): void {\n    if (this.gcTask) {\n      this.gcTask.cancel();\n      this.gcTask = null;\n    }\n  }\n\n  get started(): boolean {\n    return this.gcTask !== null;\n  }\n\n  private scheduleGC(localStore: LocalStore): void {\n    debugAssert(\n      this.gcTask === null,\n      'Cannot schedule GC while a task is pending'\n    );\n    const delay = this.hasRun ? REGULAR_GC_DELAY_MS : INITIAL_GC_DELAY_MS;\n    logDebug(\n      'LruGarbageCollector',\n      `Garbage collection scheduled in ${delay}ms`\n    );\n    this.gcTask = this.asyncQueue.enqueueAfterDelay(\n      TimerId.LruGarbageCollection,\n      delay,\n      () => {\n        this.gcTask = null;\n        this.hasRun = true;\n        return localStore\n          .collectGarbage(this.garbageCollector)\n          .then(() => this.scheduleGC(localStore))\n          .catch(ignoreIfPrimaryLeaseLoss);\n      }\n    );\n  }\n}\n\n/** Implements the steps for LRU garbage collection. */\nexport class LruGarbageCollector {\n  constructor(\n    private readonly delegate: LruDelegate,\n    readonly params: LruParams\n  ) {}\n\n  /** Given a percentile of target to collect, returns the number of targets to collect. */\n  calculateTargetCount(\n    txn: PersistenceTransaction,\n    percentile: number\n  ): PersistencePromise<number> {\n    return this.delegate.getSequenceNumberCount(txn).next(targetCount => {\n      return Math.floor((percentile / 100.0) * targetCount);\n    });\n  }\n\n  /** Returns the nth sequence number, counting in order from the smallest. */\n  nthSequenceNumber(\n    txn: PersistenceTransaction,\n    n: number\n  ): PersistencePromise<ListenSequenceNumber> {\n    if (n === 0) {\n      return PersistencePromise.resolve(ListenSequence.INVALID);\n    }\n\n    const buffer = new RollingSequenceNumberBuffer(n);\n    return this.delegate\n      .forEachTarget(txn, target => buffer.addElement(target.sequenceNumber))\n      .next(() => {\n        return this.delegate.forEachOrphanedDocumentSequenceNumber(\n          txn,\n          sequenceNumber => buffer.addElement(sequenceNumber)\n        );\n      })\n      .next(() => buffer.maxValue);\n  }\n\n  /**\n   * Removes targets with a sequence number equal to or less than the given upper bound, and removes\n   * document associations with those targets.\n   */\n  removeTargets(\n    txn: PersistenceTransaction,\n    upperBound: ListenSequenceNumber,\n    activeTargetIds: ActiveTargets\n  ): PersistencePromise<number> {\n    return this.delegate.removeTargets(txn, upperBound, activeTargetIds);\n  }\n\n  /**\n   * Removes documents that have a sequence number equal to or less than the upper bound and are not\n   * otherwise pinned.\n   */\n  removeOrphanedDocuments(\n    txn: PersistenceTransaction,\n    upperBound: ListenSequenceNumber\n  ): PersistencePromise<number> {\n    return this.delegate.removeOrphanedDocuments(txn, upperBound);\n  }\n\n  collect(\n    txn: PersistenceTransaction,\n    activeTargetIds: ActiveTargets\n  ): PersistencePromise<LruResults> {\n    if (\n      this.params.cacheSizeCollectionThreshold === LruParams.COLLECTION_DISABLED\n    ) {\n      logDebug('LruGarbageCollector', 'Garbage collection skipped; disabled');\n      return PersistencePromise.resolve(GC_DID_NOT_RUN);\n    }\n\n    return this.getCacheSize(txn).next(cacheSize => {\n      if (cacheSize < this.params.cacheSizeCollectionThreshold) {\n        logDebug(\n          'LruGarbageCollector',\n          `Garbage collection skipped; Cache size ${cacheSize} ` +\n            `is lower than threshold ${this.params.cacheSizeCollectionThreshold}`\n        );\n        return GC_DID_NOT_RUN;\n      } else {\n        return this.runGarbageCollection(txn, activeTargetIds);\n      }\n    });\n  }\n\n  getCacheSize(txn: PersistenceTransaction): PersistencePromise<number> {\n    return this.delegate.getCacheSize(txn);\n  }\n\n  private runGarbageCollection(\n    txn: PersistenceTransaction,\n    activeTargetIds: ActiveTargets\n  ): PersistencePromise<LruResults> {\n    let upperBoundSequenceNumber: number;\n    let sequenceNumbersToCollect: number, targetsRemoved: number;\n    // Timestamps for various pieces of the process\n    let countedTargetsTs: number,\n      foundUpperBoundTs: number,\n      removedTargetsTs: number,\n      removedDocumentsTs: number;\n    const startTs = Date.now();\n    return this.calculateTargetCount(txn, this.params.percentileToCollect)\n      .next(sequenceNumbers => {\n        // Cap at the configured max\n        if (sequenceNumbers > this.params.maximumSequenceNumbersToCollect) {\n          logDebug(\n            'LruGarbageCollector',\n            'Capping sequence numbers to collect down ' +\n              `to the maximum of ${this.params.maximumSequenceNumbersToCollect} ` +\n              `from ${sequenceNumbers}`\n          );\n          sequenceNumbersToCollect = this.params\n            .maximumSequenceNumbersToCollect;\n        } else {\n          sequenceNumbersToCollect = sequenceNumbers;\n        }\n        countedTargetsTs = Date.now();\n\n        return this.nthSequenceNumber(txn, sequenceNumbersToCollect);\n      })\n      .next(upperBound => {\n        upperBoundSequenceNumber = upperBound;\n        foundUpperBoundTs = Date.now();\n\n        return this.removeTargets(\n          txn,\n          upperBoundSequenceNumber,\n          activeTargetIds\n        );\n      })\n      .next(numTargetsRemoved => {\n        targetsRemoved = numTargetsRemoved;\n        removedTargetsTs = Date.now();\n\n        return this.removeOrphanedDocuments(txn, upperBoundSequenceNumber);\n      })\n      .next(documentsRemoved => {\n        removedDocumentsTs = Date.now();\n\n        if (getLogLevel() <= LogLevel.DEBUG) {\n          const desc =\n            'LRU Garbage Collection\\n' +\n            `\\tCounted targets in ${countedTargetsTs - startTs}ms\\n` +\n            `\\tDetermined least recently used ${sequenceNumbersToCollect} in ` +\n            `${foundUpperBoundTs - countedTargetsTs}ms\\n` +\n            `\\tRemoved ${targetsRemoved} targets in ` +\n            `${removedTargetsTs - foundUpperBoundTs}ms\\n` +\n            `\\tRemoved ${documentsRemoved} documents in ` +\n            `${removedDocumentsTs - removedTargetsTs}ms\\n` +\n            `Total Duration: ${removedDocumentsTs - startTs}ms`;\n          logDebug('LruGarbageCollector', desc);\n        }\n\n        return PersistencePromise.resolve<LruResults>({\n          didRun: true,\n          sequenceNumbersCollected: sequenceNumbersToCollect,\n          targetsRemoved,\n          documentsRemoved\n        });\n      });\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Timestamp } from '../api/timestamp';\nimport { User } from '../auth/user';\nimport { Query } from '../core/query';\nimport { SnapshotVersion } from '../core/snapshot_version';\nimport { Target } from '../core/target';\nimport { BatchId, TargetId } from '../core/types';\nimport {\n  DocumentKeySet,\n  documentKeySet,\n  DocumentMap,\n  maybeDocumentMap,\n  MaybeDocumentMap\n} from '../model/collections';\nimport { MaybeDocument, NoDocument } from '../model/document';\nimport { DocumentKey } from '../model/document_key';\nimport { Mutation, PatchMutation, Precondition } from '../model/mutation';\nimport {\n  BATCHID_UNKNOWN,\n  MutationBatch,\n  MutationBatchResult\n} from '../model/mutation_batch';\nimport { RemoteEvent, TargetChange } from '../remote/remote_event';\nimport { hardAssert, debugAssert } from '../util/assert';\nimport { Code, FirestoreError } from '../util/error';\nimport { logDebug } from '../util/log';\nimport { primitiveComparator } from '../util/misc';\nimport { ObjectMap } from '../util/obj_map';\nimport { SortedMap } from '../util/sorted_map';\n\nimport { LocalDocumentsView } from './local_documents_view';\nimport { LocalViewChanges } from './local_view_changes';\nimport { LruGarbageCollector, LruResults } from './lru_garbage_collector';\nimport { MutationQueue } from './mutation_queue';\nimport {\n  Persistence,\n  PersistenceTransaction,\n  PRIMARY_LEASE_LOST_ERROR_MSG\n} from './persistence';\nimport { PersistencePromise } from './persistence_promise';\nimport { TargetCache } from './target_cache';\nimport { QueryEngine } from './query_engine';\nimport { ReferenceSet } from './reference_set';\nimport { RemoteDocumentCache } from './remote_document_cache';\nimport { RemoteDocumentChangeBuffer } from './remote_document_change_buffer';\nimport { ClientId } from './shared_client_state';\nimport { TargetData, TargetPurpose } from './target_data';\nimport { ByteString } from '../util/byte_string';\n\nconst LOG_TAG = 'LocalStore';\n\n/** The result of a write to the local store. */\nexport interface LocalWriteResult {\n  batchId: BatchId;\n  changes: MaybeDocumentMap;\n}\n\n/** The result of a user-change operation in the local store. */\nexport interface UserChangeResult {\n  readonly affectedDocuments: MaybeDocumentMap;\n  readonly removedBatchIds: BatchId[];\n  readonly addedBatchIds: BatchId[];\n}\n\n/** The result of executing a query against the local store. */\nexport interface QueryResult {\n  readonly documents: DocumentMap;\n  readonly remoteKeys: DocumentKeySet;\n}\n\n/**\n * Local storage in the Firestore client. Coordinates persistence components\n * like the mutation queue and remote document cache to present a\n * latency-compensated view of stored data.\n *\n * The LocalStore is responsible for accepting mutations from the Sync Engine.\n * Writes from the client are put into a queue as provisional Mutations until\n * they are processed by the RemoteStore and confirmed as having been written\n * to the server.\n *\n * The local store provides the local version of documents that have been\n * modified locally. It maintains the constraint:\n *\n *   LocalDocument = RemoteDocument + Active(LocalMutations)\n *\n * (Active mutations are those that are enqueued and have not been previously\n * acknowledged or rejected).\n *\n * The RemoteDocument (\"ground truth\") state is provided via the\n * applyChangeBatch method. It will be some version of a server-provided\n * document OR will be a server-provided document PLUS acknowledged mutations:\n *\n *   RemoteDocument' = RemoteDocument + Acknowledged(LocalMutations)\n *\n * Note that this \"dirty\" version of a RemoteDocument will not be identical to a\n * server base version, since it has LocalMutations added to it pending getting\n * an authoritative copy from the server.\n *\n * Since LocalMutations can be rejected by the server, we have to be able to\n * revert a LocalMutation that has already been applied to the LocalDocument\n * (typically done by replaying all remaining LocalMutations to the\n * RemoteDocument to re-apply).\n *\n * The LocalStore is responsible for the garbage collection of the documents it\n * contains. For now, it every doc referenced by a view, the mutation queue, or\n * the RemoteStore.\n *\n * It also maintains the persistence of mapping queries to resume tokens and\n * target ids. It needs to know this data about queries to properly know what\n * docs it would be allowed to garbage collect.\n *\n * The LocalStore must be able to efficiently execute queries against its local\n * cache of the documents, to provide the initial set of results before any\n * remote changes have been received.\n *\n * Note: In TypeScript, most methods return Promises since the implementation\n * may rely on fetching data from IndexedDB which is async.\n * These Promises will only be rejected on an I/O error or other internal\n * (unexpected) failure (e.g. failed assert) and always represent an\n * unrecoverable error (should be caught / reported by the async_queue).\n */\nexport class LocalStore {\n  /**\n   * The maximum time to leave a resume token buffered without writing it out.\n   * This value is arbitrary: it's long enough to avoid several writes\n   * (possibly indefinitely if updates come more frequently than this) but\n   * short enough that restarting after crashing will still have a pretty\n   * recent resume token.\n   */\n  private static readonly RESUME_TOKEN_MAX_AGE_MICROS = 5 * 60 * 1e6;\n\n  /**\n   * The set of all mutations that have been sent but not yet been applied to\n   * the backend.\n   */\n  private mutationQueue: MutationQueue;\n\n  /** The set of all cached remote documents. */\n  private remoteDocuments: RemoteDocumentCache;\n\n  /**\n   * The \"local\" view of all documents (layering mutationQueue on top of\n   * remoteDocumentCache).\n   */\n  private localDocuments: LocalDocumentsView;\n\n  /**\n   * The set of document references maintained by any local views.\n   */\n  private localViewReferences = new ReferenceSet();\n\n  /** Maps a target to its `TargetData`. */\n  private targetCache: TargetCache;\n\n  /**\n   * Maps a targetID to data about its target.\n   *\n   * PORTING NOTE: We are using an immutable data structure on Web to make re-runs\n   * of `applyRemoteEvent()` idempotent.\n   */\n  private targetDataByTarget = new SortedMap<TargetId, TargetData>(\n    primitiveComparator\n  );\n\n  /** Maps a target to its targetID. */\n  // TODO(wuandy): Evaluate if TargetId can be part of Target.\n  private targetIdByTarget = new ObjectMap<Target, TargetId>(t =>\n    t.canonicalId()\n  );\n\n  /**\n   * The read time of the last entry processed by `getNewDocumentChanges()`.\n   *\n   * PORTING NOTE: This is only used for multi-tab synchronization.\n   */\n  private lastDocumentChangeReadTime = SnapshotVersion.MIN;\n\n  constructor(\n    /** Manages our in-memory or durable persistence. */\n    private persistence: Persistence,\n    private queryEngine: QueryEngine,\n    initialUser: User\n  ) {\n    debugAssert(\n      persistence.started,\n      'LocalStore was passed an unstarted persistence implementation'\n    );\n    this.persistence.referenceDelegate.setInMemoryPins(\n      this.localViewReferences\n    );\n    this.mutationQueue = persistence.getMutationQueue(initialUser);\n    this.remoteDocuments = persistence.getRemoteDocumentCache();\n    this.targetCache = persistence.getTargetCache();\n    this.localDocuments = new LocalDocumentsView(\n      this.remoteDocuments,\n      this.mutationQueue,\n      this.persistence.getIndexManager()\n    );\n    this.queryEngine.setLocalDocumentsView(this.localDocuments);\n  }\n\n  /** Starts the LocalStore. */\n  start(): Promise<void> {\n    return this.synchronizeLastDocumentChangeReadTime();\n  }\n\n  /**\n   * Tells the LocalStore that the currently authenticated user has changed.\n   *\n   * In response the local store switches the mutation queue to the new user and\n   * returns any resulting document changes.\n   */\n  // PORTING NOTE: Android and iOS only return the documents affected by the\n  // change.\n  async handleUserChange(user: User): Promise<UserChangeResult> {\n    let newMutationQueue = this.mutationQueue;\n    let newLocalDocuments = this.localDocuments;\n\n    const result = await this.persistence.runTransaction(\n      'Handle user change',\n      'readonly',\n      txn => {\n        // Swap out the mutation queue, grabbing the pending mutation batches\n        // before and after.\n        let oldBatches: MutationBatch[];\n        return this.mutationQueue\n          .getAllMutationBatches(txn)\n          .next(promisedOldBatches => {\n            oldBatches = promisedOldBatches;\n\n            newMutationQueue = this.persistence.getMutationQueue(user);\n\n            // Recreate our LocalDocumentsView using the new\n            // MutationQueue.\n            newLocalDocuments = new LocalDocumentsView(\n              this.remoteDocuments,\n              newMutationQueue,\n              this.persistence.getIndexManager()\n            );\n            return newMutationQueue.getAllMutationBatches(txn);\n          })\n          .next(newBatches => {\n            const removedBatchIds: BatchId[] = [];\n            const addedBatchIds: BatchId[] = [];\n\n            // Union the old/new changed keys.\n            let changedKeys = documentKeySet();\n\n            for (const batch of oldBatches) {\n              removedBatchIds.push(batch.batchId);\n              for (const mutation of batch.mutations) {\n                changedKeys = changedKeys.add(mutation.key);\n              }\n            }\n\n            for (const batch of newBatches) {\n              addedBatchIds.push(batch.batchId);\n              for (const mutation of batch.mutations) {\n                changedKeys = changedKeys.add(mutation.key);\n              }\n            }\n\n            // Return the set of all (potentially) changed documents and the list\n            // of mutation batch IDs that were affected by change.\n            return newLocalDocuments\n              .getDocuments(txn, changedKeys)\n              .next(affectedDocuments => {\n                return {\n                  affectedDocuments,\n                  removedBatchIds,\n                  addedBatchIds\n                };\n              });\n          });\n      }\n    );\n\n    this.mutationQueue = newMutationQueue;\n    this.localDocuments = newLocalDocuments;\n    this.queryEngine.setLocalDocumentsView(this.localDocuments);\n\n    return result;\n  }\n\n  /* Accept locally generated Mutations and commit them to storage. */\n  localWrite(mutations: Mutation[]): Promise<LocalWriteResult> {\n    const localWriteTime = Timestamp.now();\n    const keys = mutations.reduce(\n      (keys, m) => keys.add(m.key),\n      documentKeySet()\n    );\n\n    let existingDocs: MaybeDocumentMap;\n\n    return this.persistence\n      .runTransaction('Locally write mutations', 'readwrite', txn => {\n        // Load and apply all existing mutations. This lets us compute the\n        // current base state for all non-idempotent transforms before applying\n        // any additional user-provided writes.\n        return this.localDocuments.getDocuments(txn, keys).next(docs => {\n          existingDocs = docs;\n\n          // For non-idempotent mutations (such as `FieldValue.increment()`),\n          // we record the base state in a separate patch mutation. This is\n          // later used to guarantee consistent values and prevents flicker\n          // even if the backend sends us an update that already includes our\n          // transform.\n          const baseMutations: Mutation[] = [];\n\n          for (const mutation of mutations) {\n            const baseValue = mutation.extractBaseValue(\n              existingDocs.get(mutation.key)\n            );\n            if (baseValue != null) {\n              // NOTE: The base state should only be applied if there's some\n              // existing document to override, so use a Precondition of\n              // exists=true\n              baseMutations.push(\n                new PatchMutation(\n                  mutation.key,\n                  baseValue,\n                  baseValue.fieldMask(),\n                  Precondition.exists(true)\n                )\n              );\n            }\n          }\n\n          return this.mutationQueue.addMutationBatch(\n            txn,\n            localWriteTime,\n            baseMutations,\n            mutations\n          );\n        });\n      })\n      .then(batch => {\n        const changes = batch.applyToLocalDocumentSet(existingDocs);\n        return { batchId: batch.batchId, changes };\n      });\n  }\n\n  /** Returns the local view of the documents affected by a mutation batch. */\n  // PORTING NOTE: Multi-tab only.\n  lookupMutationDocuments(batchId: BatchId): Promise<MaybeDocumentMap | null> {\n    return this.persistence.runTransaction(\n      'Lookup mutation documents',\n      'readonly',\n      txn => {\n        return this.mutationQueue\n          .lookupMutationKeys(txn, batchId)\n          .next(keys => {\n            if (keys) {\n              return this.localDocuments.getDocuments(\n                txn,\n                keys\n              ) as PersistencePromise<MaybeDocumentMap | null>;\n            } else {\n              return PersistencePromise.resolve<MaybeDocumentMap | null>(null);\n            }\n          });\n      }\n    );\n  }\n\n  /**\n   * Acknowledge the given batch.\n   *\n   * On the happy path when a batch is acknowledged, the local store will\n   *\n   *  + remove the batch from the mutation queue;\n   *  + apply the changes to the remote document cache;\n   *  + recalculate the latency compensated view implied by those changes (there\n   *    may be mutations in the queue that affect the documents but haven't been\n   *    acknowledged yet); and\n   *  + give the changed documents back the sync engine\n   *\n   * @returns The resulting (modified) documents.\n   */\n  acknowledgeBatch(\n    batchResult: MutationBatchResult\n  ): Promise<MaybeDocumentMap> {\n    return this.persistence.runTransaction(\n      'Acknowledge batch',\n      'readwrite-primary',\n      txn => {\n        const affected = batchResult.batch.keys();\n        const documentBuffer = this.remoteDocuments.newChangeBuffer({\n          trackRemovals: true // Make sure document removals show up in `getNewDocumentChanges()`\n        });\n        return this.mutationQueue\n          .acknowledgeBatch(txn, batchResult.batch, batchResult.streamToken)\n          .next(() =>\n            this.applyWriteToRemoteDocuments(txn, batchResult, documentBuffer)\n          )\n          .next(() => documentBuffer.apply(txn))\n          .next(() => this.mutationQueue.performConsistencyCheck(txn))\n          .next(() => this.localDocuments.getDocuments(txn, affected));\n      }\n    );\n  }\n\n  /**\n   * Remove mutations from the MutationQueue for the specified batch;\n   * LocalDocuments will be recalculated.\n   *\n   * @returns The resulting modified documents.\n   */\n  rejectBatch(batchId: BatchId): Promise<MaybeDocumentMap> {\n    return this.persistence.runTransaction(\n      'Reject batch',\n      'readwrite-primary',\n      txn => {\n        let affectedKeys: DocumentKeySet;\n        return this.mutationQueue\n          .lookupMutationBatch(txn, batchId)\n          .next((batch: MutationBatch | null) => {\n            hardAssert(batch !== null, 'Attempt to reject nonexistent batch!');\n            affectedKeys = batch.keys();\n            return this.mutationQueue.removeMutationBatch(txn, batch);\n          })\n          .next(() => {\n            return this.mutationQueue.performConsistencyCheck(txn);\n          })\n          .next(() => {\n            return this.localDocuments.getDocuments(txn, affectedKeys);\n          });\n      }\n    );\n  }\n\n  /**\n   * Returns the largest (latest) batch id in mutation queue that is pending server response.\n   * Returns `BATCHID_UNKNOWN` if the queue is empty.\n   */\n  getHighestUnacknowledgedBatchId(): Promise<BatchId> {\n    return this.persistence.runTransaction(\n      'Get highest unacknowledged batch id',\n      'readonly',\n      txn => {\n        return this.mutationQueue.getHighestUnacknowledgedBatchId(txn);\n      }\n    );\n  }\n\n  /** Returns the last recorded stream token for the current user. */\n  getLastStreamToken(): Promise<ByteString> {\n    return this.persistence.runTransaction(\n      'Get last stream token',\n      'readonly',\n      txn => {\n        return this.mutationQueue.getLastStreamToken(txn);\n      }\n    );\n  }\n\n  /**\n   * Sets the stream token for the current user without acknowledging any\n   * mutation batch. This is usually only useful after a stream handshake or in\n   * response to an error that requires clearing the stream token.\n   */\n  setLastStreamToken(streamToken: ByteString): Promise<void> {\n    return this.persistence.runTransaction(\n      'Set last stream token',\n      'readwrite-primary',\n      txn => {\n        return this.mutationQueue.setLastStreamToken(txn, streamToken);\n      }\n    );\n  }\n\n  /**\n   * Returns the last consistent snapshot processed (used by the RemoteStore to\n   * determine whether to buffer incoming snapshots from the backend).\n   */\n  getLastRemoteSnapshotVersion(): Promise<SnapshotVersion> {\n    return this.persistence.runTransaction(\n      'Get last remote snapshot version',\n      'readonly',\n      txn => this.targetCache.getLastRemoteSnapshotVersion(txn)\n    );\n  }\n\n  /**\n   * Update the \"ground-state\" (remote) documents. We assume that the remote\n   * event reflects any write batches that have been acknowledged or rejected\n   * (i.e. we do not re-apply local mutations to updates from this event).\n   *\n   * LocalDocuments are re-calculated if there are remaining mutations in the\n   * queue.\n   */\n  applyRemoteEvent(remoteEvent: RemoteEvent): Promise<MaybeDocumentMap> {\n    const remoteVersion = remoteEvent.snapshotVersion;\n    let newTargetDataByTargetMap = this.targetDataByTarget;\n\n    return this.persistence\n      .runTransaction('Apply remote event', 'readwrite-primary', txn => {\n        const documentBuffer = this.remoteDocuments.newChangeBuffer({\n          trackRemovals: true // Make sure document removals show up in `getNewDocumentChanges()`\n        });\n\n        // Reset newTargetDataByTargetMap in case this transaction gets re-run.\n        newTargetDataByTargetMap = this.targetDataByTarget;\n\n        const promises = [] as Array<PersistencePromise<void>>;\n        remoteEvent.targetChanges.forEach((change, targetId) => {\n          const oldTargetData = newTargetDataByTargetMap.get(targetId);\n          if (!oldTargetData) {\n            return;\n          }\n\n          // Only update the remote keys if the target is still active. This\n          // ensures that we can persist the updated target data along with\n          // the updated assignment.\n          promises.push(\n            this.targetCache\n              .removeMatchingKeys(txn, change.removedDocuments, targetId)\n              .next(() => {\n                return this.targetCache.addMatchingKeys(\n                  txn,\n                  change.addedDocuments,\n                  targetId\n                );\n              })\n          );\n\n          const resumeToken = change.resumeToken;\n          // Update the resume token if the change includes one.\n          if (resumeToken.approximateByteSize() > 0) {\n            const newTargetData = oldTargetData\n              .withResumeToken(resumeToken, remoteVersion)\n              .withSequenceNumber(txn.currentSequenceNumber);\n            newTargetDataByTargetMap = newTargetDataByTargetMap.insert(\n              targetId,\n              newTargetData\n            );\n\n            // Update the target data if there are target changes (or if\n            // sufficient time has passed since the last update).\n            if (\n              LocalStore.shouldPersistTargetData(\n                oldTargetData,\n                newTargetData,\n                change\n              )\n            ) {\n              promises.push(\n                this.targetCache.updateTargetData(txn, newTargetData)\n              );\n            }\n          }\n        });\n\n        let changedDocs = maybeDocumentMap();\n        let updatedKeys = documentKeySet();\n        remoteEvent.documentUpdates.forEach((key, doc) => {\n          updatedKeys = updatedKeys.add(key);\n        });\n\n        // Each loop iteration only affects its \"own\" doc, so it's safe to get all the remote\n        // documents in advance in a single call.\n        promises.push(\n          documentBuffer.getEntries(txn, updatedKeys).next(existingDocs => {\n            remoteEvent.documentUpdates.forEach((key, doc) => {\n              const existingDoc = existingDocs.get(key);\n\n              // Note: The order of the steps below is important, since we want\n              // to ensure that rejected limbo resolutions (which fabricate\n              // NoDocuments with SnapshotVersion.MIN) never add documents to\n              // cache.\n              if (\n                doc instanceof NoDocument &&\n                doc.version.isEqual(SnapshotVersion.MIN)\n              ) {\n                // NoDocuments with SnapshotVersion.MIN are used in manufactured\n                // events. We remove these documents from cache since we lost\n                // access.\n                documentBuffer.removeEntry(key, remoteVersion);\n                changedDocs = changedDocs.insert(key, doc);\n              } else if (\n                existingDoc == null ||\n                doc.version.compareTo(existingDoc.version) > 0 ||\n                (doc.version.compareTo(existingDoc.version) === 0 &&\n                  existingDoc.hasPendingWrites)\n              ) {\n                debugAssert(\n                  !SnapshotVersion.MIN.isEqual(remoteVersion),\n                  'Cannot add a document when the remote version is zero'\n                );\n                documentBuffer.addEntry(doc, remoteVersion);\n                changedDocs = changedDocs.insert(key, doc);\n              } else {\n                logDebug(\n                  LOG_TAG,\n                  'Ignoring outdated watch update for ',\n                  key,\n                  '. Current version:',\n                  existingDoc.version,\n                  ' Watch version:',\n                  doc.version\n                );\n              }\n\n              if (remoteEvent.resolvedLimboDocuments.has(key)) {\n                promises.push(\n                  this.persistence.referenceDelegate.updateLimboDocument(\n                    txn,\n                    key\n                  )\n                );\n              }\n            });\n          })\n        );\n\n        // HACK: The only reason we allow a null snapshot version is so that we\n        // can synthesize remote events when we get permission denied errors while\n        // trying to resolve the state of a locally cached document that is in\n        // limbo.\n        if (!remoteVersion.isEqual(SnapshotVersion.MIN)) {\n          const updateRemoteVersion = this.targetCache\n            .getLastRemoteSnapshotVersion(txn)\n            .next(lastRemoteSnapshotVersion => {\n              debugAssert(\n                remoteVersion.compareTo(lastRemoteSnapshotVersion) >= 0,\n                'Watch stream reverted to previous snapshot?? ' +\n                  remoteVersion +\n                  ' < ' +\n                  lastRemoteSnapshotVersion\n              );\n              return this.targetCache.setTargetsMetadata(\n                txn,\n                txn.currentSequenceNumber,\n                remoteVersion\n              );\n            });\n          promises.push(updateRemoteVersion);\n        }\n\n        return PersistencePromise.waitFor(promises)\n          .next(() => documentBuffer.apply(txn))\n          .next(() => {\n            return this.localDocuments.getLocalViewOfDocuments(\n              txn,\n              changedDocs\n            );\n          });\n      })\n      .then(changedDocs => {\n        this.targetDataByTarget = newTargetDataByTargetMap;\n        return changedDocs;\n      });\n  }\n\n  /**\n   * Returns true if the newTargetData should be persisted during an update of\n   * an active target. TargetData should always be persisted when a target is\n   * being released and should not call this function.\n   *\n   * While the target is active, TargetData updates can be omitted when nothing\n   * about the target has changed except metadata like the resume token or\n   * snapshot version. Occasionally it's worth the extra write to prevent these\n   * values from getting too stale after a crash, but this doesn't have to be\n   * too frequent.\n   */\n  private static shouldPersistTargetData(\n    oldTargetData: TargetData,\n    newTargetData: TargetData,\n    change: TargetChange\n  ): boolean {\n    hardAssert(\n      newTargetData.resumeToken.approximateByteSize() > 0,\n      'Attempted to persist target data with no resume token'\n    );\n\n    // Always persist target data if we don't already have a resume token.\n    if (oldTargetData.resumeToken.approximateByteSize() === 0) {\n      return true;\n    }\n\n    // Don't allow resume token changes to be buffered indefinitely. This\n    // allows us to be reasonably up-to-date after a crash and avoids needing\n    // to loop over all active queries on shutdown. Especially in the browser\n    // we may not get time to do anything interesting while the current tab is\n    // closing.\n    const timeDelta =\n      newTargetData.snapshotVersion.toMicroseconds() -\n      oldTargetData.snapshotVersion.toMicroseconds();\n    if (timeDelta >= this.RESUME_TOKEN_MAX_AGE_MICROS) {\n      return true;\n    }\n\n    // Otherwise if the only thing that has changed about a target is its resume\n    // token it's not worth persisting. Note that the RemoteStore keeps an\n    // in-memory view of the currently active targets which includes the current\n    // resume token, so stream failure or user changes will still use an\n    // up-to-date resume token regardless of what we do here.\n    const changes =\n      change.addedDocuments.size +\n      change.modifiedDocuments.size +\n      change.removedDocuments.size;\n    return changes > 0;\n  }\n\n  /**\n   * Notify local store of the changed views to locally pin documents.\n   */\n  notifyLocalViewChanges(viewChanges: LocalViewChanges[]): Promise<void> {\n    for (const viewChange of viewChanges) {\n      const targetId = viewChange.targetId;\n\n      this.localViewReferences.addReferences(viewChange.addedKeys, targetId);\n      this.localViewReferences.removeReferences(\n        viewChange.removedKeys,\n        targetId\n      );\n\n      if (!viewChange.fromCache) {\n        const targetData = this.targetDataByTarget.get(targetId);\n        debugAssert(\n          targetData !== null,\n          `Can't set limbo-free snapshot version for unknown target: ${targetId}`\n        );\n\n        // Advance the last limbo free snapshot version\n        const lastLimboFreeSnapshotVersion = targetData.snapshotVersion;\n        const updatedTargetData = targetData.withLastLimboFreeSnapshotVersion(\n          lastLimboFreeSnapshotVersion\n        );\n        this.targetDataByTarget = this.targetDataByTarget.insert(\n          targetId,\n          updatedTargetData\n        );\n      }\n    }\n    return this.persistence.runTransaction(\n      'notifyLocalViewChanges',\n      'readwrite',\n      txn => {\n        return PersistencePromise.forEach(\n          viewChanges,\n          (viewChange: LocalViewChanges) => {\n            return PersistencePromise.forEach(\n              viewChange.removedKeys,\n              (key: DocumentKey) =>\n                this.persistence.referenceDelegate.removeReference(txn, key)\n            );\n          }\n        );\n      }\n    );\n  }\n\n  /**\n   * Gets the mutation batch after the passed in batchId in the mutation queue\n   * or null if empty.\n   * @param afterBatchId If provided, the batch to search after.\n   * @returns The next mutation or null if there wasn't one.\n   */\n  nextMutationBatch(afterBatchId?: BatchId): Promise<MutationBatch | null> {\n    return this.persistence.runTransaction(\n      'Get next mutation batch',\n      'readonly',\n      txn => {\n        if (afterBatchId === undefined) {\n          afterBatchId = BATCHID_UNKNOWN;\n        }\n        return this.mutationQueue.getNextMutationBatchAfterBatchId(\n          txn,\n          afterBatchId\n        );\n      }\n    );\n  }\n\n  /**\n   * Read the current value of a Document with a given key or null if not\n   * found - used for testing.\n   */\n  readDocument(key: DocumentKey): Promise<MaybeDocument | null> {\n    return this.persistence.runTransaction('read document', 'readonly', txn => {\n      return this.localDocuments.getDocument(txn, key);\n    });\n  }\n\n  /**\n   * Assigns the given target an internal ID so that its results can be pinned so\n   * they don't get GC'd. A target must be allocated in the local store before\n   * the store can be used to manage its view.\n   *\n   * Allocating an already allocated `Target` will return the existing `TargetData`\n   * for that `Target`.\n   */\n  allocateTarget(target: Target): Promise<TargetData> {\n    return this.persistence\n      .runTransaction('Allocate target', 'readwrite', txn => {\n        let targetData: TargetData;\n        return this.targetCache\n          .getTargetData(txn, target)\n          .next((cached: TargetData | null) => {\n            if (cached) {\n              // This target has been listened to previously, so reuse the\n              // previous targetID.\n              // TODO(mcg): freshen last accessed date?\n              targetData = cached;\n              return PersistencePromise.resolve(targetData);\n            } else {\n              return this.targetCache.allocateTargetId(txn).next(targetId => {\n                targetData = new TargetData(\n                  target,\n                  targetId,\n                  TargetPurpose.Listen,\n                  txn.currentSequenceNumber\n                );\n                return this.targetCache\n                  .addTargetData(txn, targetData)\n                  .next(() => targetData);\n              });\n            }\n          });\n      })\n      .then(targetData => {\n        if (this.targetDataByTarget.get(targetData.targetId) === null) {\n          this.targetDataByTarget = this.targetDataByTarget.insert(\n            targetData.targetId,\n            targetData\n          );\n          this.targetIdByTarget.set(target, targetData.targetId);\n        }\n        return targetData;\n      });\n  }\n\n  /**\n   * Returns the TargetData as seen by the LocalStore, including updates that may\n   * have not yet been persisted to the TargetCache.\n   */\n  // Visible for testing.\n  getTargetData(\n    transaction: PersistenceTransaction,\n    target: Target\n  ): PersistencePromise<TargetData | null> {\n    const targetId = this.targetIdByTarget.get(target);\n    if (targetId !== undefined) {\n      return PersistencePromise.resolve<TargetData | null>(\n        this.targetDataByTarget.get(targetId)\n      );\n    } else {\n      return this.targetCache.getTargetData(transaction, target);\n    }\n  }\n\n  /**\n   * Unpin all the documents associated with the given target. If\n   * `keepPersistedTargetData` is set to false and Eager GC enabled, the method\n   * directly removes the associated target data from the target cache.\n   *\n   * Releasing a non-existing `Target` is a no-op.\n   */\n  // PORTING NOTE: `keepPersistedTargetData` is multi-tab only.\n  releaseTarget(\n    targetId: number,\n    keepPersistedTargetData: boolean\n  ): Promise<void> {\n    const targetData = this.targetDataByTarget.get(targetId);\n    debugAssert(\n      targetData !== null,\n      `Tried to release nonexistent target: ${targetId}`\n    );\n\n    const mode = keepPersistedTargetData ? 'readwrite' : 'readwrite-primary';\n    return this.persistence\n      .runTransaction('Release target', mode, txn => {\n        // References for documents sent via Watch are automatically removed\n        // when we delete a target's data from the reference delegate.\n        // Since this does not remove references for locally mutated documents,\n        // we have to remove the target associations for these documents\n        // manually.\n        // This operation needs to be run inside the transaction since EagerGC\n        // uses the local view references during the transaction's commit.\n        // Fortunately, the operation is safe to be re-run in case the\n        // transaction fails since there are no side effects if the target has\n        // already been removed.\n        const removed = this.localViewReferences.removeReferencesForId(\n          targetId\n        );\n\n        if (!keepPersistedTargetData) {\n          return PersistencePromise.forEach(removed, (key: DocumentKey) =>\n            this.persistence.referenceDelegate.removeReference(txn, key)\n          ).next(() => {\n            this.persistence.referenceDelegate.removeTarget(txn, targetData!);\n          });\n        } else {\n          return PersistencePromise.resolve();\n        }\n      })\n      .then(() => {\n        this.targetDataByTarget = this.targetDataByTarget.remove(targetId);\n        this.targetIdByTarget.delete(targetData!.target);\n      });\n  }\n\n  /**\n   * Runs the specified query against the local store and returns the results,\n   * potentially taking advantage of query data from previous executions (such\n   * as the set of remote keys).\n   *\n   * @param usePreviousResults Whether results from previous executions can\n   * be used to optimize this query execution.\n   */\n  executeQuery(\n    query: Query,\n    usePreviousResults: boolean\n  ): Promise<QueryResult> {\n    let lastLimboFreeSnapshotVersion = SnapshotVersion.MIN;\n    let remoteKeys = documentKeySet();\n\n    return this.persistence.runTransaction('Execute query', 'readonly', txn => {\n      return this.getTargetData(txn, query.toTarget())\n        .next(targetData => {\n          if (targetData) {\n            lastLimboFreeSnapshotVersion =\n              targetData.lastLimboFreeSnapshotVersion;\n            return this.targetCache\n              .getMatchingKeysForTargetId(txn, targetData.targetId)\n              .next(result => {\n                remoteKeys = result;\n              });\n          }\n        })\n        .next(() =>\n          this.queryEngine.getDocumentsMatchingQuery(\n            txn,\n            query,\n            usePreviousResults\n              ? lastLimboFreeSnapshotVersion\n              : SnapshotVersion.MIN,\n            usePreviousResults ? remoteKeys : documentKeySet()\n          )\n        )\n        .next(documents => {\n          return { documents, remoteKeys };\n        });\n    });\n  }\n\n  /**\n   * Returns the keys of the documents that are associated with the given\n   * target id in the remote table.\n   */\n  remoteDocumentKeys(targetId: TargetId): Promise<DocumentKeySet> {\n    return this.persistence.runTransaction(\n      'Remote document keys',\n      'readonly',\n      txn => {\n        return this.targetCache.getMatchingKeysForTargetId(txn, targetId);\n      }\n    );\n  }\n\n  // PORTING NOTE: Multi-tab only.\n  getActiveClients(): Promise<ClientId[]> {\n    return this.persistence.getActiveClients();\n  }\n\n  // PORTING NOTE: Multi-tab only.\n  removeCachedMutationBatchMetadata(batchId: BatchId): void {\n    this.mutationQueue.removeCachedMutationKeys(batchId);\n  }\n\n  // PORTING NOTE: Multi-tab only.\n  setNetworkEnabled(networkEnabled: boolean): void {\n    this.persistence.setNetworkEnabled(networkEnabled);\n  }\n\n  private applyWriteToRemoteDocuments(\n    txn: PersistenceTransaction,\n    batchResult: MutationBatchResult,\n    documentBuffer: RemoteDocumentChangeBuffer\n  ): PersistencePromise<void> {\n    const batch = batchResult.batch;\n    const docKeys = batch.keys();\n    let promiseChain = PersistencePromise.resolve();\n    docKeys.forEach(docKey => {\n      promiseChain = promiseChain\n        .next(() => {\n          return documentBuffer.getEntry(txn, docKey);\n        })\n        .next((remoteDoc: MaybeDocument | null) => {\n          let doc = remoteDoc;\n          const ackVersion = batchResult.docVersions.get(docKey);\n          hardAssert(\n            ackVersion !== null,\n            'ackVersions should contain every doc in the write.'\n          );\n          if (!doc || doc.version.compareTo(ackVersion!) < 0) {\n            doc = batch.applyToRemoteDocument(docKey, doc, batchResult);\n            if (!doc) {\n              debugAssert(\n                !remoteDoc,\n                'Mutation batch ' +\n                  batch +\n                  ' applied to document ' +\n                  remoteDoc +\n                  ' resulted in null'\n              );\n            } else {\n              // We use the commitVersion as the readTime rather than the\n              // document's updateTime since the updateTime is not advanced\n              // for updates that do not modify the underlying document.\n              documentBuffer.addEntry(doc, batchResult.commitVersion);\n            }\n          }\n        });\n    });\n    return promiseChain.next(() =>\n      this.mutationQueue.removeMutationBatch(txn, batch)\n    );\n  }\n\n  collectGarbage(garbageCollector: LruGarbageCollector): Promise<LruResults> {\n    return this.persistence.runTransaction(\n      'Collect garbage',\n      'readwrite-primary',\n      txn => garbageCollector.collect(txn, this.targetDataByTarget)\n    );\n  }\n\n  // PORTING NOTE: Multi-tab only.\n  getTarget(targetId: TargetId): Promise<Target | null> {\n    const cachedTargetData = this.targetDataByTarget.get(targetId);\n\n    if (cachedTargetData) {\n      return Promise.resolve(cachedTargetData.target);\n    } else {\n      return this.persistence.runTransaction(\n        'Get target data',\n        'readonly',\n        txn => {\n          return this.targetCache\n            .getTargetDataForTarget(txn, targetId)\n            .next(targetData => (targetData ? targetData.target : null));\n        }\n      );\n    }\n  }\n\n  /**\n   * Returns the set of documents that have been updated since the last call.\n   * If this is the first call, returns the set of changes since client\n   * initialization. Further invocations will return document changes since\n   * the point of rejection.\n   */\n  // PORTING NOTE: Multi-tab only.\n  getNewDocumentChanges(): Promise<MaybeDocumentMap> {\n    return this.persistence\n      .runTransaction('Get new document changes', 'readonly', txn =>\n        this.remoteDocuments.getNewDocumentChanges(\n          txn,\n          this.lastDocumentChangeReadTime\n        )\n      )\n      .then(({ changedDocs, readTime }) => {\n        this.lastDocumentChangeReadTime = readTime;\n        return changedDocs;\n      });\n  }\n\n  /**\n   * Reads the newest document change from persistence and forwards the internal\n   * synchronization marker so that calls to `getNewDocumentChanges()`\n   * only return changes that happened after client initialization.\n   */\n  // PORTING NOTE: Multi-tab only.\n  async synchronizeLastDocumentChangeReadTime(): Promise<void> {\n    this.lastDocumentChangeReadTime = await this.persistence.runTransaction(\n      'Synchronize last document change read time',\n      'readonly',\n      txn => this.remoteDocuments.getLastReadTime(txn)\n    );\n  }\n}\n\n/**\n * Verifies the error thrown by a LocalStore operation. If a LocalStore\n * operation fails because the primary lease has been taken by another client,\n * we ignore the error (the persistence layer will immediately call\n * `applyPrimaryLease` to propagate the primary state change). All other errors\n * are re-thrown.\n *\n * @param err An error returned by a LocalStore operation.\n * @return A Promise that resolves after we recovered, or the original error.\n */\nexport async function ignoreIfPrimaryLeaseLoss(\n  err: FirestoreError\n): Promise<void> {\n  if (\n    err.code === Code.FAILED_PRECONDITION &&\n    err.message === PRIMARY_LEASE_LOST_ERROR_MSG\n  ) {\n    logDebug(LOG_TAG, 'Unexpectedly lost primary lease');\n  } else {\n    throw err;\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nimport { fail } from './assert';\nimport { Code, FirestoreError } from './error';\nimport { Dict, forEach } from './obj';\n\n/** Types accepted by validateType() and related methods for validation. */\nexport type ValidationType =\n  | 'undefined'\n  | 'object'\n  | 'function'\n  | 'boolean'\n  | 'number'\n  | 'string'\n  | 'non-empty string';\n\n/**\n * Validates that no arguments were passed in the invocation of functionName.\n *\n * Forward the magic \"arguments\" variable as second parameter on which the\n * parameter validation is performed:\n * validateNoArgs('myFunction', arguments);\n */\nexport function validateNoArgs(functionName: string, args: IArguments): void {\n  if (args.length !== 0) {\n    throw new FirestoreError(\n      Code.INVALID_ARGUMENT,\n      `Function ${functionName}() does not support arguments, ` +\n        'but was called with ' +\n        formatPlural(args.length, 'argument') +\n        '.'\n    );\n  }\n}\n\n/**\n * Validates the invocation of functionName has the exact number of arguments.\n *\n * Forward the magic \"arguments\" variable as second parameter on which the\n * parameter validation is performed:\n * validateExactNumberOfArgs('myFunction', arguments, 2);\n */\nexport function validateExactNumberOfArgs(\n  functionName: string,\n  args: IArguments,\n  numberOfArgs: number\n): void {\n  if (args.length !== numberOfArgs) {\n    throw new FirestoreError(\n      Code.INVALID_ARGUMENT,\n      `Function ${functionName}() requires ` +\n        formatPlural(numberOfArgs, 'argument') +\n        ', but was called with ' +\n        formatPlural(args.length, 'argument') +\n        '.'\n    );\n  }\n}\n\n/**\n * Validates the invocation of functionName has at least the provided number of\n * arguments (but can have many more).\n *\n * Forward the magic \"arguments\" variable as second parameter on which the\n * parameter validation is performed:\n * validateAtLeastNumberOfArgs('myFunction', arguments, 2);\n */\nexport function validateAtLeastNumberOfArgs(\n  functionName: string,\n  args: IArguments,\n  minNumberOfArgs: number\n): void {\n  if (args.length < minNumberOfArgs) {\n    throw new FirestoreError(\n      Code.INVALID_ARGUMENT,\n      `Function ${functionName}() requires at least ` +\n        formatPlural(minNumberOfArgs, 'argument') +\n        ', but was called with ' +\n        formatPlural(args.length, 'argument') +\n        '.'\n    );\n  }\n}\n\n/**\n * Validates the invocation of functionName has number of arguments between\n * the values provided.\n *\n * Forward the magic \"arguments\" variable as second parameter on which the\n * parameter validation is performed:\n * validateBetweenNumberOfArgs('myFunction', arguments, 2, 3);\n */\nexport function validateBetweenNumberOfArgs(\n  functionName: string,\n  args: IArguments,\n  minNumberOfArgs: number,\n  maxNumberOfArgs: number\n): void {\n  if (args.length < minNumberOfArgs || args.length > maxNumberOfArgs) {\n    throw new FirestoreError(\n      Code.INVALID_ARGUMENT,\n      `Function ${functionName}() requires between ${minNumberOfArgs} and ` +\n        `${maxNumberOfArgs} arguments, but was called with ` +\n        formatPlural(args.length, 'argument') +\n        '.'\n    );\n  }\n}\n\n/**\n * Validates the provided argument is an array and has as least the expected\n * number of elements.\n */\nexport function validateNamedArrayAtLeastNumberOfElements<T>(\n  functionName: string,\n  value: T[],\n  name: string,\n  minNumberOfElements: number\n): void {\n  if (!(value instanceof Array) || value.length < minNumberOfElements) {\n    throw new FirestoreError(\n      Code.INVALID_ARGUMENT,\n      `Function ${functionName}() requires its ${name} argument to be an ` +\n        'array with at least ' +\n        `${formatPlural(minNumberOfElements, 'element')}.`\n    );\n  }\n}\n\n/**\n * Validates the provided positional argument has the native JavaScript type\n * using typeof checks.\n */\nexport function validateArgType(\n  functionName: string,\n  type: ValidationType,\n  position: number,\n  argument: unknown\n): void {\n  validateType(functionName, type, `${ordinal(position)} argument`, argument);\n}\n\n/**\n * Validates the provided argument has the native JavaScript type using\n * typeof checks or is undefined.\n */\nexport function validateOptionalArgType(\n  functionName: string,\n  type: ValidationType,\n  position: number,\n  argument: unknown\n): void {\n  if (argument !== undefined) {\n    validateArgType(functionName, type, position, argument);\n  }\n}\n\n/**\n * Validates the provided named option has the native JavaScript type using\n * typeof checks.\n */\nexport function validateNamedType(\n  functionName: string,\n  type: ValidationType,\n  optionName: string,\n  argument: unknown\n): void {\n  validateType(functionName, type, `${optionName} option`, argument);\n}\n\n/**\n * Validates the provided named option has the native JavaScript type using\n * typeof checks or is undefined.\n */\nexport function validateNamedOptionalType(\n  functionName: string,\n  type: ValidationType,\n  optionName: string,\n  argument: unknown\n): void {\n  if (argument !== undefined) {\n    validateNamedType(functionName, type, optionName, argument);\n  }\n}\n\nexport function validateArrayElements<T>(\n  functionName: string,\n  optionName: string,\n  typeDescription: string,\n  argument: T[],\n  validator: (arg0: T) => boolean\n): void {\n  if (!(argument instanceof Array)) {\n    throw new FirestoreError(\n      Code.INVALID_ARGUMENT,\n      `Function ${functionName}() requires its ${optionName} ` +\n        `option to be an array, but it was: ${valueDescription(argument)}`\n    );\n  }\n\n  for (let i = 0; i < argument.length; ++i) {\n    if (!validator(argument[i])) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        `Function ${functionName}() requires all ${optionName} ` +\n          `elements to be ${typeDescription}, but the value at index ${i} ` +\n          `was: ${valueDescription(argument[i])}`\n      );\n    }\n  }\n}\n\nexport function validateOptionalArrayElements<T>(\n  functionName: string,\n  optionName: string,\n  typeDescription: string,\n  argument: T[] | undefined,\n  validator: (arg0: T) => boolean\n): void {\n  if (argument !== undefined) {\n    validateArrayElements(\n      functionName,\n      optionName,\n      typeDescription,\n      argument,\n      validator\n    );\n  }\n}\n\n/**\n * Validates that the provided named option equals one of the expected values.\n */\nexport function validateNamedPropertyEquals<T>(\n  functionName: string,\n  inputName: string,\n  optionName: string,\n  input: T,\n  expected: T[]\n): void {\n  const expectedDescription: string[] = [];\n\n  for (const val of expected) {\n    if (val === input) {\n      return;\n    }\n    expectedDescription.push(valueDescription(val));\n  }\n\n  const actualDescription = valueDescription(input);\n  throw new FirestoreError(\n    Code.INVALID_ARGUMENT,\n    `Invalid value ${actualDescription} provided to function ${functionName}() for option ` +\n      `\"${optionName}\". Acceptable values: ${expectedDescription.join(', ')}`\n  );\n}\n\n/**\n * Validates that the provided named option equals one of the expected values or\n * is undefined.\n */\nexport function validateNamedOptionalPropertyEquals<T>(\n  functionName: string,\n  inputName: string,\n  optionName: string,\n  input: T,\n  expected: T[]\n): void {\n  if (input !== undefined) {\n    validateNamedPropertyEquals(\n      functionName,\n      inputName,\n      optionName,\n      input,\n      expected\n    );\n  }\n}\n\n/**\n * Validates that the provided argument is a valid enum.\n *\n * @param functionName Function making the validation call.\n * @param enums Array containing all possible values for the enum.\n * @param position Position of the argument in `functionName`.\n * @param argument Arugment to validate.\n */\nexport function validateStringEnum<T>(\n  functionName: string,\n  enums: string[],\n  position: number,\n  argument: unknown\n): void {\n  if (!enums.some(element => element === argument)) {\n    throw new FirestoreError(\n      Code.INVALID_ARGUMENT,\n      `Invalid value ${valueDescription(argument)} provided to function ` +\n        `${functionName}() for its ${ordinal(position)} argument. Acceptable ` +\n        `values: ${enums.join(', ')}`\n    );\n  }\n}\n\n/** Helper to validate the type of a provided input. */\nfunction validateType(\n  functionName: string,\n  type: ValidationType,\n  inputName: string,\n  input: unknown\n): void {\n  let valid = false;\n  if (type === 'object') {\n    valid = isPlainObject(input);\n  } else if (type === 'non-empty string') {\n    valid = typeof input === 'string' && input !== '';\n  } else {\n    valid = typeof input === type;\n  }\n\n  if (!valid) {\n    const description = valueDescription(input);\n    throw new FirestoreError(\n      Code.INVALID_ARGUMENT,\n      `Function ${functionName}() requires its ${inputName} ` +\n        `to be of type ${type}, but it was: ${description}`\n    );\n  }\n}\n\n/**\n * Returns true if it's a non-null object without a custom prototype\n * (i.e. excludes Array, Date, etc.).\n */\nexport function isPlainObject(input: unknown): boolean {\n  return (\n    typeof input === 'object' &&\n    input !== null &&\n    (Object.getPrototypeOf(input) === Object.prototype ||\n      Object.getPrototypeOf(input) === null)\n  );\n}\n\n/** Returns a string describing the type / value of the provided input. */\nexport function valueDescription(input: unknown): string {\n  if (input === undefined) {\n    return 'undefined';\n  } else if (input === null) {\n    return 'null';\n  } else if (typeof input === 'string') {\n    if (input.length > 20) {\n      input = `${input.substring(0, 20)}...`;\n    }\n    return JSON.stringify(input);\n  } else if (typeof input === 'number' || typeof input === 'boolean') {\n    return '' + input;\n  } else if (typeof input === 'object') {\n    if (input instanceof Array) {\n      return 'an array';\n    } else {\n      const customObjectName = tryGetCustomObjectType(input!);\n      if (customObjectName) {\n        return `a custom ${customObjectName} object`;\n      } else {\n        return 'an object';\n      }\n    }\n  } else if (typeof input === 'function') {\n    return 'a function';\n  } else {\n    return fail('Unknown wrong type: ' + typeof input);\n  }\n}\n\n/** Hacky method to try to get the constructor name for an object. */\nexport function tryGetCustomObjectType(input: object): string | null {\n  if (input.constructor) {\n    const funcNameRegex = /function\\s+([^\\s(]+)\\s*\\(/;\n    const results = funcNameRegex.exec(input.constructor.toString());\n    if (results && results.length > 1) {\n      return results[1];\n    }\n  }\n  return null;\n}\n\n/** Validates the provided argument is defined. */\nexport function validateDefined(\n  functionName: string,\n  position: number,\n  argument: unknown\n): void {\n  if (argument === undefined) {\n    throw new FirestoreError(\n      Code.INVALID_ARGUMENT,\n      `Function ${functionName}() requires a valid ${ordinal(position)} ` +\n        `argument, but it was undefined.`\n    );\n  }\n}\n\n/**\n * Validates the provided positional argument is an object, and its keys and\n * values match the expected keys and types provided in optionTypes.\n */\nexport function validateOptionNames(\n  functionName: string,\n  options: object,\n  optionNames: string[]\n): void {\n  forEach(options as Dict<unknown>, (key, _) => {\n    if (optionNames.indexOf(key) < 0) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        `Unknown option '${key}' passed to function ${functionName}(). ` +\n          'Available options: ' +\n          optionNames.join(', ')\n      );\n    }\n  });\n}\n\n/**\n * Helper method to throw an error that the provided argument did not pass\n * an instanceof check.\n */\nexport function invalidClassError(\n  functionName: string,\n  type: string,\n  position: number,\n  argument: unknown\n): Error {\n  const description = valueDescription(argument);\n  return new FirestoreError(\n    Code.INVALID_ARGUMENT,\n    `Function ${functionName}() requires its ${ordinal(position)} ` +\n      `argument to be a ${type}, but it was: ${description}`\n  );\n}\n\nexport function validatePositiveNumber(\n  functionName: string,\n  position: number,\n  n: number\n): void {\n  if (n <= 0) {\n    throw new FirestoreError(\n      Code.INVALID_ARGUMENT,\n      `Function \"${functionName}()\" requires its ${ordinal(\n        position\n      )} argument to be a positive number, but it was: ${n}.`\n    );\n  }\n}\n\n/** Converts a number to its english word representation */\nfunction ordinal(num: number): string {\n  switch (num) {\n    case 1:\n      return 'first';\n    case 2:\n      return 'second';\n    case 3:\n      return 'third';\n    default:\n      return num + 'th';\n  }\n}\n\n/**\n * Formats the given word as plural conditionally given the preceding number.\n */\nfunction formatPlural(num: number, str: string): string {\n  return `${num} ${str}` + (num === 1 ? '' : 's');\n}\n","/**\n * @license\n * Copyright 2017 Google Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Code, FirestoreError } from './error';\n\n/**\n * Helper function to prevent instantiation through the constructor.\n *\n * This method creates a new constructor that throws when it's invoked.\n * The prototype of that constructor is then set to the prototype of the hidden\n * \"class\" to expose all the prototype methods and allow for instanceof\n * checks.\n *\n * To also make all the static methods available, all properties of the\n * original constructor are copied to the new constructor.\n */\nexport function makeConstructorPrivate<T extends Function>(\n  cls: T,\n  optionalMessage?: string\n): T {\n  function PublicConstructor(): never {\n    let error = 'This constructor is private.';\n    if (optionalMessage) {\n      error += ' ';\n      error += optionalMessage;\n    }\n    throw new FirestoreError(Code.INVALID_ARGUMENT, error);\n  }\n\n  // Make sure instanceof checks work and all methods are exposed on the public\n  // constructor\n  PublicConstructor.prototype = cls.prototype;\n\n  // Copy any static methods/members\n  Object.assign(PublicConstructor, cls);\n\n  // eslint-disable-next-line @typescript-eslint/no-explicit-any\n  return PublicConstructor as any;\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { PlatformSupport } from '../platform/platform';\nimport { makeConstructorPrivate } from '../util/api';\nimport { Code, FirestoreError } from '../util/error';\nimport {\n  invalidClassError,\n  validateArgType,\n  validateExactNumberOfArgs\n} from '../util/input_validation';\nimport { ByteString } from '../util/byte_string';\n\n/** Helper function to assert Uint8Array is available at runtime. */\nfunction assertUint8ArrayAvailable(): void {\n  if (typeof Uint8Array === 'undefined') {\n    throw new FirestoreError(\n      Code.UNIMPLEMENTED,\n      'Uint8Arrays are not available in this environment.'\n    );\n  }\n}\n\n/** Helper function to assert Base64 functions are available at runtime. */\nfunction assertBase64Available(): void {\n  if (!PlatformSupport.getPlatform().base64Available) {\n    throw new FirestoreError(\n      Code.UNIMPLEMENTED,\n      'Blobs are unavailable in Firestore in this environment.'\n    );\n  }\n}\n\n/**\n * Immutable class holding a blob (binary data).\n * This class is directly exposed in the public API.\n *\n * Note that while you can't hide the constructor in JavaScript code, we are\n * using the hack above to make sure no-one outside this module can call it.\n */\nexport class Blob {\n  // Prefix with underscore to signal that we consider this not part of the\n  // public API and to prevent it from showing up for autocompletion.\n  _byteString: ByteString;\n\n  constructor(byteString: ByteString) {\n    assertBase64Available();\n    this._byteString = byteString;\n  }\n\n  static fromBase64String(base64: string): Blob {\n    validateExactNumberOfArgs('Blob.fromBase64String', arguments, 1);\n    validateArgType('Blob.fromBase64String', 'string', 1, base64);\n    assertBase64Available();\n    try {\n      return new Blob(ByteString.fromBase64String(base64));\n    } catch (e) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        'Failed to construct Blob from Base64 string: ' + e\n      );\n    }\n  }\n\n  static fromUint8Array(array: Uint8Array): Blob {\n    validateExactNumberOfArgs('Blob.fromUint8Array', arguments, 1);\n    assertUint8ArrayAvailable();\n    if (!(array instanceof Uint8Array)) {\n      throw invalidClassError('Blob.fromUint8Array', 'Uint8Array', 1, array);\n    }\n    return new Blob(ByteString.fromUint8Array(array));\n  }\n\n  toBase64(): string {\n    validateExactNumberOfArgs('Blob.toBase64', arguments, 0);\n    assertBase64Available();\n    return this._byteString.toBase64();\n  }\n\n  toUint8Array(): Uint8Array {\n    validateExactNumberOfArgs('Blob.toUint8Array', arguments, 0);\n    assertUint8ArrayAvailable();\n    return this._byteString.toUint8Array();\n  }\n\n  toString(): string {\n    return 'Blob(base64: ' + this.toBase64() + ')';\n  }\n\n  isEqual(other: Blob): boolean {\n    return this._byteString.isEqual(other._byteString);\n  }\n}\n\n// Public instance that disallows construction at runtime. This constructor is\n// used when exporting Blob on firebase.firestore.Blob and will be called Blob\n// publicly. Internally we still use Blob which has a type checked private\n// constructor. Note that Blob and PublicBlob can be used interchangeably in\n// instanceof checks.\n// For our internal TypeScript code PublicBlob doesn't exist as a type, and so\n// we need to use Blob as type and export it too.\nexport const PublicBlob = makeConstructorPrivate(\n  Blob,\n  'Use Blob.fromUint8Array() or Blob.fromBase64String() instead.'\n);\n","/**\n * @license\n * Copyright 2017 Google Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport * as firestore from '@firebase/firestore-types';\n\nimport { FieldPath as InternalFieldPath } from '../model/path';\nimport { Code, FirestoreError } from '../util/error';\nimport {\n  invalidClassError,\n  validateArgType,\n  validateNamedArrayAtLeastNumberOfElements\n} from '../util/input_validation';\n\n// The objects that are a part of this API are exposed to third-parties as\n// compiled javascript so we want to flag our private members with a leading\n// underscore to discourage their use.\n\n/**\n * A FieldPath refers to a field in a document. The path may consist of a single\n * field name (referring to a top-level field in the document), or a list of\n * field names (referring to a nested field in the document).\n */\nexport class FieldPath implements firestore.FieldPath {\n  /** Internal representation of a Firestore field path. */\n  _internalPath: InternalFieldPath;\n\n  /**\n   * Creates a FieldPath from the provided field names. If more than one field\n   * name is provided, the path will point to a nested field in a document.\n   *\n   * @param fieldNames A list of field names.\n   */\n  constructor(...fieldNames: string[]) {\n    validateNamedArrayAtLeastNumberOfElements(\n      'FieldPath',\n      fieldNames,\n      'fieldNames',\n      1\n    );\n\n    for (let i = 0; i < fieldNames.length; ++i) {\n      validateArgType('FieldPath', 'string', i, fieldNames[i]);\n      if (fieldNames[i].length === 0) {\n        throw new FirestoreError(\n          Code.INVALID_ARGUMENT,\n          `Invalid field name at argument $(i + 1). ` +\n            'Field names must not be empty.'\n        );\n      }\n    }\n\n    this._internalPath = new InternalFieldPath(fieldNames);\n  }\n\n  /**\n   * Internal Note: The backend doesn't technically support querying by\n   * document ID. Instead it queries by the entire document name (full path\n   * included), but in the cases we currently support documentId(), the net\n   * effect is the same.\n   */\n  private static readonly _DOCUMENT_ID = new FieldPath(\n    InternalFieldPath.keyField().canonicalString()\n  );\n\n  static documentId(): FieldPath {\n    return FieldPath._DOCUMENT_ID;\n  }\n\n  isEqual(other: firestore.FieldPath): boolean {\n    if (!(other instanceof FieldPath)) {\n      throw invalidClassError('isEqual', 'FieldPath', 1, other);\n    }\n    return this._internalPath.isEqual(other._internalPath);\n  }\n}\n\n/**\n * Matches any characters in a field path string that are reserved.\n */\nconst RESERVED = new RegExp('[~\\\\*/\\\\[\\\\]]');\n\n/**\n * Parses a field path string into a FieldPath, treating dots as separators.\n */\nexport function fromDotSeparatedString(path: string): FieldPath {\n  const found = path.search(RESERVED);\n  if (found >= 0) {\n    throw new FirestoreError(\n      Code.INVALID_ARGUMENT,\n      `Invalid field path (${path}). Paths must not contain ` +\n        `'~', '*', '/', '[', or ']'`\n    );\n  }\n  try {\n    return new FieldPath(...path.split('.'));\n  } catch (e) {\n    throw new FirestoreError(\n      Code.INVALID_ARGUMENT,\n      `Invalid field path (${path}). Paths must not be empty, ` +\n        `begin with '.', end with '.', or contain '..'`\n    );\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport * as firestore from '@firebase/firestore-types';\n\nimport { makeConstructorPrivate } from '../util/api';\nimport {\n  validateArgType,\n  validateAtLeastNumberOfArgs,\n  validateExactNumberOfArgs,\n  validateNoArgs\n} from '../util/input_validation';\n\n/**\n * An opaque base class for FieldValue sentinel objects in our public API,\n * with public static methods for creating said sentinel objects.\n */\nexport abstract class FieldValueImpl implements firestore.FieldValue {\n  protected constructor(readonly _methodName: string) {}\n\n  static delete(): FieldValueImpl {\n    validateNoArgs('FieldValue.delete', arguments);\n    return DeleteFieldValueImpl.instance;\n  }\n\n  static serverTimestamp(): FieldValueImpl {\n    validateNoArgs('FieldValue.serverTimestamp', arguments);\n    return ServerTimestampFieldValueImpl.instance;\n  }\n\n  static arrayUnion(...elements: unknown[]): FieldValueImpl {\n    validateAtLeastNumberOfArgs('FieldValue.arrayUnion', arguments, 1);\n    // NOTE: We don't actually parse the data until it's used in set() or\n    // update() since we need access to the Firestore instance.\n    return new ArrayUnionFieldValueImpl(elements);\n  }\n\n  static arrayRemove(...elements: unknown[]): FieldValueImpl {\n    validateAtLeastNumberOfArgs('FieldValue.arrayRemove', arguments, 1);\n    // NOTE: We don't actually parse the data until it's used in set() or\n    // update() since we need access to the Firestore instance.\n    return new ArrayRemoveFieldValueImpl(elements);\n  }\n\n  static increment(n: number): FieldValueImpl {\n    validateArgType('FieldValue.increment', 'number', 1, n);\n    validateExactNumberOfArgs('FieldValue.increment', arguments, 1);\n    return new NumericIncrementFieldValueImpl(n);\n  }\n\n  isEqual(other: FieldValueImpl): boolean {\n    return this === other;\n  }\n}\n\nexport class DeleteFieldValueImpl extends FieldValueImpl {\n  private constructor() {\n    super('FieldValue.delete');\n  }\n  /** Singleton instance. */\n  static instance = new DeleteFieldValueImpl();\n}\n\nexport class ServerTimestampFieldValueImpl extends FieldValueImpl {\n  private constructor() {\n    super('FieldValue.serverTimestamp');\n  }\n  /** Singleton instance. */\n  static instance = new ServerTimestampFieldValueImpl();\n}\n\nexport class ArrayUnionFieldValueImpl extends FieldValueImpl {\n  constructor(readonly _elements: unknown[]) {\n    super('FieldValue.arrayUnion');\n  }\n}\n\nexport class ArrayRemoveFieldValueImpl extends FieldValueImpl {\n  constructor(readonly _elements: unknown[]) {\n    super('FieldValue.arrayRemove');\n  }\n}\n\nexport class NumericIncrementFieldValueImpl extends FieldValueImpl {\n  constructor(readonly _operand: number) {\n    super('FieldValue.increment');\n  }\n}\n\n// Public instance that disallows construction at runtime. This constructor is\n// used when exporting FieldValueImpl on firebase.firestore.FieldValue and will\n// be called FieldValue publicly. Internally we still use FieldValueImpl which\n// has a type-checked private constructor. Note that FieldValueImpl and\n// PublicFieldValue can be used interchangeably in instanceof checks.\n// For our internal TypeScript code PublicFieldValue doesn't exist as a type,\n// and so we need to use FieldValueImpl as type and export it too.\nexport const PublicFieldValue = makeConstructorPrivate(\n  FieldValueImpl,\n  'Use FieldValue.<field>() instead.'\n);\n","/**\n * @license\n * Copyright 2017 Google Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Code, FirestoreError } from '../util/error';\nimport {\n  validateArgType,\n  validateExactNumberOfArgs\n} from '../util/input_validation';\nimport { primitiveComparator } from '../util/misc';\n\n/**\n * Immutable class representing a geo point as latitude-longitude pair.\n * This class is directly exposed in the public API, including its constructor.\n */\nexport class GeoPoint {\n  // Prefix with underscore to signal this is a private variable in JS and\n  // prevent it showing up for autocompletion when typing latitude or longitude.\n  private _lat: number;\n  private _long: number;\n\n  constructor(latitude: number, longitude: number) {\n    validateExactNumberOfArgs('GeoPoint', arguments, 2);\n    validateArgType('GeoPoint', 'number', 1, latitude);\n    validateArgType('GeoPoint', 'number', 2, longitude);\n    if (!isFinite(latitude) || latitude < -90 || latitude > 90) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        'Latitude must be a number between -90 and 90, but was: ' + latitude\n      );\n    }\n    if (!isFinite(longitude) || longitude < -180 || longitude > 180) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        'Longitude must be a number between -180 and 180, but was: ' + longitude\n      );\n    }\n\n    this._lat = latitude;\n    this._long = longitude;\n  }\n\n  /**\n   * Returns the latitude of this geo point, a number between -90 and 90.\n   */\n  get latitude(): number {\n    return this._lat;\n  }\n\n  /**\n   * Returns the longitude of this geo point, a number between -180 and 180.\n   */\n  get longitude(): number {\n    return this._long;\n  }\n\n  isEqual(other: GeoPoint): boolean {\n    return this._lat === other._lat && this._long === other._long;\n  }\n\n  /**\n   * Actually private to JS consumers of our API, so this function is prefixed\n   * with an underscore.\n   */\n  _compareTo(other: GeoPoint): number {\n    return (\n      primitiveComparator(this._lat, other._lat) ||\n      primitiveComparator(this._long, other._long)\n    );\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport * as firestore from '@firebase/firestore-types';\n\nimport * as api from '../protos/firestore_proto_api';\n\nimport { Timestamp } from './timestamp';\nimport { DatabaseId } from '../core/database_info';\nimport { DocumentKey } from '../model/document_key';\nimport {\n  FieldMask,\n  FieldTransform,\n  Mutation,\n  PatchMutation,\n  Precondition,\n  SetMutation,\n  TransformMutation\n} from '../model/mutation';\nimport { FieldPath } from '../model/path';\nimport { debugAssert, fail } from '../util/assert';\nimport { Code, FirestoreError } from '../util/error';\nimport { isPlainObject, valueDescription } from '../util/input_validation';\nimport { Dict, forEach, isEmpty } from '../util/obj';\nimport { ObjectValue } from '../model/field_value';\nimport {\n  ArrayRemoveTransformOperation,\n  ArrayUnionTransformOperation,\n  NumericIncrementTransformOperation,\n  ServerTimestampTransform\n} from '../model/transform_operation';\nimport { JsonProtoSerializer } from '../remote/serializer';\nimport { SortedSet } from '../util/sorted_set';\nimport { Blob } from './blob';\nimport {\n  FieldPath as ExternalFieldPath,\n  fromDotSeparatedString\n} from './field_path';\nimport {\n  ArrayRemoveFieldValueImpl,\n  ArrayUnionFieldValueImpl,\n  DeleteFieldValueImpl,\n  FieldValueImpl,\n  NumericIncrementFieldValueImpl,\n  ServerTimestampFieldValueImpl\n} from './field_value';\nimport { GeoPoint } from './geo_point';\n\nconst RESERVED_FIELD_REGEX = /^__.*__$/;\n\n/** The result of parsing document data (e.g. for a setData call). */\nexport class ParsedSetData {\n  constructor(\n    readonly data: ObjectValue,\n    readonly fieldMask: FieldMask | null,\n    readonly fieldTransforms: FieldTransform[]\n  ) {}\n\n  toMutations(key: DocumentKey, precondition: Precondition): Mutation[] {\n    const mutations = [] as Mutation[];\n    if (this.fieldMask !== null) {\n      mutations.push(\n        new PatchMutation(key, this.data, this.fieldMask, precondition)\n      );\n    } else {\n      mutations.push(new SetMutation(key, this.data, precondition));\n    }\n    if (this.fieldTransforms.length > 0) {\n      mutations.push(new TransformMutation(key, this.fieldTransforms));\n    }\n    return mutations;\n  }\n}\n\n/** The result of parsing \"update\" data (i.e. for an updateData call). */\nexport class ParsedUpdateData {\n  constructor(\n    readonly data: ObjectValue,\n    readonly fieldMask: FieldMask,\n    readonly fieldTransforms: FieldTransform[]\n  ) {}\n\n  toMutations(key: DocumentKey, precondition: Precondition): Mutation[] {\n    const mutations = [\n      new PatchMutation(key, this.data, this.fieldMask, precondition)\n    ] as Mutation[];\n    if (this.fieldTransforms.length > 0) {\n      mutations.push(new TransformMutation(key, this.fieldTransforms));\n    }\n    return mutations;\n  }\n}\n\n/*\n * Represents what type of API method provided the data being parsed; useful\n * for determining which error conditions apply during parsing and providing\n * better error messages.\n */\nconst enum UserDataSource {\n  Set,\n  Update,\n  MergeSet,\n  /**\n   * Indicates the source is a where clause, cursor bound, arrayUnion()\n   * element, etc. Of note, isWrite(source) will return false.\n   */\n  Argument,\n  /**\n   * Indicates that the source is an Argument that may directly contain nested\n   * arrays (e.g. the operand of an `in` query).\n   */\n  ArrayArgument\n}\n\nfunction isWrite(dataSource: UserDataSource): boolean {\n  switch (dataSource) {\n    case UserDataSource.Set: // fall through\n    case UserDataSource.MergeSet: // fall through\n    case UserDataSource.Update:\n      return true;\n    case UserDataSource.Argument:\n    case UserDataSource.ArrayArgument:\n      return false;\n    default:\n      throw fail(`Unexpected case for UserDataSource: ${dataSource}`);\n  }\n}\n\n/** A \"context\" object passed around while parsing user data. */\nclass ParseContext {\n  readonly fieldTransforms: FieldTransform[];\n  readonly fieldMask: FieldPath[];\n  /**\n   * Initializes a ParseContext with the given source and path.\n   *\n   * @param dataSource Indicates what kind of API method this data came from.\n   * @param methodName The name of the method the user called to create this\n   *     ParseContext.\n   * @param path A path within the object being parsed. This could be an empty\n   *     path (in which case the context represents the root of the data being\n   *     parsed), or a nonempty path (indicating the context represents a nested\n   *     location within the data).\n   * @param arrayElement Whether or not this context corresponds to an element\n   *     of an array.\n   * @param fieldTransforms A mutable list of field transforms encountered while\n   *     parsing the data.\n   * @param fieldMask A mutable list of field paths encountered while parsing\n   *     the data.\n   *\n   * TODO(b/34871131): We don't support array paths right now, so path can be\n   * null to indicate the context represents any location within an array (in\n   * which case certain features will not work and errors will be somewhat\n   * compromised).\n   */\n  constructor(\n    readonly dataSource: UserDataSource,\n    readonly methodName: string,\n    readonly path: FieldPath | null,\n    readonly arrayElement?: boolean,\n    fieldTransforms?: FieldTransform[],\n    fieldMask?: FieldPath[]\n  ) {\n    // Minor hack: If fieldTransforms is undefined, we assume this is an\n    // external call and we need to validate the entire path.\n    if (fieldTransforms === undefined) {\n      this.validatePath();\n    }\n    this.arrayElement = arrayElement !== undefined ? arrayElement : false;\n    this.fieldTransforms = fieldTransforms || [];\n    this.fieldMask = fieldMask || [];\n  }\n\n  childContextForField(field: string): ParseContext {\n    const childPath = this.path == null ? null : this.path.child(field);\n    const context = new ParseContext(\n      this.dataSource,\n      this.methodName,\n      childPath,\n      /*arrayElement=*/ false,\n      this.fieldTransforms,\n      this.fieldMask\n    );\n    context.validatePathSegment(field);\n    return context;\n  }\n\n  childContextForFieldPath(field: FieldPath): ParseContext {\n    const childPath = this.path == null ? null : this.path.child(field);\n    const context = new ParseContext(\n      this.dataSource,\n      this.methodName,\n      childPath,\n      /*arrayElement=*/ false,\n      this.fieldTransforms,\n      this.fieldMask\n    );\n    context.validatePath();\n    return context;\n  }\n\n  childContextForArray(index: number): ParseContext {\n    // TODO(b/34871131): We don't support array paths right now; so make path\n    // null.\n    return new ParseContext(\n      this.dataSource,\n      this.methodName,\n      /*path=*/ null,\n      /*arrayElement=*/ true,\n      this.fieldTransforms,\n      this.fieldMask\n    );\n  }\n\n  createError(reason: string): Error {\n    const fieldDescription =\n      this.path === null || this.path.isEmpty()\n        ? ''\n        : ` (found in field ${this.path.toString()})`;\n    return new FirestoreError(\n      Code.INVALID_ARGUMENT,\n      `Function ${this.methodName}() called with invalid data. ` +\n        reason +\n        fieldDescription\n    );\n  }\n\n  /** Returns 'true' if 'fieldPath' was traversed when creating this context. */\n  contains(fieldPath: FieldPath): boolean {\n    return (\n      this.fieldMask.find(field => fieldPath.isPrefixOf(field)) !== undefined ||\n      this.fieldTransforms.find(transform =>\n        fieldPath.isPrefixOf(transform.field)\n      ) !== undefined\n    );\n  }\n\n  private validatePath(): void {\n    // TODO(b/34871131): Remove null check once we have proper paths for fields\n    // within arrays.\n    if (this.path === null) {\n      return;\n    }\n    for (let i = 0; i < this.path.length; i++) {\n      this.validatePathSegment(this.path.get(i));\n    }\n  }\n\n  private validatePathSegment(segment: string): void {\n    if (segment.length === 0) {\n      throw this.createError('Document fields must not be empty');\n    }\n    if (isWrite(this.dataSource) && RESERVED_FIELD_REGEX.test(segment)) {\n      throw this.createError('Document fields cannot begin and end with \"__\"');\n    }\n  }\n}\n/**\n * An interface that allows arbitrary pre-converting of user data. This\n * abstraction allows for, e.g.:\n *  * The public API to convert DocumentReference objects to DocRef objects,\n *    avoiding a circular dependency between user_data_converter.ts and\n *    database.ts\n *  * Tests to convert test-only sentinels (e.g. '<DELETE>') into types\n *    compatible with UserDataReader.\n *\n * Returns the converted value (can return back the input to act as a no-op).\n *\n * It can also throw an Error which will be wrapped into a friendly message.\n */\nexport type DataPreConverter = (input: unknown) => unknown;\n\n/**\n * A placeholder object for DocumentReferences in this file, in order to\n * avoid a circular dependency. See the comments for `DataPreConverter` for\n * the full context.\n */\nexport class DocumentKeyReference {\n  constructor(public databaseId: DatabaseId, public key: DocumentKey) {}\n}\n\n/**\n * Helper for parsing raw user input (provided via the API) into internal model\n * classes.\n */\nexport class UserDataReader {\n  constructor(\n    private readonly serializer: JsonProtoSerializer,\n    private readonly preConverter: DataPreConverter\n  ) {}\n\n  /** Parse document data from a non-merge set() call. */\n  parseSetData(methodName: string, input: unknown): ParsedSetData {\n    const context = new ParseContext(\n      UserDataSource.Set,\n      methodName,\n      FieldPath.EMPTY_PATH\n    );\n    validatePlainObject('Data must be an object, but it was:', context, input);\n    const updateData = this.parseObject(input, context)!;\n\n    return new ParsedSetData(\n      new ObjectValue(updateData),\n      /* fieldMask= */ null,\n      context.fieldTransforms\n    );\n  }\n\n  /** Parse document data from a set() call with '{merge:true}'. */\n  parseMergeData(\n    methodName: string,\n    input: unknown,\n    fieldPaths?: Array<string | firestore.FieldPath>\n  ): ParsedSetData {\n    const context = new ParseContext(\n      UserDataSource.MergeSet,\n      methodName,\n      FieldPath.EMPTY_PATH\n    );\n    validatePlainObject('Data must be an object, but it was:', context, input);\n    const updateData = this.parseObject(input, context);\n\n    let fieldMask: FieldMask;\n    let fieldTransforms: FieldTransform[];\n\n    if (!fieldPaths) {\n      fieldMask = FieldMask.fromArray(context.fieldMask);\n      fieldTransforms = context.fieldTransforms;\n    } else {\n      let validatedFieldPaths = new SortedSet<FieldPath>(FieldPath.comparator);\n\n      for (const stringOrFieldPath of fieldPaths) {\n        let fieldPath: FieldPath;\n\n        if (stringOrFieldPath instanceof ExternalFieldPath) {\n          fieldPath = stringOrFieldPath._internalPath;\n        } else if (typeof stringOrFieldPath === 'string') {\n          fieldPath = fieldPathFromDotSeparatedString(\n            methodName,\n            stringOrFieldPath\n          );\n        } else {\n          throw fail(\n            'Expected stringOrFieldPath to be a string or a FieldPath'\n          );\n        }\n\n        if (!context.contains(fieldPath)) {\n          throw new FirestoreError(\n            Code.INVALID_ARGUMENT,\n            `Field '${fieldPath}' is specified in your field mask but missing from your input data.`\n          );\n        }\n\n        validatedFieldPaths = validatedFieldPaths.add(fieldPath);\n      }\n\n      fieldMask = FieldMask.fromSet(validatedFieldPaths);\n      fieldTransforms = context.fieldTransforms.filter(transform =>\n        fieldMask.covers(transform.field)\n      );\n    }\n    return new ParsedSetData(\n      new ObjectValue(updateData),\n      fieldMask,\n      fieldTransforms\n    );\n  }\n\n  /** Parse update data from an update() call. */\n  parseUpdateData(methodName: string, input: unknown): ParsedUpdateData {\n    const context = new ParseContext(\n      UserDataSource.Update,\n      methodName,\n      FieldPath.EMPTY_PATH\n    );\n    validatePlainObject('Data must be an object, but it was:', context, input);\n\n    let fieldMaskPaths = new SortedSet<FieldPath>(FieldPath.comparator);\n    const updateData = ObjectValue.newBuilder();\n    forEach(input as Dict<unknown>, (key, value) => {\n      const path = fieldPathFromDotSeparatedString(methodName, key);\n\n      const childContext = context.childContextForFieldPath(path);\n      value = this.runPreConverter(value, childContext);\n      if (value instanceof DeleteFieldValueImpl) {\n        // Add it to the field mask, but don't add anything to updateData.\n        fieldMaskPaths = fieldMaskPaths.add(path);\n      } else {\n        const parsedValue = this.parseData(value, childContext);\n        if (parsedValue != null) {\n          fieldMaskPaths = fieldMaskPaths.add(path);\n          updateData.set(path, parsedValue);\n        }\n      }\n    });\n\n    const mask = FieldMask.fromSet(fieldMaskPaths);\n    return new ParsedUpdateData(\n      updateData.build(),\n      mask,\n      context.fieldTransforms\n    );\n  }\n\n  /** Parse update data from a list of field/value arguments. */\n  parseUpdateVarargs(\n    methodName: string,\n    field: string | ExternalFieldPath,\n    value: unknown,\n    moreFieldsAndValues: unknown[]\n  ): ParsedUpdateData {\n    const context = new ParseContext(\n      UserDataSource.Update,\n      methodName,\n      FieldPath.EMPTY_PATH\n    );\n    const keys = [fieldPathFromArgument(methodName, field)];\n    const values = [value];\n\n    if (moreFieldsAndValues.length % 2 !== 0) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        `Function ${methodName}() needs to be called with an even number ` +\n          'of arguments that alternate between field names and values.'\n      );\n    }\n\n    for (let i = 0; i < moreFieldsAndValues.length; i += 2) {\n      keys.push(\n        fieldPathFromArgument(\n          methodName,\n          moreFieldsAndValues[i] as string | ExternalFieldPath\n        )\n      );\n      values.push(moreFieldsAndValues[i + 1]);\n    }\n\n    let fieldMaskPaths = new SortedSet<FieldPath>(FieldPath.comparator);\n    const updateData = ObjectValue.newBuilder();\n\n    for (let i = 0; i < keys.length; ++i) {\n      const path = keys[i];\n      const childContext = context.childContextForFieldPath(path);\n      const value = this.runPreConverter(values[i], childContext);\n      if (value instanceof DeleteFieldValueImpl) {\n        // Add it to the field mask, but don't add anything to updateData.\n        fieldMaskPaths = fieldMaskPaths.add(path);\n      } else {\n        const parsedValue = this.parseData(value, childContext);\n        if (parsedValue != null) {\n          fieldMaskPaths = fieldMaskPaths.add(path);\n          updateData.set(path, parsedValue);\n        }\n      }\n    }\n\n    const mask = FieldMask.fromSet(fieldMaskPaths);\n    return new ParsedUpdateData(\n      updateData.build(),\n      mask,\n      context.fieldTransforms\n    );\n  }\n\n  /**\n   * Parse a \"query value\" (e.g. value in a where filter or a value in a cursor\n   * bound).\n   *\n   * @param allowArrays Whether the query value is an array that may directly\n   * contain additional arrays (e.g. the operand of an `in` query).\n   */\n  parseQueryValue(\n    methodName: string,\n    input: unknown,\n    allowArrays = false\n  ): api.Value {\n    const context = new ParseContext(\n      allowArrays ? UserDataSource.ArrayArgument : UserDataSource.Argument,\n      methodName,\n      FieldPath.EMPTY_PATH\n    );\n    const parsed = this.parseData(input, context);\n    debugAssert(parsed != null, 'Parsed data should not be null.');\n    debugAssert(\n      context.fieldTransforms.length === 0,\n      'Field transforms should have been disallowed.'\n    );\n    return parsed;\n  }\n\n  /** Sends data through this.preConverter, handling any thrown errors. */\n  private runPreConverter(input: unknown, context: ParseContext): unknown {\n    try {\n      return this.preConverter(input);\n    } catch (e) {\n      const message = errorMessage(e);\n      throw context.createError(message);\n    }\n  }\n\n  /**\n   * Internal helper for parsing user data.\n   *\n   * @param input Data to be parsed.\n   * @param context A context object representing the current path being parsed,\n   * the source of the data being parsed, etc.\n   * @return The parsed value, or null if the value was a FieldValue sentinel\n   * that should not be included in the resulting parsed data.\n   */\n  private parseData(input: unknown, context: ParseContext): api.Value | null {\n    input = this.runPreConverter(input, context);\n    if (looksLikeJsonObject(input)) {\n      validatePlainObject('Unsupported field value:', context, input);\n      return this.parseObject(input, context);\n    } else if (input instanceof FieldValueImpl) {\n      // FieldValues usually parse into transforms (except FieldValue.delete())\n      // in which case we do not want to include this field in our parsed data\n      // (as doing so will overwrite the field directly prior to the transform\n      // trying to transform it). So we don't add this location to\n      // context.fieldMask and we return null as our parsing result.\n      this.parseSentinelFieldValue(input, context);\n      return null;\n    } else {\n      // If context.path is null we are inside an array and we don't support\n      // field mask paths more granular than the top-level array.\n      if (context.path) {\n        context.fieldMask.push(context.path);\n      }\n\n      if (input instanceof Array) {\n        // TODO(b/34871131): Include the path containing the array in the error\n        // message.\n        // In the case of IN queries, the parsed data is an array (representing\n        // the set of values to be included for the IN query) that may directly\n        // contain additional arrays (each representing an individual field\n        // value), so we disable this validation.\n        if (\n          context.arrayElement &&\n          context.dataSource !== UserDataSource.ArrayArgument\n        ) {\n          throw context.createError('Nested arrays are not supported');\n        }\n        return this.parseArray(input as unknown[], context);\n      } else {\n        return this.parseScalarValue(input, context);\n      }\n    }\n  }\n\n  private parseObject(\n    obj: Dict<unknown>,\n    context: ParseContext\n  ): { mapValue: api.MapValue } {\n    const fields: Dict<api.Value> = {};\n\n    if (isEmpty(obj)) {\n      // If we encounter an empty object, we explicitly add it to the update\n      // mask to ensure that the server creates a map entry.\n      if (context.path && context.path.length > 0) {\n        context.fieldMask.push(context.path);\n      }\n    } else {\n      forEach(obj, (key: string, val: unknown) => {\n        const parsedValue = this.parseData(\n          val,\n          context.childContextForField(key)\n        );\n        if (parsedValue != null) {\n          fields[key] = parsedValue;\n        }\n      });\n    }\n\n    return { mapValue: { fields } };\n  }\n\n  private parseArray(array: unknown[], context: ParseContext): api.Value {\n    const values: api.Value[] = [];\n    let entryIndex = 0;\n    for (const entry of array) {\n      let parsedEntry = this.parseData(\n        entry,\n        context.childContextForArray(entryIndex)\n      );\n      if (parsedEntry == null) {\n        // Just include nulls in the array for fields being replaced with a\n        // sentinel.\n        parsedEntry = { nullValue: 'NULL_VALUE' };\n      }\n      values.push(parsedEntry);\n      entryIndex++;\n    }\n    return { arrayValue: { values } };\n  }\n\n  /**\n   * \"Parses\" the provided FieldValueImpl, adding any necessary transforms to\n   * context.fieldTransforms.\n   */\n  private parseSentinelFieldValue(\n    value: FieldValueImpl,\n    context: ParseContext\n  ): void {\n    // Sentinels are only supported with writes, and not within arrays.\n    if (!isWrite(context.dataSource)) {\n      throw context.createError(\n        `${value._methodName}() can only be used with update() and set()`\n      );\n    }\n    if (context.path === null) {\n      throw context.createError(\n        `${value._methodName}() is not currently supported inside arrays`\n      );\n    }\n\n    if (value instanceof DeleteFieldValueImpl) {\n      if (context.dataSource === UserDataSource.MergeSet) {\n        // No transform to add for a delete, but we need to add it to our\n        // fieldMask so it gets deleted.\n        context.fieldMask.push(context.path);\n      } else if (context.dataSource === UserDataSource.Update) {\n        debugAssert(\n          context.path.length > 0,\n          'FieldValue.delete() at the top level should have already' +\n            ' been handled.'\n        );\n        throw context.createError(\n          'FieldValue.delete() can only appear at the top level ' +\n            'of your update data'\n        );\n      } else {\n        // We shouldn't encounter delete sentinels for queries or non-merge set() calls.\n        throw context.createError(\n          'FieldValue.delete() cannot be used with set() unless you pass ' +\n            '{merge:true}'\n        );\n      }\n    } else if (value instanceof ServerTimestampFieldValueImpl) {\n      context.fieldTransforms.push(\n        new FieldTransform(context.path, ServerTimestampTransform.instance)\n      );\n    } else if (value instanceof ArrayUnionFieldValueImpl) {\n      const parsedElements = this.parseArrayTransformElements(\n        value._methodName,\n        value._elements\n      );\n      const arrayUnion = new ArrayUnionTransformOperation(parsedElements);\n      context.fieldTransforms.push(\n        new FieldTransform(context.path, arrayUnion)\n      );\n    } else if (value instanceof ArrayRemoveFieldValueImpl) {\n      const parsedElements = this.parseArrayTransformElements(\n        value._methodName,\n        value._elements\n      );\n      const arrayRemove = new ArrayRemoveTransformOperation(parsedElements);\n      context.fieldTransforms.push(\n        new FieldTransform(context.path, arrayRemove)\n      );\n    } else if (value instanceof NumericIncrementFieldValueImpl) {\n      const operand = this.parseQueryValue(\n        'FieldValue.increment',\n        value._operand\n      );\n      const numericIncrement = new NumericIncrementTransformOperation(\n        this.serializer,\n        operand\n      );\n      context.fieldTransforms.push(\n        new FieldTransform(context.path, numericIncrement)\n      );\n    } else {\n      fail('Unknown FieldValue type: ' + value);\n    }\n  }\n\n  /**\n   * Helper to parse a scalar value (i.e. not an Object, Array, or FieldValue)\n   *\n   * @return The parsed value\n   */\n  private parseScalarValue(value: unknown, context: ParseContext): api.Value {\n    if (value === null) {\n      return { nullValue: 'NULL_VALUE' };\n    } else if (typeof value === 'number') {\n      return this.serializer.toNumber(value);\n    } else if (typeof value === 'boolean') {\n      return { booleanValue: value };\n    } else if (typeof value === 'string') {\n      return { stringValue: value };\n    } else if (value instanceof Date) {\n      const timestamp = Timestamp.fromDate(value);\n      return { timestampValue: this.serializer.toTimestamp(timestamp) };\n    } else if (value instanceof Timestamp) {\n      // Firestore backend truncates precision down to microseconds. To ensure\n      // offline mode works the same with regards to truncation, perform the\n      // truncation immediately without waiting for the backend to do that.\n      const timestamp = new Timestamp(\n        value.seconds,\n        Math.floor(value.nanoseconds / 1000) * 1000\n      );\n      return { timestampValue: this.serializer.toTimestamp(timestamp) };\n    } else if (value instanceof GeoPoint) {\n      return {\n        geoPointValue: {\n          latitude: value.latitude,\n          longitude: value.longitude\n        }\n      };\n    } else if (value instanceof Blob) {\n      return { bytesValue: this.serializer.toBytes(value) };\n    } else if (value instanceof DocumentKeyReference) {\n      return {\n        referenceValue: this.serializer.toResourceName(\n          value.key.path,\n          value.databaseId\n        )\n      };\n    } else {\n      throw context.createError(\n        `Unsupported field value: ${valueDescription(value)}`\n      );\n    }\n  }\n\n  private parseArrayTransformElements(\n    methodName: string,\n    elements: unknown[]\n  ): api.Value[] {\n    return elements.map((element, i) => {\n      // Although array transforms are used with writes, the actual elements\n      // being unioned or removed are not considered writes since they cannot\n      // contain any FieldValue sentinels, etc.\n      const context = new ParseContext(\n        UserDataSource.Argument,\n        methodName,\n        FieldPath.EMPTY_PATH\n      );\n      return this.parseData(element, context.childContextForArray(i))!;\n    });\n  }\n}\n\n/**\n * Checks whether an object looks like a JSON object that should be converted\n * into a struct. Normal class/prototype instances are considered to look like\n * JSON objects since they should be converted to a struct value. Arrays, Dates,\n * GeoPoints, etc. are not considered to look like JSON objects since they map\n * to specific FieldValue types other than ObjectValue.\n */\nfunction looksLikeJsonObject(input: unknown): boolean {\n  return (\n    typeof input === 'object' &&\n    input !== null &&\n    !(input instanceof Array) &&\n    !(input instanceof Date) &&\n    !(input instanceof Timestamp) &&\n    !(input instanceof GeoPoint) &&\n    !(input instanceof Blob) &&\n    !(input instanceof DocumentKeyReference) &&\n    !(input instanceof FieldValueImpl)\n  );\n}\n\nfunction validatePlainObject(\n  message: string,\n  context: ParseContext,\n  input: unknown\n): asserts input is Dict<unknown> {\n  if (!looksLikeJsonObject(input) || !isPlainObject(input)) {\n    const description = valueDescription(input);\n    if (description === 'an object') {\n      // Massage the error if it was an object.\n      throw context.createError(message + ' a custom object');\n    } else {\n      throw context.createError(message + ' ' + description);\n    }\n  }\n}\n\n/**\n * Helper that calls fromDotSeparatedString() but wraps any error thrown.\n */\nexport function fieldPathFromArgument(\n  methodName: string,\n  path: string | ExternalFieldPath\n): FieldPath {\n  if (path instanceof ExternalFieldPath) {\n    return path._internalPath;\n  } else if (typeof path === 'string') {\n    return fieldPathFromDotSeparatedString(methodName, path);\n  } else {\n    const message = 'Field path arguments must be of type string or FieldPath.';\n    throw new FirestoreError(\n      Code.INVALID_ARGUMENT,\n      `Function ${methodName}() called with invalid data. ${message}`\n    );\n  }\n}\n\n/**\n * Wraps fromDotSeparatedString with an error message about the method that\n * was thrown.\n * @param methodName The publicly visible method name\n * @param path The dot-separated string form of a field path which will be split\n * on dots.\n */\nfunction fieldPathFromDotSeparatedString(\n  methodName: string,\n  path: string\n): FieldPath {\n  try {\n    return fromDotSeparatedString(path)._internalPath;\n  } catch (e) {\n    const message = errorMessage(e);\n    throw new FirestoreError(\n      Code.INVALID_ARGUMENT,\n      `Function ${methodName}() called with invalid data. ${message}`\n    );\n  }\n}\n\n/**\n * Extracts the message from a caught exception, which should be an Error object\n * though JS doesn't guarantee that.\n */\nfunction errorMessage(error: Error | object): string {\n  return error instanceof Error ? error.message : error.toString();\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { AsyncQueue, TimerId } from '../util/async_queue';\nimport { logDebug } from '../util/log';\nimport { CancelablePromise } from '../util/promise';\nconst LOG_TAG = 'ExponentialBackoff';\n\n/**\n * Initial backoff time in milliseconds after an error.\n * Set to 1s according to https://cloud.google.com/apis/design/errors.\n */\nconst DEFAULT_BACKOFF_INITIAL_DELAY_MS = 1000;\n\nconst DEFAULT_BACKOFF_FACTOR = 1.5;\n\n/** Maximum backoff time in milliseconds */\nconst DEFAULT_BACKOFF_MAX_DELAY_MS = 60 * 1000;\n\n/**\n * A helper for running delayed tasks following an exponential backoff curve\n * between attempts.\n *\n * Each delay is made up of a \"base\" delay which follows the exponential\n * backoff curve, and a +/- 50% \"jitter\" that is calculated and added to the\n * base delay. This prevents clients from accidentally synchronizing their\n * delays causing spikes of load to the backend.\n */\nexport class ExponentialBackoff {\n  private currentBaseMs: number = 0;\n  private timerPromise: CancelablePromise<void> | null = null;\n  /** The last backoff attempt, as epoch milliseconds. */\n  private lastAttemptTime = Date.now();\n\n  constructor(\n    /**\n     * The AsyncQueue to run backoff operations on.\n     */\n    private readonly queue: AsyncQueue,\n    /**\n     * The ID to use when scheduling backoff operations on the AsyncQueue.\n     */\n    private readonly timerId: TimerId,\n    /**\n     * The initial delay (used as the base delay on the first retry attempt).\n     * Note that jitter will still be applied, so the actual delay could be as\n     * little as 0.5*initialDelayMs.\n     */\n    private readonly initialDelayMs: number = DEFAULT_BACKOFF_INITIAL_DELAY_MS,\n    /**\n     * The multiplier to use to determine the extended base delay after each\n     * attempt.\n     */\n    private readonly backoffFactor: number = DEFAULT_BACKOFF_FACTOR,\n    /**\n     * The maximum base delay after which no further backoff is performed.\n     * Note that jitter will still be applied, so the actual delay could be as\n     * much as 1.5*maxDelayMs.\n     */\n    private readonly maxDelayMs: number = DEFAULT_BACKOFF_MAX_DELAY_MS\n  ) {\n    this.reset();\n  }\n\n  /**\n   * Resets the backoff delay.\n   *\n   * The very next backoffAndWait() will have no delay. If it is called again\n   * (i.e. due to an error), initialDelayMs (plus jitter) will be used, and\n   * subsequent ones will increase according to the backoffFactor.\n   */\n  reset(): void {\n    this.currentBaseMs = 0;\n  }\n\n  /**\n   * Resets the backoff delay to the maximum delay (e.g. for use after a\n   * RESOURCE_EXHAUSTED error).\n   */\n  resetToMax(): void {\n    this.currentBaseMs = this.maxDelayMs;\n  }\n\n  /**\n   * Returns a promise that resolves after currentDelayMs, and increases the\n   * delay for any subsequent attempts. If there was a pending backoff operation\n   * already, it will be canceled.\n   */\n  backoffAndRun(op: () => Promise<void>): void {\n    // Cancel any pending backoff operation.\n    this.cancel();\n\n    // First schedule using the current base (which may be 0 and should be\n    // honored as such).\n    const desiredDelayWithJitterMs = Math.floor(\n      this.currentBaseMs + this.jitterDelayMs()\n    );\n\n    // Guard against lastAttemptTime being in the future due to a clock change.\n    const delaySoFarMs = Math.max(0, Date.now() - this.lastAttemptTime);\n\n    // Guard against the backoff delay already being past.\n    const remainingDelayMs = Math.max(\n      0,\n      desiredDelayWithJitterMs - delaySoFarMs\n    );\n\n    if (this.currentBaseMs > 0) {\n      logDebug(\n        LOG_TAG,\n        `Backing off for ${remainingDelayMs} ms ` +\n          `(base delay: ${this.currentBaseMs} ms, ` +\n          `delay with jitter: ${desiredDelayWithJitterMs} ms, ` +\n          `last attempt: ${delaySoFarMs} ms ago)`\n      );\n    }\n\n    this.timerPromise = this.queue.enqueueAfterDelay(\n      this.timerId,\n      remainingDelayMs,\n      () => {\n        this.lastAttemptTime = Date.now();\n        return op();\n      }\n    );\n\n    // Apply backoff factor to determine next delay and ensure it is within\n    // bounds.\n    this.currentBaseMs *= this.backoffFactor;\n    if (this.currentBaseMs < this.initialDelayMs) {\n      this.currentBaseMs = this.initialDelayMs;\n    }\n    if (this.currentBaseMs > this.maxDelayMs) {\n      this.currentBaseMs = this.maxDelayMs;\n    }\n  }\n\n  cancel(): void {\n    if (this.timerPromise !== null) {\n      this.timerPromise.cancel();\n      this.timerPromise = null;\n    }\n  }\n\n  /** Returns a random value in the range [-currentBaseMs/2, currentBaseMs/2] */\n  private jitterDelayMs(): number {\n    return (Math.random() - 0.5) * this.currentBaseMs;\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { CredentialsProvider, Token } from '../api/credentials';\nimport { SnapshotVersion } from '../core/snapshot_version';\nimport { TargetId } from '../core/types';\nimport { TargetData } from '../local/target_data';\nimport { Mutation, MutationResult } from '../model/mutation';\nimport * as api from '../protos/firestore_proto_api';\nimport { hardAssert, debugAssert } from '../util/assert';\nimport { AsyncQueue, TimerId } from '../util/async_queue';\nimport { Code, FirestoreError } from '../util/error';\nimport { logError, logDebug } from '../util/log';\n\nimport { CancelablePromise } from '../util/promise';\nimport { isNullOrUndefined } from '../util/types';\nimport { ExponentialBackoff } from './backoff';\nimport { Connection, Stream } from './connection';\nimport { JsonProtoSerializer } from './serializer';\nimport { WatchChange } from './watch_change';\nimport { ByteString } from '../util/byte_string';\n\nconst LOG_TAG = 'PersistentStream';\n\n// The generated proto interfaces for these class are missing the database\n// field. So we add it here.\n// TODO(b/36015800): Remove this once the api generator is fixed.\ninterface ListenRequest extends api.ListenRequest {\n  database?: string;\n}\nexport interface WriteRequest extends api.WriteRequest {\n  database?: string;\n}\n/**\n * PersistentStream can be in one of 5 states (each described in detail below)\n * based on the following state transition diagram:\n *\n *          start() called             auth & connection succeeded\n * INITIAL ----------------> STARTING -----------------------------> OPEN\n *                             ^  |                                   |\n *                             |  |                    error occurred |\n *                             |  \\-----------------------------v-----/\n *                             |                                |\n *                    backoff  |                                |\n *                    elapsed  |              start() called    |\n *                             \\--- BACKOFF <---------------- ERROR\n *\n * [any state] --------------------------> INITIAL\n *               stop() called or\n *               idle timer expired\n */\nconst enum PersistentStreamState {\n  /**\n   * The streaming RPC is not yet running and there's no error condition.\n   * Calling start() will start the stream immediately without backoff.\n   * While in this state isStarted() will return false.\n   */\n  Initial,\n\n  /**\n   * The stream is starting, either waiting for an auth token or for the stream\n   * to successfully open. While in this state, isStarted() will return true but\n   * isOpen() will return false.\n   */\n  Starting,\n\n  /**\n   * The streaming RPC is up and running. Requests and responses can flow\n   * freely. Both isStarted() and isOpen() will return true.\n   */\n  Open,\n\n  /**\n   * The stream encountered an error. The next start attempt will back off.\n   * While in this state isStarted() will return false.\n   */\n  Error,\n\n  /**\n   * An in-between state after an error where the stream is waiting before\n   * re-starting. After waiting is complete, the stream will try to open.\n   * While in this state isStarted() will return true but isOpen() will return\n   * false.\n   */\n  Backoff\n}\n\n/**\n * Provides a common interface that is shared by the listeners for stream\n * events by the concrete implementation classes.\n */\nexport interface PersistentStreamListener {\n  /**\n   * Called after the stream was established and can accept outgoing\n   * messages\n   */\n  onOpen: () => Promise<void>;\n  /**\n   * Called after the stream has closed. If there was an error, the\n   * FirestoreError will be set.\n   */\n  onClose: (err?: FirestoreError) => Promise<void>;\n}\n\n/** The time a stream stays open after it is marked idle. */\nconst IDLE_TIMEOUT_MS = 60 * 1000;\n\n/**\n * A PersistentStream is an abstract base class that represents a streaming RPC\n * to the Firestore backend. It's built on top of the connections own support\n * for streaming RPCs, and adds several critical features for our clients:\n *\n *   - Exponential backoff on failure\n *   - Authentication via CredentialsProvider\n *   - Dispatching all callbacks into the shared worker queue\n *   - Closing idle streams after 60 seconds of inactivity\n *\n * Subclasses of PersistentStream implement serialization of models to and\n * from the JSON representation of the protocol buffers for a specific\n * streaming RPC.\n *\n * ## Starting and Stopping\n *\n * Streaming RPCs are stateful and need to be start()ed before messages can\n * be sent and received. The PersistentStream will call the onOpen() function\n * of the listener once the stream is ready to accept requests.\n *\n * Should a start() fail, PersistentStream will call the registered onClose()\n * listener with a FirestoreError indicating what went wrong.\n *\n * A PersistentStream can be started and stopped repeatedly.\n *\n * Generic types:\n *  SendType: The type of the outgoing message of the underlying\n *    connection stream\n *  ReceiveType: The type of the incoming message of the underlying\n *    connection stream\n *  ListenerType: The type of the listener that will be used for callbacks\n */\nexport abstract class PersistentStream<\n  SendType,\n  ReceiveType,\n  ListenerType extends PersistentStreamListener\n> {\n  private state = PersistentStreamState.Initial;\n  /**\n   * A close count that's incremented every time the stream is closed; used by\n   * getCloseGuardedDispatcher() to invalidate callbacks that happen after\n   * close.\n   */\n  private closeCount = 0;\n\n  private idleTimer: CancelablePromise<void> | null = null;\n  private stream: Stream<SendType, ReceiveType> | null = null;\n\n  protected backoff: ExponentialBackoff;\n\n  constructor(\n    private queue: AsyncQueue,\n    connectionTimerId: TimerId,\n    private idleTimerId: TimerId,\n    protected connection: Connection,\n    private credentialsProvider: CredentialsProvider,\n    protected listener: ListenerType\n  ) {\n    this.backoff = new ExponentialBackoff(queue, connectionTimerId);\n  }\n\n  /**\n   * Returns true if start() has been called and no error has occurred. True\n   * indicates the stream is open or in the process of opening (which\n   * encompasses respecting backoff, getting auth tokens, and starting the\n   * actual RPC). Use isOpen() to determine if the stream is open and ready for\n   * outbound requests.\n   */\n  isStarted(): boolean {\n    return (\n      this.state === PersistentStreamState.Starting ||\n      this.state === PersistentStreamState.Open ||\n      this.state === PersistentStreamState.Backoff\n    );\n  }\n\n  /**\n   * Returns true if the underlying RPC is open (the onOpen() listener has been\n   * called) and the stream is ready for outbound requests.\n   */\n  isOpen(): boolean {\n    return this.state === PersistentStreamState.Open;\n  }\n\n  /**\n   * Starts the RPC. Only allowed if isStarted() returns false. The stream is\n   * not immediately ready for use: onOpen() will be invoked when the RPC is\n   * ready for outbound requests, at which point isOpen() will return true.\n   *\n   * When start returns, isStarted() will return true.\n   */\n  start(): void {\n    if (this.state === PersistentStreamState.Error) {\n      this.performBackoff();\n      return;\n    }\n\n    debugAssert(\n      this.state === PersistentStreamState.Initial,\n      'Already started'\n    );\n    this.auth();\n  }\n\n  /**\n   * Stops the RPC. This call is idempotent and allowed regardless of the\n   * current isStarted() state.\n   *\n   * When stop returns, isStarted() and isOpen() will both return false.\n   */\n  async stop(): Promise<void> {\n    if (this.isStarted()) {\n      await this.close(PersistentStreamState.Initial);\n    }\n  }\n\n  /**\n   * After an error the stream will usually back off on the next attempt to\n   * start it. If the error warrants an immediate restart of the stream, the\n   * sender can use this to indicate that the receiver should not back off.\n   *\n   * Each error will call the onClose() listener. That function can decide to\n   * inhibit backoff if required.\n   */\n  inhibitBackoff(): void {\n    debugAssert(\n      !this.isStarted(),\n      'Can only inhibit backoff in a stopped state'\n    );\n\n    this.state = PersistentStreamState.Initial;\n    this.backoff.reset();\n  }\n\n  /**\n   * Marks this stream as idle. If no further actions are performed on the\n   * stream for one minute, the stream will automatically close itself and\n   * notify the stream's onClose() handler with Status.OK. The stream will then\n   * be in a !isStarted() state, requiring the caller to start the stream again\n   * before further use.\n   *\n   * Only streams that are in state 'Open' can be marked idle, as all other\n   * states imply pending network operations.\n   */\n  markIdle(): void {\n    // Starts the idle time if we are in state 'Open' and are not yet already\n    // running a timer (in which case the previous idle timeout still applies).\n    if (this.isOpen() && this.idleTimer === null) {\n      this.idleTimer = this.queue.enqueueAfterDelay(\n        this.idleTimerId,\n        IDLE_TIMEOUT_MS,\n        () => this.handleIdleCloseTimer()\n      );\n    }\n  }\n\n  /** Sends a message to the underlying stream. */\n  protected sendRequest(msg: SendType): void {\n    this.cancelIdleCheck();\n    this.stream!.send(msg);\n  }\n\n  /** Called by the idle timer when the stream should close due to inactivity. */\n  private async handleIdleCloseTimer(): Promise<void> {\n    if (this.isOpen()) {\n      // When timing out an idle stream there's no reason to force the stream into backoff when\n      // it restarts so set the stream state to Initial instead of Error.\n      return this.close(PersistentStreamState.Initial);\n    }\n  }\n\n  /** Marks the stream as active again. */\n  private cancelIdleCheck(): void {\n    if (this.idleTimer) {\n      this.idleTimer.cancel();\n      this.idleTimer = null;\n    }\n  }\n\n  /**\n   * Closes the stream and cleans up as necessary:\n   *\n   * * closes the underlying GRPC stream;\n   * * calls the onClose handler with the given 'error';\n   * * sets internal stream state to 'finalState';\n   * * adjusts the backoff timer based on the error\n   *\n   * A new stream can be opened by calling start().\n   *\n   * @param finalState the intended state of the stream after closing.\n   * @param error the error the connection was closed with.\n   */\n  private async close(\n    finalState: PersistentStreamState,\n    error?: FirestoreError\n  ): Promise<void> {\n    debugAssert(this.isStarted(), 'Only started streams should be closed.');\n    debugAssert(\n      finalState === PersistentStreamState.Error || isNullOrUndefined(error),\n      \"Can't provide an error when not in an error state.\"\n    );\n\n    // Cancel any outstanding timers (they're guaranteed not to execute).\n    this.cancelIdleCheck();\n    this.backoff.cancel();\n\n    // Invalidates any stream-related callbacks (e.g. from auth or the\n    // underlying stream), guaranteeing they won't execute.\n    this.closeCount++;\n\n    if (finalState !== PersistentStreamState.Error) {\n      // If this is an intentional close ensure we don't delay our next connection attempt.\n      this.backoff.reset();\n    } else if (error && error.code === Code.RESOURCE_EXHAUSTED) {\n      // Log the error. (Probably either 'quota exceeded' or 'max queue length reached'.)\n      logError(error.toString());\n      logError(\n        'Using maximum backoff delay to prevent overloading the backend.'\n      );\n      this.backoff.resetToMax();\n    } else if (error && error.code === Code.UNAUTHENTICATED) {\n      // \"unauthenticated\" error means the token was rejected. Try force refreshing it in case it\n      // just expired.\n      this.credentialsProvider.invalidateToken();\n    }\n\n    // Clean up the underlying stream because we are no longer interested in events.\n    if (this.stream !== null) {\n      this.tearDown();\n      this.stream.close();\n      this.stream = null;\n    }\n\n    // This state must be assigned before calling onClose() to allow the callback to\n    // inhibit backoff or otherwise manipulate the state in its non-started state.\n    this.state = finalState;\n\n    // Notify the listener that the stream closed.\n    await this.listener.onClose(error);\n  }\n\n  /**\n   * Can be overridden to perform additional cleanup before the stream is closed.\n   * Calling super.tearDown() is not required.\n   */\n  protected tearDown(): void {}\n\n  /**\n   * Used by subclasses to start the concrete RPC and return the underlying\n   * connection stream.\n   */\n  protected abstract startRpc(\n    token: Token | null\n  ): Stream<SendType, ReceiveType>;\n\n  /**\n   * Called after the stream has received a message. The function will be\n   * called on the right queue and must return a Promise.\n   * @param message The message received from the stream.\n   */\n  protected abstract onMessage(message: ReceiveType): Promise<void>;\n\n  private auth(): void {\n    debugAssert(\n      this.state === PersistentStreamState.Initial,\n      'Must be in initial state to auth'\n    );\n\n    this.state = PersistentStreamState.Starting;\n\n    const dispatchIfNotClosed = this.getCloseGuardedDispatcher(this.closeCount);\n\n    // TODO(mikelehen): Just use dispatchIfNotClosed, but see TODO below.\n    const closeCount = this.closeCount;\n\n    this.credentialsProvider.getToken().then(\n      token => {\n        // Stream can be stopped while waiting for authentication.\n        // TODO(mikelehen): We really should just use dispatchIfNotClosed\n        // and let this dispatch onto the queue, but that opened a spec test can\n        // of worms that I don't want to deal with in this PR.\n        if (this.closeCount === closeCount) {\n          // Normally we'd have to schedule the callback on the AsyncQueue.\n          // However, the following calls are safe to be called outside the\n          // AsyncQueue since they don't chain asynchronous calls\n          this.startStream(token);\n        }\n      },\n      (error: Error) => {\n        dispatchIfNotClosed(() => {\n          const rpcError = new FirestoreError(\n            Code.UNKNOWN,\n            'Fetching auth token failed: ' + error.message\n          );\n          return this.handleStreamClose(rpcError);\n        });\n      }\n    );\n  }\n\n  private startStream(token: Token | null): void {\n    debugAssert(\n      this.state === PersistentStreamState.Starting,\n      'Trying to start stream in a non-starting state'\n    );\n\n    const dispatchIfNotClosed = this.getCloseGuardedDispatcher(this.closeCount);\n\n    this.stream = this.startRpc(token);\n    this.stream.onOpen(() => {\n      dispatchIfNotClosed(() => {\n        debugAssert(\n          this.state === PersistentStreamState.Starting,\n          'Expected stream to be in state Starting, but was ' + this.state\n        );\n        this.state = PersistentStreamState.Open;\n        return this.listener!.onOpen();\n      });\n    });\n    this.stream.onClose((error?: FirestoreError) => {\n      dispatchIfNotClosed(() => {\n        return this.handleStreamClose(error);\n      });\n    });\n    this.stream.onMessage((msg: ReceiveType) => {\n      dispatchIfNotClosed(() => {\n        return this.onMessage(msg);\n      });\n    });\n  }\n\n  private performBackoff(): void {\n    debugAssert(\n      this.state === PersistentStreamState.Error,\n      'Should only perform backoff when in Error state'\n    );\n    this.state = PersistentStreamState.Backoff;\n\n    this.backoff.backoffAndRun(async () => {\n      debugAssert(\n        this.state === PersistentStreamState.Backoff,\n        'Backoff elapsed but state is now: ' + this.state\n      );\n\n      this.state = PersistentStreamState.Initial;\n      this.start();\n      debugAssert(this.isStarted(), 'PersistentStream should have started');\n    });\n  }\n\n  // Visible for tests\n  handleStreamClose(error?: FirestoreError): Promise<void> {\n    debugAssert(\n      this.isStarted(),\n      \"Can't handle server close on non-started stream\"\n    );\n    logDebug(LOG_TAG, `close with error: ${error}`);\n\n    this.stream = null;\n\n    // In theory the stream could close cleanly, however, in our current model\n    // we never expect this to happen because if we stop a stream ourselves,\n    // this callback will never be called. To prevent cases where we retry\n    // without a backoff accidentally, we set the stream to error in all cases.\n    return this.close(PersistentStreamState.Error, error);\n  }\n\n  /**\n   * Returns a \"dispatcher\" function that dispatches operations onto the\n   * AsyncQueue but only runs them if closeCount remains unchanged. This allows\n   * us to turn auth / stream callbacks into no-ops if the stream is closed /\n   * re-opened, etc.\n   */\n  private getCloseGuardedDispatcher(\n    startCloseCount: number\n  ): (fn: () => Promise<void>) => void {\n    return (fn: () => Promise<void>): void => {\n      this.queue.enqueueAndForget(() => {\n        if (this.closeCount === startCloseCount) {\n          return fn();\n        } else {\n          logDebug(\n            LOG_TAG,\n            'stream callback skipped by getCloseGuardedDispatcher.'\n          );\n          return Promise.resolve();\n        }\n      });\n    };\n  }\n}\n\n/** Listener for the PersistentWatchStream */\nexport interface WatchStreamListener extends PersistentStreamListener {\n  /**\n   * Called on a watchChange. The snapshot parameter will be MIN if the watch\n   * change did not have a snapshot associated with it.\n   */\n  onWatchChange: (\n    watchChange: WatchChange,\n    snapshot: SnapshotVersion\n  ) => Promise<void>;\n}\n\n/**\n * A PersistentStream that implements the Listen RPC.\n *\n * Once the Listen stream has called the onOpen() listener, any number of\n * listen() and unlisten() calls can be made to control what changes will be\n * sent from the server for ListenResponses.\n */\nexport class PersistentListenStream extends PersistentStream<\n  api.ListenRequest,\n  api.ListenResponse,\n  WatchStreamListener\n> {\n  constructor(\n    queue: AsyncQueue,\n    connection: Connection,\n    credentials: CredentialsProvider,\n    private serializer: JsonProtoSerializer,\n    listener: WatchStreamListener\n  ) {\n    super(\n      queue,\n      TimerId.ListenStreamConnectionBackoff,\n      TimerId.ListenStreamIdle,\n      connection,\n      credentials,\n      listener\n    );\n  }\n\n  protected startRpc(\n    token: Token | null\n  ): Stream<api.ListenRequest, api.ListenResponse> {\n    return this.connection.openStream<api.ListenRequest, api.ListenResponse>(\n      'Listen',\n      token\n    );\n  }\n\n  protected onMessage(watchChangeProto: api.ListenResponse): Promise<void> {\n    // A successful response means the stream is healthy\n    this.backoff.reset();\n\n    const watchChange = this.serializer.fromWatchChange(watchChangeProto);\n    const snapshot = this.serializer.versionFromListenResponse(\n      watchChangeProto\n    );\n    return this.listener!.onWatchChange(watchChange, snapshot);\n  }\n\n  /**\n   * Registers interest in the results of the given target. If the target\n   * includes a resumeToken it will be included in the request. Results that\n   * affect the target will be streamed back as WatchChange messages that\n   * reference the targetId.\n   */\n  watch(targetData: TargetData): void {\n    const request: ListenRequest = {};\n    request.database = this.serializer.encodedDatabaseId;\n    request.addTarget = this.serializer.toTarget(targetData);\n\n    const labels = this.serializer.toListenRequestLabels(targetData);\n    if (labels) {\n      request.labels = labels;\n    }\n\n    this.sendRequest(request);\n  }\n\n  /**\n   * Unregisters interest in the results of the target associated with the\n   * given targetId.\n   */\n  unwatch(targetId: TargetId): void {\n    const request: ListenRequest = {};\n    request.database = this.serializer.encodedDatabaseId;\n    request.removeTarget = targetId;\n    this.sendRequest(request);\n  }\n}\n\n/** Listener for the PersistentWriteStream */\nexport interface WriteStreamListener extends PersistentStreamListener {\n  /**\n   * Called by the PersistentWriteStream upon a successful handshake response\n   * from the server, which is the receiver's cue to send any pending writes.\n   */\n  onHandshakeComplete: () => Promise<void>;\n\n  /**\n   * Called by the PersistentWriteStream upon receiving a StreamingWriteResponse\n   * from the server that contains a mutation result.\n   */\n  onMutationResult: (\n    commitVersion: SnapshotVersion,\n    results: MutationResult[]\n  ) => Promise<void>;\n}\n\n/**\n * A Stream that implements the Write RPC.\n *\n * The Write RPC requires the caller to maintain special streamToken\n * state in between calls, to help the server understand which responses the\n * client has processed by the time the next request is made. Every response\n * will contain a streamToken; this value must be passed to the next\n * request.\n *\n * After calling start() on this stream, the next request must be a handshake,\n * containing whatever streamToken is on hand. Once a response to this\n * request is received, all pending mutations may be submitted. When\n * submitting multiple batches of mutations at the same time, it's\n * okay to use the same streamToken for the calls to writeMutations.\n *\n * TODO(b/33271235): Use proto types\n */\nexport class PersistentWriteStream extends PersistentStream<\n  api.WriteRequest,\n  api.WriteResponse,\n  WriteStreamListener\n> {\n  private handshakeComplete_ = false;\n\n  constructor(\n    queue: AsyncQueue,\n    connection: Connection,\n    credentials: CredentialsProvider,\n    private serializer: JsonProtoSerializer,\n    listener: WriteStreamListener\n  ) {\n    super(\n      queue,\n      TimerId.WriteStreamConnectionBackoff,\n      TimerId.WriteStreamIdle,\n      connection,\n      credentials,\n      listener\n    );\n  }\n\n  /**\n   * The last received stream token from the server, used to acknowledge which\n   * responses the client has processed. Stream tokens are opaque checkpoint\n   * markers whose only real value is their inclusion in the next request.\n   *\n   * PersistentWriteStream manages propagating this value from responses to the\n   * next request.\n   */\n  lastStreamToken: ByteString = ByteString.EMPTY_BYTE_STRING;\n\n  /**\n   * Tracks whether or not a handshake has been successfully exchanged and\n   * the stream is ready to accept mutations.\n   */\n  get handshakeComplete(): boolean {\n    return this.handshakeComplete_;\n  }\n\n  // Override of PersistentStream.start\n  start(): void {\n    this.handshakeComplete_ = false;\n    super.start();\n  }\n\n  protected tearDown(): void {\n    if (this.handshakeComplete_) {\n      this.writeMutations([]);\n    }\n  }\n\n  protected startRpc(\n    token: Token | null\n  ): Stream<api.WriteRequest, api.WriteResponse> {\n    return this.connection.openStream<api.WriteRequest, api.WriteResponse>(\n      'Write',\n      token\n    );\n  }\n\n  protected onMessage(responseProto: api.WriteResponse): Promise<void> {\n    // Always capture the last stream token.\n    hardAssert(\n      !!responseProto.streamToken,\n      'Got a write response without a stream token'\n    );\n    this.lastStreamToken = this.serializer.fromBytes(responseProto.streamToken);\n\n    if (!this.handshakeComplete_) {\n      // The first response is always the handshake response\n      hardAssert(\n        !responseProto.writeResults || responseProto.writeResults.length === 0,\n        'Got mutation results for handshake'\n      );\n      this.handshakeComplete_ = true;\n      return this.listener!.onHandshakeComplete();\n    } else {\n      // A successful first write response means the stream is healthy,\n      // Note, that we could consider a successful handshake healthy, however,\n      // the write itself might be causing an error we want to back off from.\n      this.backoff.reset();\n\n      const results = this.serializer.fromWriteResults(\n        responseProto.writeResults,\n        responseProto.commitTime\n      );\n      const commitVersion = this.serializer.fromVersion(\n        responseProto.commitTime!\n      );\n      return this.listener!.onMutationResult(commitVersion, results);\n    }\n  }\n\n  /**\n   * Sends an initial streamToken to the server, performing the handshake\n   * required to make the StreamingWrite RPC work. Subsequent\n   * calls should wait until onHandshakeComplete was called.\n   */\n  writeHandshake(): void {\n    debugAssert(this.isOpen(), 'Writing handshake requires an opened stream');\n    debugAssert(!this.handshakeComplete_, 'Handshake already completed');\n    // TODO(dimond): Support stream resumption. We intentionally do not set the\n    // stream token on the handshake, ignoring any stream token we might have.\n    const request: WriteRequest = {};\n    request.database = this.serializer.encodedDatabaseId;\n    this.sendRequest(request);\n  }\n\n  /** Sends a group of mutations to the Firestore backend to apply. */\n  writeMutations(mutations: Mutation[]): void {\n    debugAssert(this.isOpen(), 'Writing mutations requires an opened stream');\n    debugAssert(\n      this.handshakeComplete_,\n      'Handshake must be complete before writing mutations'\n    );\n    debugAssert(\n      this.lastStreamToken.approximateByteSize() > 0,\n      'Trying to write mutation without a token'\n    );\n\n    const request: WriteRequest = {\n      streamToken: this.serializer.toBytes(this.lastStreamToken),\n      writes: mutations.map(mutation => this.serializer.toMutation(mutation))\n    };\n\n    this.sendRequest(request);\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { CredentialsProvider } from '../api/credentials';\nimport { maybeDocumentMap } from '../model/collections';\nimport { MaybeDocument } from '../model/document';\nimport { DocumentKey } from '../model/document_key';\nimport { Mutation, MutationResult } from '../model/mutation';\nimport * as api from '../protos/firestore_proto_api';\nimport { hardAssert } from '../util/assert';\nimport { AsyncQueue } from '../util/async_queue';\nimport { Code, FirestoreError } from '../util/error';\nimport { Connection } from './connection';\nimport {\n  WatchStreamListener,\n  WriteStreamListener,\n  PersistentListenStream,\n  PersistentWriteStream\n} from './persistent_stream';\n\nimport { JsonProtoSerializer } from './serializer';\n\n// The generated proto interfaces for these class are missing the database\n// field. So we add it here.\n// TODO(b/36015800): Remove this once the api generator is fixed.\ninterface BatchGetDocumentsRequest extends api.BatchGetDocumentsRequest {\n  database?: string;\n}\ninterface CommitRequest extends api.CommitRequest {\n  database?: string;\n}\n\n/**\n * Datastore is a wrapper around the external Google Cloud Datastore grpc API,\n * which provides an interface that is more convenient for the rest of the\n * client SDK architecture to consume.\n */\nexport class Datastore {\n  constructor(\n    private queue: AsyncQueue,\n    private connection: Connection,\n    private credentials: CredentialsProvider,\n    private serializer: JsonProtoSerializer\n  ) {}\n\n  newPersistentWriteStream(\n    listener: WriteStreamListener\n  ): PersistentWriteStream {\n    return new PersistentWriteStream(\n      this.queue,\n      this.connection,\n      this.credentials,\n      this.serializer,\n      listener\n    );\n  }\n\n  newPersistentWatchStream(\n    listener: WatchStreamListener\n  ): PersistentListenStream {\n    return new PersistentListenStream(\n      this.queue,\n      this.connection,\n      this.credentials,\n      this.serializer,\n      listener\n    );\n  }\n\n  commit(mutations: Mutation[]): Promise<MutationResult[]> {\n    const params: CommitRequest = {\n      database: this.serializer.encodedDatabaseId,\n      writes: mutations.map(m => this.serializer.toMutation(m))\n    };\n    return this.invokeRPC<CommitRequest, api.CommitResponse>(\n      'Commit',\n      params\n    ).then(response => {\n      return this.serializer.fromWriteResults(\n        response.writeResults,\n        response.commitTime\n      );\n    });\n  }\n\n  lookup(keys: DocumentKey[]): Promise<MaybeDocument[]> {\n    const params: BatchGetDocumentsRequest = {\n      database: this.serializer.encodedDatabaseId,\n      documents: keys.map(k => this.serializer.toName(k))\n    };\n    return this.invokeStreamingRPC<\n      BatchGetDocumentsRequest,\n      api.BatchGetDocumentsResponse\n    >('BatchGetDocuments', params).then(response => {\n      let docs = maybeDocumentMap();\n      response.forEach(proto => {\n        const doc = this.serializer.fromMaybeDocument(proto);\n        docs = docs.insert(doc.key, doc);\n      });\n      const result: MaybeDocument[] = [];\n      keys.forEach(key => {\n        const doc = docs.get(key);\n        hardAssert(!!doc, 'Missing entity in write response for ' + key);\n        result.push(doc);\n      });\n      return result;\n    });\n  }\n\n  /** Gets an auth token and invokes the provided RPC. */\n  private invokeRPC<Req, Resp>(rpcName: string, request: Req): Promise<Resp> {\n    return this.credentials\n      .getToken()\n      .then(token => {\n        return this.connection.invokeRPC<Req, Resp>(rpcName, request, token);\n      })\n      .catch((error: FirestoreError) => {\n        if (error.code === Code.UNAUTHENTICATED) {\n          this.credentials.invalidateToken();\n        }\n        throw error;\n      });\n  }\n\n  /** Gets an auth token and invokes the provided RPC with streamed results. */\n  private invokeStreamingRPC<Req, Resp>(\n    rpcName: string,\n    request: Req\n  ): Promise<Resp[]> {\n    return this.credentials\n      .getToken()\n      .then(token => {\n        return this.connection.invokeStreamingRPC<Req, Resp>(\n          rpcName,\n          request,\n          token\n        );\n      })\n      .catch((error: FirestoreError) => {\n        if (error.code === Code.UNAUTHENTICATED) {\n          this.credentials.invalidateToken();\n        }\n        throw error;\n      });\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { ParsedSetData, ParsedUpdateData } from '../api/user_data_reader';\nimport { documentVersionMap } from '../model/collections';\nimport { Document, NoDocument, MaybeDocument } from '../model/document';\n\nimport { DocumentKey } from '../model/document_key';\nimport {\n  DeleteMutation,\n  Mutation,\n  Precondition,\n  VerifyMutation\n} from '../model/mutation';\nimport { Datastore } from '../remote/datastore';\nimport { fail, debugAssert } from '../util/assert';\nimport { Code, FirestoreError } from '../util/error';\nimport { SnapshotVersion } from './snapshot_version';\n\n/**\n * Internal transaction object responsible for accumulating the mutations to\n * perform and the base versions for any documents read.\n */\nexport class Transaction {\n  // The version of each document that was read during this transaction.\n  private readVersions = documentVersionMap();\n  private mutations: Mutation[] = [];\n  private committed = false;\n\n  /**\n   * A deferred usage error that occurred previously in this transaction that\n   * will cause the transaction to fail once it actually commits.\n   */\n  private lastWriteError: FirestoreError | null = null;\n\n  /**\n   * Set of documents that have been written in the transaction.\n   *\n   * When there's more than one write to the same key in a transaction, any\n   * writes after the first are handled differently.\n   */\n  private writtenDocs: Set<DocumentKey> = new Set();\n\n  constructor(private datastore: Datastore) {}\n\n  async lookup(keys: DocumentKey[]): Promise<MaybeDocument[]> {\n    this.ensureCommitNotCalled();\n\n    if (this.mutations.length > 0) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        'Firestore transactions require all reads to be executed before all writes.'\n      );\n    }\n    const docs = await this.datastore.lookup(keys);\n    docs.forEach(doc => {\n      if (doc instanceof NoDocument || doc instanceof Document) {\n        this.recordVersion(doc);\n      } else {\n        fail('Document in a transaction was a ' + doc.constructor.name);\n      }\n    });\n    return docs;\n  }\n\n  set(key: DocumentKey, data: ParsedSetData): void {\n    this.write(data.toMutations(key, this.precondition(key)));\n    this.writtenDocs.add(key);\n  }\n\n  update(key: DocumentKey, data: ParsedUpdateData): void {\n    try {\n      this.write(data.toMutations(key, this.preconditionForUpdate(key)));\n    } catch (e) {\n      this.lastWriteError = e;\n    }\n    this.writtenDocs.add(key);\n  }\n\n  delete(key: DocumentKey): void {\n    this.write([new DeleteMutation(key, this.precondition(key))]);\n    this.writtenDocs.add(key);\n  }\n\n  async commit(): Promise<void> {\n    this.ensureCommitNotCalled();\n\n    if (this.lastWriteError) {\n      throw this.lastWriteError;\n    }\n    let unwritten = this.readVersions;\n    // For each mutation, note that the doc was written.\n    this.mutations.forEach(mutation => {\n      unwritten = unwritten.remove(mutation.key);\n    });\n    // For each document that was read but not written to, we want to perform\n    // a `verify` operation.\n    unwritten.forEach((key, _version) => {\n      this.mutations.push(new VerifyMutation(key, this.precondition(key)));\n    });\n    await this.datastore.commit(this.mutations);\n    this.committed = true;\n  }\n\n  private recordVersion(doc: MaybeDocument): void {\n    let docVersion: SnapshotVersion;\n\n    if (doc instanceof Document) {\n      docVersion = doc.version;\n    } else if (doc instanceof NoDocument) {\n      // For deleted docs, we must use baseVersion 0 when we overwrite them.\n      docVersion = SnapshotVersion.forDeletedDoc();\n    } else {\n      throw fail('Document in a transaction was a ' + doc.constructor.name);\n    }\n\n    const existingVersion = this.readVersions.get(doc.key);\n    if (existingVersion !== null) {\n      if (!docVersion.isEqual(existingVersion)) {\n        // This transaction will fail no matter what.\n        throw new FirestoreError(\n          Code.ABORTED,\n          'Document version changed between two reads.'\n        );\n      }\n    } else {\n      this.readVersions = this.readVersions.insert(doc.key, docVersion);\n    }\n  }\n\n  /**\n   * Returns the version of this document when it was read in this transaction,\n   * as a precondition, or no precondition if it was not read.\n   */\n  private precondition(key: DocumentKey): Precondition {\n    const version = this.readVersions.get(key);\n    if (!this.writtenDocs.has(key) && version) {\n      return Precondition.updateTime(version);\n    } else {\n      return Precondition.NONE;\n    }\n  }\n\n  /**\n   * Returns the precondition for a document if the operation is an update.\n   */\n  private preconditionForUpdate(key: DocumentKey): Precondition {\n    const version = this.readVersions.get(key);\n    // The first time a document is written, we want to take into account the\n    // read time and existence\n    if (!this.writtenDocs.has(key) && version) {\n      if (version.isEqual(SnapshotVersion.forDeletedDoc())) {\n        // The document doesn't exist, so fail the transaction.\n\n        // This has to be validated locally because you can't send a\n        // precondition that a document does not exist without changing the\n        // semantics of the backend write to be an insert. This is the reverse\n        // of what we want, since we want to assert that the document doesn't\n        // exist but then send the update and have it fail. Since we can't\n        // express that to the backend, we have to validate locally.\n\n        // Note: this can change once we can send separate verify writes in the\n        // transaction.\n        throw new FirestoreError(\n          Code.INVALID_ARGUMENT,\n          \"Can't update a document that doesn't exist.\"\n        );\n      }\n      // Document exists, base precondition on document update time.\n      return Precondition.updateTime(version);\n    } else {\n      // Document was not read, so we just use the preconditions for a blind\n      // update.\n      return Precondition.exists(true);\n    }\n  }\n\n  private write(mutations: Mutation[]): void {\n    this.ensureCommitNotCalled();\n    this.mutations = this.mutations.concat(mutations);\n  }\n\n  private ensureCommitNotCalled(): void {\n    debugAssert(\n      !this.committed,\n      'A transaction object cannot be used after its update callback has been invoked.'\n    );\n  }\n}\n","/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { OnlineState } from '../core/types';\nimport { debugAssert } from '../util/assert';\nimport { AsyncQueue, TimerId } from '../util/async_queue';\nimport { FirestoreError } from '../util/error';\nimport { logError, logDebug } from '../util/log';\nimport { CancelablePromise } from '../util/promise';\n\nconst LOG_TAG = 'OnlineStateTracker';\n\n// To deal with transient failures, we allow multiple stream attempts before\n// giving up and transitioning from OnlineState.Unknown to Offline.\n// TODO(mikelehen): This used to be set to 2 as a mitigation for b/66228394.\n// @jdimond thinks that bug is sufficiently fixed so that we can set this back\n// to 1. If that works okay, we could potentially remove this logic entirely.\nconst MAX_WATCH_STREAM_FAILURES = 1;\n\n// To deal with stream attempts that don't succeed or fail in a timely manner,\n// we have a timeout for OnlineState to reach Online or Offline.\n// If the timeout is reached, we transition to Offline rather than waiting\n// indefinitely.\nconst ONLINE_STATE_TIMEOUT_MS = 10 * 1000;\n\n/**\n * A component used by the RemoteStore to track the OnlineState (that is,\n * whether or not the client as a whole should be considered to be online or\n * offline), implementing the appropriate heuristics.\n *\n * In particular, when the client is trying to connect to the backend, we\n * allow up to MAX_WATCH_STREAM_FAILURES within ONLINE_STATE_TIMEOUT_MS for\n * a connection to succeed. If we have too many failures or the timeout elapses,\n * then we set the OnlineState to Offline, and the client will behave as if\n * it is offline (get()s will return cached data, etc.).\n */\nexport class OnlineStateTracker {\n  /** The current OnlineState. */\n  private state = OnlineState.Unknown;\n\n  /**\n   * A count of consecutive failures to open the stream. If it reaches the\n   * maximum defined by MAX_WATCH_STREAM_FAILURES, we'll set the OnlineState to\n   * Offline.\n   */\n  private watchStreamFailures = 0;\n\n  /**\n   * A timer that elapses after ONLINE_STATE_TIMEOUT_MS, at which point we\n   * transition from OnlineState.Unknown to OnlineState.Offline without waiting\n   * for the stream to actually fail (MAX_WATCH_STREAM_FAILURES times).\n   */\n  private onlineStateTimer: CancelablePromise<void> | null = null;\n\n  /**\n   * Whether the client should log a warning message if it fails to connect to\n   * the backend (initially true, cleared after a successful stream, or if we've\n   * logged the message already).\n   */\n  private shouldWarnClientIsOffline = true;\n\n  constructor(\n    private asyncQueue: AsyncQueue,\n    private onlineStateHandler: (onlineState: OnlineState) => void\n  ) {}\n\n  /**\n   * Called by RemoteStore when a watch stream is started (including on each\n   * backoff attempt).\n   *\n   * If this is the first attempt, it sets the OnlineState to Unknown and starts\n   * the onlineStateTimer.\n   */\n  handleWatchStreamStart(): void {\n    if (this.watchStreamFailures === 0) {\n      this.setAndBroadcast(OnlineState.Unknown);\n\n      debugAssert(\n        this.onlineStateTimer === null,\n        `onlineStateTimer shouldn't be started yet`\n      );\n      this.onlineStateTimer = this.asyncQueue.enqueueAfterDelay(\n        TimerId.OnlineStateTimeout,\n        ONLINE_STATE_TIMEOUT_MS,\n        () => {\n          this.onlineStateTimer = null;\n          debugAssert(\n            this.state === OnlineState.Unknown,\n            'Timer should be canceled if we transitioned to a different state.'\n          );\n          this.logClientOfflineWarningIfNecessary(\n            `Backend didn't respond within ${ONLINE_STATE_TIMEOUT_MS / 1000} ` +\n              `seconds.`\n          );\n          this.setAndBroadcast(OnlineState.Offline);\n\n          // NOTE: handleWatchStreamFailure() will continue to increment\n          // watchStreamFailures even though we are already marked Offline,\n          // but this is non-harmful.\n\n          return Promise.resolve();\n        }\n      );\n    }\n  }\n\n  /**\n   * Updates our OnlineState as appropriate after the watch stream reports a\n   * failure. The first failure moves us to the 'Unknown' state. We then may\n   * allow multiple failures (based on MAX_WATCH_STREAM_FAILURES) before we\n   * actually transition to the 'Offline' state.\n   */\n  handleWatchStreamFailure(error: FirestoreError): void {\n    if (this.state === OnlineState.Online) {\n      this.setAndBroadcast(OnlineState.Unknown);\n\n      // To get to OnlineState.Online, set() must have been called which would\n      // have reset our heuristics.\n      debugAssert(\n        this.watchStreamFailures === 0,\n        'watchStreamFailures must be 0'\n      );\n      debugAssert(\n        this.onlineStateTimer === null,\n        'onlineStateTimer must be null'\n      );\n    } else {\n      this.watchStreamFailures++;\n      if (this.watchStreamFailures >= MAX_WATCH_STREAM_FAILURES) {\n        this.clearOnlineStateTimer();\n\n        this.logClientOfflineWarningIfNecessary(\n          `Connection failed ${MAX_WATCH_STREAM_FAILURES} ` +\n            `times. Most recent error: ${error.toString()}`\n        );\n\n        this.setAndBroadcast(OnlineState.Offline);\n      }\n    }\n  }\n\n  /**\n   * Explicitly sets the OnlineState to the specified state.\n   *\n   * Note that this resets our timers / failure counters, etc. used by our\n   * Offline heuristics, so must not be used in place of\n   * handleWatchStreamStart() and handleWatchStreamFailure().\n   */\n  set(newState: OnlineState): void {\n    this.clearOnlineStateTimer();\n    this.watchStreamFailures = 0;\n\n    if (newState === OnlineState.Online) {\n      // We've connected to watch at least once. Don't warn the developer\n      // about being offline going forward.\n      this.shouldWarnClientIsOffline = false;\n    }\n\n    this.setAndBroadcast(newState);\n  }\n\n  private setAndBroadcast(newState: OnlineState): void {\n    if (newState !== this.state) {\n      this.state = newState;\n      this.onlineStateHandler(newState);\n    }\n  }\n\n  private logClientOfflineWarningIfNecessary(details: string): void {\n    const message =\n      `Could not reach Cloud Firestore backend. ${details}\\n` +\n      `This typically indicates that your device does not have a healthy ` +\n      `Internet connection at the moment. The client will operate in offline ` +\n      `mode until it is able to successfully connect to the backend.`;\n    if (this.shouldWarnClientIsOffline) {\n      logError(message);\n      this.shouldWarnClientIsOffline = false;\n    } else {\n      logDebug(LOG_TAG, message);\n    }\n  }\n\n  private clearOnlineStateTimer(): void {\n    if (this.onlineStateTimer !== null) {\n      this.onlineStateTimer.cancel();\n      this.onlineStateTimer = null;\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { SnapshotVersion } from '../core/snapshot_version';\nimport { Transaction } from '../core/transaction';\nimport { OnlineState, TargetId } from '../core/types';\nimport { ignoreIfPrimaryLeaseLoss, LocalStore } from '../local/local_store';\nimport { TargetData, TargetPurpose } from '../local/target_data';\nimport { MutationResult } from '../model/mutation';\nimport {\n  BATCHID_UNKNOWN,\n  MutationBatch,\n  MutationBatchResult\n} from '../model/mutation_batch';\nimport { debugAssert } from '../util/assert';\nimport { FirestoreError } from '../util/error';\nimport { logDebug } from '../util/log';\nimport { DocumentKeySet } from '../model/collections';\nimport { AsyncQueue } from '../util/async_queue';\nimport { ConnectivityMonitor, NetworkStatus } from './connectivity_monitor';\nimport { Datastore } from './datastore';\nimport { OnlineStateTracker } from './online_state_tracker';\nimport {\n  PersistentListenStream,\n  PersistentWriteStream\n} from './persistent_stream';\nimport { RemoteSyncer } from './remote_syncer';\nimport { isPermanentError, isPermanentWriteError } from './rpc_error';\nimport {\n  DocumentWatchChange,\n  ExistenceFilterChange,\n  TargetMetadataProvider,\n  WatchChange,\n  WatchChangeAggregator,\n  WatchTargetChange,\n  WatchTargetChangeState\n} from './watch_change';\nimport { ByteString } from '../util/byte_string';\n\nconst LOG_TAG = 'RemoteStore';\n\n// TODO(b/35853402): Negotiate this with the stream.\nconst MAX_PENDING_WRITES = 10;\n\n/**\n * RemoteStore - An interface to remotely stored data, basically providing a\n * wrapper around the Datastore that is more reliable for the rest of the\n * system.\n *\n * RemoteStore is responsible for maintaining the connection to the server.\n * - maintaining a list of active listens.\n * - reconnecting when the connection is dropped.\n * - resuming all the active listens on reconnect.\n *\n * RemoteStore handles all incoming events from the Datastore.\n * - listening to the watch stream and repackaging the events as RemoteEvents\n * - notifying SyncEngine of any changes to the active listens.\n *\n * RemoteStore takes writes from other components and handles them reliably.\n * - pulling pending mutations from LocalStore and sending them to Datastore.\n * - retrying mutations that failed because of network problems.\n * - acking mutations to the SyncEngine once they are accepted or rejected.\n */\nexport class RemoteStore implements TargetMetadataProvider {\n  /**\n   * A list of up to MAX_PENDING_WRITES writes that we have fetched from the\n   * LocalStore via fillWritePipeline() and have or will send to the write\n   * stream.\n   *\n   * Whenever writePipeline.length > 0 the RemoteStore will attempt to start or\n   * restart the write stream. When the stream is established the writes in the\n   * pipeline will be sent in order.\n   *\n   * Writes remain in writePipeline until they are acknowledged by the backend\n   * and thus will automatically be re-sent if the stream is interrupted /\n   * restarted before they're acknowledged.\n   *\n   * Write responses from the backend are linked to their originating request\n   * purely based on order, and so we can just shift() writes from the front of\n   * the writePipeline as we receive responses.\n   */\n  private writePipeline: MutationBatch[] = [];\n\n  /**\n   * A mapping of watched targets that the client cares about tracking and the\n   * user has explicitly called a 'listen' for this target.\n   *\n   * These targets may or may not have been sent to or acknowledged by the\n   * server. On re-establishing the listen stream, these targets should be sent\n   * to the server. The targets removed with unlistens are removed eagerly\n   * without waiting for confirmation from the listen stream.\n   */\n  private listenTargets = new Map<TargetId, TargetData>();\n\n  private connectivityMonitor: ConnectivityMonitor;\n  private watchStream: PersistentListenStream;\n  private writeStream: PersistentWriteStream;\n  private watchChangeAggregator: WatchChangeAggregator | null = null;\n\n  /**\n   * Set to true by enableNetwork() and false by disableNetwork() and indicates\n   * the user-preferred network state.\n   */\n  private networkEnabled = false;\n\n  private isPrimary = false;\n\n  private onlineStateTracker: OnlineStateTracker;\n\n  constructor(\n    /**\n     * The local store, used to fill the write pipeline with outbound mutations.\n     */\n    private localStore: LocalStore,\n    /** The client-side proxy for interacting with the backend. */\n    private datastore: Datastore,\n    asyncQueue: AsyncQueue,\n    onlineStateHandler: (onlineState: OnlineState) => void,\n    connectivityMonitor: ConnectivityMonitor\n  ) {\n    this.connectivityMonitor = connectivityMonitor;\n    this.connectivityMonitor.addCallback((status: NetworkStatus) => {\n      asyncQueue.enqueueAndForget(async () => {\n        if (this.canUseNetwork()) {\n          logDebug(\n            LOG_TAG,\n            'Restarting streams for network reachability change.'\n          );\n          await this.restartNetwork();\n        }\n      });\n    });\n\n    this.onlineStateTracker = new OnlineStateTracker(\n      asyncQueue,\n      onlineStateHandler\n    );\n\n    // Create streams (but note they're not started yet).\n    this.watchStream = this.datastore.newPersistentWatchStream({\n      onOpen: this.onWatchStreamOpen.bind(this),\n      onClose: this.onWatchStreamClose.bind(this),\n      onWatchChange: this.onWatchStreamChange.bind(this)\n    });\n\n    this.writeStream = this.datastore.newPersistentWriteStream({\n      onOpen: this.onWriteStreamOpen.bind(this),\n      onClose: this.onWriteStreamClose.bind(this),\n      onHandshakeComplete: this.onWriteHandshakeComplete.bind(this),\n      onMutationResult: this.onMutationResult.bind(this)\n    });\n  }\n\n  /**\n   * SyncEngine to notify of watch and write events. This must be set\n   * immediately after construction.\n   */\n  syncEngine!: RemoteSyncer;\n\n  /**\n   * Starts up the remote store, creating streams, restoring state from\n   * LocalStore, etc.\n   */\n  start(): Promise<void> {\n    return this.enableNetwork();\n  }\n\n  /** Re-enables the network. Idempotent. */\n  async enableNetwork(): Promise<void> {\n    this.networkEnabled = true;\n\n    if (this.canUseNetwork()) {\n      this.writeStream.lastStreamToken = await this.localStore.getLastStreamToken();\n\n      if (this.shouldStartWatchStream()) {\n        this.startWatchStream();\n      } else {\n        this.onlineStateTracker.set(OnlineState.Unknown);\n      }\n\n      // This will start the write stream if necessary.\n      await this.fillWritePipeline();\n    }\n  }\n\n  /**\n   * Temporarily disables the network. The network can be re-enabled using\n   * enableNetwork().\n   */\n  async disableNetwork(): Promise<void> {\n    this.networkEnabled = false;\n    await this.disableNetworkInternal();\n\n    // Set the OnlineState to Offline so get()s return from cache, etc.\n    this.onlineStateTracker.set(OnlineState.Offline);\n  }\n\n  private async disableNetworkInternal(): Promise<void> {\n    await this.writeStream.stop();\n    await this.watchStream.stop();\n\n    if (this.writePipeline.length > 0) {\n      logDebug(\n        LOG_TAG,\n        `Stopping write stream with ${this.writePipeline.length} pending writes`\n      );\n      this.writePipeline = [];\n    }\n\n    this.cleanUpWatchStreamState();\n  }\n\n  async shutdown(): Promise<void> {\n    logDebug(LOG_TAG, 'RemoteStore shutting down.');\n    this.networkEnabled = false;\n    await this.disableNetworkInternal();\n    this.connectivityMonitor.shutdown();\n\n    // Set the OnlineState to Unknown (rather than Offline) to avoid potentially\n    // triggering spurious listener events with cached data, etc.\n    this.onlineStateTracker.set(OnlineState.Unknown);\n  }\n\n  /**\n   * Starts new listen for the given target. Uses resume token if provided. It\n   * is a no-op if the target of given `TargetData` is already being listened to.\n   */\n  listen(targetData: TargetData): void {\n    if (this.listenTargets.has(targetData.targetId)) {\n      return;\n    }\n\n    // Mark this as something the client is currently listening for.\n    this.listenTargets.set(targetData.targetId, targetData);\n\n    if (this.shouldStartWatchStream()) {\n      // The listen will be sent in onWatchStreamOpen\n      this.startWatchStream();\n    } else if (this.watchStream.isOpen()) {\n      this.sendWatchRequest(targetData);\n    }\n  }\n\n  /**\n   * Removes the listen from server. It is a no-op if the given target id is\n   * not being listened to.\n   */\n  unlisten(targetId: TargetId): void {\n    debugAssert(\n      this.listenTargets.has(targetId),\n      `unlisten called on target no currently watched: ${targetId}`\n    );\n\n    this.listenTargets.delete(targetId);\n    if (this.watchStream.isOpen()) {\n      this.sendUnwatchRequest(targetId);\n    }\n\n    if (this.listenTargets.size === 0) {\n      if (this.watchStream.isOpen()) {\n        this.watchStream.markIdle();\n      } else if (this.canUseNetwork()) {\n        // Revert to OnlineState.Unknown if the watch stream is not open and we\n        // have no listeners, since without any listens to send we cannot\n        // confirm if the stream is healthy and upgrade to OnlineState.Online.\n        this.onlineStateTracker.set(OnlineState.Unknown);\n      }\n    }\n  }\n\n  /** {@link TargetMetadataProvider.getTargetDataForTarget} */\n  getTargetDataForTarget(targetId: TargetId): TargetData | null {\n    return this.listenTargets.get(targetId) || null;\n  }\n\n  /** {@link TargetMetadataProvider.getRemoteKeysForTarget} */\n  getRemoteKeysForTarget(targetId: TargetId): DocumentKeySet {\n    return this.syncEngine.getRemoteKeysForTarget(targetId);\n  }\n\n  /**\n   * We need to increment the the expected number of pending responses we're due\n   * from watch so we wait for the ack to process any messages from this target.\n   */\n  private sendWatchRequest(targetData: TargetData): void {\n    this.watchChangeAggregator!.recordPendingTargetRequest(targetData.targetId);\n    this.watchStream.watch(targetData);\n  }\n\n  /**\n   * We need to increment the expected number of pending responses we're due\n   * from watch so we wait for the removal on the server before we process any\n   * messages from this target.\n   */\n  private sendUnwatchRequest(targetId: TargetId): void {\n    this.watchChangeAggregator!.recordPendingTargetRequest(targetId);\n    this.watchStream.unwatch(targetId);\n  }\n\n  private startWatchStream(): void {\n    debugAssert(\n      this.shouldStartWatchStream(),\n      'startWatchStream() called when shouldStartWatchStream() is false.'\n    );\n\n    this.watchChangeAggregator = new WatchChangeAggregator(this);\n    this.watchStream.start();\n    this.onlineStateTracker.handleWatchStreamStart();\n  }\n\n  /**\n   * Returns whether the watch stream should be started because it's necessary\n   * and has not yet been started.\n   */\n  private shouldStartWatchStream(): boolean {\n    return (\n      this.canUseNetwork() &&\n      !this.watchStream.isStarted() &&\n      this.listenTargets.size > 0\n    );\n  }\n\n  canUseNetwork(): boolean {\n    return this.isPrimary && this.networkEnabled;\n  }\n\n  private cleanUpWatchStreamState(): void {\n    this.watchChangeAggregator = null;\n  }\n\n  private async onWatchStreamOpen(): Promise<void> {\n    this.listenTargets.forEach((targetData, targetId) => {\n      this.sendWatchRequest(targetData);\n    });\n  }\n\n  private async onWatchStreamClose(error?: FirestoreError): Promise<void> {\n    if (error === undefined) {\n      // Graceful stop (due to stop() or idle timeout). Make sure that's\n      // desirable.\n      debugAssert(\n        !this.shouldStartWatchStream(),\n        'Watch stream was stopped gracefully while still needed.'\n      );\n    }\n\n    this.cleanUpWatchStreamState();\n\n    // If we still need the watch stream, retry the connection.\n    if (this.shouldStartWatchStream()) {\n      this.onlineStateTracker.handleWatchStreamFailure(error!);\n\n      this.startWatchStream();\n    } else {\n      // No need to restart watch stream because there are no active targets.\n      // The online state is set to unknown because there is no active attempt\n      // at establishing a connection\n      this.onlineStateTracker.set(OnlineState.Unknown);\n    }\n  }\n\n  private async onWatchStreamChange(\n    watchChange: WatchChange,\n    snapshotVersion: SnapshotVersion\n  ): Promise<void> {\n    // Mark the client as online since we got a message from the server\n    this.onlineStateTracker.set(OnlineState.Online);\n\n    if (\n      watchChange instanceof WatchTargetChange &&\n      watchChange.state === WatchTargetChangeState.Removed &&\n      watchChange.cause\n    ) {\n      // There was an error on a target, don't wait for a consistent snapshot\n      // to raise events\n      return this.handleTargetError(watchChange);\n    }\n\n    if (watchChange instanceof DocumentWatchChange) {\n      this.watchChangeAggregator!.handleDocumentChange(watchChange);\n    } else if (watchChange instanceof ExistenceFilterChange) {\n      this.watchChangeAggregator!.handleExistenceFilter(watchChange);\n    } else {\n      debugAssert(\n        watchChange instanceof WatchTargetChange,\n        'Expected watchChange to be an instance of WatchTargetChange'\n      );\n      this.watchChangeAggregator!.handleTargetChange(watchChange);\n    }\n\n    if (!snapshotVersion.isEqual(SnapshotVersion.MIN)) {\n      const lastRemoteSnapshotVersion = await this.localStore.getLastRemoteSnapshotVersion();\n      if (snapshotVersion.compareTo(lastRemoteSnapshotVersion) >= 0) {\n        // We have received a target change with a global snapshot if the snapshot\n        // version is not equal to SnapshotVersion.MIN.\n        await this.raiseWatchSnapshot(snapshotVersion);\n      }\n    }\n  }\n\n  /**\n   * Takes a batch of changes from the Datastore, repackages them as a\n   * RemoteEvent, and passes that on to the listener, which is typically the\n   * SyncEngine.\n   */\n  private raiseWatchSnapshot(snapshotVersion: SnapshotVersion): Promise<void> {\n    debugAssert(\n      !snapshotVersion.isEqual(SnapshotVersion.MIN),\n      \"Can't raise event for unknown SnapshotVersion\"\n    );\n    const remoteEvent = this.watchChangeAggregator!.createRemoteEvent(\n      snapshotVersion\n    );\n\n    // Update in-memory resume tokens. LocalStore will update the\n    // persistent view of these when applying the completed RemoteEvent.\n    remoteEvent.targetChanges.forEach((change, targetId) => {\n      if (change.resumeToken.approximateByteSize() > 0) {\n        const targetData = this.listenTargets.get(targetId);\n        // A watched target might have been removed already.\n        if (targetData) {\n          this.listenTargets.set(\n            targetId,\n            targetData.withResumeToken(change.resumeToken, snapshotVersion)\n          );\n        }\n      }\n    });\n\n    // Re-establish listens for the targets that have been invalidated by\n    // existence filter mismatches.\n    remoteEvent.targetMismatches.forEach(targetId => {\n      const targetData = this.listenTargets.get(targetId);\n      if (!targetData) {\n        // A watched target might have been removed already.\n        return;\n      }\n\n      // Clear the resume token for the target, since we're in a known mismatch\n      // state.\n      this.listenTargets.set(\n        targetId,\n        targetData.withResumeToken(\n          ByteString.EMPTY_BYTE_STRING,\n          targetData.snapshotVersion\n        )\n      );\n\n      // Cause a hard reset by unwatching and rewatching immediately, but\n      // deliberately don't send a resume token so that we get a full update.\n      this.sendUnwatchRequest(targetId);\n\n      // Mark the target we send as being on behalf of an existence filter\n      // mismatch, but don't actually retain that in listenTargets. This ensures\n      // that we flag the first re-listen this way without impacting future\n      // listens of this target (that might happen e.g. on reconnect).\n      const requestTargetData = new TargetData(\n        targetData.target,\n        targetId,\n        TargetPurpose.ExistenceFilterMismatch,\n        targetData.sequenceNumber\n      );\n      this.sendWatchRequest(requestTargetData);\n    });\n\n    // Finally raise remote event\n    return this.syncEngine.applyRemoteEvent(remoteEvent);\n  }\n\n  /** Handles an error on a target */\n  private handleTargetError(watchChange: WatchTargetChange): Promise<void> {\n    debugAssert(!!watchChange.cause, 'Handling target error without a cause');\n    const error = watchChange.cause!;\n    let promiseChain = Promise.resolve();\n    watchChange.targetIds.forEach(targetId => {\n      promiseChain = promiseChain.then(async () => {\n        // A watched target might have been removed already.\n        if (this.listenTargets.has(targetId)) {\n          this.listenTargets.delete(targetId);\n          this.watchChangeAggregator!.removeTarget(targetId);\n          return this.syncEngine.rejectListen(targetId, error);\n        }\n      });\n    });\n    return promiseChain;\n  }\n\n  /**\n   * Attempts to fill our write pipeline with writes from the LocalStore.\n   *\n   * Called internally to bootstrap or refill the write pipeline and by\n   * SyncEngine whenever there are new mutations to process.\n   *\n   * Starts the write stream if necessary.\n   */\n  async fillWritePipeline(): Promise<void> {\n    if (this.canAddToWritePipeline()) {\n      const lastBatchIdRetrieved =\n        this.writePipeline.length > 0\n          ? this.writePipeline[this.writePipeline.length - 1].batchId\n          : BATCHID_UNKNOWN;\n      const batch = await this.localStore.nextMutationBatch(\n        lastBatchIdRetrieved\n      );\n\n      if (batch === null) {\n        if (this.writePipeline.length === 0) {\n          this.writeStream.markIdle();\n        }\n      } else {\n        this.addToWritePipeline(batch);\n        await this.fillWritePipeline();\n      }\n    }\n\n    if (this.shouldStartWriteStream()) {\n      this.startWriteStream();\n    }\n  }\n\n  /**\n   * Returns true if we can add to the write pipeline (i.e. the network is\n   * enabled and the write pipeline is not full).\n   */\n  private canAddToWritePipeline(): boolean {\n    return (\n      this.canUseNetwork() && this.writePipeline.length < MAX_PENDING_WRITES\n    );\n  }\n\n  // For testing\n  outstandingWrites(): number {\n    return this.writePipeline.length;\n  }\n\n  /**\n   * Queues additional writes to be sent to the write stream, sending them\n   * immediately if the write stream is established.\n   */\n  private addToWritePipeline(batch: MutationBatch): void {\n    debugAssert(\n      this.canAddToWritePipeline(),\n      'addToWritePipeline called when pipeline is full'\n    );\n    this.writePipeline.push(batch);\n\n    if (this.writeStream.isOpen() && this.writeStream.handshakeComplete) {\n      this.writeStream.writeMutations(batch.mutations);\n    }\n  }\n\n  private shouldStartWriteStream(): boolean {\n    return (\n      this.canUseNetwork() &&\n      !this.writeStream.isStarted() &&\n      this.writePipeline.length > 0\n    );\n  }\n\n  private startWriteStream(): void {\n    debugAssert(\n      this.shouldStartWriteStream(),\n      'startWriteStream() called when shouldStartWriteStream() is false.'\n    );\n    this.writeStream.start();\n  }\n\n  private async onWriteStreamOpen(): Promise<void> {\n    this.writeStream.writeHandshake();\n  }\n\n  private onWriteHandshakeComplete(): Promise<void> {\n    // Record the stream token.\n    return this.localStore\n      .setLastStreamToken(this.writeStream.lastStreamToken)\n      .then(() => {\n        // Send the write pipeline now that the stream is established.\n        for (const batch of this.writePipeline) {\n          this.writeStream.writeMutations(batch.mutations);\n        }\n      })\n      .catch(ignoreIfPrimaryLeaseLoss);\n  }\n\n  private onMutationResult(\n    commitVersion: SnapshotVersion,\n    results: MutationResult[]\n  ): Promise<void> {\n    // This is a response to a write containing mutations and should be\n    // correlated to the first write in our write pipeline.\n    debugAssert(\n      this.writePipeline.length > 0,\n      'Got result for empty write pipeline'\n    );\n    const batch = this.writePipeline.shift()!;\n    const success = MutationBatchResult.from(\n      batch,\n      commitVersion,\n      results,\n      this.writeStream.lastStreamToken\n    );\n    return this.syncEngine.applySuccessfulWrite(success).then(() => {\n      // It's possible that with the completion of this mutation another\n      // slot has freed up.\n      return this.fillWritePipeline();\n    });\n  }\n\n  private async onWriteStreamClose(error?: FirestoreError): Promise<void> {\n    if (error === undefined) {\n      // Graceful stop (due to stop() or idle timeout). Make sure that's\n      // desirable.\n      debugAssert(\n        !this.shouldStartWriteStream(),\n        'Write stream was stopped gracefully while still needed.'\n      );\n    }\n\n    // If the write stream closed due to an error, invoke the error callbacks if\n    // there are pending writes.\n    if (error && this.writePipeline.length > 0) {\n      // A promise that is resolved after we processed the error\n      let errorHandling: Promise<void>;\n      if (this.writeStream.handshakeComplete) {\n        // This error affects the actual write.\n        errorHandling = this.handleWriteError(error!);\n      } else {\n        // If there was an error before the handshake has finished, it's\n        // possible that the server is unable to process the stream token\n        // we're sending. (Perhaps it's too old?)\n        errorHandling = this.handleHandshakeError(error!);\n      }\n\n      return errorHandling.then(() => {\n        // The write stream might have been started by refilling the write\n        // pipeline for failed writes\n        if (this.shouldStartWriteStream()) {\n          this.startWriteStream();\n        }\n      });\n    }\n    // No pending writes, nothing to do\n  }\n\n  private async handleHandshakeError(error: FirestoreError): Promise<void> {\n    // Reset the token if it's a permanent error, signaling the write stream is\n    // no longer valid. Note that the handshake does not count as a write: see\n    // comments on isPermanentWriteError for details.\n    if (isPermanentError(error.code)) {\n      logDebug(\n        LOG_TAG,\n        'RemoteStore error before completed handshake; resetting stream token: ',\n        this.writeStream.lastStreamToken\n      );\n      this.writeStream.lastStreamToken = ByteString.EMPTY_BYTE_STRING;\n\n      return this.localStore\n        .setLastStreamToken(ByteString.EMPTY_BYTE_STRING)\n        .catch(ignoreIfPrimaryLeaseLoss);\n    } else {\n      // Some other error, don't reset stream token. Our stream logic will\n      // just retry with exponential backoff.\n    }\n  }\n\n  private async handleWriteError(error: FirestoreError): Promise<void> {\n    // Only handle permanent errors here. If it's transient, just let the retry\n    // logic kick in.\n    if (isPermanentWriteError(error.code)) {\n      // This was a permanent error, the request itself was the problem\n      // so it's not going to succeed if we resend it.\n      const batch = this.writePipeline.shift()!;\n\n      // In this case it's also unlikely that the server itself is melting\n      // down -- this was just a bad request so inhibit backoff on the next\n      // restart.\n      this.writeStream.inhibitBackoff();\n\n      return this.syncEngine\n        .rejectFailedWrite(batch.batchId, error)\n        .then(() => {\n          // It's possible that with the completion of this mutation\n          // another slot has freed up.\n          return this.fillWritePipeline();\n        });\n    } else {\n      // Transient error, just let the retry logic kick in.\n    }\n  }\n\n  createTransaction(): Transaction {\n    return new Transaction(this.datastore);\n  }\n\n  private async restartNetwork(): Promise<void> {\n    this.networkEnabled = false;\n    await this.disableNetworkInternal();\n    this.onlineStateTracker.set(OnlineState.Unknown);\n    await this.enableNetwork();\n  }\n\n  async handleCredentialChange(): Promise<void> {\n    if (this.canUseNetwork()) {\n      // Tear down and re-create our network streams. This will ensure we get a fresh auth token\n      // for the new user and re-fill the write pipeline with new mutations from the LocalStore\n      // (since mutations are per-user).\n      logDebug(LOG_TAG, 'RemoteStore restarting streams for new credential');\n      await this.restartNetwork();\n    }\n  }\n\n  /**\n   * Toggles the network state when the client gains or loses its primary lease.\n   */\n  async applyPrimaryState(isPrimary: boolean): Promise<void> {\n    this.isPrimary = isPrimary;\n\n    if (isPrimary && this.networkEnabled) {\n      await this.enableNetwork();\n    } else if (!isPrimary) {\n      await this.disableNetworkInternal();\n      this.onlineStateTracker.set(OnlineState.Unknown);\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { BatchId, MutationBatchState, TargetId } from '../core/types';\nimport { QueryTargetState } from './shared_client_state_syncer';\nimport { debugAssert } from '../util/assert';\nimport { ClientId } from './shared_client_state';\nimport { User } from '../auth/user';\n\n// The format of the LocalStorage key that stores the client state is:\n//     firestore_clients_<persistence_prefix>_<instance_key>\nexport const CLIENT_STATE_KEY_PREFIX = 'firestore_clients';\n\n/** Assembles the key for a client state in WebStorage */\nexport function createWebStorageClientStateKey(\n  persistenceKey: string,\n  clientId: ClientId\n): string {\n  debugAssert(\n    clientId.indexOf('_') === -1,\n    `Client key cannot contain '_', but was '${clientId}'`\n  );\n\n  return `${CLIENT_STATE_KEY_PREFIX}_${persistenceKey}_${clientId}`;\n}\n\n/**\n * The JSON representation of a clients's metadata as used during WebStorage\n * serialization. The ClientId is omitted here as it is encoded as part of the\n * key.\n */\nexport interface ClientStateSchema {\n  activeTargetIds: number[];\n  updateTimeMs: number;\n}\n\n// The format of the WebStorage key that stores the mutation state is:\n//     firestore_mutations_<persistence_prefix>_<batch_id>\n//     (for unauthenticated users)\n// or: firestore_mutations_<persistence_prefix>_<batch_id>_<user_uid>\n//\n// 'user_uid' is last to avoid needing to escape '_' characters that it might\n// contain.\nexport const MUTATION_BATCH_KEY_PREFIX = 'firestore_mutations';\n\n/** Assembles the key for a mutation batch in WebStorage */\nexport function createWebStorageMutationBatchKey(\n  persistenceKey: string,\n  user: User,\n  batchId: BatchId\n): string {\n  let mutationKey = `${MUTATION_BATCH_KEY_PREFIX}_${persistenceKey}_${batchId}`;\n\n  if (user.isAuthenticated()) {\n    mutationKey += `_${user.uid}`;\n  }\n\n  return mutationKey;\n}\n\n/**\n * The JSON representation of a mutation batch's metadata as used during\n * WebStorage serialization. The UserId and BatchId is omitted as it is\n * encoded as part of the key.\n */\nexport interface MutationMetadataSchema {\n  state: MutationBatchState;\n  error?: { code: string; message: string }; // Only set when state === 'rejected'\n  updateTimeMs: number;\n}\n\n// The format of the WebStorage key that stores a query target's metadata is:\n//     firestore_targets_<persistence_prefix>_<target_id>\nexport const QUERY_TARGET_KEY_PREFIX = 'firestore_targets';\n\n/** Assembles the key for a query state in WebStorage */\nexport function createWebStorageQueryTargetMetadataKey(\n  persistenceKey: string,\n  targetId: TargetId\n): string {\n  return `${QUERY_TARGET_KEY_PREFIX}_${persistenceKey}_${targetId}`;\n}\n\n/**\n * The JSON representation of a query target's state as used during WebStorage\n * serialization. The TargetId is omitted as it is encoded as part of the key.\n */\nexport interface QueryTargetStateSchema {\n  state: QueryTargetState;\n  error?: { code: string; message: string }; // Only set when state === 'rejected'\n  updateTimeMs: number;\n}\n\n// The WebStorage prefix that stores the primary tab's online state. The\n// format of the key is:\n//     firestore_online_state_<persistence_prefix>\nexport const ONLINE_STATE_KEY_PREFIX = 'firestore_online_state';\n\n/** Assembles the key for the online state of the primary tab. */\nexport function createWebStorageOnlineStateKey(persistenceKey: string): string {\n  return `${ONLINE_STATE_KEY_PREFIX}_${persistenceKey}`;\n}\n\n/**\n * The JSON representation of the system's online state, as written by the\n * primary client.\n */\nexport interface SharedOnlineStateSchema {\n  /**\n   * The clientId of the client that wrote this onlineState value. Tracked so\n   * that on startup, clients can check if this client is still active when\n   * determining whether to apply this value or not.\n   */\n  readonly clientId: string;\n  readonly onlineState: string;\n}\n\n// The WebStorage key prefix for the key that stores the last sequence number allocated. The key\n// looks like 'firestore_sequence_number_<persistence_prefix>'.\nexport const SEQUENCE_NUMBER_KEY_PREFIX = 'firestore_sequence_number';\n\n/** Assembles the key for the current sequence number. */\nexport function createWebStorageSequenceNumberKey(\n  persistenceKey: string\n): string {\n  return `${SEQUENCE_NUMBER_KEY_PREFIX}_${persistenceKey}`;\n}\n","/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { User } from '../auth/user';\nimport { ListenSequence } from '../core/listen_sequence';\nimport {\n  BatchId,\n  ListenSequenceNumber,\n  MutationBatchState,\n  OnlineState,\n  TargetId\n} from '../core/types';\nimport { TargetIdSet, targetIdSet } from '../model/collections';\nimport { Platform } from '../platform/platform';\nimport { hardAssert, debugAssert } from '../util/assert';\nimport { AsyncQueue } from '../util/async_queue';\nimport { Code, FirestoreError } from '../util/error';\nimport { forEach } from '../util/obj';\nimport { logError, logDebug } from '../util/log';\nimport { SortedSet } from '../util/sorted_set';\nimport { isSafeInteger } from '../util/types';\nimport {\n  QueryTargetState,\n  SharedClientStateSyncer\n} from './shared_client_state_syncer';\nimport {\n  CLIENT_STATE_KEY_PREFIX,\n  ClientStateSchema,\n  createWebStorageClientStateKey,\n  createWebStorageMutationBatchKey,\n  createWebStorageOnlineStateKey,\n  createWebStorageQueryTargetMetadataKey,\n  createWebStorageSequenceNumberKey,\n  MUTATION_BATCH_KEY_PREFIX,\n  MutationMetadataSchema,\n  QUERY_TARGET_KEY_PREFIX,\n  QueryTargetStateSchema,\n  SharedOnlineStateSchema\n} from './shared_client_state_schema';\n\nconst LOG_TAG = 'SharedClientState';\n\n/**\n * A randomly-generated key assigned to each Firestore instance at startup.\n */\nexport type ClientId = string;\n\n/**\n * A `SharedClientState` keeps track of the global state of the mutations\n * and query targets for all active clients with the same persistence key (i.e.\n * project ID and FirebaseApp name). It relays local changes to other clients\n * and updates its local state as new state is observed.\n *\n * `SharedClientState` is primarily used for synchronization in Multi-Tab\n * environments. Each tab is responsible for registering its active query\n * targets and mutations. `SharedClientState` will then notify the listener\n * assigned to `.syncEngine` for updates to mutations and queries that\n * originated in other clients.\n *\n * To receive notifications, `.syncEngine` and `.onlineStateHandler` has to be\n * assigned before calling `start()`.\n */\nexport interface SharedClientState {\n  syncEngine: SharedClientStateSyncer | null;\n  onlineStateHandler: ((onlineState: OnlineState) => void) | null;\n  sequenceNumberHandler:\n    | ((sequenceNumber: ListenSequenceNumber) => void)\n    | null;\n\n  /** Registers the Mutation Batch ID of a newly pending mutation. */\n  addPendingMutation(batchId: BatchId): void;\n\n  /**\n   * Records that a pending mutation has been acknowledged or rejected.\n   * Called by the primary client to notify secondary clients of mutation\n   * results as they come back from the backend.\n   */\n  updateMutationState(\n    batchId: BatchId,\n    state: 'acknowledged' | 'rejected',\n    error?: FirestoreError\n  ): void;\n\n  /**\n   * Associates a new Query Target ID with the local Firestore client. Returns\n   * the new query state for the query (which can be 'current' if the query is\n   * already associated with another tab).\n   *\n   * If the target id is already associated with local client, the method simply\n   * returns its `QueryTargetState`.\n   */\n  addLocalQueryTarget(targetId: TargetId): QueryTargetState;\n\n  /** Removes the Query Target ID association from the local client. */\n  removeLocalQueryTarget(targetId: TargetId): void;\n\n  /** Checks whether the target is associated with the local client. */\n  isLocalQueryTarget(targetId: TargetId): boolean;\n\n  /**\n   * Processes an update to a query target.\n   *\n   * Called by the primary client to notify secondary clients of document\n   * changes or state transitions that affect the provided query target.\n   */\n  updateQueryState(\n    targetId: TargetId,\n    state: QueryTargetState,\n    error?: FirestoreError\n  ): void;\n\n  /**\n   * Removes the target's metadata entry.\n   *\n   * Called by the primary client when all clients stopped listening to a query\n   * target.\n   */\n  clearQueryState(targetId: TargetId): void;\n\n  /**\n   * Gets the active Query Targets IDs for all active clients.\n   *\n   * The implementation for this may require O(n) runtime, where 'n' is the size\n   * of the result set.\n   */\n  // Visible for testing\n  getAllActiveQueryTargets(): SortedSet<TargetId>;\n\n  /**\n   * Checks whether the provided target ID is currently being listened to by\n   * any of the active clients.\n   *\n   * The implementation may require O(n*log m) runtime, where 'n' is the number\n   * of clients and 'm' the number of targets.\n   */\n  isActiveQueryTarget(targetId: TargetId): boolean;\n\n  /**\n   * Starts the SharedClientState, reads existing client data and registers\n   * listeners for updates to new and existing clients.\n   */\n  start(): Promise<void>;\n\n  /** Shuts down the `SharedClientState` and its listeners. */\n  shutdown(): void;\n\n  /**\n   * Changes the active user and removes all existing user-specific data. The\n   * user change does not call back into SyncEngine (for example, no mutations\n   * will be marked as removed).\n   */\n  handleUserChange(\n    user: User,\n    removedBatchIds: BatchId[],\n    addedBatchIds: BatchId[]\n  ): void;\n\n  /** Changes the shared online state of all clients. */\n  setOnlineState(onlineState: OnlineState): void;\n\n  writeSequenceNumber(sequenceNumber: ListenSequenceNumber): void;\n}\n\n/**\n * Holds the state of a mutation batch, including its user ID, batch ID and\n * whether the batch is 'pending', 'acknowledged' or 'rejected'.\n */\n// Visible for testing\nexport class MutationMetadata {\n  constructor(\n    readonly user: User,\n    readonly batchId: BatchId,\n    readonly state: MutationBatchState,\n    readonly error?: FirestoreError\n  ) {\n    debugAssert(\n      (error !== undefined) === (state === 'rejected'),\n      `MutationMetadata must contain an error iff state is 'rejected'`\n    );\n  }\n\n  /**\n   * Parses a MutationMetadata from its JSON representation in WebStorage.\n   * Logs a warning and returns null if the format of the data is not valid.\n   */\n  static fromWebStorageEntry(\n    user: User,\n    batchId: BatchId,\n    value: string\n  ): MutationMetadata | null {\n    const mutationBatch = JSON.parse(value) as MutationMetadataSchema;\n\n    let validData =\n      typeof mutationBatch === 'object' &&\n      ['pending', 'acknowledged', 'rejected'].indexOf(mutationBatch.state) !==\n        -1 &&\n      (mutationBatch.error === undefined ||\n        typeof mutationBatch.error === 'object');\n\n    let firestoreError: FirestoreError | undefined = undefined;\n\n    if (validData && mutationBatch.error) {\n      validData =\n        typeof mutationBatch.error.message === 'string' &&\n        typeof mutationBatch.error.code === 'string';\n      if (validData) {\n        firestoreError = new FirestoreError(\n          mutationBatch.error.code as Code,\n          mutationBatch.error.message\n        );\n      }\n    }\n\n    if (validData) {\n      return new MutationMetadata(\n        user,\n        batchId,\n        mutationBatch.state,\n        firestoreError\n      );\n    } else {\n      logError(\n        LOG_TAG,\n        `Failed to parse mutation state for ID '${batchId}': ${value}`\n      );\n      return null;\n    }\n  }\n\n  toWebStorageJSON(): string {\n    const batchMetadata: MutationMetadataSchema = {\n      state: this.state,\n      updateTimeMs: Date.now() // Modify the existing value to trigger update.\n    };\n\n    if (this.error) {\n      batchMetadata.error = {\n        code: this.error.code,\n        message: this.error.message\n      };\n    }\n\n    return JSON.stringify(batchMetadata);\n  }\n}\n\n/**\n * Holds the state of a query target, including its target ID and whether the\n * target is 'not-current', 'current' or 'rejected'.\n */\n// Visible for testing\nexport class QueryTargetMetadata {\n  constructor(\n    readonly targetId: TargetId,\n    readonly state: QueryTargetState,\n    readonly error?: FirestoreError\n  ) {\n    debugAssert(\n      (error !== undefined) === (state === 'rejected'),\n      `QueryTargetMetadata must contain an error iff state is 'rejected'`\n    );\n  }\n\n  /**\n   * Parses a QueryTargetMetadata from its JSON representation in WebStorage.\n   * Logs a warning and returns null if the format of the data is not valid.\n   */\n  static fromWebStorageEntry(\n    targetId: TargetId,\n    value: string\n  ): QueryTargetMetadata | null {\n    const targetState = JSON.parse(value) as QueryTargetStateSchema;\n\n    let validData =\n      typeof targetState === 'object' &&\n      ['not-current', 'current', 'rejected'].indexOf(targetState.state) !==\n        -1 &&\n      (targetState.error === undefined ||\n        typeof targetState.error === 'object');\n\n    let firestoreError: FirestoreError | undefined = undefined;\n\n    if (validData && targetState.error) {\n      validData =\n        typeof targetState.error.message === 'string' &&\n        typeof targetState.error.code === 'string';\n      if (validData) {\n        firestoreError = new FirestoreError(\n          targetState.error.code as Code,\n          targetState.error.message\n        );\n      }\n    }\n\n    if (validData) {\n      return new QueryTargetMetadata(\n        targetId,\n        targetState.state,\n        firestoreError\n      );\n    } else {\n      logError(\n        LOG_TAG,\n        `Failed to parse target state for ID '${targetId}': ${value}`\n      );\n      return null;\n    }\n  }\n\n  toWebStorageJSON(): string {\n    const targetState: QueryTargetStateSchema = {\n      state: this.state,\n      updateTimeMs: Date.now() // Modify the existing value to trigger update.\n    };\n\n    if (this.error) {\n      targetState.error = {\n        code: this.error.code,\n        message: this.error.message\n      };\n    }\n\n    return JSON.stringify(targetState);\n  }\n}\n\n/**\n * Metadata state of a single client denoting the query targets it is actively\n * listening to.\n */\n// Visible for testing.\nexport interface ClientState {\n  readonly activeTargetIds: TargetIdSet;\n}\n\n/**\n * This class represents the immutable ClientState for a client read from\n * WebStorage, containing the list of active query targets.\n */\nclass RemoteClientState implements ClientState {\n  private constructor(\n    readonly clientId: ClientId,\n    readonly activeTargetIds: TargetIdSet\n  ) {}\n\n  /**\n   * Parses a RemoteClientState from the JSON representation in WebStorage.\n   * Logs a warning and returns null if the format of the data is not valid.\n   */\n  static fromWebStorageEntry(\n    clientId: ClientId,\n    value: string\n  ): RemoteClientState | null {\n    const clientState = JSON.parse(value) as ClientStateSchema;\n\n    let validData =\n      typeof clientState === 'object' &&\n      clientState.activeTargetIds instanceof Array;\n\n    let activeTargetIdsSet = targetIdSet();\n\n    for (let i = 0; validData && i < clientState.activeTargetIds.length; ++i) {\n      validData = isSafeInteger(clientState.activeTargetIds[i]);\n      activeTargetIdsSet = activeTargetIdsSet.add(\n        clientState.activeTargetIds[i]\n      );\n    }\n\n    if (validData) {\n      return new RemoteClientState(clientId, activeTargetIdsSet);\n    } else {\n      logError(\n        LOG_TAG,\n        `Failed to parse client data for instance '${clientId}': ${value}`\n      );\n      return null;\n    }\n  }\n}\n\n/**\n * This class represents the online state for all clients participating in\n * multi-tab. The online state is only written to by the primary client, and\n * used in secondary clients to update their query views.\n */\nexport class SharedOnlineState {\n  constructor(readonly clientId: string, readonly onlineState: OnlineState) {}\n\n  /**\n   * Parses a SharedOnlineState from its JSON representation in WebStorage.\n   * Logs a warning and returns null if the format of the data is not valid.\n   */\n  static fromWebStorageEntry(value: string): SharedOnlineState | null {\n    const onlineState = JSON.parse(value) as SharedOnlineStateSchema;\n\n    const validData =\n      typeof onlineState === 'object' &&\n      ['Unknown', 'Online', 'Offline'].indexOf(onlineState.onlineState) !==\n        -1 &&\n      typeof onlineState.clientId === 'string';\n\n    if (validData) {\n      return new SharedOnlineState(\n        onlineState.clientId,\n        onlineState.onlineState as OnlineState\n      );\n    } else {\n      logError(LOG_TAG, `Failed to parse online state: ${value}`);\n      return null;\n    }\n  }\n}\n\n/**\n * Metadata state of the local client. Unlike `RemoteClientState`, this class is\n * mutable and keeps track of all pending mutations, which allows us to\n * update the range of pending mutation batch IDs as new mutations are added or\n * removed.\n *\n * The data in `LocalClientState` is not read from WebStorage and instead\n * updated via its instance methods. The updated state can be serialized via\n * `toWebStorageJSON()`.\n */\n// Visible for testing.\nexport class LocalClientState implements ClientState {\n  activeTargetIds = targetIdSet();\n\n  addQueryTarget(targetId: TargetId): void {\n    this.activeTargetIds = this.activeTargetIds.add(targetId);\n  }\n\n  removeQueryTarget(targetId: TargetId): void {\n    this.activeTargetIds = this.activeTargetIds.delete(targetId);\n  }\n\n  /**\n   * Converts this entry into a JSON-encoded format we can use for WebStorage.\n   * Does not encode `clientId` as it is part of the key in WebStorage.\n   */\n  toWebStorageJSON(): string {\n    const data: ClientStateSchema = {\n      activeTargetIds: this.activeTargetIds.toArray(),\n      updateTimeMs: Date.now() // Modify the existing value to trigger update.\n    };\n    return JSON.stringify(data);\n  }\n}\n\n/**\n * `WebStorageSharedClientState` uses WebStorage (window.localStorage) as the\n * backing store for the SharedClientState. It keeps track of all active\n * clients and supports modifications of the local client's data.\n */\nexport class WebStorageSharedClientState implements SharedClientState {\n  syncEngine: SharedClientStateSyncer | null = null;\n  onlineStateHandler: ((onlineState: OnlineState) => void) | null = null;\n  sequenceNumberHandler:\n    | ((sequenceNumber: ListenSequenceNumber) => void)\n    | null = null;\n\n  private readonly storage: Storage;\n  private readonly localClientStorageKey: string;\n  private readonly sequenceNumberKey: string;\n  private readonly activeClients: { [key: string]: ClientState } = {};\n  private readonly storageListener = this.handleWebStorageEvent.bind(this);\n  private readonly onlineStateKey: string;\n  private readonly clientStateKeyRe: RegExp;\n  private readonly mutationBatchKeyRe: RegExp;\n  private readonly queryTargetKeyRe: RegExp;\n  private started = false;\n  private currentUser: User;\n\n  /**\n   * Captures WebStorage events that occur before `start()` is called. These\n   * events are replayed once `WebStorageSharedClientState` is started.\n   */\n  private earlyEvents: StorageEvent[] = [];\n\n  constructor(\n    private readonly queue: AsyncQueue,\n    private readonly platform: Platform,\n    private readonly persistenceKey: string,\n    private readonly localClientId: ClientId,\n    initialUser: User\n  ) {\n    if (!WebStorageSharedClientState.isAvailable(this.platform)) {\n      throw new FirestoreError(\n        Code.UNIMPLEMENTED,\n        'LocalStorage is not available on this platform.'\n      );\n    }\n    // Escape the special characters mentioned here:\n    // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Regular_Expressions\n    const escapedPersistenceKey = persistenceKey.replace(\n      /[.*+?^${}()|[\\]\\\\]/g,\n      '\\\\$&'\n    );\n\n    this.storage = this.platform.window!.localStorage;\n    this.currentUser = initialUser;\n    this.localClientStorageKey = createWebStorageClientStateKey(\n      this.persistenceKey,\n      this.localClientId\n    );\n    this.sequenceNumberKey = createWebStorageSequenceNumberKey(\n      this.persistenceKey\n    );\n    this.activeClients[this.localClientId] = new LocalClientState();\n\n    this.clientStateKeyRe = new RegExp(\n      `^${CLIENT_STATE_KEY_PREFIX}_${escapedPersistenceKey}_([^_]*)$`\n    );\n    this.mutationBatchKeyRe = new RegExp(\n      `^${MUTATION_BATCH_KEY_PREFIX}_${escapedPersistenceKey}_(\\\\d+)(?:_(.*))?$`\n    );\n    this.queryTargetKeyRe = new RegExp(\n      `^${QUERY_TARGET_KEY_PREFIX}_${escapedPersistenceKey}_(\\\\d+)$`\n    );\n\n    this.onlineStateKey = createWebStorageOnlineStateKey(this.persistenceKey);\n\n    // Rather than adding the storage observer during start(), we add the\n    // storage observer during initialization. This ensures that we collect\n    // events before other components populate their initial state (during their\n    // respective start() calls). Otherwise, we might for example miss a\n    // mutation that is added after LocalStore's start() processed the existing\n    // mutations but before we observe WebStorage events.\n    this.platform.window!.addEventListener('storage', this.storageListener);\n  }\n\n  /** Returns 'true' if WebStorage is available in the current environment. */\n  static isAvailable(platform: Platform): boolean {\n    return !!(platform.window && platform.window.localStorage != null);\n  }\n\n  async start(): Promise<void> {\n    debugAssert(!this.started, 'WebStorageSharedClientState already started');\n    debugAssert(\n      this.syncEngine !== null,\n      'syncEngine property must be set before calling start()'\n    );\n    debugAssert(\n      this.onlineStateHandler !== null,\n      'onlineStateHandler property must be set before calling start()'\n    );\n\n    // Retrieve the list of existing clients to backfill the data in\n    // SharedClientState.\n    const existingClients = await this.syncEngine!.getActiveClients();\n\n    for (const clientId of existingClients) {\n      if (clientId === this.localClientId) {\n        continue;\n      }\n\n      const storageItem = this.getItem(\n        createWebStorageClientStateKey(this.persistenceKey, clientId)\n      );\n      if (storageItem) {\n        const clientState = RemoteClientState.fromWebStorageEntry(\n          clientId,\n          storageItem\n        );\n        if (clientState) {\n          this.activeClients[clientState.clientId] = clientState;\n        }\n      }\n    }\n\n    this.persistClientState();\n\n    // Check if there is an existing online state and call the callback handler\n    // if applicable.\n    const onlineStateJSON = this.storage.getItem(this.onlineStateKey);\n    if (onlineStateJSON) {\n      const onlineState = this.fromWebStorageOnlineState(onlineStateJSON);\n      if (onlineState) {\n        this.handleOnlineStateEvent(onlineState);\n      }\n    }\n\n    for (const event of this.earlyEvents) {\n      this.handleWebStorageEvent(event);\n    }\n\n    this.earlyEvents = [];\n\n    // Register a window unload hook to remove the client metadata entry from\n    // WebStorage even if `shutdown()` was not called.\n    this.platform.window!.addEventListener('unload', () => this.shutdown());\n\n    this.started = true;\n  }\n\n  writeSequenceNumber(sequenceNumber: ListenSequenceNumber): void {\n    this.setItem(this.sequenceNumberKey, JSON.stringify(sequenceNumber));\n  }\n\n  getAllActiveQueryTargets(): TargetIdSet {\n    let activeTargets = targetIdSet();\n    forEach(this.activeClients, (key, value) => {\n      activeTargets = activeTargets.unionWith(value.activeTargetIds);\n    });\n    return activeTargets;\n  }\n\n  isActiveQueryTarget(targetId: TargetId): boolean {\n    // This is not using `obj.forEach` since `forEach` doesn't support early\n    // return.\n    for (const clientId in this.activeClients) {\n      if (this.activeClients.hasOwnProperty(clientId)) {\n        if (this.activeClients[clientId].activeTargetIds.has(targetId)) {\n          return true;\n        }\n      }\n    }\n    return false;\n  }\n\n  addPendingMutation(batchId: BatchId): void {\n    this.persistMutationState(batchId, 'pending');\n  }\n\n  updateMutationState(\n    batchId: BatchId,\n    state: 'acknowledged' | 'rejected',\n    error?: FirestoreError\n  ): void {\n    this.persistMutationState(batchId, state, error);\n\n    // Once a final mutation result is observed by other clients, they no longer\n    // access the mutation's metadata entry. Since WebStorage replays events\n    // in order, it is safe to delete the entry right after updating it.\n    this.removeMutationState(batchId);\n  }\n\n  addLocalQueryTarget(targetId: TargetId): QueryTargetState {\n    let queryState: QueryTargetState = 'not-current';\n\n    // Lookup an existing query state if the target ID was already registered\n    // by another tab\n    if (this.isActiveQueryTarget(targetId)) {\n      const storageItem = this.storage.getItem(\n        createWebStorageQueryTargetMetadataKey(this.persistenceKey, targetId)\n      );\n\n      if (storageItem) {\n        const metadata = QueryTargetMetadata.fromWebStorageEntry(\n          targetId,\n          storageItem\n        );\n        if (metadata) {\n          queryState = metadata.state;\n        }\n      }\n    }\n\n    this.localClientState.addQueryTarget(targetId);\n    this.persistClientState();\n\n    return queryState;\n  }\n\n  removeLocalQueryTarget(targetId: TargetId): void {\n    this.localClientState.removeQueryTarget(targetId);\n    this.persistClientState();\n  }\n\n  isLocalQueryTarget(targetId: TargetId): boolean {\n    return this.localClientState.activeTargetIds.has(targetId);\n  }\n\n  clearQueryState(targetId: TargetId): void {\n    this.removeItem(\n      createWebStorageQueryTargetMetadataKey(this.persistenceKey, targetId)\n    );\n  }\n\n  updateQueryState(\n    targetId: TargetId,\n    state: QueryTargetState,\n    error?: FirestoreError\n  ): void {\n    this.persistQueryTargetState(targetId, state, error);\n  }\n\n  handleUserChange(\n    user: User,\n    removedBatchIds: BatchId[],\n    addedBatchIds: BatchId[]\n  ): void {\n    removedBatchIds.forEach(batchId => {\n      this.removeMutationState(batchId);\n    });\n    this.currentUser = user;\n    addedBatchIds.forEach(batchId => {\n      this.addPendingMutation(batchId);\n    });\n  }\n\n  setOnlineState(onlineState: OnlineState): void {\n    this.persistOnlineState(onlineState);\n  }\n\n  shutdown(): void {\n    if (this.started) {\n      this.platform.window!.removeEventListener(\n        'storage',\n        this.storageListener\n      );\n      this.removeItem(this.localClientStorageKey);\n      this.started = false;\n    }\n  }\n\n  private getItem(key: string): string | null {\n    const value = this.storage.getItem(key);\n    logDebug(LOG_TAG, 'READ', key, value);\n    return value;\n  }\n\n  private setItem(key: string, value: string): void {\n    logDebug(LOG_TAG, 'SET', key, value);\n    this.storage.setItem(key, value);\n  }\n\n  private removeItem(key: string): void {\n    logDebug(LOG_TAG, 'REMOVE', key);\n    this.storage.removeItem(key);\n  }\n\n  private handleWebStorageEvent(event: StorageEvent): void {\n    if (event.storageArea === this.storage) {\n      logDebug(LOG_TAG, 'EVENT', event.key, event.newValue);\n\n      if (event.key === this.localClientStorageKey) {\n        logError(\n          'Received WebStorage notification for local change. Another client might have ' +\n            'garbage-collected our state'\n        );\n        return;\n      }\n\n      this.queue.enqueueAndForget(async () => {\n        if (!this.started) {\n          this.earlyEvents.push(event);\n          return;\n        }\n\n        if (event.key === null) {\n          return;\n        }\n\n        if (this.clientStateKeyRe.test(event.key)) {\n          if (event.newValue != null) {\n            const clientState = this.fromWebStorageClientState(\n              event.key,\n              event.newValue\n            );\n            if (clientState) {\n              return this.handleClientStateEvent(\n                clientState.clientId,\n                clientState\n              );\n            }\n          } else {\n            const clientId = this.fromWebStorageClientStateKey(event.key)!;\n            return this.handleClientStateEvent(clientId, null);\n          }\n        } else if (this.mutationBatchKeyRe.test(event.key)) {\n          if (event.newValue !== null) {\n            const mutationMetadata = this.fromWebStorageMutationMetadata(\n              event.key,\n              event.newValue\n            );\n            if (mutationMetadata) {\n              return this.handleMutationBatchEvent(mutationMetadata);\n            }\n          }\n        } else if (this.queryTargetKeyRe.test(event.key)) {\n          if (event.newValue !== null) {\n            const queryTargetMetadata = this.fromWebStorageQueryTargetMetadata(\n              event.key,\n              event.newValue\n            );\n            if (queryTargetMetadata) {\n              return this.handleQueryTargetEvent(queryTargetMetadata);\n            }\n          }\n        } else if (event.key === this.onlineStateKey) {\n          if (event.newValue !== null) {\n            const onlineState = this.fromWebStorageOnlineState(event.newValue);\n            if (onlineState) {\n              return this.handleOnlineStateEvent(onlineState);\n            }\n          }\n        } else if (event.key === this.sequenceNumberKey) {\n          debugAssert(\n            !!this.sequenceNumberHandler,\n            'Missing sequenceNumberHandler'\n          );\n          const sequenceNumber = fromWebStorageSequenceNumber(event.newValue);\n          if (sequenceNumber !== ListenSequence.INVALID) {\n            this.sequenceNumberHandler!(sequenceNumber);\n          }\n        }\n      });\n    }\n  }\n\n  private get localClientState(): LocalClientState {\n    return this.activeClients[this.localClientId] as LocalClientState;\n  }\n\n  private persistClientState(): void {\n    this.setItem(\n      this.localClientStorageKey,\n      this.localClientState.toWebStorageJSON()\n    );\n  }\n\n  private persistMutationState(\n    batchId: BatchId,\n    state: MutationBatchState,\n    error?: FirestoreError\n  ): void {\n    const mutationState = new MutationMetadata(\n      this.currentUser,\n      batchId,\n      state,\n      error\n    );\n    const mutationKey = createWebStorageMutationBatchKey(\n      this.persistenceKey,\n      this.currentUser,\n      batchId\n    );\n    this.setItem(mutationKey, mutationState.toWebStorageJSON());\n  }\n\n  private removeMutationState(batchId: BatchId): void {\n    const mutationKey = createWebStorageMutationBatchKey(\n      this.persistenceKey,\n      this.currentUser,\n      batchId\n    );\n    this.removeItem(mutationKey);\n  }\n\n  private persistOnlineState(onlineState: OnlineState): void {\n    const entry: SharedOnlineStateSchema = {\n      clientId: this.localClientId,\n      onlineState\n    };\n    this.storage.setItem(this.onlineStateKey, JSON.stringify(entry));\n  }\n\n  private persistQueryTargetState(\n    targetId: TargetId,\n    state: QueryTargetState,\n    error?: FirestoreError\n  ): void {\n    const targetKey = createWebStorageQueryTargetMetadataKey(\n      this.persistenceKey,\n      targetId\n    );\n    const targetMetadata = new QueryTargetMetadata(targetId, state, error);\n    this.setItem(targetKey, targetMetadata.toWebStorageJSON());\n  }\n\n  /**\n   * Parses a client state key in WebStorage. Returns null if the key does not\n   * match the expected key format.\n   */\n  private fromWebStorageClientStateKey(key: string): ClientId | null {\n    const match = this.clientStateKeyRe.exec(key);\n    return match ? match[1] : null;\n  }\n\n  /**\n   * Parses a client state in WebStorage. Returns 'null' if the value could not\n   * be parsed.\n   */\n  private fromWebStorageClientState(\n    key: string,\n    value: string\n  ): RemoteClientState | null {\n    const clientId = this.fromWebStorageClientStateKey(key);\n    debugAssert(clientId !== null, `Cannot parse client state key '${key}'`);\n    return RemoteClientState.fromWebStorageEntry(clientId, value);\n  }\n\n  /**\n   * Parses a mutation batch state in WebStorage. Returns 'null' if the value\n   * could not be parsed.\n   */\n  private fromWebStorageMutationMetadata(\n    key: string,\n    value: string\n  ): MutationMetadata | null {\n    const match = this.mutationBatchKeyRe.exec(key);\n    debugAssert(match !== null, `Cannot parse mutation batch key '${key}'`);\n\n    const batchId = Number(match[1]);\n    const userId = match[2] !== undefined ? match[2] : null;\n    return MutationMetadata.fromWebStorageEntry(\n      new User(userId),\n      batchId,\n      value\n    );\n  }\n\n  /**\n   * Parses a query target state from WebStorage. Returns 'null' if the value\n   * could not be parsed.\n   */\n  private fromWebStorageQueryTargetMetadata(\n    key: string,\n    value: string\n  ): QueryTargetMetadata | null {\n    const match = this.queryTargetKeyRe.exec(key);\n    debugAssert(match !== null, `Cannot parse query target key '${key}'`);\n\n    const targetId = Number(match[1]);\n    return QueryTargetMetadata.fromWebStorageEntry(targetId, value);\n  }\n\n  /**\n   * Parses an online state from WebStorage. Returns 'null' if the value\n   * could not be parsed.\n   */\n  private fromWebStorageOnlineState(value: string): SharedOnlineState | null {\n    return SharedOnlineState.fromWebStorageEntry(value);\n  }\n\n  private async handleMutationBatchEvent(\n    mutationBatch: MutationMetadata\n  ): Promise<void> {\n    if (mutationBatch.user.uid !== this.currentUser.uid) {\n      logDebug(\n        LOG_TAG,\n        `Ignoring mutation for non-active user ${mutationBatch.user.uid}`\n      );\n      return;\n    }\n\n    return this.syncEngine!.applyBatchState(\n      mutationBatch.batchId,\n      mutationBatch.state,\n      mutationBatch.error\n    );\n  }\n\n  private handleQueryTargetEvent(\n    targetMetadata: QueryTargetMetadata\n  ): Promise<void> {\n    return this.syncEngine!.applyTargetState(\n      targetMetadata.targetId,\n      targetMetadata.state,\n      targetMetadata.error\n    );\n  }\n\n  private handleClientStateEvent(\n    clientId: ClientId,\n    clientState: RemoteClientState | null\n  ): Promise<void> {\n    const existingTargets = this.getAllActiveQueryTargets();\n\n    if (clientState) {\n      this.activeClients[clientId] = clientState;\n    } else {\n      delete this.activeClients[clientId];\n    }\n\n    const newTargets = this.getAllActiveQueryTargets();\n\n    const addedTargets: TargetId[] = [];\n    const removedTargets: TargetId[] = [];\n\n    newTargets.forEach(async targetId => {\n      if (!existingTargets.has(targetId)) {\n        addedTargets.push(targetId);\n      }\n    });\n\n    existingTargets.forEach(async targetId => {\n      if (!newTargets.has(targetId)) {\n        removedTargets.push(targetId);\n      }\n    });\n\n    return this.syncEngine!.applyActiveTargetsChange(\n      addedTargets,\n      removedTargets\n    );\n  }\n\n  private handleOnlineStateEvent(onlineState: SharedOnlineState): void {\n    // We check whether the client that wrote this online state is still active\n    // by comparing its client ID to the list of clients kept active in\n    // IndexedDb. If a client does not update their IndexedDb client state\n    // within 5 seconds, it is considered inactive and we don't emit an online\n    // state event.\n    if (this.activeClients[onlineState.clientId]) {\n      this.onlineStateHandler!(onlineState.onlineState);\n    }\n  }\n}\n\nfunction fromWebStorageSequenceNumber(\n  seqString: string | null\n): ListenSequenceNumber {\n  let sequenceNumber = ListenSequence.INVALID;\n  if (seqString != null) {\n    try {\n      const parsed = JSON.parse(seqString);\n      hardAssert(\n        typeof parsed === 'number',\n        'Found non-numeric sequence number'\n      );\n      sequenceNumber = parsed;\n    } catch (e) {\n      logError(LOG_TAG, 'Failed to read sequence number from WebStorage', e);\n    }\n  }\n  return sequenceNumber;\n}\n\n/**\n * `MemorySharedClientState` is a simple implementation of SharedClientState for\n * clients using memory persistence. The state in this class remains fully\n * isolated and no synchronization is performed.\n */\nexport class MemorySharedClientState implements SharedClientState {\n  private localState = new LocalClientState();\n  private queryState: { [targetId: number]: QueryTargetState } = {};\n\n  syncEngine: SharedClientStateSyncer | null = null;\n  onlineStateHandler: ((onlineState: OnlineState) => void) | null = null;\n  sequenceNumberHandler:\n    | ((sequenceNumber: ListenSequenceNumber) => void)\n    | null = null;\n\n  addPendingMutation(batchId: BatchId): void {\n    // No op.\n  }\n\n  updateMutationState(\n    batchId: BatchId,\n    state: 'acknowledged' | 'rejected',\n    error?: FirestoreError\n  ): void {\n    // No op.\n  }\n\n  addLocalQueryTarget(targetId: TargetId): QueryTargetState {\n    this.localState.addQueryTarget(targetId);\n    return this.queryState[targetId] || 'not-current';\n  }\n\n  updateQueryState(\n    targetId: TargetId,\n    state: QueryTargetState,\n    error?: FirestoreError\n  ): void {\n    this.queryState[targetId] = state;\n  }\n\n  removeLocalQueryTarget(targetId: TargetId): void {\n    this.localState.removeQueryTarget(targetId);\n  }\n\n  isLocalQueryTarget(targetId: TargetId): boolean {\n    return this.localState.activeTargetIds.has(targetId);\n  }\n\n  clearQueryState(targetId: TargetId): void {\n    delete this.queryState[targetId];\n  }\n\n  getAllActiveQueryTargets(): TargetIdSet {\n    return this.localState.activeTargetIds;\n  }\n\n  isActiveQueryTarget(targetId: TargetId): boolean {\n    return this.localState.activeTargetIds.has(targetId);\n  }\n\n  start(): Promise<void> {\n    this.localState = new LocalClientState();\n    return Promise.resolve();\n  }\n\n  handleUserChange(\n    user: User,\n    removedBatchIds: BatchId[],\n    addedBatchIds: BatchId[]\n  ): void {\n    // No op.\n  }\n\n  setOnlineState(onlineState: OnlineState): void {\n    // No op.\n  }\n\n  shutdown(): void {}\n\n  writeSequenceNumber(sequenceNumber: ListenSequenceNumber): void {}\n}\n","/**\n * @license\n * Copyright 2017 Google Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { TargetId } from './types';\n\n/** Offset to ensure non-overlapping target ids. */\nconst OFFSET = 2;\n\n/**\n * Generates monotonically increasing target IDs for sending targets to the\n * watch stream.\n *\n * The client constructs two generators, one for the target cache, and one for\n * for the sync engine (to generate limbo documents targets). These\n * generators produce non-overlapping IDs (by using even and odd IDs\n * respectively).\n *\n * By separating the target ID space, the query cache can generate target IDs\n * that persist across client restarts, while sync engine can independently\n * generate in-memory target IDs that are transient and can be reused after a\n * restart.\n */\nexport class TargetIdGenerator {\n  constructor(private lastId: number) {}\n\n  next(): TargetId {\n    this.lastId += OFFSET;\n    return this.lastId;\n  }\n\n  static forTargetCache(): TargetIdGenerator {\n    // The target cache generator must return '2' in its first call to `next()`\n    // as there is no differentiation in the protocol layer between an unset\n    // number and the number '0'. If we were to sent a target with target ID\n    // '0', the backend would consider it unset and replace it with its own ID.\n    return new TargetIdGenerator(2 - OFFSET);\n  }\n\n  static forSyncEngine(): TargetIdGenerator {\n    // Sync engine assigns target IDs for limbo document detection.\n    return new TargetIdGenerator(1 - OFFSET);\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { QueryResult } from '../local/local_store';\nimport {\n  documentKeySet,\n  DocumentKeySet,\n  MaybeDocumentMap\n} from '../model/collections';\nimport { Document, MaybeDocument } from '../model/document';\nimport { DocumentKey } from '../model/document_key';\nimport { DocumentSet } from '../model/document_set';\nimport { TargetChange } from '../remote/remote_event';\nimport { debugAssert, fail } from '../util/assert';\n\nimport { Query } from './query';\nimport { OnlineState } from './types';\nimport {\n  ChangeType,\n  DocumentChangeSet,\n  SyncState,\n  ViewSnapshot\n} from './view_snapshot';\n\nexport type LimboDocumentChange = AddedLimboDocument | RemovedLimboDocument;\nexport class AddedLimboDocument {\n  constructor(public key: DocumentKey) {}\n}\nexport class RemovedLimboDocument {\n  constructor(public key: DocumentKey) {}\n}\n\n/** The result of applying a set of doc changes to a view. */\nexport interface ViewDocumentChanges {\n  /** The new set of docs that should be in the view. */\n  documentSet: DocumentSet;\n  /** The diff of these docs with the previous set of docs. */\n  changeSet: DocumentChangeSet;\n  /**\n   * Whether the set of documents passed in was not sufficient to calculate the\n   * new state of the view and there needs to be another pass based on the\n   * local cache.\n   */\n  needsRefill: boolean;\n\n  mutatedKeys: DocumentKeySet;\n}\n\nexport interface ViewChange {\n  snapshot?: ViewSnapshot;\n  limboChanges: LimboDocumentChange[];\n}\n\n/**\n * View is responsible for computing the final merged truth of what docs are in\n * a query. It gets notified of local and remote changes to docs, and applies\n * the query filters and limits to determine the most correct possible results.\n */\nexport class View {\n  private syncState: SyncState | null = null;\n  /**\n   * A flag whether the view is current with the backend. A view is considered\n   * current after it has seen the current flag from the backend and did not\n   * lose consistency within the watch stream (e.g. because of an existence\n   * filter mismatch).\n   */\n  private current = false;\n  private documentSet: DocumentSet;\n  /** Documents in the view but not in the remote target */\n  private limboDocuments = documentKeySet();\n  /** Document Keys that have local changes */\n  private mutatedKeys = documentKeySet();\n\n  constructor(\n    private query: Query,\n    /** Documents included in the remote target */\n    private _syncedDocuments: DocumentKeySet\n  ) {\n    this.documentSet = new DocumentSet(query.docComparator.bind(query));\n  }\n\n  /**\n   * The set of remote documents that the server has told us belongs to the target associated with\n   * this view.\n   */\n  get syncedDocuments(): DocumentKeySet {\n    return this._syncedDocuments;\n  }\n\n  /**\n   * Iterates over a set of doc changes, applies the query limit, and computes\n   * what the new results should be, what the changes were, and whether we may\n   * need to go back to the local cache for more results. Does not make any\n   * changes to the view.\n   * @param docChanges The doc changes to apply to this view.\n   * @param previousChanges If this is being called with a refill, then start\n   *        with this set of docs and changes instead of the current view.\n   * @return a new set of docs, changes, and refill flag.\n   */\n  computeDocChanges(\n    docChanges: MaybeDocumentMap,\n    previousChanges?: ViewDocumentChanges\n  ): ViewDocumentChanges {\n    const changeSet = previousChanges\n      ? previousChanges.changeSet\n      : new DocumentChangeSet();\n    const oldDocumentSet = previousChanges\n      ? previousChanges.documentSet\n      : this.documentSet;\n    let newMutatedKeys = previousChanges\n      ? previousChanges.mutatedKeys\n      : this.mutatedKeys;\n    let newDocumentSet = oldDocumentSet;\n    let needsRefill = false;\n\n    // Track the last doc in a (full) limit. This is necessary, because some\n    // update (a delete, or an update moving a doc past the old limit) might\n    // mean there is some other document in the local cache that either should\n    // come (1) between the old last limit doc and the new last document, in the\n    // case of updates, or (2) after the new last document, in the case of\n    // deletes. So we keep this doc at the old limit to compare the updates to.\n    //\n    // Note that this should never get used in a refill (when previousChanges is\n    // set), because there will only be adds -- no deletes or updates.\n    const lastDocInLimit =\n      this.query.hasLimitToFirst() && oldDocumentSet.size === this.query.limit\n        ? oldDocumentSet.last()\n        : null;\n    const firstDocInLimit =\n      this.query.hasLimitToLast() && oldDocumentSet.size === this.query.limit\n        ? oldDocumentSet.first()\n        : null;\n\n    docChanges.inorderTraversal(\n      (key: DocumentKey, newMaybeDoc: MaybeDocument) => {\n        const oldDoc = oldDocumentSet.get(key);\n        let newDoc = newMaybeDoc instanceof Document ? newMaybeDoc : null;\n        if (newDoc) {\n          debugAssert(\n            key.isEqual(newDoc.key),\n            'Mismatching keys found in document changes: ' +\n              key +\n              ' != ' +\n              newDoc.key\n          );\n          newDoc = this.query.matches(newDoc) ? newDoc : null;\n        }\n\n        const oldDocHadPendingMutations = oldDoc\n          ? this.mutatedKeys.has(oldDoc.key)\n          : false;\n        const newDocHasPendingMutations = newDoc\n          ? newDoc.hasLocalMutations ||\n            // We only consider committed mutations for documents that were\n            // mutated during the lifetime of the view.\n            (this.mutatedKeys.has(newDoc.key) && newDoc.hasCommittedMutations)\n          : false;\n\n        let changeApplied = false;\n\n        // Calculate change\n        if (oldDoc && newDoc) {\n          const docsEqual = oldDoc.data().isEqual(newDoc.data());\n          if (!docsEqual) {\n            if (!this.shouldWaitForSyncedDocument(oldDoc, newDoc)) {\n              changeSet.track({\n                type: ChangeType.Modified,\n                doc: newDoc\n              });\n              changeApplied = true;\n\n              if (\n                (lastDocInLimit &&\n                  this.query.docComparator(newDoc, lastDocInLimit) > 0) ||\n                (firstDocInLimit &&\n                  this.query.docComparator(newDoc, firstDocInLimit) < 0)\n              ) {\n                // This doc moved from inside the limit to outside the limit.\n                // That means there may be some other doc in the local cache\n                // that should be included instead.\n                needsRefill = true;\n              }\n            }\n          } else if (oldDocHadPendingMutations !== newDocHasPendingMutations) {\n            changeSet.track({ type: ChangeType.Metadata, doc: newDoc });\n            changeApplied = true;\n          }\n        } else if (!oldDoc && newDoc) {\n          changeSet.track({ type: ChangeType.Added, doc: newDoc });\n          changeApplied = true;\n        } else if (oldDoc && !newDoc) {\n          changeSet.track({ type: ChangeType.Removed, doc: oldDoc });\n          changeApplied = true;\n\n          if (lastDocInLimit || firstDocInLimit) {\n            // A doc was removed from a full limit query. We'll need to\n            // requery from the local cache to see if we know about some other\n            // doc that should be in the results.\n            needsRefill = true;\n          }\n        }\n\n        if (changeApplied) {\n          if (newDoc) {\n            newDocumentSet = newDocumentSet.add(newDoc);\n            if (newDocHasPendingMutations) {\n              newMutatedKeys = newMutatedKeys.add(key);\n            } else {\n              newMutatedKeys = newMutatedKeys.delete(key);\n            }\n          } else {\n            newDocumentSet = newDocumentSet.delete(key);\n            newMutatedKeys = newMutatedKeys.delete(key);\n          }\n        }\n      }\n    );\n\n    // Drop documents out to meet limit/limitToLast requirement.\n    if (this.query.hasLimitToFirst() || this.query.hasLimitToLast()) {\n      while (newDocumentSet.size > this.query.limit!) {\n        const oldDoc = this.query.hasLimitToFirst()\n          ? newDocumentSet.last()\n          : newDocumentSet.first();\n        newDocumentSet = newDocumentSet.delete(oldDoc!.key);\n        newMutatedKeys = newMutatedKeys.delete(oldDoc!.key);\n        changeSet.track({ type: ChangeType.Removed, doc: oldDoc! });\n      }\n    }\n\n    debugAssert(\n      !needsRefill || !previousChanges,\n      'View was refilled using docs that themselves needed refilling.'\n    );\n    return {\n      documentSet: newDocumentSet,\n      changeSet,\n      needsRefill,\n      mutatedKeys: newMutatedKeys\n    };\n  }\n\n  private shouldWaitForSyncedDocument(\n    oldDoc: Document,\n    newDoc: Document\n  ): boolean {\n    // We suppress the initial change event for documents that were modified as\n    // part of a write acknowledgment (e.g. when the value of a server transform\n    // is applied) as Watch will send us the same document again.\n    // By suppressing the event, we only raise two user visible events (one with\n    // `hasPendingWrites` and the final state of the document) instead of three\n    // (one with `hasPendingWrites`, the modified document with\n    // `hasPendingWrites` and the final state of the document).\n    return (\n      oldDoc.hasLocalMutations &&\n      newDoc.hasCommittedMutations &&\n      !newDoc.hasLocalMutations\n    );\n  }\n\n  /**\n   * Updates the view with the given ViewDocumentChanges and optionally updates\n   * limbo docs and sync state from the provided target change.\n   * @param docChanges The set of changes to make to the view's docs.\n   * @param updateLimboDocuments Whether to update limbo documents based on this\n   *        change.\n   * @param targetChange A target change to apply for computing limbo docs and\n   *        sync state.\n   * @return A new ViewChange with the given docs, changes, and sync state.\n   */\n  // PORTING NOTE: The iOS/Android clients always compute limbo document changes.\n  applyChanges(\n    docChanges: ViewDocumentChanges,\n    updateLimboDocuments: boolean,\n    targetChange?: TargetChange\n  ): ViewChange {\n    debugAssert(\n      !docChanges.needsRefill,\n      'Cannot apply changes that need a refill'\n    );\n    const oldDocs = this.documentSet;\n    this.documentSet = docChanges.documentSet;\n    this.mutatedKeys = docChanges.mutatedKeys;\n    // Sort changes based on type and query comparator\n    const changes = docChanges.changeSet.getChanges();\n    changes.sort((c1, c2) => {\n      return (\n        compareChangeType(c1.type, c2.type) ||\n        this.query.docComparator(c1.doc, c2.doc)\n      );\n    });\n\n    this.applyTargetChange(targetChange);\n    const limboChanges = updateLimboDocuments\n      ? this.updateLimboDocuments()\n      : [];\n    const synced = this.limboDocuments.size === 0 && this.current;\n    const newSyncState = synced ? SyncState.Synced : SyncState.Local;\n    const syncStateChanged = newSyncState !== this.syncState;\n    this.syncState = newSyncState;\n\n    if (changes.length === 0 && !syncStateChanged) {\n      // no changes\n      return { limboChanges };\n    } else {\n      const snap: ViewSnapshot = new ViewSnapshot(\n        this.query,\n        docChanges.documentSet,\n        oldDocs,\n        changes,\n        docChanges.mutatedKeys,\n        newSyncState === SyncState.Local,\n        syncStateChanged,\n        /* excludesMetadataChanges= */ false\n      );\n      return {\n        snapshot: snap,\n        limboChanges\n      };\n    }\n  }\n\n  /**\n   * Applies an OnlineState change to the view, potentially generating a\n   * ViewChange if the view's syncState changes as a result.\n   */\n  applyOnlineStateChange(onlineState: OnlineState): ViewChange {\n    if (this.current && onlineState === OnlineState.Offline) {\n      // If we're offline, set `current` to false and then call applyChanges()\n      // to refresh our syncState and generate a ViewChange as appropriate. We\n      // are guaranteed to get a new TargetChange that sets `current` back to\n      // true once the client is back online.\n      this.current = false;\n      return this.applyChanges(\n        {\n          documentSet: this.documentSet,\n          changeSet: new DocumentChangeSet(),\n          mutatedKeys: this.mutatedKeys,\n          needsRefill: false\n        },\n        /* updateLimboDocuments= */ false\n      );\n    } else {\n      // No effect, just return a no-op ViewChange.\n      return { limboChanges: [] };\n    }\n  }\n\n  /**\n   * Returns whether the doc for the given key should be in limbo.\n   */\n  private shouldBeInLimbo(key: DocumentKey): boolean {\n    // If the remote end says it's part of this query, it's not in limbo.\n    if (this._syncedDocuments.has(key)) {\n      return false;\n    }\n    // The local store doesn't think it's a result, so it shouldn't be in limbo.\n    if (!this.documentSet.has(key)) {\n      return false;\n    }\n    // If there are local changes to the doc, they might explain why the server\n    // doesn't know that it's part of the query. So don't put it in limbo.\n    // TODO(klimt): Ideally, we would only consider changes that might actually\n    // affect this specific query.\n    if (this.documentSet.get(key)!.hasLocalMutations) {\n      return false;\n    }\n    // Everything else is in limbo.\n    return true;\n  }\n\n  /**\n   * Updates syncedDocuments, current, and limbo docs based on the given change.\n   * Returns the list of changes to which docs are in limbo.\n   */\n  private applyTargetChange(targetChange?: TargetChange): void {\n    if (targetChange) {\n      targetChange.addedDocuments.forEach(\n        key => (this._syncedDocuments = this._syncedDocuments.add(key))\n      );\n      targetChange.modifiedDocuments.forEach(key => {\n        debugAssert(\n          this._syncedDocuments.has(key),\n          `Modified document ${key} not found in view.`\n        );\n      });\n      targetChange.removedDocuments.forEach(\n        key => (this._syncedDocuments = this._syncedDocuments.delete(key))\n      );\n      this.current = targetChange.current;\n    }\n  }\n\n  private updateLimboDocuments(): LimboDocumentChange[] {\n    // We can only determine limbo documents when we're in-sync with the server.\n    if (!this.current) {\n      return [];\n    }\n\n    // TODO(klimt): Do this incrementally so that it's not quadratic when\n    // updating many documents.\n    const oldLimboDocuments = this.limboDocuments;\n    this.limboDocuments = documentKeySet();\n    this.documentSet.forEach(doc => {\n      if (this.shouldBeInLimbo(doc.key)) {\n        this.limboDocuments = this.limboDocuments.add(doc.key);\n      }\n    });\n\n    // Diff the new limbo docs with the old limbo docs.\n    const changes: LimboDocumentChange[] = [];\n    oldLimboDocuments.forEach(key => {\n      if (!this.limboDocuments.has(key)) {\n        changes.push(new RemovedLimboDocument(key));\n      }\n    });\n    this.limboDocuments.forEach(key => {\n      if (!oldLimboDocuments.has(key)) {\n        changes.push(new AddedLimboDocument(key));\n      }\n    });\n    return changes;\n  }\n\n  /**\n   * Update the in-memory state of the current view with the state read from\n   * persistence.\n   *\n   * We update the query view whenever a client's primary status changes:\n   * - When a client transitions from primary to secondary, it can miss\n   *   LocalStorage updates and its query views may temporarily not be\n   *   synchronized with the state on disk.\n   * - For secondary to primary transitions, the client needs to update the list\n   *   of `syncedDocuments` since secondary clients update their query views\n   *   based purely on synthesized RemoteEvents.\n   *\n   * @param queryResult.documents - The documents that match the query according\n   * to the LocalStore.\n   * @param queryResult.remoteKeys - The keys of the documents that match the\n   * query according to the backend.\n   *\n   * @return The ViewChange that resulted from this synchronization.\n   */\n  // PORTING NOTE: Multi-tab only.\n  synchronizeWithPersistedState(queryResult: QueryResult): ViewChange {\n    this._syncedDocuments = queryResult.remoteKeys;\n    this.limboDocuments = documentKeySet();\n    const docChanges = this.computeDocChanges(queryResult.documents);\n    return this.applyChanges(docChanges, /*updateLimboDocuments=*/ true);\n  }\n\n  /**\n   * Returns a view snapshot as if this query was just listened to. Contains\n   * a document add for every existing document and the `fromCache` and\n   * `hasPendingWrites` status of the already established view.\n   */\n  // PORTING NOTE: Multi-tab only.\n  computeInitialSnapshot(): ViewSnapshot {\n    return ViewSnapshot.fromInitialDocuments(\n      this.query,\n      this.documentSet,\n      this.mutatedKeys,\n      this.syncState === SyncState.Local\n    );\n  }\n}\n\nfunction compareChangeType(c1: ChangeType, c2: ChangeType): number {\n  const order = (change: ChangeType): 0 | 1 | 2 => {\n    switch (change) {\n      case ChangeType.Added:\n        return 1;\n      case ChangeType.Modified:\n        return 2;\n      case ChangeType.Metadata:\n        // A metadata change is converted to a modified change at the public\n        // api layer.  Since we sort by document key and then change type,\n        // metadata and modified changes must be sorted equivalently.\n        return 2;\n      case ChangeType.Removed:\n        return 0;\n      default:\n        return fail('Unknown ChangeType: ' + change);\n    }\n  };\n\n  return order(c1) - order(c2);\n}\n","/**\n * @license\n * Copyright 2019 Google Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Deferred } from '../util/promise';\nimport { TimerId, AsyncQueue } from '../util/async_queue';\nimport { ExponentialBackoff } from '../remote/backoff';\nimport { Transaction } from './transaction';\nimport { RemoteStore } from '../remote/remote_store';\nimport { isNullOrUndefined } from '../util/types';\nimport { isPermanentError } from '../remote/rpc_error';\nimport { FirestoreError } from '../util/error';\n\nconst RETRY_COUNT = 5;\n\n/**\n * TransactionRunner encapsulates the logic needed to run and retry transactions\n * with backoff.\n */\nexport class TransactionRunner<T> {\n  private retries = RETRY_COUNT;\n  private backoff: ExponentialBackoff;\n\n  constructor(\n    private readonly asyncQueue: AsyncQueue,\n    private readonly remoteStore: RemoteStore,\n    private readonly updateFunction: (transaction: Transaction) => Promise<T>,\n    private readonly deferred: Deferred<T>\n  ) {\n    this.backoff = new ExponentialBackoff(\n      this.asyncQueue,\n      TimerId.RetryTransaction\n    );\n  }\n\n  /** Runs the transaction and sets the result on deferred. */\n  run(): void {\n    this.runWithBackOff();\n  }\n\n  private runWithBackOff(): void {\n    this.backoff.backoffAndRun(async () => {\n      const transaction = this.remoteStore.createTransaction();\n      const userPromise = this.tryRunUpdateFunction(transaction);\n      if (userPromise) {\n        userPromise\n          .then(result => {\n            this.asyncQueue.enqueueAndForget(() => {\n              return transaction\n                .commit()\n                .then(() => {\n                  this.deferred.resolve(result);\n                })\n                .catch(commitError => {\n                  this.handleTransactionError(commitError);\n                });\n            });\n          })\n          .catch(userPromiseError => {\n            this.handleTransactionError(userPromiseError);\n          });\n      }\n    });\n  }\n\n  private tryRunUpdateFunction(transaction: Transaction): Promise<T> | null {\n    try {\n      const userPromise = this.updateFunction(transaction);\n      if (\n        isNullOrUndefined(userPromise) ||\n        !userPromise.catch ||\n        !userPromise.then\n      ) {\n        this.deferred.reject(\n          Error('Transaction callback must return a Promise')\n        );\n        return null;\n      }\n      return userPromise;\n    } catch (error) {\n      // Do not retry errors thrown by user provided updateFunction.\n      this.deferred.reject(error);\n      return null;\n    }\n  }\n\n  private handleTransactionError(error: Error): void {\n    if (this.retries > 0 && this.isRetryableTransactionError(error)) {\n      this.retries -= 1;\n      this.asyncQueue.enqueueAndForget(() => {\n        this.runWithBackOff();\n        return Promise.resolve();\n      });\n    } else {\n      this.deferred.reject(error);\n    }\n  }\n\n  private isRetryableTransactionError(error: Error): boolean {\n    if (error.name === 'FirebaseError') {\n      // In transactions, the backend will fail outdated reads with FAILED_PRECONDITION and\n      // non-matching document versions with ABORTED. These errors should be retried.\n      const code = (error as FirestoreError).code;\n      return (\n        code === 'aborted' ||\n        code === 'failed-precondition' ||\n        !isPermanentError(code)\n      );\n    }\n    return false;\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { User } from '../auth/user';\nimport { ignoreIfPrimaryLeaseLoss, LocalStore } from '../local/local_store';\nimport { LocalViewChanges } from '../local/local_view_changes';\nimport { ReferenceSet } from '../local/reference_set';\nimport { TargetData, TargetPurpose } from '../local/target_data';\nimport {\n  documentKeySet,\n  DocumentKeySet,\n  MaybeDocumentMap\n} from '../model/collections';\nimport { MaybeDocument, NoDocument } from '../model/document';\nimport { DocumentKey } from '../model/document_key';\nimport { Mutation } from '../model/mutation';\nimport { MutationBatchResult, BATCHID_UNKNOWN } from '../model/mutation_batch';\nimport { RemoteEvent, TargetChange } from '../remote/remote_event';\nimport { RemoteStore } from '../remote/remote_store';\nimport { RemoteSyncer } from '../remote/remote_syncer';\nimport { debugAssert, fail, hardAssert } from '../util/assert';\nimport { Code, FirestoreError } from '../util/error';\nimport { logDebug } from '../util/log';\nimport { primitiveComparator } from '../util/misc';\nimport { ObjectMap } from '../util/obj_map';\nimport { Deferred } from '../util/promise';\nimport { SortedMap } from '../util/sorted_map';\n\nimport { ClientId, SharedClientState } from '../local/shared_client_state';\nimport {\n  QueryTargetState,\n  SharedClientStateSyncer\n} from '../local/shared_client_state_syncer';\nimport { SortedSet } from '../util/sorted_set';\nimport { ListenSequence } from './listen_sequence';\nimport { Query, LimitType } from './query';\nimport { SnapshotVersion } from './snapshot_version';\nimport { Target } from './target';\nimport { TargetIdGenerator } from './target_id_generator';\nimport { Transaction } from './transaction';\nimport {\n  BatchId,\n  MutationBatchState,\n  OnlineState,\n  OnlineStateSource,\n  TargetId\n} from './types';\nimport {\n  AddedLimboDocument,\n  LimboDocumentChange,\n  RemovedLimboDocument,\n  View,\n  ViewChange,\n  ViewDocumentChanges\n} from './view';\nimport { ViewSnapshot } from './view_snapshot';\nimport { AsyncQueue } from '../util/async_queue';\nimport { TransactionRunner } from './transaction_runner';\n\nconst LOG_TAG = 'SyncEngine';\n\n/**\n * QueryView contains all of the data that SyncEngine needs to keep track of for\n * a particular query.\n */\nclass QueryView {\n  constructor(\n    /**\n     * The query itself.\n     */\n    public query: Query,\n    /**\n     * The target number created by the client that is used in the watch\n     * stream to identify this query.\n     */\n    public targetId: TargetId,\n    /**\n     * The view is responsible for computing the final merged truth of what\n     * docs are in the query. It gets notified of local and remote changes,\n     * and applies the query filters and limits to determine the most correct\n     * possible results.\n     */\n    public view: View\n  ) {}\n}\n\n/** Tracks a limbo resolution. */\nclass LimboResolution {\n  constructor(public key: DocumentKey) {}\n\n  /**\n   * Set to true once we've received a document. This is used in\n   * getRemoteKeysForTarget() and ultimately used by WatchChangeAggregator to\n   * decide whether it needs to manufacture a delete event for the target once\n   * the target is CURRENT.\n   */\n  receivedDocument: boolean = false;\n}\n\n/**\n * Interface implemented by EventManager to handle notifications from\n * SyncEngine.\n */\nexport interface SyncEngineListener {\n  /** Handles new view snapshots. */\n  onWatchChange(snapshots: ViewSnapshot[]): void;\n\n  /** Handles the failure of a query. */\n  onWatchError(query: Query, error: Error): void;\n\n  /** Handles a change in online state. */\n  onOnlineStateChange(onlineState: OnlineState): void;\n}\n\n/**\n * SyncEngine is the central controller in the client SDK architecture. It is\n * the glue code between the EventManager, LocalStore, and RemoteStore. Some of\n * SyncEngine's responsibilities include:\n * 1. Coordinating client requests and remote events between the EventManager\n *    and the local and remote data stores.\n * 2. Managing a View object for each query, providing the unified view between\n *    the local and remote data stores.\n * 3. Notifying the RemoteStore when the LocalStore has new mutations in its\n *    queue that need sending to the backend.\n *\n * The SyncEngines methods should only ever be called by methods running in the\n * global async queue.\n */\nexport class SyncEngine implements RemoteSyncer, SharedClientStateSyncer {\n  private syncEngineListener: SyncEngineListener | null = null;\n\n  private queryViewsByQuery = new ObjectMap<Query, QueryView>(q =>\n    q.canonicalId()\n  );\n  private queriesByTarget = new Map<TargetId, Query[]>();\n  /**\n   * The keys of documents that are in limbo for which we haven't yet started a\n   * limbo resolution query.\n   */\n  private enqueuedLimboResolutions: DocumentKey[] = [];\n  /**\n   * Keeps track of the target ID for each document that is in limbo with an\n   * active target.\n   */\n  private activeLimboTargetsByKey = new SortedMap<DocumentKey, TargetId>(\n    DocumentKey.comparator\n  );\n  /**\n   * Keeps track of the information about an active limbo resolution for each\n   * active target ID that was started for the purpose of limbo resolution.\n   */\n  private activeLimboResolutionsByTarget = new Map<TargetId, LimboResolution>();\n  private limboDocumentRefs = new ReferenceSet();\n  /** Stores user completion handlers, indexed by User and BatchId. */\n  private mutationUserCallbacks = {} as {\n    [uidKey: string]: SortedMap<BatchId, Deferred<void>>;\n  };\n  /** Stores user callbacks waiting for all pending writes to be acknowledged. */\n  private pendingWritesCallbacks = new Map<BatchId, Array<Deferred<void>>>();\n  private limboTargetIdGenerator = TargetIdGenerator.forSyncEngine();\n\n  // The primary state is set to `true` or `false` immediately after Firestore\n  // startup. In the interim, a client should only be considered primary if\n  // `isPrimary` is true.\n  private isPrimary: undefined | boolean = undefined;\n  private onlineState = OnlineState.Unknown;\n\n  constructor(\n    private localStore: LocalStore,\n    private remoteStore: RemoteStore,\n    // PORTING NOTE: Manages state synchronization in multi-tab environments.\n    private sharedClientState: SharedClientState,\n    private currentUser: User,\n    private maxConcurrentLimboResolutions: number\n  ) {}\n\n  // Only used for testing.\n  get isPrimaryClient(): boolean {\n    return this.isPrimary === true;\n  }\n\n  /** Subscribes to SyncEngine notifications. Has to be called exactly once. */\n  subscribe(syncEngineListener: SyncEngineListener): void {\n    debugAssert(\n      syncEngineListener !== null,\n      'SyncEngine listener cannot be null'\n    );\n    debugAssert(\n      this.syncEngineListener === null,\n      'SyncEngine already has a subscriber.'\n    );\n\n    this.syncEngineListener = syncEngineListener;\n  }\n\n  /**\n   * Initiates the new listen, resolves promise when listen enqueued to the\n   * server. All the subsequent view snapshots or errors are sent to the\n   * subscribed handlers. Returns the targetId of the query.\n   */\n  async listen(query: Query): Promise<TargetId> {\n    this.assertSubscribed('listen()');\n\n    let targetId;\n    let viewSnapshot;\n\n    const queryView = this.queryViewsByQuery.get(query);\n    if (queryView) {\n      // PORTING NOTE: With Multi-Tab Web, it is possible that a query view\n      // already exists when EventManager calls us for the first time. This\n      // happens when the primary tab is already listening to this query on\n      // behalf of another tab and the user of the primary also starts listening\n      // to the query. EventManager will not have an assigned target ID in this\n      // case and calls `listen` to obtain this ID.\n      targetId = queryView.targetId;\n      this.sharedClientState.addLocalQueryTarget(targetId);\n      viewSnapshot = queryView.view.computeInitialSnapshot();\n    } else {\n      const targetData = await this.localStore.allocateTarget(query.toTarget());\n\n      const status = this.sharedClientState.addLocalQueryTarget(\n        targetData.targetId\n      );\n      targetId = targetData.targetId;\n      viewSnapshot = await this.initializeViewAndComputeSnapshot(\n        query,\n        targetId,\n        status === 'current'\n      );\n      if (this.isPrimary) {\n        this.remoteStore.listen(targetData);\n      }\n    }\n\n    this.syncEngineListener!.onWatchChange([viewSnapshot]);\n    return targetId;\n  }\n\n  /**\n   * Registers a view for a previously unknown query and computes its initial\n   * snapshot.\n   */\n  private async initializeViewAndComputeSnapshot(\n    query: Query,\n    targetId: TargetId,\n    current: boolean\n  ): Promise<ViewSnapshot> {\n    const queryResult = await this.localStore.executeQuery(\n      query,\n      /* usePreviousResults= */ true\n    );\n    const view = new View(query, queryResult.remoteKeys);\n    const viewDocChanges = view.computeDocChanges(queryResult.documents);\n    const synthesizedTargetChange = TargetChange.createSynthesizedTargetChangeForCurrentChange(\n      targetId,\n      current && this.onlineState !== OnlineState.Offline\n    );\n    const viewChange = view.applyChanges(\n      viewDocChanges,\n      /* updateLimboDocuments= */ this.isPrimary === true,\n      synthesizedTargetChange\n    );\n    debugAssert(\n      viewChange.limboChanges.length === 0,\n      'View returned limbo docs before target ack from the server.'\n    );\n    debugAssert(\n      !!viewChange.snapshot,\n      'applyChanges for new view should always return a snapshot'\n    );\n\n    const data = new QueryView(query, targetId, view);\n    this.queryViewsByQuery.set(query, data);\n    if (this.queriesByTarget.has(targetId)) {\n      this.queriesByTarget.get(targetId)!.push(query);\n    } else {\n      this.queriesByTarget.set(targetId, [query]);\n    }\n    return viewChange.snapshot!;\n  }\n\n  /**\n   * Reconcile the list of synced documents in an existing view with those\n   * from persistence.\n   */\n  // PORTING NOTE: Multi-tab only.\n  private async synchronizeViewAndComputeSnapshot(\n    queryView: QueryView\n  ): Promise<ViewChange> {\n    const queryResult = await this.localStore.executeQuery(\n      queryView.query,\n      /* usePreviousResults= */ true\n    );\n    const viewSnapshot = queryView.view.synchronizeWithPersistedState(\n      queryResult\n    );\n    if (this.isPrimary) {\n      this.updateTrackedLimbos(queryView.targetId, viewSnapshot.limboChanges);\n    }\n    return viewSnapshot;\n  }\n\n  /** Stops listening to the query. */\n  async unlisten(query: Query): Promise<void> {\n    this.assertSubscribed('unlisten()');\n\n    const queryView = this.queryViewsByQuery.get(query)!;\n    debugAssert(!!queryView, 'Trying to unlisten on query not found:' + query);\n\n    // Only clean up the query view and target if this is the only query mapped\n    // to the target.\n    const queries = this.queriesByTarget.get(queryView.targetId)!;\n    if (queries.length > 1) {\n      this.queriesByTarget.set(\n        queryView.targetId,\n        queries.filter(q => !q.isEqual(query))\n      );\n      this.queryViewsByQuery.delete(query);\n      return;\n    }\n\n    // No other queries are mapped to the target, clean up the query and the target.\n    if (this.isPrimary) {\n      // We need to remove the local query target first to allow us to verify\n      // whether any other client is still interested in this target.\n      this.sharedClientState.removeLocalQueryTarget(queryView.targetId);\n      const targetRemainsActive = this.sharedClientState.isActiveQueryTarget(\n        queryView.targetId\n      );\n\n      if (!targetRemainsActive) {\n        await this.localStore\n          .releaseTarget(queryView.targetId, /*keepPersistedTargetData=*/ false)\n          .then(() => {\n            this.sharedClientState.clearQueryState(queryView.targetId);\n            this.remoteStore.unlisten(queryView.targetId);\n            this.removeAndCleanupTarget(queryView.targetId);\n          })\n          .catch(ignoreIfPrimaryLeaseLoss);\n      }\n    } else {\n      this.removeAndCleanupTarget(queryView.targetId);\n      await this.localStore.releaseTarget(\n        queryView.targetId,\n        /*keepPersistedTargetData=*/ true\n      );\n    }\n  }\n\n  /**\n   * Initiates the write of local mutation batch which involves adding the\n   * writes to the mutation queue, notifying the remote store about new\n   * mutations and raising events for any changes this write caused.\n   *\n   * The promise returned by this call is resolved when the above steps\n   * have completed, *not* when the write was acked by the backend. The\n   * userCallback is resolved once the write was acked/rejected by the\n   * backend (or failed locally for any other reason).\n   */\n  async write(batch: Mutation[], userCallback: Deferred<void>): Promise<void> {\n    this.assertSubscribed('write()');\n    const result = await this.localStore.localWrite(batch);\n    this.sharedClientState.addPendingMutation(result.batchId);\n    this.addMutationCallback(result.batchId, userCallback);\n    await this.emitNewSnapsAndNotifyLocalStore(result.changes);\n    await this.remoteStore.fillWritePipeline();\n  }\n\n  /**\n   * Takes an updateFunction in which a set of reads and writes can be performed\n   * atomically. In the updateFunction, the client can read and write values\n   * using the supplied transaction object. After the updateFunction, all\n   * changes will be committed. If a retryable error occurs (ex: some other\n   * client has changed any of the data referenced), then the updateFunction\n   * will be called again after a backoff. If the updateFunction still fails\n   * after all retries, then the transaction will be rejected.\n   *\n   * The transaction object passed to the updateFunction contains methods for\n   * accessing documents and collections. Unlike other datastore access, data\n   * accessed with the transaction will not reflect local changes that have not\n   * been committed. For this reason, it is required that all reads are\n   * performed before any writes. Transactions must be performed while online.\n   *\n   * The Deferred input is resolved when the transaction is fully committed.\n   */\n  runTransaction<T>(\n    asyncQueue: AsyncQueue,\n    updateFunction: (transaction: Transaction) => Promise<T>,\n    deferred: Deferred<T>\n  ): void {\n    new TransactionRunner<T>(\n      asyncQueue,\n      this.remoteStore,\n      updateFunction,\n      deferred\n    ).run();\n  }\n\n  async applyRemoteEvent(remoteEvent: RemoteEvent): Promise<void> {\n    this.assertSubscribed('applyRemoteEvent()');\n    try {\n      const changes = await this.localStore.applyRemoteEvent(remoteEvent);\n      // Update `receivedDocument` as appropriate for any limbo targets.\n      remoteEvent.targetChanges.forEach((targetChange, targetId) => {\n        const limboResolution = this.activeLimboResolutionsByTarget.get(\n          targetId\n        );\n        if (limboResolution) {\n          // Since this is a limbo resolution lookup, it's for a single document\n          // and it could be added, modified, or removed, but not a combination.\n          hardAssert(\n            targetChange.addedDocuments.size +\n              targetChange.modifiedDocuments.size +\n              targetChange.removedDocuments.size <=\n              1,\n            'Limbo resolution for single document contains multiple changes.'\n          );\n          if (targetChange.addedDocuments.size > 0) {\n            limboResolution.receivedDocument = true;\n          } else if (targetChange.modifiedDocuments.size > 0) {\n            hardAssert(\n              limboResolution.receivedDocument,\n              'Received change for limbo target document without add.'\n            );\n          } else if (targetChange.removedDocuments.size > 0) {\n            hardAssert(\n              limboResolution.receivedDocument,\n              'Received remove for limbo target document without add.'\n            );\n            limboResolution.receivedDocument = false;\n          } else {\n            // This was probably just a CURRENT targetChange or similar.\n          }\n        }\n      });\n      await this.emitNewSnapsAndNotifyLocalStore(changes, remoteEvent);\n    } catch (error) {\n      await ignoreIfPrimaryLeaseLoss(error);\n    }\n  }\n\n  /**\n   * Applies an OnlineState change to the sync engine and notifies any views of\n   * the change.\n   */\n  applyOnlineStateChange(\n    onlineState: OnlineState,\n    source: OnlineStateSource\n  ): void {\n    // If we are the secondary client, we explicitly ignore the remote store's\n    // online state (the local client may go offline, even though the primary\n    // tab remains online) and only apply the primary tab's online state from\n    // SharedClientState.\n    if (\n      (this.isPrimary && source === OnlineStateSource.RemoteStore) ||\n      (!this.isPrimary && source === OnlineStateSource.SharedClientState)\n    ) {\n      this.assertSubscribed('applyOnlineStateChange()');\n      const newViewSnapshots = [] as ViewSnapshot[];\n      this.queryViewsByQuery.forEach((query, queryView) => {\n        const viewChange = queryView.view.applyOnlineStateChange(onlineState);\n        debugAssert(\n          viewChange.limboChanges.length === 0,\n          'OnlineState should not affect limbo documents.'\n        );\n        if (viewChange.snapshot) {\n          newViewSnapshots.push(viewChange.snapshot);\n        }\n      });\n      this.syncEngineListener!.onOnlineStateChange(onlineState);\n      this.syncEngineListener!.onWatchChange(newViewSnapshots);\n\n      this.onlineState = onlineState;\n      if (this.isPrimary) {\n        this.sharedClientState.setOnlineState(onlineState);\n      }\n    }\n  }\n\n  async rejectListen(targetId: TargetId, err: FirestoreError): Promise<void> {\n    this.assertSubscribed('rejectListens()');\n\n    // PORTING NOTE: Multi-tab only.\n    this.sharedClientState.updateQueryState(targetId, 'rejected', err);\n\n    const limboResolution = this.activeLimboResolutionsByTarget.get(targetId);\n    const limboKey = limboResolution && limboResolution.key;\n    if (limboKey) {\n      // Since this query failed, we won't want to manually unlisten to it.\n      // So go ahead and remove it from bookkeeping.\n      this.activeLimboTargetsByKey = this.activeLimboTargetsByKey.remove(\n        limboKey\n      );\n      this.activeLimboResolutionsByTarget.delete(targetId);\n      this.pumpEnqueuedLimboResolutions();\n\n      // TODO(klimt): We really only should do the following on permission\n      // denied errors, but we don't have the cause code here.\n\n      // It's a limbo doc. Create a synthetic event saying it was deleted.\n      // This is kind of a hack. Ideally, we would have a method in the local\n      // store to purge a document. However, it would be tricky to keep all of\n      // the local store's invariants with another method.\n      let documentUpdates = new SortedMap<DocumentKey, MaybeDocument>(\n        DocumentKey.comparator\n      );\n      documentUpdates = documentUpdates.insert(\n        limboKey,\n        new NoDocument(limboKey, SnapshotVersion.forDeletedDoc())\n      );\n      const resolvedLimboDocuments = documentKeySet().add(limboKey);\n      const event = new RemoteEvent(\n        SnapshotVersion.MIN,\n        /* targetChanges= */ new Map<TargetId, TargetChange>(),\n        /* targetMismatches= */ new SortedSet<TargetId>(primitiveComparator),\n        documentUpdates,\n        resolvedLimboDocuments\n      );\n      return this.applyRemoteEvent(event);\n    } else {\n      await this.localStore\n        .releaseTarget(targetId, /* keepPersistedTargetData */ false)\n        .then(() => this.removeAndCleanupTarget(targetId, err))\n        .catch(ignoreIfPrimaryLeaseLoss);\n    }\n  }\n\n  // PORTING NOTE: Multi-tab only\n  async applyBatchState(\n    batchId: BatchId,\n    batchState: MutationBatchState,\n    error?: FirestoreError\n  ): Promise<void> {\n    this.assertSubscribed('applyBatchState()');\n    const documents = await this.localStore.lookupMutationDocuments(batchId);\n\n    if (documents === null) {\n      // A throttled tab may not have seen the mutation before it was completed\n      // and removed from the mutation queue, in which case we won't have cached\n      // the affected documents. In this case we can safely ignore the update\n      // since that means we didn't apply the mutation locally at all (if we\n      // had, we would have cached the affected documents), and so we will just\n      // see any resulting document changes via normal remote document updates\n      // as applicable.\n      logDebug(LOG_TAG, 'Cannot apply mutation batch with id: ' + batchId);\n      return;\n    }\n\n    if (batchState === 'pending') {\n      // If we are the primary client, we need to send this write to the\n      // backend. Secondary clients will ignore these writes since their remote\n      // connection is disabled.\n      await this.remoteStore.fillWritePipeline();\n    } else if (batchState === 'acknowledged' || batchState === 'rejected') {\n      // NOTE: Both these methods are no-ops for batches that originated from\n      // other clients.\n      this.processUserCallback(batchId, error ? error : null);\n      this.localStore.removeCachedMutationBatchMetadata(batchId);\n    } else {\n      fail(`Unknown batchState: ${batchState}`);\n    }\n\n    await this.emitNewSnapsAndNotifyLocalStore(documents);\n  }\n\n  async applySuccessfulWrite(\n    mutationBatchResult: MutationBatchResult\n  ): Promise<void> {\n    this.assertSubscribed('applySuccessfulWrite()');\n\n    const batchId = mutationBatchResult.batch.batchId;\n\n    // The local store may or may not be able to apply the write result and\n    // raise events immediately (depending on whether the watcher is caught\n    // up), so we raise user callbacks first so that they consistently happen\n    // before listen events.\n    this.processUserCallback(batchId, /*error=*/ null);\n\n    this.triggerPendingWritesCallbacks(batchId);\n\n    try {\n      const changes = await this.localStore.acknowledgeBatch(\n        mutationBatchResult\n      );\n      this.sharedClientState.updateMutationState(batchId, 'acknowledged');\n      await this.emitNewSnapsAndNotifyLocalStore(changes);\n    } catch (error) {\n      await ignoreIfPrimaryLeaseLoss(error);\n    }\n  }\n\n  async rejectFailedWrite(\n    batchId: BatchId,\n    error: FirestoreError\n  ): Promise<void> {\n    this.assertSubscribed('rejectFailedWrite()');\n\n    // The local store may or may not be able to apply the write result and\n    // raise events immediately (depending on whether the watcher is caught up),\n    // so we raise user callbacks first so that they consistently happen before\n    // listen events.\n    this.processUserCallback(batchId, error);\n\n    this.triggerPendingWritesCallbacks(batchId);\n\n    try {\n      const changes = await this.localStore.rejectBatch(batchId);\n      this.sharedClientState.updateMutationState(batchId, 'rejected', error);\n      await this.emitNewSnapsAndNotifyLocalStore(changes);\n    } catch (error) {\n      await ignoreIfPrimaryLeaseLoss(error);\n    }\n  }\n\n  /**\n   * Registers a user callback that resolves when all pending mutations at the moment of calling\n   * are acknowledged .\n   */\n  async registerPendingWritesCallback(callback: Deferred<void>): Promise<void> {\n    if (!this.remoteStore.canUseNetwork()) {\n      logDebug(\n        LOG_TAG,\n        'The network is disabled. The task returned by ' +\n          \"'awaitPendingWrites()' will not complete until the network is enabled.\"\n      );\n    }\n\n    const highestBatchId = await this.localStore.getHighestUnacknowledgedBatchId();\n    if (highestBatchId === BATCHID_UNKNOWN) {\n      // Trigger the callback right away if there is no pending writes at the moment.\n      callback.resolve();\n      return;\n    }\n\n    const callbacks = this.pendingWritesCallbacks.get(highestBatchId) || [];\n    callbacks.push(callback);\n    this.pendingWritesCallbacks.set(highestBatchId, callbacks);\n  }\n\n  /**\n   * Triggers the callbacks that are waiting for this batch id to get acknowledged by server,\n   * if there are any.\n   */\n  private triggerPendingWritesCallbacks(batchId: BatchId): void {\n    (this.pendingWritesCallbacks.get(batchId) || []).forEach(callback => {\n      callback.resolve();\n    });\n\n    this.pendingWritesCallbacks.delete(batchId);\n  }\n\n  /** Reject all outstanding callbacks waiting for pending writes to complete. */\n  private rejectOutstandingPendingWritesCallbacks(errorMessage: string): void {\n    this.pendingWritesCallbacks.forEach(callbacks => {\n      callbacks.forEach(callback => {\n        callback.reject(new FirestoreError(Code.CANCELLED, errorMessage));\n      });\n    });\n\n    this.pendingWritesCallbacks.clear();\n  }\n\n  private addMutationCallback(\n    batchId: BatchId,\n    callback: Deferred<void>\n  ): void {\n    let newCallbacks = this.mutationUserCallbacks[this.currentUser.toKey()];\n    if (!newCallbacks) {\n      newCallbacks = new SortedMap<BatchId, Deferred<void>>(\n        primitiveComparator\n      );\n    }\n    newCallbacks = newCallbacks.insert(batchId, callback);\n    this.mutationUserCallbacks[this.currentUser.toKey()] = newCallbacks;\n  }\n\n  /**\n   * Resolves or rejects the user callback for the given batch and then discards\n   * it.\n   */\n  private processUserCallback(batchId: BatchId, error: Error | null): void {\n    let newCallbacks = this.mutationUserCallbacks[this.currentUser.toKey()];\n\n    // NOTE: Mutations restored from persistence won't have callbacks, so it's\n    // okay for there to be no callback for this ID.\n    if (newCallbacks) {\n      const callback = newCallbacks.get(batchId);\n      if (callback) {\n        debugAssert(\n          batchId === newCallbacks.minKey(),\n          'Mutation callbacks processed out-of-order?'\n        );\n        if (error) {\n          callback.reject(error);\n        } else {\n          callback.resolve();\n        }\n        newCallbacks = newCallbacks.remove(batchId);\n      }\n      this.mutationUserCallbacks[this.currentUser.toKey()] = newCallbacks;\n    }\n  }\n\n  private removeAndCleanupTarget(\n    targetId: number,\n    error: Error | null = null\n  ): void {\n    this.sharedClientState.removeLocalQueryTarget(targetId);\n\n    debugAssert(\n      this.queriesByTarget.has(targetId) &&\n        this.queriesByTarget.get(targetId)!.length !== 0,\n      `There are no queries mapped to target id ${targetId}`\n    );\n\n    for (const query of this.queriesByTarget.get(targetId)!) {\n      this.queryViewsByQuery.delete(query);\n      if (error) {\n        this.syncEngineListener!.onWatchError(query, error);\n      }\n    }\n\n    this.queriesByTarget.delete(targetId);\n\n    if (this.isPrimary) {\n      const limboKeys = this.limboDocumentRefs.referencesForId(targetId);\n      this.limboDocumentRefs.removeReferencesForId(targetId);\n      limboKeys.forEach(limboKey => {\n        const isReferenced = this.limboDocumentRefs.containsKey(limboKey);\n        if (!isReferenced) {\n          // We removed the last reference for this key\n          this.removeLimboTarget(limboKey);\n        }\n      });\n    }\n  }\n\n  private removeLimboTarget(key: DocumentKey): void {\n    // It's possible that the target already got removed because the query failed. In that case,\n    // the key won't exist in `limboTargetsByKey`. Only do the cleanup if we still have the target.\n    const limboTargetId = this.activeLimboTargetsByKey.get(key);\n    if (limboTargetId === null) {\n      // This target already got removed, because the query failed.\n      return;\n    }\n\n    this.remoteStore.unlisten(limboTargetId);\n    this.activeLimboTargetsByKey = this.activeLimboTargetsByKey.remove(key);\n    this.activeLimboResolutionsByTarget.delete(limboTargetId);\n    this.pumpEnqueuedLimboResolutions();\n  }\n\n  private updateTrackedLimbos(\n    targetId: TargetId,\n    limboChanges: LimboDocumentChange[]\n  ): void {\n    for (const limboChange of limboChanges) {\n      if (limboChange instanceof AddedLimboDocument) {\n        this.limboDocumentRefs.addReference(limboChange.key, targetId);\n        this.trackLimboChange(limboChange);\n      } else if (limboChange instanceof RemovedLimboDocument) {\n        logDebug(LOG_TAG, 'Document no longer in limbo: ' + limboChange.key);\n        this.limboDocumentRefs.removeReference(limboChange.key, targetId);\n        const isReferenced = this.limboDocumentRefs.containsKey(\n          limboChange.key\n        );\n        if (!isReferenced) {\n          // We removed the last reference for this key\n          this.removeLimboTarget(limboChange.key);\n        }\n      } else {\n        fail('Unknown limbo change: ' + JSON.stringify(limboChange));\n      }\n    }\n  }\n\n  private trackLimboChange(limboChange: AddedLimboDocument): void {\n    const key = limboChange.key;\n    if (!this.activeLimboTargetsByKey.get(key)) {\n      logDebug(LOG_TAG, 'New document in limbo: ' + key);\n      this.enqueuedLimboResolutions.push(key);\n      this.pumpEnqueuedLimboResolutions();\n    }\n  }\n\n  /**\n   * Starts listens for documents in limbo that are enqueued for resolution,\n   * subject to a maximum number of concurrent resolutions.\n   *\n   * Without bounding the number of concurrent resolutions, the server can fail\n   * with \"resource exhausted\" errors which can lead to pathological client\n   * behavior as seen in https://github.com/firebase/firebase-js-sdk/issues/2683.\n   */\n  private pumpEnqueuedLimboResolutions(): void {\n    while (\n      this.enqueuedLimboResolutions.length > 0 &&\n      this.activeLimboTargetsByKey.size < this.maxConcurrentLimboResolutions\n    ) {\n      const key = this.enqueuedLimboResolutions.shift()!;\n      const limboTargetId = this.limboTargetIdGenerator.next();\n      this.activeLimboResolutionsByTarget.set(\n        limboTargetId,\n        new LimboResolution(key)\n      );\n      this.activeLimboTargetsByKey = this.activeLimboTargetsByKey.insert(\n        key,\n        limboTargetId\n      );\n      this.remoteStore.listen(\n        new TargetData(\n          Query.atPath(key.path).toTarget(),\n          limboTargetId,\n          TargetPurpose.LimboResolution,\n          ListenSequence.INVALID\n        )\n      );\n    }\n  }\n\n  // Visible for testing\n  activeLimboDocumentResolutions(): SortedMap<DocumentKey, TargetId> {\n    return this.activeLimboTargetsByKey;\n  }\n\n  // Visible for testing\n  enqueuedLimboDocumentResolutions(): DocumentKey[] {\n    return this.enqueuedLimboResolutions;\n  }\n\n  private async emitNewSnapsAndNotifyLocalStore(\n    changes: MaybeDocumentMap,\n    remoteEvent?: RemoteEvent\n  ): Promise<void> {\n    const newSnaps: ViewSnapshot[] = [];\n    const docChangesInAllViews: LocalViewChanges[] = [];\n    const queriesProcessed: Array<Promise<void>> = [];\n\n    this.queryViewsByQuery.forEach((_, queryView) => {\n      queriesProcessed.push(\n        Promise.resolve()\n          .then(() => {\n            const viewDocChanges = queryView.view.computeDocChanges(changes);\n            if (!viewDocChanges.needsRefill) {\n              return viewDocChanges;\n            }\n            // The query has a limit and some docs were removed, so we need\n            // to re-run the query against the local store to make sure we\n            // didn't lose any good docs that had been past the limit.\n            return this.localStore\n              .executeQuery(queryView.query, /* usePreviousResults= */ false)\n              .then(({ documents }) => {\n                return queryView.view.computeDocChanges(\n                  documents,\n                  viewDocChanges\n                );\n              });\n          })\n          .then((viewDocChanges: ViewDocumentChanges) => {\n            const targetChange =\n              remoteEvent && remoteEvent.targetChanges.get(queryView.targetId);\n            const viewChange = queryView.view.applyChanges(\n              viewDocChanges,\n              /* updateLimboDocuments= */ this.isPrimary === true,\n              targetChange\n            );\n            this.updateTrackedLimbos(\n              queryView.targetId,\n              viewChange.limboChanges\n            );\n            if (viewChange.snapshot) {\n              if (this.isPrimary) {\n                this.sharedClientState.updateQueryState(\n                  queryView.targetId,\n                  viewChange.snapshot.fromCache ? 'not-current' : 'current'\n                );\n              }\n\n              newSnaps.push(viewChange.snapshot);\n              const docChanges = LocalViewChanges.fromSnapshot(\n                queryView.targetId,\n                viewChange.snapshot\n              );\n              docChangesInAllViews.push(docChanges);\n            }\n          })\n      );\n    });\n\n    await Promise.all(queriesProcessed);\n    this.syncEngineListener!.onWatchChange(newSnaps);\n    await this.localStore.notifyLocalViewChanges(docChangesInAllViews);\n  }\n\n  private assertSubscribed(fnName: string): void {\n    debugAssert(\n      this.syncEngineListener !== null,\n      'Trying to call ' + fnName + ' before calling subscribe().'\n    );\n  }\n\n  async handleCredentialChange(user: User): Promise<void> {\n    const userChanged = !this.currentUser.isEqual(user);\n    this.currentUser = user;\n\n    if (userChanged) {\n      // Fails tasks waiting for pending writes requested by previous user.\n      this.rejectOutstandingPendingWritesCallbacks(\n        \"'waitForPendingWrites' promise is rejected due to a user change.\"\n      );\n\n      const result = await this.localStore.handleUserChange(user);\n      // TODO(b/114226417): Consider calling this only in the primary tab.\n      this.sharedClientState.handleUserChange(\n        user,\n        result.removedBatchIds,\n        result.addedBatchIds\n      );\n      await this.emitNewSnapsAndNotifyLocalStore(result.affectedDocuments);\n    }\n\n    await this.remoteStore.handleCredentialChange();\n  }\n\n  // PORTING NOTE: Multi-tab only\n  async applyPrimaryState(isPrimary: boolean): Promise<void> {\n    if (isPrimary === true && this.isPrimary !== true) {\n      this.isPrimary = true;\n      await this.remoteStore.applyPrimaryState(true);\n\n      // Secondary tabs only maintain Views for their local listeners and the\n      // Views internal state may not be 100% populated (in particular\n      // secondary tabs don't track syncedDocuments, the set of documents the\n      // server considers to be in the target). So when a secondary becomes\n      // primary, we need to need to make sure that all views for all targets\n      // match the state on disk.\n      const activeTargets = this.sharedClientState.getAllActiveQueryTargets();\n      const activeQueries = await this.synchronizeQueryViewsAndRaiseSnapshots(\n        activeTargets.toArray()\n      );\n      for (const targetData of activeQueries) {\n        this.remoteStore.listen(targetData);\n      }\n    } else if (isPrimary === false && this.isPrimary !== false) {\n      this.isPrimary = false;\n\n      const activeTargets: TargetId[] = [];\n\n      let p = Promise.resolve();\n      this.queriesByTarget.forEach((_, targetId) => {\n        if (this.sharedClientState.isLocalQueryTarget(targetId)) {\n          activeTargets.push(targetId);\n        } else {\n          p = p.then(() => {\n            this.removeAndCleanupTarget(targetId);\n            return this.localStore.releaseTarget(\n              targetId,\n              /*keepPersistedTargetData=*/ true\n            );\n          });\n        }\n        this.remoteStore.unlisten(targetId);\n      });\n      await p;\n\n      await this.synchronizeQueryViewsAndRaiseSnapshots(activeTargets);\n      this.resetLimboDocuments();\n      await this.remoteStore.applyPrimaryState(false);\n    }\n  }\n\n  // PORTING NOTE: Multi-tab only.\n  private resetLimboDocuments(): void {\n    this.activeLimboResolutionsByTarget.forEach((_, targetId) => {\n      this.remoteStore.unlisten(targetId);\n    });\n    this.limboDocumentRefs.removeAllReferences();\n    this.activeLimboResolutionsByTarget = new Map<TargetId, LimboResolution>();\n    this.activeLimboTargetsByKey = new SortedMap<DocumentKey, TargetId>(\n      DocumentKey.comparator\n    );\n  }\n\n  /**\n   * Reconcile the query views of the provided query targets with the state from\n   * persistence. Raises snapshots for any changes that affect the local\n   * client and returns the updated state of all target's query data.\n   */\n  // PORTING NOTE: Multi-tab only.\n  private async synchronizeQueryViewsAndRaiseSnapshots(\n    targets: TargetId[]\n  ): Promise<TargetData[]> {\n    const activeQueries: TargetData[] = [];\n    const newViewSnapshots: ViewSnapshot[] = [];\n    for (const targetId of targets) {\n      let targetData: TargetData;\n      const queries = this.queriesByTarget.get(targetId);\n\n      if (queries && queries.length !== 0) {\n        // For queries that have a local View, we need to update their state\n        // in LocalStore (as the resume token and the snapshot version\n        // might have changed) and reconcile their views with the persisted\n        // state (the list of syncedDocuments may have gotten out of sync).\n        await this.localStore.releaseTarget(\n          targetId,\n          /*keepPersistedTargetData=*/ true\n        );\n        targetData = await this.localStore.allocateTarget(\n          queries[0].toTarget()\n        );\n\n        for (const query of queries) {\n          const queryView = this.queryViewsByQuery.get(query);\n          debugAssert(!!queryView, `No query view found for ${query}`);\n\n          const viewChange = await this.synchronizeViewAndComputeSnapshot(\n            queryView\n          );\n          if (viewChange.snapshot) {\n            newViewSnapshots.push(viewChange.snapshot);\n          }\n        }\n      } else {\n        debugAssert(\n          this.isPrimary === true,\n          'A secondary tab should never have an active target without an active query.'\n        );\n        // For queries that never executed on this client, we need to\n        // allocate the target in LocalStore and initialize a new View.\n        const target = await this.localStore.getTarget(targetId);\n        debugAssert(!!target, `Target for id ${targetId} not found`);\n        targetData = await this.localStore.allocateTarget(target);\n        await this.initializeViewAndComputeSnapshot(\n          this.synthesizeTargetToQuery(target!),\n          targetId,\n          /*current=*/ false\n        );\n      }\n\n      activeQueries.push(targetData!);\n    }\n\n    this.syncEngineListener!.onWatchChange(newViewSnapshots);\n    return activeQueries;\n  }\n\n  /**\n   * Creates a `Query` object from the specified `Target`. There is no way to\n   * obtain the original `Query`, so we synthesize a `Query` from the `Target`\n   * object.\n   *\n   * The synthesized result might be different from the original `Query`, but\n   * since the synthesized `Query` should return the same results as the\n   * original one (only the presentation of results might differ), the potential\n   * difference will not cause issues.\n   */\n  // PORTING NOTE: Multi-tab only\n  private synthesizeTargetToQuery(target: Target): Query {\n    return new Query(\n      target.path,\n      target.collectionGroup,\n      target.orderBy,\n      target.filters,\n      target.limit,\n      LimitType.First,\n      target.startAt,\n      target.endAt\n    );\n  }\n\n  // PORTING NOTE: Multi-tab only\n  getActiveClients(): Promise<ClientId[]> {\n    return this.localStore.getActiveClients();\n  }\n\n  // PORTING NOTE: Multi-tab only\n  async applyTargetState(\n    targetId: TargetId,\n    state: QueryTargetState,\n    error?: FirestoreError\n  ): Promise<void> {\n    if (this.isPrimary) {\n      // If we receive a target state notification via WebStorage, we are\n      // either already secondary or another tab has taken the primary lease.\n      logDebug(LOG_TAG, 'Ignoring unexpected query state notification.');\n      return;\n    }\n\n    if (this.queriesByTarget.has(targetId)) {\n      switch (state) {\n        case 'current':\n        case 'not-current': {\n          const changes = await this.localStore.getNewDocumentChanges();\n          const synthesizedRemoteEvent = RemoteEvent.createSynthesizedRemoteEventForCurrentChange(\n            targetId,\n            state === 'current'\n          );\n          await this.emitNewSnapsAndNotifyLocalStore(\n            changes,\n            synthesizedRemoteEvent\n          );\n          break;\n        }\n        case 'rejected': {\n          await this.localStore.releaseTarget(\n            targetId,\n            /* keepPersistedTargetData */ true\n          );\n          this.removeAndCleanupTarget(targetId, error);\n          break;\n        }\n        default:\n          fail('Unexpected target state: ' + state);\n      }\n    }\n  }\n\n  // PORTING NOTE: Multi-tab only\n  async applyActiveTargetsChange(\n    added: TargetId[],\n    removed: TargetId[]\n  ): Promise<void> {\n    if (!this.isPrimary) {\n      return;\n    }\n\n    for (const targetId of added) {\n      debugAssert(\n        !this.queriesByTarget.has(targetId),\n        'Trying to add an already active target'\n      );\n      const target = await this.localStore.getTarget(targetId);\n      debugAssert(\n        !!target,\n        `Query data for active target ${targetId} not found`\n      );\n      const targetData = await this.localStore.allocateTarget(target);\n      await this.initializeViewAndComputeSnapshot(\n        this.synthesizeTargetToQuery(target),\n        targetData.targetId,\n        /*current=*/ false\n      );\n      this.remoteStore.listen(targetData);\n    }\n\n    for (const targetId of removed) {\n      // Check that the target is still active since the target might have been\n      // removed if it has been rejected by the backend.\n      if (!this.queriesByTarget.has(targetId)) {\n        continue;\n      }\n\n      // Release queries that are still active.\n      await this.localStore\n        .releaseTarget(targetId, /* keepPersistedTargetData */ false)\n        .then(() => {\n          this.remoteStore.unlisten(targetId);\n          this.removeAndCleanupTarget(targetId);\n        })\n        .catch(ignoreIfPrimaryLeaseLoss);\n    }\n  }\n\n  // PORTING NOTE: Multi-tab only. In other clients, LocalStore is unaware of\n  // the online state.\n  enableNetwork(): Promise<void> {\n    this.localStore.setNetworkEnabled(true);\n    return this.remoteStore.enableNetwork();\n  }\n\n  // PORTING NOTE: Multi-tab only. In other clients, LocalStore is unaware of\n  // the online state.\n  disableNetwork(): Promise<void> {\n    this.localStore.setNetworkEnabled(false);\n    return this.remoteStore.disableNetwork();\n  }\n\n  getRemoteKeysForTarget(targetId: TargetId): DocumentKeySet {\n    const limboResolution = this.activeLimboResolutionsByTarget.get(targetId);\n    if (limboResolution && limboResolution.receivedDocument) {\n      return documentKeySet().add(limboResolution.key);\n    } else {\n      let keySet = documentKeySet();\n      const queries = this.queriesByTarget.get(targetId);\n      if (!queries) {\n        return keySet;\n      }\n      for (const query of queries) {\n        const queryView = this.queryViewsByQuery.get(query);\n        debugAssert(!!queryView, `No query view found for ${query}`);\n        keySet = keySet.unionWith(queryView.view.syncedDocuments);\n      }\n      return keySet;\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { debugAssert } from '../util/assert';\nimport { EventHandler } from '../util/misc';\nimport { ObjectMap } from '../util/obj_map';\nimport { Query } from './query';\nimport { SyncEngine, SyncEngineListener } from './sync_engine';\nimport { OnlineState, TargetId } from './types';\nimport { DocumentViewChange, ChangeType, ViewSnapshot } from './view_snapshot';\n\n/**\n * Holds the listeners and the last received ViewSnapshot for a query being\n * tracked by EventManager.\n */\nclass QueryListenersInfo {\n  viewSnap: ViewSnapshot | null = null;\n  targetId: TargetId = 0;\n  listeners: QueryListener[] = [];\n}\n\n/**\n * Interface for handling events from the EventManager.\n */\nexport interface Observer<T> {\n  next: EventHandler<T>;\n  error: EventHandler<Error>;\n}\n\n/**\n * EventManager is responsible for mapping queries to query event emitters.\n * It handles \"fan-out\". -- Identical queries will re-use the same watch on the\n * backend.\n */\nexport class EventManager implements SyncEngineListener {\n  private queries = new ObjectMap<Query, QueryListenersInfo>(q =>\n    q.canonicalId()\n  );\n\n  private onlineState = OnlineState.Unknown;\n\n  private snapshotsInSyncListeners: Set<Observer<void>> = new Set();\n\n  constructor(private syncEngine: SyncEngine) {\n    this.syncEngine.subscribe(this);\n  }\n\n  listen(listener: QueryListener): Promise<TargetId> {\n    const query = listener.query;\n    let firstListen = false;\n\n    let queryInfo = this.queries.get(query);\n    if (!queryInfo) {\n      firstListen = true;\n      queryInfo = new QueryListenersInfo();\n      this.queries.set(query, queryInfo);\n    }\n    queryInfo.listeners.push(listener);\n\n    // Run global snapshot listeners if a consistent snapshot has been emitted.\n    const raisedEvent = listener.applyOnlineStateChange(this.onlineState);\n    debugAssert(\n      !raisedEvent,\n      \"applyOnlineStateChange() shouldn't raise an event for brand-new listeners.\"\n    );\n\n    if (queryInfo.viewSnap) {\n      const raisedEvent = listener.onViewSnapshot(queryInfo.viewSnap);\n      if (raisedEvent) {\n        this.raiseSnapshotsInSyncEvent();\n      }\n    }\n\n    if (firstListen) {\n      return this.syncEngine.listen(query).then(targetId => {\n        queryInfo!.targetId = targetId;\n        return targetId;\n      });\n    } else {\n      return Promise.resolve(queryInfo.targetId);\n    }\n  }\n\n  async unlisten(listener: QueryListener): Promise<void> {\n    const query = listener.query;\n    let lastListen = false;\n\n    const queryInfo = this.queries.get(query);\n    if (queryInfo) {\n      const i = queryInfo.listeners.indexOf(listener);\n      if (i >= 0) {\n        queryInfo.listeners.splice(i, 1);\n        lastListen = queryInfo.listeners.length === 0;\n      }\n    }\n\n    if (lastListen) {\n      this.queries.delete(query);\n      return this.syncEngine.unlisten(query);\n    }\n  }\n\n  onWatchChange(viewSnaps: ViewSnapshot[]): void {\n    let raisedEvent = false;\n    for (const viewSnap of viewSnaps) {\n      const query = viewSnap.query;\n      const queryInfo = this.queries.get(query);\n      if (queryInfo) {\n        for (const listener of queryInfo.listeners) {\n          if (listener.onViewSnapshot(viewSnap)) {\n            raisedEvent = true;\n          }\n        }\n        queryInfo.viewSnap = viewSnap;\n      }\n    }\n    if (raisedEvent) {\n      this.raiseSnapshotsInSyncEvent();\n    }\n  }\n\n  onWatchError(query: Query, error: Error): void {\n    const queryInfo = this.queries.get(query);\n    if (queryInfo) {\n      for (const listener of queryInfo.listeners) {\n        listener.onError(error);\n      }\n    }\n\n    // Remove all listeners. NOTE: We don't need to call syncEngine.unlisten()\n    // after an error.\n    this.queries.delete(query);\n  }\n\n  onOnlineStateChange(onlineState: OnlineState): void {\n    this.onlineState = onlineState;\n    let raisedEvent = false;\n    this.queries.forEach((_, queryInfo) => {\n      for (const listener of queryInfo.listeners) {\n        // Run global snapshot listeners if a consistent snapshot has been emitted.\n        if (listener.applyOnlineStateChange(onlineState)) {\n          raisedEvent = true;\n        }\n      }\n    });\n    if (raisedEvent) {\n      this.raiseSnapshotsInSyncEvent();\n    }\n  }\n\n  addSnapshotsInSyncListener(observer: Observer<void>): void {\n    this.snapshotsInSyncListeners.add(observer);\n    // Immediately fire an initial event, indicating all existing listeners\n    // are in-sync.\n    observer.next();\n  }\n\n  removeSnapshotsInSyncListener(observer: Observer<void>): void {\n    this.snapshotsInSyncListeners.delete(observer);\n  }\n\n  // Call all global snapshot listeners that have been set.\n  private raiseSnapshotsInSyncEvent(): void {\n    this.snapshotsInSyncListeners.forEach(observer => {\n      observer.next();\n    });\n  }\n}\n\nexport interface ListenOptions {\n  /** Raise events even when only the metadata changes */\n  readonly includeMetadataChanges?: boolean;\n\n  /**\n   * Wait for a sync with the server when online, but still raise events while\n   * offline.\n   */\n  readonly waitForSyncWhenOnline?: boolean;\n}\n\n/**\n * QueryListener takes a series of internal view snapshots and determines\n * when to raise the event.\n *\n * It uses an Observer to dispatch events.\n */\nexport class QueryListener {\n  /**\n   * Initial snapshots (e.g. from cache) may not be propagated to the wrapped\n   * observer. This flag is set to true once we've actually raised an event.\n   */\n  private raisedInitialEvent = false;\n\n  private options: ListenOptions;\n\n  private snap: ViewSnapshot | null = null;\n\n  private onlineState = OnlineState.Unknown;\n\n  constructor(\n    readonly query: Query,\n    private queryObserver: Observer<ViewSnapshot>,\n    options?: ListenOptions\n  ) {\n    this.options = options || {};\n  }\n\n  /**\n   * Applies the new ViewSnapshot to this listener, raising a user-facing event\n   * if applicable (depending on what changed, whether the user has opted into\n   * metadata-only changes, etc.). Returns true if a user-facing event was\n   * indeed raised.\n   */\n  onViewSnapshot(snap: ViewSnapshot): boolean {\n    debugAssert(\n      snap.docChanges.length > 0 || snap.syncStateChanged,\n      'We got a new snapshot with no changes?'\n    );\n\n    if (!this.options.includeMetadataChanges) {\n      // Remove the metadata only changes.\n      const docChanges: DocumentViewChange[] = [];\n      for (const docChange of snap.docChanges) {\n        if (docChange.type !== ChangeType.Metadata) {\n          docChanges.push(docChange);\n        }\n      }\n      snap = new ViewSnapshot(\n        snap.query,\n        snap.docs,\n        snap.oldDocs,\n        docChanges,\n        snap.mutatedKeys,\n        snap.fromCache,\n        snap.syncStateChanged,\n        /* excludesMetadataChanges= */ true\n      );\n    }\n    let raisedEvent = false;\n    if (!this.raisedInitialEvent) {\n      if (this.shouldRaiseInitialEvent(snap, this.onlineState)) {\n        this.raiseInitialEvent(snap);\n        raisedEvent = true;\n      }\n    } else if (this.shouldRaiseEvent(snap)) {\n      this.queryObserver.next(snap);\n      raisedEvent = true;\n    }\n\n    this.snap = snap;\n    return raisedEvent;\n  }\n\n  onError(error: Error): void {\n    this.queryObserver.error(error);\n  }\n\n  /** Returns whether a snapshot was raised. */\n  applyOnlineStateChange(onlineState: OnlineState): boolean {\n    this.onlineState = onlineState;\n    let raisedEvent = false;\n    if (\n      this.snap &&\n      !this.raisedInitialEvent &&\n      this.shouldRaiseInitialEvent(this.snap, onlineState)\n    ) {\n      this.raiseInitialEvent(this.snap);\n      raisedEvent = true;\n    }\n    return raisedEvent;\n  }\n\n  private shouldRaiseInitialEvent(\n    snap: ViewSnapshot,\n    onlineState: OnlineState\n  ): boolean {\n    debugAssert(\n      !this.raisedInitialEvent,\n      'Determining whether to raise first event but already had first event'\n    );\n\n    // Always raise the first event when we're synced\n    if (!snap.fromCache) {\n      return true;\n    }\n\n    // NOTE: We consider OnlineState.Unknown as online (it should become Offline\n    // or Online if we wait long enough).\n    const maybeOnline = onlineState !== OnlineState.Offline;\n    // Don't raise the event if we're online, aren't synced yet (checked\n    // above) and are waiting for a sync.\n    if (this.options.waitForSyncWhenOnline && maybeOnline) {\n      debugAssert(\n        snap.fromCache,\n        'Waiting for sync, but snapshot is not from cache'\n      );\n      return false;\n    }\n\n    // Raise data from cache if we have any documents or we are offline\n    return !snap.docs.isEmpty() || onlineState === OnlineState.Offline;\n  }\n\n  private shouldRaiseEvent(snap: ViewSnapshot): boolean {\n    // We don't need to handle includeDocumentMetadataChanges here because\n    // the Metadata only changes have already been stripped out if needed.\n    // At this point the only changes we will see are the ones we should\n    // propagate.\n    if (snap.docChanges.length > 0) {\n      return true;\n    }\n\n    const hasPendingWritesChanged =\n      this.snap && this.snap.hasPendingWrites !== snap.hasPendingWrites;\n    if (snap.syncStateChanged || hasPendingWritesChanged) {\n      return this.options.includeMetadataChanges === true;\n    }\n\n    // Generally we should have hit one of the cases above, but it's possible\n    // to get here if there were only metadata docChanges and they got\n    // stripped out.\n    return false;\n  }\n\n  private raiseInitialEvent(snap: ViewSnapshot): void {\n    debugAssert(\n      !this.raisedInitialEvent,\n      'Trying to raise initial events for second time'\n    );\n    snap = ViewSnapshot.fromInitialDocuments(\n      snap.query,\n      snap.docs,\n      snap.mutatedKeys,\n      snap.fromCache\n    );\n    this.raisedInitialEvent = true;\n    this.queryObserver.next(snap);\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { QueryEngine } from './query_engine';\nimport { LocalDocumentsView } from './local_documents_view';\nimport { PersistenceTransaction } from './persistence';\nimport { PersistencePromise } from './persistence_promise';\nimport { LimitType, Query } from '../core/query';\nimport { SnapshotVersion } from '../core/snapshot_version';\nimport {\n  DocumentKeySet,\n  DocumentMap,\n  MaybeDocumentMap\n} from '../model/collections';\nimport { Document } from '../model/document';\nimport { debugAssert } from '../util/assert';\nimport { getLogLevel, LogLevel, logDebug } from '../util/log';\nimport { SortedSet } from '../util/sorted_set';\n\n// TOOD(b/140938512): Drop SimpleQueryEngine and rename IndexFreeQueryEngine.\n\n/**\n * A query engine that takes advantage of the target document mapping in the\n * QueryCache. The IndexFreeQueryEngine optimizes query execution by only\n * reading the documents that previously matched a query plus any documents that were\n * edited after the query was last listened to.\n *\n * There are some cases where Index-Free queries are not guaranteed to produce\n * the same results as full collection scans. In these cases, the\n * IndexFreeQueryEngine falls back to full query processing. These cases are:\n *\n * - Limit queries where a document that matched the query previously no longer\n *   matches the query.\n *\n * - Limit queries where a document edit may cause the document to sort below\n *   another document that is in the local cache.\n *\n * - Queries that have never been CURRENT or free of Limbo documents.\n */\nexport class IndexFreeQueryEngine implements QueryEngine {\n  private localDocumentsView: LocalDocumentsView | undefined;\n\n  setLocalDocumentsView(localDocuments: LocalDocumentsView): void {\n    this.localDocumentsView = localDocuments;\n  }\n\n  getDocumentsMatchingQuery(\n    transaction: PersistenceTransaction,\n    query: Query,\n    lastLimboFreeSnapshotVersion: SnapshotVersion,\n    remoteKeys: DocumentKeySet\n  ): PersistencePromise<DocumentMap> {\n    debugAssert(\n      this.localDocumentsView !== undefined,\n      'setLocalDocumentsView() not called'\n    );\n\n    // Queries that match all documents don't benefit from using\n    // IndexFreeQueries. It is more efficient to scan all documents in a\n    // collection, rather than to perform individual lookups.\n    if (query.matchesAllDocuments()) {\n      return this.executeFullCollectionScan(transaction, query);\n    }\n\n    // Queries that have never seen a snapshot without limbo free documents\n    // should also be run as a full collection scan.\n    if (lastLimboFreeSnapshotVersion.isEqual(SnapshotVersion.MIN)) {\n      return this.executeFullCollectionScan(transaction, query);\n    }\n\n    return this.localDocumentsView!.getDocuments(transaction, remoteKeys).next(\n      documents => {\n        const previousResults = this.applyQuery(query, documents);\n\n        if (\n          (query.hasLimitToFirst() || query.hasLimitToLast()) &&\n          this.needsRefill(\n            query.limitType,\n            previousResults,\n            remoteKeys,\n            lastLimboFreeSnapshotVersion\n          )\n        ) {\n          return this.executeFullCollectionScan(transaction, query);\n        }\n\n        if (getLogLevel() <= LogLevel.DEBUG) {\n          logDebug(\n            'IndexFreeQueryEngine',\n            'Re-using previous result from %s to execute query: %s',\n            lastLimboFreeSnapshotVersion.toString(),\n            query.toString()\n          );\n        }\n\n        // Retrieve all results for documents that were updated since the last\n        // limbo-document free remote snapshot.\n        return this.localDocumentsView!.getDocumentsMatchingQuery(\n          transaction,\n          query,\n          lastLimboFreeSnapshotVersion\n        ).next(updatedResults => {\n          // We merge `previousResults` into `updateResults`, since\n          // `updateResults` is already a DocumentMap. If a document is\n          // contained in both lists, then its contents are the same.\n          previousResults.forEach(doc => {\n            updatedResults = updatedResults.insert(doc.key, doc);\n          });\n          return updatedResults;\n        });\n      }\n    );\n  }\n\n  /** Applies the query filter and sorting to the provided documents.  */\n  private applyQuery(\n    query: Query,\n    documents: MaybeDocumentMap\n  ): SortedSet<Document> {\n    // Sort the documents and re-apply the query filter since previously\n    // matching documents do not necessarily still match the query.\n    let queryResults = new SortedSet<Document>((d1, d2) =>\n      query.docComparator(d1, d2)\n    );\n    documents.forEach((_, maybeDoc) => {\n      if (maybeDoc instanceof Document && query.matches(maybeDoc)) {\n        queryResults = queryResults.add(maybeDoc);\n      }\n    });\n    return queryResults;\n  }\n\n  /**\n   * Determines if a limit query needs to be refilled from cache, making it\n   * ineligible for index-free execution.\n   *\n   * @param sortedPreviousResults The documents that matched the query when it\n   * was last synchronized, sorted by the query's comparator.\n   * @param remoteKeys The document keys that matched the query at the last\n   * snapshot.\n   * @param limboFreeSnapshotVersion The version of the snapshot when the query\n   * was last synchronized.\n   */\n  private needsRefill(\n    limitType: LimitType,\n    sortedPreviousResults: SortedSet<Document>,\n    remoteKeys: DocumentKeySet,\n    limboFreeSnapshotVersion: SnapshotVersion\n  ): boolean {\n    // The query needs to be refilled if a previously matching document no\n    // longer matches.\n    if (remoteKeys.size !== sortedPreviousResults.size) {\n      return true;\n    }\n\n    // Limit queries are not eligible for index-free query execution if there is\n    // a potential that an older document from cache now sorts before a document\n    // that was previously part of the limit. This, however, can only happen if\n    // the document at the edge of the limit goes out of limit.\n    // If a document that is not the limit boundary sorts differently,\n    // the boundary of the limit itself did not change and documents from cache\n    // will continue to be \"rejected\" by this boundary. Therefore, we can ignore\n    // any modifications that don't affect the last document.\n    const docAtLimitEdge =\n      limitType === LimitType.First\n        ? sortedPreviousResults.last()\n        : sortedPreviousResults.first();\n    if (!docAtLimitEdge) {\n      // We don't need to refill the query if there were already no documents.\n      return false;\n    }\n    return (\n      docAtLimitEdge.hasPendingWrites ||\n      docAtLimitEdge.version.compareTo(limboFreeSnapshotVersion) > 0\n    );\n  }\n\n  private executeFullCollectionScan(\n    transaction: PersistenceTransaction,\n    query: Query\n  ): PersistencePromise<DocumentMap> {\n    if (getLogLevel() <= LogLevel.DEBUG) {\n      logDebug(\n        'IndexFreeQueryEngine',\n        'Using full collection scan to execute query: %s',\n        query.toString()\n      );\n    }\n\n    return this.localDocumentsView!.getDocumentsMatchingQuery(\n      transaction,\n      query,\n      SnapshotVersion.MIN\n    );\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { ResourcePath } from '../model/path';\nimport { fail, hardAssert } from '../util/assert';\n\n/**\n * Helpers for dealing with resource paths stored in IndexedDB.\n *\n * Resource paths in their canonical string form do not sort as the server\n * sorts them. Specifically the server splits paths into segments first and then\n * sorts, putting end-of-segment before any character. In a UTF-8 string\n * encoding the slash ('/') that denotes the end-of-segment naturally comes\n * after other characters so the intent here is to encode the path delimiters in\n * such a way that the resulting strings sort naturally.\n *\n * Resource paths are also used for prefix scans so it's important to\n * distinguish whole segments from any longer segments of which they might be a\n * prefix. For example, it's important to make it possible to scan documents in\n * a collection \"foo\" without encountering documents in a collection \"foobar\".\n *\n * Separate from the concerns about resource path ordering and separation,\n * On Android, SQLite imposes additional restrictions since it does not handle\n * keys with embedded NUL bytes particularly well. Rather than change the\n * implementation we keep the encoding identical to keep the ports similar.\n *\n * Taken together this means resource paths when encoded for storage in\n * IndexedDB have the following characteristics:\n *\n *   * Segment separators (\"/\") sort before everything else.\n *   * All paths have a trailing separator.\n *   * NUL bytes do not exist in the output, since IndexedDB doesn't treat them\n * well.\n *\n * Therefore resource paths are encoded into string form using the following\n * rules:\n *\n *   * '\\x01' is used as an escape character.\n *   * Path separators are encoded as \"\\x01\\x01\"\n *   * NUL bytes are encoded as \"\\x01\\x10\"\n *   * '\\x01' is encoded as \"\\x01\\x11\"\n *\n * This encoding leaves some room between path separators and the NUL byte\n * just in case we decide to support integer document ids after all.\n *\n * Note that characters treated specially by the backend ('.', '/', and '~')\n * are not treated specially here. This class assumes that any unescaping of\n * resource path strings into actual ResourcePath objects will handle these\n * characters there.\n */\nexport type EncodedResourcePath = string;\n\nconst escapeChar = '\\u0001';\nconst encodedSeparatorChar = '\\u0001';\nconst encodedNul = '\\u0010';\nconst encodedEscape = '\\u0011';\n\n/**\n * Encodes a resource path into a IndexedDb-compatible string form.\n */\nexport function encodeResourcePath(path: ResourcePath): EncodedResourcePath {\n  let result = '';\n  for (let i = 0; i < path.length; i++) {\n    if (result.length > 0) {\n      result = encodeSeparator(result);\n    }\n    result = encodeSegment(path.get(i), result);\n  }\n  return encodeSeparator(result);\n}\n\n/** Encodes a single segment of a resource path into the given result */\nfunction encodeSegment(segment: string, resultBuf: string): string {\n  let result = resultBuf;\n  const length = segment.length;\n  for (let i = 0; i < length; i++) {\n    const c = segment.charAt(i);\n    switch (c) {\n      case '\\0':\n        result += escapeChar + encodedNul;\n        break;\n      case escapeChar:\n        result += escapeChar + encodedEscape;\n        break;\n      default:\n        result += c;\n    }\n  }\n  return result;\n}\n\n/** Encodes a path separator into the given result */\nfunction encodeSeparator(result: string): string {\n  return result + escapeChar + encodedSeparatorChar;\n}\n\n/**\n * Decodes the given IndexedDb-compatible string form of a resource path into\n * a ResourcePath instance. Note that this method is not suitable for use with\n * decoding resource names from the server; those are One Platform format\n * strings.\n */\nexport function decodeResourcePath(path: EncodedResourcePath): ResourcePath {\n  // Event the empty path must encode as a path of at least length 2. A path\n  // with exactly 2 must be the empty path.\n  const length = path.length;\n  hardAssert(length >= 2, 'Invalid path ' + path);\n  if (length === 2) {\n    hardAssert(\n      path.charAt(0) === escapeChar && path.charAt(1) === encodedSeparatorChar,\n      'Non-empty path ' + path + ' had length 2'\n    );\n    return ResourcePath.EMPTY_PATH;\n  }\n\n  // Escape characters cannot exist past the second-to-last position in the\n  // source value.\n  const lastReasonableEscapeIndex = length - 2;\n\n  const segments: string[] = [];\n  let segmentBuilder = '';\n\n  for (let start = 0; start < length; ) {\n    // The last two characters of a valid encoded path must be a separator, so\n    // there must be an end to this segment.\n    const end = path.indexOf(escapeChar, start);\n    if (end < 0 || end > lastReasonableEscapeIndex) {\n      fail('Invalid encoded resource path: \"' + path + '\"');\n    }\n\n    const next = path.charAt(end + 1);\n    switch (next) {\n      case encodedSeparatorChar:\n        const currentPiece = path.substring(start, end);\n        let segment;\n        if (segmentBuilder.length === 0) {\n          // Avoid copying for the common case of a segment that excludes \\0\n          // and \\001\n          segment = currentPiece;\n        } else {\n          segmentBuilder += currentPiece;\n          segment = segmentBuilder;\n          segmentBuilder = '';\n        }\n        segments.push(segment);\n        break;\n      case encodedNul:\n        segmentBuilder += path.substring(start, end);\n        segmentBuilder += '\\0';\n        break;\n      case encodedEscape:\n        // The escape character can be used in the output to encode itself.\n        segmentBuilder += path.substring(start, end + 1);\n        break;\n      default:\n        fail('Invalid encoded resource path: \"' + path + '\"');\n    }\n\n    start = end + 2;\n  }\n\n  return new ResourcePath(segments);\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { getUA } from '@firebase/util';\nimport { debugAssert } from '../util/assert';\nimport { Code, FirestoreError } from '../util/error';\nimport { logDebug, logError } from '../util/log';\nimport { Deferred } from '../util/promise';\nimport { SCHEMA_VERSION } from './indexeddb_schema';\nimport { PersistencePromise } from './persistence_promise';\n\nconst LOG_TAG = 'SimpleDb';\n\n/**\n * The maximum number of retry attempts for an IndexedDb transaction that fails\n * with a DOMException.\n */\nconst TRANSACTION_RETRY_COUNT = 3;\n\n// The different modes supported by `SimpleDb.runTransaction()`\ntype SimpleDbTransactionMode = 'readonly' | 'readwrite';\n\nexport interface SimpleDbSchemaConverter {\n  createOrUpgrade(\n    db: IDBDatabase,\n    txn: IDBTransaction,\n    fromVersion: number,\n    toVersion: number\n  ): PersistencePromise<void>;\n}\n\n/**\n * Provides a wrapper around IndexedDb with a simplified interface that uses\n * Promise-like return values to chain operations. Real promises cannot be used\n * since .then() continuations are executed asynchronously (e.g. via\n * .setImmediate), which would cause IndexedDB to end the transaction.\n * See PersistencePromise for more details.\n */\nexport class SimpleDb {\n  /**\n   * Opens the specified database, creating or upgrading it if necessary.\n   *\n   * Note that `version` must not be a downgrade. IndexedDB does not support downgrading the schema\n   * version. We currently do not support any way to do versioning outside of IndexedDB's versioning\n   * mechanism, as only version-upgrade transactions are allowed to do things like create\n   * objectstores.\n   */\n  static openOrCreate(\n    name: string,\n    version: number,\n    schemaConverter: SimpleDbSchemaConverter\n  ): Promise<SimpleDb> {\n    debugAssert(\n      SimpleDb.isAvailable(),\n      'IndexedDB not supported in current environment.'\n    );\n    logDebug(LOG_TAG, 'Opening database:', name);\n    return new PersistencePromise<SimpleDb>((resolve, reject) => {\n      // TODO(mikelehen): Investigate browser compatibility.\n      // https://developer.mozilla.org/en-US/docs/Web/API/IndexedDB_API/Using_IndexedDB\n      // suggests IE9 and older WebKit browsers handle upgrade\n      // differently. They expect setVersion, as described here:\n      // https://developer.mozilla.org/en-US/docs/Web/API/IDBVersionChangeRequest/setVersion\n      const request = window.indexedDB.open(name, version);\n\n      request.onsuccess = (event: Event) => {\n        const db = (event.target as IDBOpenDBRequest).result;\n        resolve(new SimpleDb(db));\n      };\n\n      request.onblocked = () => {\n        reject(\n          new FirestoreError(\n            Code.FAILED_PRECONDITION,\n            'Cannot upgrade IndexedDB schema while another tab is open. ' +\n              'Close all tabs that access Firestore and reload this page to proceed.'\n          )\n        );\n      };\n\n      request.onerror = (event: Event) => {\n        const error: DOMException = (event.target as IDBOpenDBRequest).error!;\n        if (error.name === 'VersionError') {\n          reject(\n            new FirestoreError(\n              Code.FAILED_PRECONDITION,\n              'A newer version of the Firestore SDK was previously used and so the persisted ' +\n                'data is not compatible with the version of the SDK you are now using. The SDK ' +\n                'will operate with persistence disabled. If you need persistence, please ' +\n                're-upgrade to a newer version of the SDK or else clear the persisted IndexedDB ' +\n                'data for your app to start fresh.'\n            )\n          );\n        } else {\n          reject(error);\n        }\n      };\n\n      request.onupgradeneeded = (event: IDBVersionChangeEvent) => {\n        logDebug(\n          LOG_TAG,\n          'Database \"' + name + '\" requires upgrade from version:',\n          event.oldVersion\n        );\n        const db = (event.target as IDBOpenDBRequest).result;\n        schemaConverter\n          .createOrUpgrade(\n            db,\n            request.transaction!,\n            event.oldVersion,\n            SCHEMA_VERSION\n          )\n          .next(() => {\n            logDebug(\n              LOG_TAG,\n              'Database upgrade to version ' + SCHEMA_VERSION + ' complete'\n            );\n          });\n      };\n    }).toPromise();\n  }\n\n  /** Deletes the specified database. */\n  static delete(name: string): Promise<void> {\n    logDebug(LOG_TAG, 'Removing database:', name);\n    return wrapRequest<void>(window.indexedDB.deleteDatabase(name)).toPromise();\n  }\n\n  /** Returns true if IndexedDB is available in the current environment. */\n  static isAvailable(): boolean {\n    if (typeof window === 'undefined' || window.indexedDB == null) {\n      return false;\n    }\n\n    if (SimpleDb.isMockPersistence()) {\n      return true;\n    }\n\n    // In some Node environments, `window` is defined, but `window.navigator` is\n    // not. We don't support IndexedDB persistence in Node if the\n    // isMockPersistence() check above returns false.\n    if (window.navigator === undefined) {\n      return false;\n    }\n\n    // We extensively use indexed array values and compound keys,\n    // which IE and Edge do not support. However, they still have indexedDB\n    // defined on the window, so we need to check for them here and make sure\n    // to return that persistence is not enabled for those browsers.\n    // For tracking support of this feature, see here:\n    // https://developer.microsoft.com/en-us/microsoft-edge/platform/status/indexeddbarraysandmultientrysupport/\n\n    // Check the UA string to find out the browser.\n    const ua = getUA();\n\n    // IE 10\n    // ua = 'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.2; Trident/6.0)';\n\n    // IE 11\n    // ua = 'Mozilla/5.0 (Windows NT 6.3; Trident/7.0; rv:11.0) like Gecko';\n\n    // Edge\n    // ua = 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML,\n    // like Gecko) Chrome/39.0.2171.71 Safari/537.36 Edge/12.0';\n\n    // iOS Safari: Disable for users running iOS version < 10.\n    const iOSVersion = SimpleDb.getIOSVersion(ua);\n    const isUnsupportedIOS = 0 < iOSVersion && iOSVersion < 10;\n\n    // Android browser: Disable for userse running version < 4.5.\n    const androidVersion = SimpleDb.getAndroidVersion(ua);\n    const isUnsupportedAndroid = 0 < androidVersion && androidVersion < 4.5;\n\n    if (\n      ua.indexOf('MSIE ') > 0 ||\n      ua.indexOf('Trident/') > 0 ||\n      ua.indexOf('Edge/') > 0 ||\n      isUnsupportedIOS ||\n      isUnsupportedAndroid\n    ) {\n      return false;\n    } else {\n      return true;\n    }\n  }\n\n  /**\n   * Returns true if the backing IndexedDB store is the Node IndexedDBShim\n   * (see https://github.com/axemclion/IndexedDBShim).\n   */\n  static isMockPersistence(): boolean {\n    return (\n      typeof process !== 'undefined' &&\n      process.env?.USE_MOCK_PERSISTENCE === 'YES'\n    );\n  }\n\n  /** Helper to get a typed SimpleDbStore from a transaction. */\n  static getStore<KeyType extends IDBValidKey, ValueType extends unknown>(\n    txn: SimpleDbTransaction,\n    store: string\n  ): SimpleDbStore<KeyType, ValueType> {\n    return txn.store<KeyType, ValueType>(store);\n  }\n\n  // visible for testing\n  /** Parse User Agent to determine iOS version. Returns -1 if not found. */\n  static getIOSVersion(ua: string): number {\n    const iOSVersionRegex = ua.match(/i(?:phone|pad|pod) os ([\\d_]+)/i);\n    const version = iOSVersionRegex\n      ? iOSVersionRegex[1]\n          .split('_')\n          .slice(0, 2)\n          .join('.')\n      : '-1';\n    return Number(version);\n  }\n\n  // visible for testing\n  /** Parse User Agent to determine Android version. Returns -1 if not found. */\n  static getAndroidVersion(ua: string): number {\n    const androidVersionRegex = ua.match(/Android ([\\d.]+)/i);\n    const version = androidVersionRegex\n      ? androidVersionRegex[1]\n          .split('.')\n          .slice(0, 2)\n          .join('.')\n      : '-1';\n    return Number(version);\n  }\n\n  constructor(private db: IDBDatabase) {\n    const iOSVersion = SimpleDb.getIOSVersion(getUA());\n    // NOTE: According to https://bugs.webkit.org/show_bug.cgi?id=197050, the\n    // bug we're checking for should exist in iOS >= 12.2 and < 13, but for\n    // whatever reason it's much harder to hit after 12.2 so we only proactively\n    // log on 12.2.\n    if (iOSVersion === 12.2) {\n      logError(\n        'Firestore persistence suffers from a bug in iOS 12.2 ' +\n          'Safari that may cause your app to stop working. See ' +\n          'https://stackoverflow.com/q/56496296/110915 for details ' +\n          'and a potential workaround.'\n      );\n    }\n  }\n\n  setVersionChangeListener(\n    versionChangeListener: (event: IDBVersionChangeEvent) => void\n  ): void {\n    this.db.onversionchange = (event: IDBVersionChangeEvent) => {\n      return versionChangeListener(event);\n    };\n  }\n\n  async runTransaction<T>(\n    mode: SimpleDbTransactionMode,\n    objectStores: string[],\n    transactionFn: (transaction: SimpleDbTransaction) => PersistencePromise<T>\n  ): Promise<T> {\n    const readonly = mode === 'readonly';\n    let attemptNumber = 0;\n\n    while (true) {\n      ++attemptNumber;\n\n      const transaction = SimpleDbTransaction.open(\n        this.db,\n        readonly ? 'readonly' : 'readwrite',\n        objectStores\n      );\n      try {\n        const transactionFnResult = transactionFn(transaction)\n          .catch(error => {\n            // Abort the transaction if there was an error.\n            transaction.abort(error);\n            // We cannot actually recover, and calling `abort()` will cause the transaction's\n            // completion promise to be rejected. This in turn means that we won't use\n            // `transactionFnResult` below. We return a rejection here so that we don't add the\n            // possibility of returning `void` to the type of `transactionFnResult`.\n            return PersistencePromise.reject<T>(error);\n          })\n          .toPromise();\n\n        // As noted above, errors are propagated by aborting the transaction. So\n        // we swallow any error here to avoid the browser logging it as unhandled.\n        transactionFnResult.catch(() => {});\n\n        // Wait for the transaction to complete (i.e. IndexedDb's onsuccess event to\n        // fire), but still return the original transactionFnResult back to the\n        // caller.\n        await transaction.completionPromise;\n        return transactionFnResult;\n      } catch (error) {\n        // TODO(schmidt-sebastian): We could probably be smarter about this and\n        // not retry exceptions that are likely unrecoverable (such as quota\n        // exceeded errors).\n\n        // Note: We cannot use an instanceof check for FirestoreException, since the\n        // exception is wrapped in a generic error by our async/await handling.\n        const retryable =\n          error.name !== 'FirebaseError' &&\n          attemptNumber < TRANSACTION_RETRY_COUNT;\n        logDebug(\n          LOG_TAG,\n          'Transaction failed with error: %s. Retrying: %s.',\n          error.message,\n          retryable\n        );\n\n        if (!retryable) {\n          return Promise.reject(error);\n        }\n      }\n    }\n  }\n\n  close(): void {\n    this.db.close();\n  }\n}\n\n/**\n * A controller for iterating over a key range or index. It allows an iterate\n * callback to delete the currently-referenced object, or jump to a new key\n * within the key range or index.\n */\nexport class IterationController {\n  private shouldStop = false;\n  private nextKey: IDBValidKey | null = null;\n\n  constructor(private dbCursor: IDBCursorWithValue) {}\n\n  get isDone(): boolean {\n    return this.shouldStop;\n  }\n\n  get skipToKey(): IDBValidKey | null {\n    return this.nextKey;\n  }\n\n  set cursor(value: IDBCursorWithValue) {\n    this.dbCursor = value;\n  }\n\n  /**\n   * This function can be called to stop iteration at any point.\n   */\n  done(): void {\n    this.shouldStop = true;\n  }\n\n  /**\n   * This function can be called to skip to that next key, which could be\n   * an index or a primary key.\n   */\n  skip(key: IDBValidKey): void {\n    this.nextKey = key;\n  }\n\n  /**\n   * Delete the current cursor value from the object store.\n   *\n   * NOTE: You CANNOT do this with a keysOnly query.\n   */\n  delete(): PersistencePromise<void> {\n    return wrapRequest<void>(this.dbCursor.delete());\n  }\n}\n\n/**\n * Callback used with iterate() method.\n */\nexport type IterateCallback<KeyType, ValueType> = (\n  key: KeyType,\n  value: ValueType,\n  control: IterationController\n) => void | PersistencePromise<void>;\n\n/** Options available to the iterate() method. */\nexport interface IterateOptions {\n  /** Index to iterate over (else primary keys will be iterated) */\n  index?: string;\n\n  /** IndxedDB Range to iterate over (else entire store will be iterated) */\n  range?: IDBKeyRange;\n\n  /** If true, values aren't read while iterating. */\n  keysOnly?: boolean;\n\n  /** If true, iterate over the store in reverse. */\n  reverse?: boolean;\n}\n\n/**\n * Wraps an IDBTransaction and exposes a store() method to get a handle to a\n * specific object store.\n */\nexport class SimpleDbTransaction {\n  private aborted = false;\n\n  /**\n   * A promise that resolves with the result of the IndexedDb transaction.\n   */\n  private readonly completionDeferred = new Deferred<void>();\n\n  static open(\n    db: IDBDatabase,\n    mode: IDBTransactionMode,\n    objectStoreNames: string[]\n  ): SimpleDbTransaction {\n    return new SimpleDbTransaction(db.transaction(objectStoreNames, mode));\n  }\n\n  constructor(private readonly transaction: IDBTransaction) {\n    this.transaction.oncomplete = () => {\n      this.completionDeferred.resolve();\n    };\n    this.transaction.onabort = () => {\n      if (transaction.error) {\n        this.completionDeferred.reject(transaction.error);\n      } else {\n        this.completionDeferred.resolve();\n      }\n    };\n    this.transaction.onerror = (event: Event) => {\n      const error = checkForAndReportiOSError(\n        (event.target as IDBRequest).error!\n      );\n      this.completionDeferred.reject(error);\n    };\n  }\n\n  get completionPromise(): Promise<void> {\n    return this.completionDeferred.promise;\n  }\n\n  abort(error?: Error): void {\n    if (error) {\n      this.completionDeferred.reject(error);\n    }\n\n    if (!this.aborted) {\n      logDebug(\n        LOG_TAG,\n        'Aborting transaction:',\n        error ? error.message : 'Client-initiated abort'\n      );\n      this.aborted = true;\n      this.transaction.abort();\n    }\n  }\n\n  /**\n   * Returns a SimpleDbStore<KeyType, ValueType> for the specified store. All\n   * operations performed on the SimpleDbStore happen within the context of this\n   * transaction and it cannot be used anymore once the transaction is\n   * completed.\n   *\n   * Note that we can't actually enforce that the KeyType and ValueType are\n   * correct, but they allow type safety through the rest of the consuming code.\n   */\n  store<KeyType extends IDBValidKey, ValueType extends unknown>(\n    storeName: string\n  ): SimpleDbStore<KeyType, ValueType> {\n    const store = this.transaction.objectStore(storeName);\n    debugAssert(!!store, 'Object store not part of transaction: ' + storeName);\n    return new SimpleDbStore<KeyType, ValueType>(store);\n  }\n}\n\n/**\n * A wrapper around an IDBObjectStore providing an API that:\n *\n * 1) Has generic KeyType / ValueType parameters to provide strongly-typed\n * methods for acting against the object store.\n * 2) Deals with IndexedDB's onsuccess / onerror event callbacks, making every\n * method return a PersistencePromise instead.\n * 3) Provides a higher-level API to avoid needing to do excessive wrapping of\n * intermediate IndexedDB types (IDBCursorWithValue, etc.)\n */\nexport class SimpleDbStore<\n  KeyType extends IDBValidKey,\n  ValueType extends unknown\n> {\n  constructor(private store: IDBObjectStore) {}\n\n  /**\n   * Writes a value into the Object Store.\n   *\n   * @param key Optional explicit key to use when writing the object, else the\n   * key will be auto-assigned (e.g. via the defined keyPath for the store).\n   * @param value The object to write.\n   */\n  put(value: ValueType): PersistencePromise<void>;\n  put(key: KeyType, value: ValueType): PersistencePromise<void>;\n  put(\n    keyOrValue: KeyType | ValueType,\n    value?: ValueType\n  ): PersistencePromise<void> {\n    let request;\n    if (value !== undefined) {\n      logDebug(LOG_TAG, 'PUT', this.store.name, keyOrValue, value);\n      request = this.store.put(value, keyOrValue as KeyType);\n    } else {\n      logDebug(LOG_TAG, 'PUT', this.store.name, '<auto-key>', keyOrValue);\n      request = this.store.put(keyOrValue as ValueType);\n    }\n    return wrapRequest<void>(request);\n  }\n\n  /**\n   * Adds a new value into an Object Store and returns the new key. Similar to\n   * IndexedDb's `add()`, this method will fail on primary key collisions.\n   *\n   * @param value The object to write.\n   * @return The key of the value to add.\n   */\n  add(value: ValueType): PersistencePromise<KeyType> {\n    logDebug(LOG_TAG, 'ADD', this.store.name, value, value);\n    const request = this.store.add(value as ValueType);\n    return wrapRequest<KeyType>(request);\n  }\n\n  /**\n   * Gets the object with the specified key from the specified store, or null\n   * if no object exists with the specified key.\n   *\n   * @key The key of the object to get.\n   * @return The object with the specified key or null if no object exists.\n   */\n  get(key: KeyType): PersistencePromise<ValueType | null> {\n    const request = this.store.get(key);\n    // We're doing an unsafe cast to ValueType.\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    return wrapRequest<any>(request).next(result => {\n      // Normalize nonexistence to null.\n      if (result === undefined) {\n        result = null;\n      }\n      logDebug(LOG_TAG, 'GET', this.store.name, key, result);\n      return result;\n    });\n  }\n\n  delete(key: KeyType | IDBKeyRange): PersistencePromise<void> {\n    logDebug(LOG_TAG, 'DELETE', this.store.name, key);\n    const request = this.store.delete(key);\n    return wrapRequest<void>(request);\n  }\n\n  /**\n   * If we ever need more of the count variants, we can add overloads. For now,\n   * all we need is to count everything in a store.\n   *\n   * Returns the number of rows in the store.\n   */\n  count(): PersistencePromise<number> {\n    logDebug(LOG_TAG, 'COUNT', this.store.name);\n    const request = this.store.count();\n    return wrapRequest<number>(request);\n  }\n\n  loadAll(): PersistencePromise<ValueType[]>;\n  loadAll(range: IDBKeyRange): PersistencePromise<ValueType[]>;\n  loadAll(index: string, range: IDBKeyRange): PersistencePromise<ValueType[]>;\n  loadAll(\n    indexOrRange?: string | IDBKeyRange,\n    range?: IDBKeyRange\n  ): PersistencePromise<ValueType[]> {\n    const cursor = this.cursor(this.options(indexOrRange, range));\n    const results: ValueType[] = [];\n    return this.iterateCursor(cursor, (key, value) => {\n      results.push(value);\n    }).next(() => {\n      return results;\n    });\n  }\n\n  deleteAll(): PersistencePromise<void>;\n  deleteAll(range: IDBKeyRange): PersistencePromise<void>;\n  deleteAll(index: string, range: IDBKeyRange): PersistencePromise<void>;\n  deleteAll(\n    indexOrRange?: string | IDBKeyRange,\n    range?: IDBKeyRange\n  ): PersistencePromise<void> {\n    logDebug(LOG_TAG, 'DELETE ALL', this.store.name);\n    const options = this.options(indexOrRange, range);\n    options.keysOnly = false;\n    const cursor = this.cursor(options);\n    return this.iterateCursor(cursor, (key, value, control) => {\n      // NOTE: Calling delete() on a cursor is documented as more efficient than\n      // calling delete() on an object store with a single key\n      // (https://developer.mozilla.org/en-US/docs/Web/API/IDBObjectStore/delete),\n      // however, this requires us *not* to use a keysOnly cursor\n      // (https://developer.mozilla.org/en-US/docs/Web/API/IDBCursor/delete). We\n      // may want to compare the performance of each method.\n      return control.delete();\n    });\n  }\n\n  /**\n   * Iterates over keys and values in an object store.\n   *\n   * @param options Options specifying how to iterate the objects in the store.\n   * @param callback will be called for each iterated object. Iteration can be\n   * canceled at any point by calling the doneFn passed to the callback.\n   * The callback can return a PersistencePromise if it performs async\n   * operations but note that iteration will continue without waiting for them\n   * to complete.\n   * @returns A PersistencePromise that resolves once all PersistencePromises\n   * returned by callbacks resolve.\n   */\n  iterate(\n    callback: IterateCallback<KeyType, ValueType>\n  ): PersistencePromise<void>;\n  iterate(\n    options: IterateOptions,\n    callback: IterateCallback<KeyType, ValueType>\n  ): PersistencePromise<void>;\n  iterate(\n    optionsOrCallback: IterateOptions | IterateCallback<KeyType, ValueType>,\n    callback?: IterateCallback<KeyType, ValueType>\n  ): PersistencePromise<void> {\n    let options;\n    if (!callback) {\n      options = {};\n      callback = optionsOrCallback as IterateCallback<KeyType, ValueType>;\n    } else {\n      options = optionsOrCallback as IterateOptions;\n    }\n    const cursor = this.cursor(options);\n    return this.iterateCursor(cursor, callback);\n  }\n\n  /**\n   * Iterates over a store, but waits for the given callback to complete for\n   * each entry before iterating the next entry. This allows the callback to do\n   * asynchronous work to determine if this iteration should continue.\n   *\n   * The provided callback should return `true` to continue iteration, and\n   * `false` otherwise.\n   */\n  iterateSerial(\n    callback: (k: KeyType, v: ValueType) => PersistencePromise<boolean>\n  ): PersistencePromise<void> {\n    const cursorRequest = this.cursor({});\n    return new PersistencePromise((resolve, reject) => {\n      cursorRequest.onerror = (event: Event) => {\n        const error = checkForAndReportiOSError(\n          (event.target as IDBRequest).error!\n        );\n        reject(error);\n      };\n      cursorRequest.onsuccess = (event: Event) => {\n        const cursor: IDBCursorWithValue = (event.target as IDBRequest).result;\n        if (!cursor) {\n          resolve();\n          return;\n        }\n\n        callback(cursor.primaryKey as KeyType, cursor.value).next(\n          shouldContinue => {\n            if (shouldContinue) {\n              cursor.continue();\n            } else {\n              resolve();\n            }\n          }\n        );\n      };\n    });\n  }\n\n  private iterateCursor(\n    cursorRequest: IDBRequest,\n    fn: IterateCallback<KeyType, ValueType>\n  ): PersistencePromise<void> {\n    const results: Array<PersistencePromise<void>> = [];\n    return new PersistencePromise((resolve, reject) => {\n      cursorRequest.onerror = (event: Event) => {\n        reject((event.target as IDBRequest).error!);\n      };\n      cursorRequest.onsuccess = (event: Event) => {\n        const cursor: IDBCursorWithValue = (event.target as IDBRequest).result;\n        if (!cursor) {\n          resolve();\n          return;\n        }\n        const controller = new IterationController(cursor);\n        const userResult = fn(\n          cursor.primaryKey as KeyType,\n          cursor.value,\n          controller\n        );\n        if (userResult instanceof PersistencePromise) {\n          const userPromise: PersistencePromise<void> = userResult.catch(\n            err => {\n              controller.done();\n              return PersistencePromise.reject(err);\n            }\n          );\n          results.push(userPromise);\n        }\n        if (controller.isDone) {\n          resolve();\n        } else if (controller.skipToKey === null) {\n          cursor.continue();\n        } else {\n          cursor.continue(controller.skipToKey);\n        }\n      };\n    }).next(() => {\n      return PersistencePromise.waitFor(results);\n    });\n  }\n\n  private options(\n    indexOrRange?: string | IDBKeyRange,\n    range?: IDBKeyRange\n  ): IterateOptions {\n    let indexName: string | undefined = undefined;\n    if (indexOrRange !== undefined) {\n      if (typeof indexOrRange === 'string') {\n        indexName = indexOrRange;\n      } else {\n        debugAssert(\n          range === undefined,\n          '3rd argument must not be defined if 2nd is a range.'\n        );\n        range = indexOrRange;\n      }\n    }\n    return { index: indexName, range };\n  }\n\n  private cursor(options: IterateOptions): IDBRequest {\n    let direction: IDBCursorDirection = 'next';\n    if (options.reverse) {\n      direction = 'prev';\n    }\n    if (options.index) {\n      const index = this.store.index(options.index);\n      if (options.keysOnly) {\n        return index.openKeyCursor(options.range, direction);\n      } else {\n        return index.openCursor(options.range, direction);\n      }\n    } else {\n      return this.store.openCursor(options.range, direction);\n    }\n  }\n}\n\n/**\n * Wraps an IDBRequest in a PersistencePromise, using the onsuccess / onerror\n * handlers to resolve / reject the PersistencePromise as appropriate.\n */\nfunction wrapRequest<R>(request: IDBRequest): PersistencePromise<R> {\n  return new PersistencePromise<R>((resolve, reject) => {\n    request.onsuccess = (event: Event) => {\n      const result = (event.target as IDBRequest).result;\n      resolve(result);\n    };\n\n    request.onerror = (event: Event) => {\n      const error = checkForAndReportiOSError(\n        (event.target as IDBRequest).error!\n      );\n      reject(error);\n    };\n  });\n}\n\n// Guard so we only report the error once.\nlet reportedIOSError = false;\nfunction checkForAndReportiOSError(error: DOMException): Error {\n  const iOSVersion = SimpleDb.getIOSVersion(getUA());\n  if (iOSVersion >= 12.2 && iOSVersion < 13) {\n    const IOS_ERROR =\n      'An internal error was encountered in the Indexed Database server';\n    if (error.message.indexOf(IOS_ERROR) >= 0) {\n      // Wrap error in a more descriptive one.\n      const newError = new FirestoreError(\n        'internal',\n        `IOS_INDEXEDDB_BUG1: IndexedDb has thrown '${IOS_ERROR}'. This is likely ` +\n          `due to an unavoidable bug in iOS. See https://stackoverflow.com/q/56496296/110915 ` +\n          `for details and a potential workaround.`\n      );\n      if (!reportedIOSError) {\n        reportedIOSError = true;\n        // Throw a global exception outside of this promise chain, for the user to\n        // potentially catch.\n        setTimeout(() => {\n          throw newError;\n        }, 0);\n      }\n      return newError;\n    }\n  }\n  return error;\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Timestamp } from '../api/timestamp';\nimport { User } from '../auth/user';\nimport { Query } from '../core/query';\nimport { BatchId } from '../core/types';\nimport { DocumentKeySet } from '../model/collections';\nimport { DocumentKey } from '../model/document_key';\nimport { Mutation } from '../model/mutation';\nimport { BATCHID_UNKNOWN, MutationBatch } from '../model/mutation_batch';\nimport { ResourcePath } from '../model/path';\nimport { debugAssert, fail, hardAssert } from '../util/assert';\nimport { primitiveComparator } from '../util/misc';\nimport { ByteString } from '../util/byte_string';\nimport { SortedMap } from '../util/sorted_map';\nimport { SortedSet } from '../util/sorted_set';\nimport { decodeResourcePath } from './encoded_resource_path';\nimport { IndexManager } from './index_manager';\nimport {\n  IndexedDbPersistence,\n  IndexedDbTransaction\n} from './indexeddb_persistence';\nimport {\n  DbDocumentMutation,\n  DbDocumentMutationKey,\n  DbMutationBatch,\n  DbMutationBatchKey,\n  DbMutationQueue,\n  DbMutationQueueKey\n} from './indexeddb_schema';\nimport { LocalSerializer } from './local_serializer';\nimport { MutationQueue } from './mutation_queue';\nimport { PersistenceTransaction, ReferenceDelegate } from './persistence';\nimport { PersistencePromise } from './persistence_promise';\nimport { SimpleDbStore, SimpleDbTransaction } from './simple_db';\n\n/** A mutation queue for a specific user, backed by IndexedDB. */\nexport class IndexedDbMutationQueue implements MutationQueue {\n  /**\n   * Caches the document keys for pending mutation batches. If the mutation\n   * has been removed from IndexedDb, the cached value may continue to\n   * be used to retrieve the batch's document keys. To remove a cached value\n   * locally, `removeCachedMutationKeys()` should be invoked either directly\n   * or through `removeMutationBatches()`.\n   *\n   * With multi-tab, when the primary client acknowledges or rejects a mutation,\n   * this cache is used by secondary clients to invalidate the local\n   * view of the documents that were previously affected by the mutation.\n   */\n  // PORTING NOTE: Multi-tab only.\n  private documentKeysByBatchId = {} as { [batchId: number]: DocumentKeySet };\n\n  constructor(\n    /**\n     * The normalized userId (e.g. null UID => \"\" userId) used to store /\n     * retrieve mutations.\n     */\n    private userId: string,\n    private readonly serializer: LocalSerializer,\n    private readonly indexManager: IndexManager,\n    private readonly referenceDelegate: ReferenceDelegate\n  ) {}\n\n  /**\n   * Creates a new mutation queue for the given user.\n   * @param user The user for which to create a mutation queue.\n   * @param serializer The serializer to use when persisting to IndexedDb.\n   */\n  static forUser(\n    user: User,\n    serializer: LocalSerializer,\n    indexManager: IndexManager,\n    referenceDelegate: ReferenceDelegate\n  ): IndexedDbMutationQueue {\n    // TODO(mcg): Figure out what constraints there are on userIDs\n    // In particular, are there any reserved characters? are empty ids allowed?\n    // For the moment store these together in the same mutations table assuming\n    // that empty userIDs aren't allowed.\n    hardAssert(user.uid !== '', 'UserID must not be an empty string.');\n    const userId = user.isAuthenticated() ? user.uid! : '';\n    return new IndexedDbMutationQueue(\n      userId,\n      serializer,\n      indexManager,\n      referenceDelegate\n    );\n  }\n\n  checkEmpty(transaction: PersistenceTransaction): PersistencePromise<boolean> {\n    let empty = true;\n    const range = IDBKeyRange.bound(\n      [this.userId, Number.NEGATIVE_INFINITY],\n      [this.userId, Number.POSITIVE_INFINITY]\n    );\n    return mutationsStore(transaction)\n      .iterate(\n        { index: DbMutationBatch.userMutationsIndex, range },\n        (key, value, control) => {\n          empty = false;\n          control.done();\n        }\n      )\n      .next(() => empty);\n  }\n\n  acknowledgeBatch(\n    transaction: PersistenceTransaction,\n    batch: MutationBatch,\n    streamToken: ByteString\n  ): PersistencePromise<void> {\n    return this.getMutationQueueMetadata(transaction).next(metadata => {\n      // We can't store the resumeToken as a ByteString in IndexedDB, so we\n      // convert it to a Base64 string for storage.\n      metadata.lastStreamToken = streamToken.toBase64();\n\n      return mutationQueuesStore(transaction).put(metadata);\n    });\n  }\n\n  getLastStreamToken(\n    transaction: PersistenceTransaction\n  ): PersistencePromise<ByteString> {\n    return this.getMutationQueueMetadata(transaction).next<ByteString>(\n      metadata => ByteString.fromBase64String(metadata.lastStreamToken)\n    );\n  }\n\n  setLastStreamToken(\n    transaction: PersistenceTransaction,\n    streamToken: ByteString\n  ): PersistencePromise<void> {\n    return this.getMutationQueueMetadata(transaction).next(metadata => {\n      // We can't store the resumeToken as a ByteString in IndexedDB, so we\n      // convert it to a Base64 string for storage.\n      metadata.lastStreamToken = streamToken.toBase64();\n      return mutationQueuesStore(transaction).put(metadata);\n    });\n  }\n\n  addMutationBatch(\n    transaction: PersistenceTransaction,\n    localWriteTime: Timestamp,\n    baseMutations: Mutation[],\n    mutations: Mutation[]\n  ): PersistencePromise<MutationBatch> {\n    const documentStore = documentMutationsStore(transaction);\n    const mutationStore = mutationsStore(transaction);\n\n    // The IndexedDb implementation in Chrome (and Firefox) does not handle\n    // compound indices that include auto-generated keys correctly. To ensure\n    // that the index entry is added correctly in all browsers, we perform two\n    // writes: The first write is used to retrieve the next auto-generated Batch\n    // ID, and the second write populates the index and stores the actual\n    // mutation batch.\n    // See: https://bugs.chromium.org/p/chromium/issues/detail?id=701972\n\n    // We write an empty object to obtain key\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    return mutationStore.add({} as any).next(batchId => {\n      hardAssert(\n        typeof batchId === 'number',\n        'Auto-generated key is not a number'\n      );\n\n      const batch = new MutationBatch(\n        batchId,\n        localWriteTime,\n        baseMutations,\n        mutations\n      );\n      const dbBatch = this.serializer.toDbMutationBatch(this.userId, batch);\n\n      const promises: Array<PersistencePromise<void>> = [];\n      let collectionParents = new SortedSet<ResourcePath>((l, r) =>\n        primitiveComparator(l.canonicalString(), r.canonicalString())\n      );\n      for (const mutation of mutations) {\n        const indexKey = DbDocumentMutation.key(\n          this.userId,\n          mutation.key.path,\n          batchId\n        );\n        collectionParents = collectionParents.add(mutation.key.path.popLast());\n        promises.push(mutationStore.put(dbBatch));\n        promises.push(\n          documentStore.put(indexKey, DbDocumentMutation.PLACEHOLDER)\n        );\n      }\n\n      collectionParents.forEach(parent => {\n        promises.push(\n          this.indexManager.addToCollectionParentIndex(transaction, parent)\n        );\n      });\n\n      transaction.addOnCommittedListener(() => {\n        this.documentKeysByBatchId[batchId] = batch.keys();\n      });\n\n      return PersistencePromise.waitFor(promises).next(() => batch);\n    });\n  }\n\n  lookupMutationBatch(\n    transaction: PersistenceTransaction,\n    batchId: BatchId\n  ): PersistencePromise<MutationBatch | null> {\n    return mutationsStore(transaction)\n      .get(batchId)\n      .next(dbBatch => {\n        if (dbBatch) {\n          hardAssert(\n            dbBatch.userId === this.userId,\n            `Unexpected user '${dbBatch.userId}' for mutation batch ${batchId}`\n          );\n          return this.serializer.fromDbMutationBatch(dbBatch);\n        }\n        return null;\n      });\n  }\n\n  lookupMutationKeys(\n    transaction: PersistenceTransaction,\n    batchId: BatchId\n  ): PersistencePromise<DocumentKeySet | null> {\n    if (this.documentKeysByBatchId[batchId]) {\n      return PersistencePromise.resolve<DocumentKeySet | null>(\n        this.documentKeysByBatchId[batchId]\n      );\n    } else {\n      return this.lookupMutationBatch(transaction, batchId).next(batch => {\n        if (batch) {\n          const keys = batch.keys();\n          this.documentKeysByBatchId[batchId] = keys;\n          return keys;\n        } else {\n          return null;\n        }\n      });\n    }\n  }\n\n  getNextMutationBatchAfterBatchId(\n    transaction: PersistenceTransaction,\n    batchId: BatchId\n  ): PersistencePromise<MutationBatch | null> {\n    const nextBatchId = batchId + 1;\n\n    const range = IDBKeyRange.lowerBound([this.userId, nextBatchId]);\n    let foundBatch: MutationBatch | null = null;\n    return mutationsStore(transaction)\n      .iterate(\n        { index: DbMutationBatch.userMutationsIndex, range },\n        (key, dbBatch, control) => {\n          if (dbBatch.userId === this.userId) {\n            hardAssert(\n              dbBatch.batchId >= nextBatchId,\n              'Should have found mutation after ' + nextBatchId\n            );\n            foundBatch = this.serializer.fromDbMutationBatch(dbBatch);\n          }\n          control.done();\n        }\n      )\n      .next(() => foundBatch);\n  }\n\n  getHighestUnacknowledgedBatchId(\n    transaction: PersistenceTransaction\n  ): PersistencePromise<BatchId> {\n    const range = IDBKeyRange.upperBound([\n      this.userId,\n      Number.POSITIVE_INFINITY\n    ]);\n\n    let batchId = BATCHID_UNKNOWN;\n    return mutationsStore(transaction)\n      .iterate(\n        { index: DbMutationBatch.userMutationsIndex, range, reverse: true },\n        (key, dbBatch, control) => {\n          batchId = dbBatch.batchId;\n          control.done();\n        }\n      )\n      .next(() => batchId);\n  }\n\n  getAllMutationBatches(\n    transaction: PersistenceTransaction\n  ): PersistencePromise<MutationBatch[]> {\n    const range = IDBKeyRange.bound(\n      [this.userId, BATCHID_UNKNOWN],\n      [this.userId, Number.POSITIVE_INFINITY]\n    );\n    return mutationsStore(transaction)\n      .loadAll(DbMutationBatch.userMutationsIndex, range)\n      .next(dbBatches =>\n        dbBatches.map(dbBatch => this.serializer.fromDbMutationBatch(dbBatch))\n      );\n  }\n\n  getAllMutationBatchesAffectingDocumentKey(\n    transaction: PersistenceTransaction,\n    documentKey: DocumentKey\n  ): PersistencePromise<MutationBatch[]> {\n    // Scan the document-mutation index starting with a prefix starting with\n    // the given documentKey.\n    const indexPrefix = DbDocumentMutation.prefixForPath(\n      this.userId,\n      documentKey.path\n    );\n    const indexStart = IDBKeyRange.lowerBound(indexPrefix);\n\n    const results: MutationBatch[] = [];\n    return documentMutationsStore(transaction)\n      .iterate({ range: indexStart }, (indexKey, _, control) => {\n        const [userID, encodedPath, batchId] = indexKey;\n\n        // Only consider rows matching exactly the specific key of\n        // interest. Note that because we order by path first, and we\n        // order terminators before path separators, we'll encounter all\n        // the index rows for documentKey contiguously. In particular, all\n        // the rows for documentKey will occur before any rows for\n        // documents nested in a subcollection beneath documentKey so we\n        // can stop as soon as we hit any such row.\n        const path = decodeResourcePath(encodedPath);\n        if (userID !== this.userId || !documentKey.path.isEqual(path)) {\n          control.done();\n          return;\n        }\n        // Look up the mutation batch in the store.\n        return mutationsStore(transaction)\n          .get(batchId)\n          .next(mutation => {\n            if (!mutation) {\n              throw fail(\n                'Dangling document-mutation reference found: ' +\n                  indexKey +\n                  ' which points to ' +\n                  batchId\n              );\n            }\n            hardAssert(\n              mutation.userId === this.userId,\n              `Unexpected user '${mutation.userId}' for mutation batch ${batchId}`\n            );\n            results.push(this.serializer.fromDbMutationBatch(mutation));\n          });\n      })\n      .next(() => results);\n  }\n\n  getAllMutationBatchesAffectingDocumentKeys(\n    transaction: PersistenceTransaction,\n    documentKeys: SortedMap<DocumentKey, unknown>\n  ): PersistencePromise<MutationBatch[]> {\n    let uniqueBatchIDs = new SortedSet<BatchId>(primitiveComparator);\n\n    const promises: Array<PersistencePromise<void>> = [];\n    documentKeys.forEach(documentKey => {\n      const indexStart = DbDocumentMutation.prefixForPath(\n        this.userId,\n        documentKey.path\n      );\n      const range = IDBKeyRange.lowerBound(indexStart);\n\n      const promise = documentMutationsStore(transaction).iterate(\n        { range },\n        (indexKey, _, control) => {\n          const [userID, encodedPath, batchID] = indexKey;\n\n          // Only consider rows matching exactly the specific key of\n          // interest. Note that because we order by path first, and we\n          // order terminators before path separators, we'll encounter all\n          // the index rows for documentKey contiguously. In particular, all\n          // the rows for documentKey will occur before any rows for\n          // documents nested in a subcollection beneath documentKey so we\n          // can stop as soon as we hit any such row.\n          const path = decodeResourcePath(encodedPath);\n          if (userID !== this.userId || !documentKey.path.isEqual(path)) {\n            control.done();\n            return;\n          }\n\n          uniqueBatchIDs = uniqueBatchIDs.add(batchID);\n        }\n      );\n\n      promises.push(promise);\n    });\n\n    return PersistencePromise.waitFor(promises).next(() =>\n      this.lookupMutationBatches(transaction, uniqueBatchIDs)\n    );\n  }\n\n  getAllMutationBatchesAffectingQuery(\n    transaction: PersistenceTransaction,\n    query: Query\n  ): PersistencePromise<MutationBatch[]> {\n    debugAssert(\n      !query.isDocumentQuery(),\n      \"Document queries shouldn't go down this path\"\n    );\n    debugAssert(\n      !query.isCollectionGroupQuery(),\n      'CollectionGroup queries should be handled in LocalDocumentsView'\n    );\n\n    const queryPath = query.path;\n    const immediateChildrenLength = queryPath.length + 1;\n\n    // TODO(mcg): Actually implement a single-collection query\n    //\n    // This is actually executing an ancestor query, traversing the whole\n    // subtree below the collection which can be horrifically inefficient for\n    // some structures. The right way to solve this is to implement the full\n    // value index, but that's not in the cards in the near future so this is\n    // the best we can do for the moment.\n    //\n    // Since we don't yet index the actual properties in the mutations, our\n    // current approach is to just return all mutation batches that affect\n    // documents in the collection being queried.\n    const indexPrefix = DbDocumentMutation.prefixForPath(\n      this.userId,\n      queryPath\n    );\n    const indexStart = IDBKeyRange.lowerBound(indexPrefix);\n\n    // Collect up unique batchIDs encountered during a scan of the index. Use a\n    // SortedSet to accumulate batch IDs so they can be traversed in order in a\n    // scan of the main table.\n    let uniqueBatchIDs = new SortedSet<BatchId>(primitiveComparator);\n    return documentMutationsStore(transaction)\n      .iterate({ range: indexStart }, (indexKey, _, control) => {\n        const [userID, encodedPath, batchID] = indexKey;\n        const path = decodeResourcePath(encodedPath);\n        if (userID !== this.userId || !queryPath.isPrefixOf(path)) {\n          control.done();\n          return;\n        }\n        // Rows with document keys more than one segment longer than the\n        // query path can't be matches. For example, a query on 'rooms'\n        // can't match the document /rooms/abc/messages/xyx.\n        // TODO(mcg): we'll need a different scanner when we implement\n        // ancestor queries.\n        if (path.length !== immediateChildrenLength) {\n          return;\n        }\n        uniqueBatchIDs = uniqueBatchIDs.add(batchID);\n      })\n      .next(() => this.lookupMutationBatches(transaction, uniqueBatchIDs));\n  }\n\n  private lookupMutationBatches(\n    transaction: PersistenceTransaction,\n    batchIDs: SortedSet<BatchId>\n  ): PersistencePromise<MutationBatch[]> {\n    const results: MutationBatch[] = [];\n    const promises: Array<PersistencePromise<void>> = [];\n    // TODO(rockwood): Implement this using iterate.\n    batchIDs.forEach(batchId => {\n      promises.push(\n        mutationsStore(transaction)\n          .get(batchId)\n          .next(mutation => {\n            if (mutation === null) {\n              throw fail(\n                'Dangling document-mutation reference found, ' +\n                  'which points to ' +\n                  batchId\n              );\n            }\n            hardAssert(\n              mutation.userId === this.userId,\n              `Unexpected user '${mutation.userId}' for mutation batch ${batchId}`\n            );\n            results.push(this.serializer.fromDbMutationBatch(mutation));\n          })\n      );\n    });\n    return PersistencePromise.waitFor(promises).next(() => results);\n  }\n\n  removeMutationBatch(\n    transaction: PersistenceTransaction,\n    batch: MutationBatch\n  ): PersistencePromise<void> {\n    return removeMutationBatch(\n      (transaction as IndexedDbTransaction).simpleDbTransaction,\n      this.userId,\n      batch\n    ).next(removedDocuments => {\n      transaction.addOnCommittedListener(() => {\n        this.removeCachedMutationKeys(batch.batchId);\n      });\n      return PersistencePromise.forEach(\n        removedDocuments,\n        (key: DocumentKey) => {\n          return this.referenceDelegate.removeMutationReference(\n            transaction,\n            key\n          );\n        }\n      );\n    });\n  }\n\n  removeCachedMutationKeys(batchId: BatchId): void {\n    delete this.documentKeysByBatchId[batchId];\n  }\n\n  performConsistencyCheck(\n    txn: PersistenceTransaction\n  ): PersistencePromise<void> {\n    return this.checkEmpty(txn).next(empty => {\n      if (!empty) {\n        return PersistencePromise.resolve();\n      }\n\n      // Verify that there are no entries in the documentMutations index if\n      // the queue is empty.\n      const startRange = IDBKeyRange.lowerBound(\n        DbDocumentMutation.prefixForUser(this.userId)\n      );\n      const danglingMutationReferences: ResourcePath[] = [];\n      return documentMutationsStore(txn)\n        .iterate({ range: startRange }, (key, _, control) => {\n          const userID = key[0];\n          if (userID !== this.userId) {\n            control.done();\n            return;\n          } else {\n            const path = decodeResourcePath(key[1]);\n            danglingMutationReferences.push(path);\n          }\n        })\n        .next(() => {\n          hardAssert(\n            danglingMutationReferences.length === 0,\n            'Document leak -- detected dangling mutation references when queue is empty. ' +\n              'Dangling keys: ' +\n              danglingMutationReferences.map(p => p.canonicalString())\n          );\n        });\n    });\n  }\n\n  containsKey(\n    txn: PersistenceTransaction,\n    key: DocumentKey\n  ): PersistencePromise<boolean> {\n    return mutationQueueContainsKey(txn, this.userId, key);\n  }\n\n  // PORTING NOTE: Multi-tab only (state is held in memory in other clients).\n  /** Returns the mutation queue's metadata from IndexedDb. */\n  private getMutationQueueMetadata(\n    transaction: PersistenceTransaction\n  ): PersistencePromise<DbMutationQueue> {\n    return mutationQueuesStore(transaction)\n      .get(this.userId)\n      .next((metadata: DbMutationQueue | null) => {\n        return (\n          metadata ||\n          new DbMutationQueue(\n            this.userId,\n            BATCHID_UNKNOWN,\n            /*lastStreamToken=*/ ''\n          )\n        );\n      });\n  }\n}\n\n/**\n * @return true if the mutation queue for the given user contains a pending\n *         mutation for the given key.\n */\nfunction mutationQueueContainsKey(\n  txn: PersistenceTransaction,\n  userId: string,\n  key: DocumentKey\n): PersistencePromise<boolean> {\n  const indexKey = DbDocumentMutation.prefixForPath(userId, key.path);\n  const encodedPath = indexKey[1];\n  const startRange = IDBKeyRange.lowerBound(indexKey);\n  let containsKey = false;\n  return documentMutationsStore(txn)\n    .iterate({ range: startRange, keysOnly: true }, (key, value, control) => {\n      const [userID, keyPath, /*batchID*/ _] = key;\n      if (userID === userId && keyPath === encodedPath) {\n        containsKey = true;\n      }\n      control.done();\n    })\n    .next(() => containsKey);\n}\n\n/** Returns true if any mutation queue contains the given document. */\nexport function mutationQueuesContainKey(\n  txn: PersistenceTransaction,\n  docKey: DocumentKey\n): PersistencePromise<boolean> {\n  let found = false;\n  return mutationQueuesStore(txn)\n    .iterateSerial(userId => {\n      return mutationQueueContainsKey(txn, userId, docKey).next(containsKey => {\n        if (containsKey) {\n          found = true;\n        }\n        return PersistencePromise.resolve(!containsKey);\n      });\n    })\n    .next(() => found);\n}\n\n/**\n * Delete a mutation batch and the associated document mutations.\n * @return A PersistencePromise of the document mutations that were removed.\n */\nexport function removeMutationBatch(\n  txn: SimpleDbTransaction,\n  userId: string,\n  batch: MutationBatch\n): PersistencePromise<DocumentKey[]> {\n  const mutationStore = txn.store<DbMutationBatchKey, DbMutationBatch>(\n    DbMutationBatch.store\n  );\n  const indexTxn = txn.store<DbDocumentMutationKey, DbDocumentMutation>(\n    DbDocumentMutation.store\n  );\n  const promises: Array<PersistencePromise<void>> = [];\n\n  const range = IDBKeyRange.only(batch.batchId);\n  let numDeleted = 0;\n  const removePromise = mutationStore.iterate(\n    { range },\n    (key, value, control) => {\n      numDeleted++;\n      return control.delete();\n    }\n  );\n  promises.push(\n    removePromise.next(() => {\n      hardAssert(\n        numDeleted === 1,\n        'Dangling document-mutation reference found: Missing batch ' +\n          batch.batchId\n      );\n    })\n  );\n  const removedDocuments: DocumentKey[] = [];\n  for (const mutation of batch.mutations) {\n    const indexKey = DbDocumentMutation.key(\n      userId,\n      mutation.key.path,\n      batch.batchId\n    );\n    promises.push(indexTxn.delete(indexKey));\n    removedDocuments.push(mutation.key);\n  }\n  return PersistencePromise.waitFor(promises).next(() => removedDocuments);\n}\n\n/**\n * Helper to get a typed SimpleDbStore for the mutations object store.\n */\nfunction mutationsStore(\n  txn: PersistenceTransaction\n): SimpleDbStore<DbMutationBatchKey, DbMutationBatch> {\n  return IndexedDbPersistence.getStore<DbMutationBatchKey, DbMutationBatch>(\n    txn,\n    DbMutationBatch.store\n  );\n}\n\n/**\n * Helper to get a typed SimpleDbStore for the mutationQueues object store.\n */\nfunction documentMutationsStore(\n  txn: PersistenceTransaction\n): SimpleDbStore<DbDocumentMutationKey, DbDocumentMutation> {\n  return IndexedDbPersistence.getStore<\n    DbDocumentMutationKey,\n    DbDocumentMutation\n  >(txn, DbDocumentMutation.store);\n}\n\n/**\n * Helper to get a typed SimpleDbStore for the mutationQueues object store.\n */\nfunction mutationQueuesStore(\n  txn: PersistenceTransaction\n): SimpleDbStore<DbMutationQueueKey, DbMutationQueue> {\n  return IndexedDbPersistence.getStore<DbMutationQueueKey, DbMutationQueue>(\n    txn,\n    DbMutationQueue.store\n  );\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Timestamp } from '../api/timestamp';\nimport { SnapshotVersion } from '../core/snapshot_version';\nimport { ListenSequenceNumber, TargetId } from '../core/types';\nimport { DocumentKeySet, documentKeySet } from '../model/collections';\nimport { DocumentKey } from '../model/document_key';\nimport { hardAssert } from '../util/assert';\nimport { immediateSuccessor } from '../util/misc';\nimport { TargetIdGenerator } from '../core/target_id_generator';\nimport {\n  decodeResourcePath,\n  encodeResourcePath\n} from './encoded_resource_path';\nimport {\n  IndexedDbLruDelegate,\n  IndexedDbPersistence,\n  IndexedDbTransaction\n} from './indexeddb_persistence';\nimport {\n  DbTarget,\n  DbTargetDocument,\n  DbTargetDocumentKey,\n  DbTargetGlobal,\n  DbTargetGlobalKey,\n  DbTargetKey\n} from './indexeddb_schema';\nimport { LocalSerializer } from './local_serializer';\nimport { ActiveTargets } from './lru_garbage_collector';\nimport { PersistenceTransaction } from './persistence';\nimport { PersistencePromise } from './persistence_promise';\nimport { TargetCache } from './target_cache';\nimport { TargetData } from './target_data';\nimport { SimpleDb, SimpleDbStore, SimpleDbTransaction } from './simple_db';\nimport { Target } from '../core/target';\n\nexport class IndexedDbTargetCache implements TargetCache {\n  constructor(\n    private readonly referenceDelegate: IndexedDbLruDelegate,\n    private serializer: LocalSerializer\n  ) {}\n\n  // PORTING NOTE: We don't cache global metadata for the target cache, since\n  // some of it (in particular `highestTargetId`) can be modified by secondary\n  // tabs. We could perhaps be more granular (and e.g. still cache\n  // `lastRemoteSnapshotVersion` in memory) but for simplicity we currently go\n  // to IndexedDb whenever we need to read metadata. We can revisit if it turns\n  // out to have a meaningful performance impact.\n\n  allocateTargetId(\n    transaction: PersistenceTransaction\n  ): PersistencePromise<TargetId> {\n    return this.retrieveMetadata(transaction).next(metadata => {\n      const targetIdGenerator = new TargetIdGenerator(metadata.highestTargetId);\n      metadata.highestTargetId = targetIdGenerator.next();\n      return this.saveMetadata(transaction, metadata).next(\n        () => metadata.highestTargetId\n      );\n    });\n  }\n\n  getLastRemoteSnapshotVersion(\n    transaction: PersistenceTransaction\n  ): PersistencePromise<SnapshotVersion> {\n    return this.retrieveMetadata(transaction).next(metadata => {\n      return SnapshotVersion.fromTimestamp(\n        new Timestamp(\n          metadata.lastRemoteSnapshotVersion.seconds,\n          metadata.lastRemoteSnapshotVersion.nanoseconds\n        )\n      );\n    });\n  }\n\n  getHighestSequenceNumber(\n    transaction: PersistenceTransaction\n  ): PersistencePromise<ListenSequenceNumber> {\n    return getHighestListenSequenceNumber(\n      (transaction as IndexedDbTransaction).simpleDbTransaction\n    );\n  }\n\n  setTargetsMetadata(\n    transaction: PersistenceTransaction,\n    highestListenSequenceNumber: number,\n    lastRemoteSnapshotVersion?: SnapshotVersion\n  ): PersistencePromise<void> {\n    return this.retrieveMetadata(transaction).next(metadata => {\n      metadata.highestListenSequenceNumber = highestListenSequenceNumber;\n      if (lastRemoteSnapshotVersion) {\n        metadata.lastRemoteSnapshotVersion = lastRemoteSnapshotVersion.toTimestamp();\n      }\n      if (highestListenSequenceNumber > metadata.highestListenSequenceNumber) {\n        metadata.highestListenSequenceNumber = highestListenSequenceNumber;\n      }\n      return this.saveMetadata(transaction, metadata);\n    });\n  }\n\n  addTargetData(\n    transaction: PersistenceTransaction,\n    targetData: TargetData\n  ): PersistencePromise<void> {\n    return this.saveTargetData(transaction, targetData).next(() => {\n      return this.retrieveMetadata(transaction).next(metadata => {\n        metadata.targetCount += 1;\n        this.updateMetadataFromTargetData(targetData, metadata);\n        return this.saveMetadata(transaction, metadata);\n      });\n    });\n  }\n\n  updateTargetData(\n    transaction: PersistenceTransaction,\n    targetData: TargetData\n  ): PersistencePromise<void> {\n    return this.saveTargetData(transaction, targetData);\n  }\n\n  removeTargetData(\n    transaction: PersistenceTransaction,\n    targetData: TargetData\n  ): PersistencePromise<void> {\n    return this.removeMatchingKeysForTargetId(transaction, targetData.targetId)\n      .next(() => targetsStore(transaction).delete(targetData.targetId))\n      .next(() => this.retrieveMetadata(transaction))\n      .next(metadata => {\n        hardAssert(\n          metadata.targetCount > 0,\n          'Removing from an empty target cache'\n        );\n        metadata.targetCount -= 1;\n        return this.saveMetadata(transaction, metadata);\n      });\n  }\n\n  /**\n   * Drops any targets with sequence number less than or equal to the upper bound, excepting those\n   * present in `activeTargetIds`. Document associations for the removed targets are also removed.\n   * Returns the number of targets removed.\n   */\n  removeTargets(\n    txn: PersistenceTransaction,\n    upperBound: ListenSequenceNumber,\n    activeTargetIds: ActiveTargets\n  ): PersistencePromise<number> {\n    let count = 0;\n    const promises: Array<PersistencePromise<void>> = [];\n    return targetsStore(txn)\n      .iterate((key, value) => {\n        const targetData = this.serializer.fromDbTarget(value);\n        if (\n          targetData.sequenceNumber <= upperBound &&\n          activeTargetIds.get(targetData.targetId) === null\n        ) {\n          count++;\n          promises.push(this.removeTargetData(txn, targetData));\n        }\n      })\n      .next(() => PersistencePromise.waitFor(promises))\n      .next(() => count);\n  }\n\n  /**\n   * Call provided function with each `TargetData` that we have cached.\n   */\n  forEachTarget(\n    txn: PersistenceTransaction,\n    f: (q: TargetData) => void\n  ): PersistencePromise<void> {\n    return targetsStore(txn).iterate((key, value) => {\n      const targetData = this.serializer.fromDbTarget(value);\n      f(targetData);\n    });\n  }\n\n  private retrieveMetadata(\n    transaction: PersistenceTransaction\n  ): PersistencePromise<DbTargetGlobal> {\n    return retrieveMetadata(\n      (transaction as IndexedDbTransaction).simpleDbTransaction\n    );\n  }\n\n  private saveMetadata(\n    transaction: PersistenceTransaction,\n    metadata: DbTargetGlobal\n  ): PersistencePromise<void> {\n    return globalTargetStore(transaction).put(DbTargetGlobal.key, metadata);\n  }\n\n  private saveTargetData(\n    transaction: PersistenceTransaction,\n    targetData: TargetData\n  ): PersistencePromise<void> {\n    return targetsStore(transaction).put(\n      this.serializer.toDbTarget(targetData)\n    );\n  }\n\n  /**\n   * In-place updates the provided metadata to account for values in the given\n   * TargetData. Saving is done separately. Returns true if there were any\n   * changes to the metadata.\n   */\n  private updateMetadataFromTargetData(\n    targetData: TargetData,\n    metadata: DbTargetGlobal\n  ): boolean {\n    let updated = false;\n    if (targetData.targetId > metadata.highestTargetId) {\n      metadata.highestTargetId = targetData.targetId;\n      updated = true;\n    }\n\n    if (targetData.sequenceNumber > metadata.highestListenSequenceNumber) {\n      metadata.highestListenSequenceNumber = targetData.sequenceNumber;\n      updated = true;\n    }\n    return updated;\n  }\n\n  getTargetCount(\n    transaction: PersistenceTransaction\n  ): PersistencePromise<number> {\n    return this.retrieveMetadata(transaction).next(\n      metadata => metadata.targetCount\n    );\n  }\n\n  getTargetData(\n    transaction: PersistenceTransaction,\n    target: Target\n  ): PersistencePromise<TargetData | null> {\n    // Iterating by the canonicalId may yield more than one result because\n    // canonicalId values are not required to be unique per target. This query\n    // depends on the queryTargets index to be efficient.\n    const canonicalId = target.canonicalId();\n    const range = IDBKeyRange.bound(\n      [canonicalId, Number.NEGATIVE_INFINITY],\n      [canonicalId, Number.POSITIVE_INFINITY]\n    );\n    let result: TargetData | null = null;\n    return targetsStore(transaction)\n      .iterate(\n        { range, index: DbTarget.queryTargetsIndexName },\n        (key, value, control) => {\n          const found = this.serializer.fromDbTarget(value);\n          // After finding a potential match, check that the target is\n          // actually equal to the requested target.\n          if (target.isEqual(found.target)) {\n            result = found;\n            control.done();\n          }\n        }\n      )\n      .next(() => result);\n  }\n\n  addMatchingKeys(\n    txn: PersistenceTransaction,\n    keys: DocumentKeySet,\n    targetId: TargetId\n  ): PersistencePromise<void> {\n    // PORTING NOTE: The reverse index (documentsTargets) is maintained by\n    // IndexedDb.\n    const promises: Array<PersistencePromise<void>> = [];\n    const store = documentTargetStore(txn);\n    keys.forEach(key => {\n      const path = encodeResourcePath(key.path);\n      promises.push(store.put(new DbTargetDocument(targetId, path)));\n      promises.push(this.referenceDelegate.addReference(txn, key));\n    });\n    return PersistencePromise.waitFor(promises);\n  }\n\n  removeMatchingKeys(\n    txn: PersistenceTransaction,\n    keys: DocumentKeySet,\n    targetId: TargetId\n  ): PersistencePromise<void> {\n    // PORTING NOTE: The reverse index (documentsTargets) is maintained by\n    // IndexedDb.\n    const store = documentTargetStore(txn);\n    return PersistencePromise.forEach(keys, (key: DocumentKey) => {\n      const path = encodeResourcePath(key.path);\n      return PersistencePromise.waitFor([\n        store.delete([targetId, path]),\n        this.referenceDelegate.removeReference(txn, key)\n      ]);\n    });\n  }\n\n  removeMatchingKeysForTargetId(\n    txn: PersistenceTransaction,\n    targetId: TargetId\n  ): PersistencePromise<void> {\n    const store = documentTargetStore(txn);\n    const range = IDBKeyRange.bound(\n      [targetId],\n      [targetId + 1],\n      /*lowerOpen=*/ false,\n      /*upperOpen=*/ true\n    );\n    return store.delete(range);\n  }\n\n  getMatchingKeysForTargetId(\n    txn: PersistenceTransaction,\n    targetId: TargetId\n  ): PersistencePromise<DocumentKeySet> {\n    const range = IDBKeyRange.bound(\n      [targetId],\n      [targetId + 1],\n      /*lowerOpen=*/ false,\n      /*upperOpen=*/ true\n    );\n    const store = documentTargetStore(txn);\n    let result = documentKeySet();\n\n    return store\n      .iterate({ range, keysOnly: true }, (key, _, control) => {\n        const path = decodeResourcePath(key[1]);\n        const docKey = new DocumentKey(path);\n        result = result.add(docKey);\n      })\n      .next(() => result);\n  }\n\n  containsKey(\n    txn: PersistenceTransaction,\n    key: DocumentKey\n  ): PersistencePromise<boolean> {\n    const path = encodeResourcePath(key.path);\n    const range = IDBKeyRange.bound(\n      [path],\n      [immediateSuccessor(path)],\n      /*lowerOpen=*/ false,\n      /*upperOpen=*/ true\n    );\n    let count = 0;\n    return documentTargetStore(txn!)\n      .iterate(\n        {\n          index: DbTargetDocument.documentTargetsIndex,\n          keysOnly: true,\n          range\n        },\n        ([targetId, path], _, control) => {\n          // Having a sentinel row for a document does not count as containing that document;\n          // For the target cache, containing the document means the document is part of some\n          // target.\n          if (targetId !== 0) {\n            count++;\n            control.done();\n          }\n        }\n      )\n      .next(() => count > 0);\n  }\n\n  getTargetDataForTarget(\n    transaction: PersistenceTransaction,\n    targetId: TargetId\n  ): PersistencePromise<TargetData | null> {\n    return targetsStore(transaction)\n      .get(targetId)\n      .next(found => {\n        if (found) {\n          return this.serializer.fromDbTarget(found);\n        } else {\n          return null;\n        }\n      });\n  }\n}\n\n/**\n * Helper to get a typed SimpleDbStore for the queries object store.\n */\nfunction targetsStore(\n  txn: PersistenceTransaction\n): SimpleDbStore<DbTargetKey, DbTarget> {\n  return IndexedDbPersistence.getStore<DbTargetKey, DbTarget>(\n    txn,\n    DbTarget.store\n  );\n}\n\n/**\n * Helper to get a typed SimpleDbStore for the target globals object store.\n */\nfunction globalTargetStore(\n  txn: PersistenceTransaction\n): SimpleDbStore<DbTargetGlobalKey, DbTargetGlobal> {\n  return IndexedDbPersistence.getStore<DbTargetGlobalKey, DbTargetGlobal>(\n    txn,\n    DbTargetGlobal.store\n  );\n}\n\nfunction retrieveMetadata(\n  txn: SimpleDbTransaction\n): PersistencePromise<DbTargetGlobal> {\n  const globalStore = SimpleDb.getStore<DbTargetGlobalKey, DbTargetGlobal>(\n    txn,\n    DbTargetGlobal.store\n  );\n  return globalStore.get(DbTargetGlobal.key).next(metadata => {\n    hardAssert(metadata !== null, 'Missing metadata row.');\n    return metadata;\n  });\n}\n\nexport function getHighestListenSequenceNumber(\n  txn: SimpleDbTransaction\n): PersistencePromise<ListenSequenceNumber> {\n  return retrieveMetadata(txn).next(\n    targetGlobal => targetGlobal.highestListenSequenceNumber\n  );\n}\n\n/**\n * Helper to get a typed SimpleDbStore for the document target object store.\n */\nexport function documentTargetStore(\n  txn: PersistenceTransaction\n): SimpleDbStore<DbTargetDocumentKey, DbTargetDocument> {\n  return IndexedDbPersistence.getStore<DbTargetDocumentKey, DbTargetDocument>(\n    txn,\n    DbTargetDocument.store\n  );\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Query } from '../core/query';\nimport {\n  DocumentKeySet,\n  DocumentMap,\n  documentMap,\n  DocumentSizeEntries,\n  DocumentSizeEntry,\n  MaybeDocumentMap,\n  maybeDocumentMap,\n  nullableMaybeDocumentMap,\n  NullableMaybeDocumentMap\n} from '../model/collections';\nimport { Document, MaybeDocument, NoDocument } from '../model/document';\nimport { DocumentKey } from '../model/document_key';\nimport { ResourcePath } from '../model/path';\nimport { primitiveComparator } from '../util/misc';\nimport { SortedMap } from '../util/sorted_map';\nimport { SortedSet } from '../util/sorted_set';\n\nimport { SnapshotVersion } from '../core/snapshot_version';\nimport { debugAssert, fail, hardAssert } from '../util/assert';\nimport { IndexManager } from './index_manager';\nimport { IndexedDbPersistence } from './indexeddb_persistence';\nimport {\n  DbRemoteDocument,\n  DbRemoteDocumentGlobal,\n  DbRemoteDocumentGlobalKey,\n  DbRemoteDocumentKey\n} from './indexeddb_schema';\nimport { LocalSerializer } from './local_serializer';\nimport { PersistenceTransaction } from './persistence';\nimport { PersistencePromise } from './persistence_promise';\nimport { RemoteDocumentCache } from './remote_document_cache';\nimport { RemoteDocumentChangeBuffer } from './remote_document_change_buffer';\nimport { IterateOptions, SimpleDbStore } from './simple_db';\nimport { ObjectMap } from '../util/obj_map';\n\nexport class IndexedDbRemoteDocumentCache implements RemoteDocumentCache {\n  /**\n   * @param {LocalSerializer} serializer The document serializer.\n   * @param {IndexManager} indexManager The query indexes that need to be maintained.\n   */\n  constructor(\n    readonly serializer: LocalSerializer,\n    private readonly indexManager: IndexManager\n  ) {}\n\n  /**\n   * Adds the supplied entries to the cache.\n   *\n   * All calls of `addEntry` are required to go through the RemoteDocumentChangeBuffer\n   * returned by `newChangeBuffer()` to ensure proper accounting of metadata.\n   */\n  private addEntry(\n    transaction: PersistenceTransaction,\n    key: DocumentKey,\n    doc: DbRemoteDocument\n  ): PersistencePromise<void> {\n    const documentStore = remoteDocumentsStore(transaction);\n    return documentStore.put(dbKey(key), doc);\n  }\n\n  /**\n   * Removes a document from the cache.\n   *\n   * All calls of `removeEntry`  are required to go through the RemoteDocumentChangeBuffer\n   * returned by `newChangeBuffer()` to ensure proper accounting of metadata.\n   */\n  private removeEntry(\n    transaction: PersistenceTransaction,\n    documentKey: DocumentKey\n  ): PersistencePromise<void> {\n    const store = remoteDocumentsStore(transaction);\n    const key = dbKey(documentKey);\n    return store.delete(key);\n  }\n\n  /**\n   * Updates the current cache size.\n   *\n   * Callers to `addEntry()` and `removeEntry()` *must* call this afterwards to update the\n   * cache's metadata.\n   */\n  private updateMetadata(\n    transaction: PersistenceTransaction,\n    sizeDelta: number\n  ): PersistencePromise<void> {\n    return this.getMetadata(transaction).next(metadata => {\n      metadata.byteSize += sizeDelta;\n      return this.setMetadata(transaction, metadata);\n    });\n  }\n\n  getEntry(\n    transaction: PersistenceTransaction,\n    documentKey: DocumentKey\n  ): PersistencePromise<MaybeDocument | null> {\n    return remoteDocumentsStore(transaction)\n      .get(dbKey(documentKey))\n      .next(dbRemoteDoc => {\n        return this.maybeDecodeDocument(dbRemoteDoc);\n      });\n  }\n\n  /**\n   * Looks up an entry in the cache.\n   *\n   * @param documentKey The key of the entry to look up.\n   * @return The cached MaybeDocument entry and its size, or null if we have nothing cached.\n   */\n  getSizedEntry(\n    transaction: PersistenceTransaction,\n    documentKey: DocumentKey\n  ): PersistencePromise<DocumentSizeEntry | null> {\n    return remoteDocumentsStore(transaction)\n      .get(dbKey(documentKey))\n      .next(dbRemoteDoc => {\n        const doc = this.maybeDecodeDocument(dbRemoteDoc);\n        return doc\n          ? {\n              maybeDocument: doc,\n              size: dbDocumentSize(dbRemoteDoc!)\n            }\n          : null;\n      });\n  }\n\n  getEntries(\n    transaction: PersistenceTransaction,\n    documentKeys: DocumentKeySet\n  ): PersistencePromise<NullableMaybeDocumentMap> {\n    let results = nullableMaybeDocumentMap();\n    return this.forEachDbEntry(\n      transaction,\n      documentKeys,\n      (key, dbRemoteDoc) => {\n        const doc = this.maybeDecodeDocument(dbRemoteDoc);\n        results = results.insert(key, doc);\n      }\n    ).next(() => results);\n  }\n\n  /**\n   * Looks up several entries in the cache.\n   *\n   * @param documentKeys The set of keys entries to look up.\n   * @return A map of MaybeDocuments indexed by key (if a document cannot be\n   *     found, the key will be mapped to null) and a map of sizes indexed by\n   *     key (zero if the key cannot be found).\n   */\n  getSizedEntries(\n    transaction: PersistenceTransaction,\n    documentKeys: DocumentKeySet\n  ): PersistencePromise<DocumentSizeEntries> {\n    let results = nullableMaybeDocumentMap();\n    let sizeMap = new SortedMap<DocumentKey, number>(DocumentKey.comparator);\n    return this.forEachDbEntry(\n      transaction,\n      documentKeys,\n      (key, dbRemoteDoc) => {\n        const doc = this.maybeDecodeDocument(dbRemoteDoc);\n        if (doc) {\n          results = results.insert(key, doc);\n          sizeMap = sizeMap.insert(key, dbDocumentSize(dbRemoteDoc!));\n        } else {\n          results = results.insert(key, null);\n          sizeMap = sizeMap.insert(key, 0);\n        }\n      }\n    ).next(() => {\n      return { maybeDocuments: results, sizeMap };\n    });\n  }\n\n  private forEachDbEntry(\n    transaction: PersistenceTransaction,\n    documentKeys: DocumentKeySet,\n    callback: (key: DocumentKey, doc: DbRemoteDocument | null) => void\n  ): PersistencePromise<void> {\n    if (documentKeys.isEmpty()) {\n      return PersistencePromise.resolve();\n    }\n\n    const range = IDBKeyRange.bound(\n      documentKeys.first()!.path.toArray(),\n      documentKeys.last()!.path.toArray()\n    );\n    const keyIter = documentKeys.getIterator();\n    let nextKey: DocumentKey | null = keyIter.getNext();\n\n    return remoteDocumentsStore(transaction)\n      .iterate({ range }, (potentialKeyRaw, dbRemoteDoc, control) => {\n        const potentialKey = DocumentKey.fromSegments(potentialKeyRaw);\n\n        // Go through keys not found in cache.\n        while (nextKey && DocumentKey.comparator(nextKey!, potentialKey) < 0) {\n          callback(nextKey!, null);\n          nextKey = keyIter.getNext();\n        }\n\n        if (nextKey && nextKey!.isEqual(potentialKey)) {\n          // Key found in cache.\n          callback(nextKey!, dbRemoteDoc);\n          nextKey = keyIter.hasNext() ? keyIter.getNext() : null;\n        }\n\n        // Skip to the next key (if there is one).\n        if (nextKey) {\n          control.skip(nextKey!.path.toArray());\n        } else {\n          control.done();\n        }\n      })\n      .next(() => {\n        // The rest of the keys are not in the cache. One case where `iterate`\n        // above won't go through them is when the cache is empty.\n        while (nextKey) {\n          callback(nextKey!, null);\n          nextKey = keyIter.hasNext() ? keyIter.getNext() : null;\n        }\n      });\n  }\n\n  getDocumentsMatchingQuery(\n    transaction: PersistenceTransaction,\n    query: Query,\n    sinceReadTime: SnapshotVersion\n  ): PersistencePromise<DocumentMap> {\n    debugAssert(\n      !query.isCollectionGroupQuery(),\n      'CollectionGroup queries should be handled in LocalDocumentsView'\n    );\n    let results = documentMap();\n\n    const immediateChildrenPathLength = query.path.length + 1;\n\n    const iterationOptions: IterateOptions = {};\n    if (sinceReadTime.isEqual(SnapshotVersion.MIN)) {\n      // Documents are ordered by key, so we can use a prefix scan to narrow\n      // down the documents we need to match the query against.\n      const startKey = query.path.toArray();\n      iterationOptions.range = IDBKeyRange.lowerBound(startKey);\n    } else {\n      // Execute an index-free query and filter by read time. This is safe\n      // since all document changes to queries that have a\n      // lastLimboFreeSnapshotVersion (`sinceReadTime`) have a read time set.\n      const collectionKey = query.path.toArray();\n      const readTimeKey = this.serializer.toDbTimestampKey(sinceReadTime);\n      iterationOptions.range = IDBKeyRange.lowerBound(\n        [collectionKey, readTimeKey],\n        /* open= */ true\n      );\n      iterationOptions.index = DbRemoteDocument.collectionReadTimeIndex;\n    }\n\n    return remoteDocumentsStore(transaction)\n      .iterate(iterationOptions, (key, dbRemoteDoc, control) => {\n        // The query is actually returning any path that starts with the query\n        // path prefix which may include documents in subcollections. For\n        // example, a query on 'rooms' will return rooms/abc/messages/xyx but we\n        // shouldn't match it. Fix this by discarding rows with document keys\n        // more than one segment longer than the query path.\n        if (key.length !== immediateChildrenPathLength) {\n          return;\n        }\n\n        const maybeDoc = this.serializer.fromDbRemoteDocument(dbRemoteDoc);\n        if (!query.path.isPrefixOf(maybeDoc.key.path)) {\n          control.done();\n        } else if (maybeDoc instanceof Document && query.matches(maybeDoc)) {\n          results = results.insert(maybeDoc.key, maybeDoc);\n        }\n      })\n      .next(() => results);\n  }\n\n  getNewDocumentChanges(\n    transaction: PersistenceTransaction,\n    sinceReadTime: SnapshotVersion\n  ): PersistencePromise<{\n    changedDocs: MaybeDocumentMap;\n    readTime: SnapshotVersion;\n  }> {\n    let changedDocs = maybeDocumentMap();\n\n    let lastReadTime = this.serializer.toDbTimestampKey(sinceReadTime);\n\n    const documentsStore = remoteDocumentsStore(transaction);\n    const range = IDBKeyRange.lowerBound(lastReadTime, true);\n    return documentsStore\n      .iterate(\n        { index: DbRemoteDocument.readTimeIndex, range },\n        (_, dbRemoteDoc) => {\n          // Unlike `getEntry()` and others, `getNewDocumentChanges()` parses\n          // the documents directly since we want to keep sentinel deletes.\n          const doc = this.serializer.fromDbRemoteDocument(dbRemoteDoc);\n          changedDocs = changedDocs.insert(doc.key, doc);\n          lastReadTime = dbRemoteDoc.readTime!;\n        }\n      )\n      .next(() => {\n        return {\n          changedDocs,\n          readTime: this.serializer.fromDbTimestampKey(lastReadTime)\n        };\n      });\n  }\n\n  getLastReadTime(\n    transaction: PersistenceTransaction\n  ): PersistencePromise<SnapshotVersion> {\n    const documentsStore = remoteDocumentsStore(transaction);\n\n    // If there are no existing entries, we return SnapshotVersion.MIN.\n    let readTime = SnapshotVersion.MIN;\n\n    return documentsStore\n      .iterate(\n        { index: DbRemoteDocument.readTimeIndex, reverse: true },\n        (key, dbRemoteDoc, control) => {\n          if (dbRemoteDoc.readTime) {\n            readTime = this.serializer.fromDbTimestampKey(dbRemoteDoc.readTime);\n          }\n          control.done();\n        }\n      )\n      .next(() => readTime);\n  }\n\n  newChangeBuffer(options?: {\n    trackRemovals: boolean;\n  }): RemoteDocumentChangeBuffer {\n    return new IndexedDbRemoteDocumentCache.RemoteDocumentChangeBuffer(\n      this,\n      !!options && options.trackRemovals\n    );\n  }\n\n  getSize(txn: PersistenceTransaction): PersistencePromise<number> {\n    return this.getMetadata(txn).next(metadata => metadata.byteSize);\n  }\n\n  private getMetadata(\n    txn: PersistenceTransaction\n  ): PersistencePromise<DbRemoteDocumentGlobal> {\n    return documentGlobalStore(txn)\n      .get(DbRemoteDocumentGlobal.key)\n      .next(metadata => {\n        hardAssert(!!metadata, 'Missing document cache metadata');\n        return metadata!;\n      });\n  }\n\n  private setMetadata(\n    txn: PersistenceTransaction,\n    metadata: DbRemoteDocumentGlobal\n  ): PersistencePromise<void> {\n    return documentGlobalStore(txn).put(DbRemoteDocumentGlobal.key, metadata);\n  }\n\n  /**\n   * Decodes `remoteDoc` and returns the document (or null, if the document\n   * corresponds to the format used for sentinel deletes).\n   */\n  private maybeDecodeDocument(\n    dbRemoteDoc: DbRemoteDocument | null\n  ): MaybeDocument | null {\n    if (dbRemoteDoc) {\n      const doc = this.serializer.fromDbRemoteDocument(dbRemoteDoc);\n      if (\n        doc instanceof NoDocument &&\n        doc.version.isEqual(SnapshotVersion.forDeletedDoc())\n      ) {\n        // The document is a sentinel removal and should only be used in the\n        // `getNewDocumentChanges()`.\n        return null;\n      }\n\n      return doc;\n    }\n    return null;\n  }\n\n  /**\n   * Handles the details of adding and updating documents in the IndexedDbRemoteDocumentCache.\n   *\n   * Unlike the MemoryRemoteDocumentChangeBuffer, the IndexedDb implementation computes the size\n   * delta for all submitted changes. This avoids having to re-read all documents from IndexedDb\n   * when we apply the changes.\n   */\n  private static RemoteDocumentChangeBuffer = class extends RemoteDocumentChangeBuffer {\n    // A map of document sizes prior to applying the changes in this buffer.\n    protected documentSizes: ObjectMap<\n      DocumentKey,\n      number\n    > = new ObjectMap(key => key.toString());\n\n    /**\n     * @param documentCache The IndexedDbRemoteDocumentCache to apply the changes to.\n     * @param trackRemovals Whether to create sentinel deletes that can be tracked by\n     * `getNewDocumentChanges()`.\n     */\n    constructor(\n      private readonly documentCache: IndexedDbRemoteDocumentCache,\n      private readonly trackRemovals: boolean\n    ) {\n      super();\n    }\n\n    protected applyChanges(\n      transaction: PersistenceTransaction\n    ): PersistencePromise<void> {\n      const promises: Array<PersistencePromise<void>> = [];\n\n      let sizeDelta = 0;\n\n      let collectionParents = new SortedSet<ResourcePath>((l, r) =>\n        primitiveComparator(l.canonicalString(), r.canonicalString())\n      );\n\n      this.changes.forEach((key, maybeDocument) => {\n        const previousSize = this.documentSizes.get(key);\n        debugAssert(\n          previousSize !== undefined,\n          `Cannot modify a document that wasn't read (for ${key})`\n        );\n        if (maybeDocument) {\n          debugAssert(\n            !this.readTime.isEqual(SnapshotVersion.MIN),\n            'Cannot add a document with a read time of zero'\n          );\n          const doc = this.documentCache.serializer.toDbRemoteDocument(\n            maybeDocument,\n            this.readTime\n          );\n          collectionParents = collectionParents.add(key.path.popLast());\n\n          const size = dbDocumentSize(doc);\n          sizeDelta += size - previousSize!;\n          promises.push(this.documentCache.addEntry(transaction, key, doc));\n        } else {\n          sizeDelta -= previousSize!;\n          if (this.trackRemovals) {\n            // In order to track removals, we store a \"sentinel delete\" in the\n            // RemoteDocumentCache. This entry is represented by a NoDocument\n            // with a version of 0 and ignored by `maybeDecodeDocument()` but\n            // preserved in `getNewDocumentChanges()`.\n            const deletedDoc = this.documentCache.serializer.toDbRemoteDocument(\n              new NoDocument(key, SnapshotVersion.forDeletedDoc()),\n              this.readTime\n            );\n            promises.push(\n              this.documentCache.addEntry(transaction, key, deletedDoc)\n            );\n          } else {\n            promises.push(this.documentCache.removeEntry(transaction, key));\n          }\n        }\n      });\n\n      collectionParents.forEach(parent => {\n        promises.push(\n          this.documentCache.indexManager.addToCollectionParentIndex(\n            transaction,\n            parent\n          )\n        );\n      });\n\n      promises.push(this.documentCache.updateMetadata(transaction, sizeDelta));\n\n      return PersistencePromise.waitFor(promises);\n    }\n\n    protected getFromCache(\n      transaction: PersistenceTransaction,\n      documentKey: DocumentKey\n    ): PersistencePromise<MaybeDocument | null> {\n      // Record the size of everything we load from the cache so we can compute a delta later.\n      return this.documentCache\n        .getSizedEntry(transaction, documentKey)\n        .next(getResult => {\n          if (getResult === null) {\n            this.documentSizes.set(documentKey, 0);\n            return null;\n          } else {\n            this.documentSizes.set(documentKey, getResult.size);\n            return getResult.maybeDocument;\n          }\n        });\n    }\n\n    protected getAllFromCache(\n      transaction: PersistenceTransaction,\n      documentKeys: DocumentKeySet\n    ): PersistencePromise<NullableMaybeDocumentMap> {\n      // Record the size of everything we load from the cache so we can compute\n      // a delta later.\n      return this.documentCache\n        .getSizedEntries(transaction, documentKeys)\n        .next(({ maybeDocuments, sizeMap }) => {\n          // Note: `getAllFromCache` returns two maps instead of a single map from\n          // keys to `DocumentSizeEntry`s. This is to allow returning the\n          // `NullableMaybeDocumentMap` directly, without a conversion.\n          sizeMap.forEach((documentKey, size) => {\n            this.documentSizes.set(documentKey, size);\n          });\n          return maybeDocuments;\n        });\n    }\n  };\n}\n\nfunction documentGlobalStore(\n  txn: PersistenceTransaction\n): SimpleDbStore<DbRemoteDocumentGlobalKey, DbRemoteDocumentGlobal> {\n  return IndexedDbPersistence.getStore<\n    DbRemoteDocumentGlobalKey,\n    DbRemoteDocumentGlobal\n  >(txn, DbRemoteDocumentGlobal.store);\n}\n\n/**\n * Helper to get a typed SimpleDbStore for the remoteDocuments object store.\n */\nfunction remoteDocumentsStore(\n  txn: PersistenceTransaction\n): SimpleDbStore<DbRemoteDocumentKey, DbRemoteDocument> {\n  return IndexedDbPersistence.getStore<DbRemoteDocumentKey, DbRemoteDocument>(\n    txn,\n    DbRemoteDocument.store\n  );\n}\n\nfunction dbKey(docKey: DocumentKey): DbRemoteDocumentKey {\n  return docKey.path.toArray();\n}\n\n/**\n * Retrusn an approximate size for the given document.\n */\nexport function dbDocumentSize(doc: DbRemoteDocument): number {\n  let value: unknown;\n  if (doc.document) {\n    value = doc.document;\n  } else if (doc.unknownDocument) {\n    value = doc.unknownDocument;\n  } else if (doc.noDocument) {\n    value = doc.noDocument;\n  } else {\n    throw fail('Unknown remote document type');\n  }\n  return JSON.stringify(value).length;\n}\n","/**\n * @license\n * Copyright 2019 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { ResourcePath } from '../model/path';\nimport { debugAssert } from '../util/assert';\nimport { SortedSet } from '../util/sorted_set';\nimport { IndexManager } from './index_manager';\nimport { PersistenceTransaction } from './persistence';\nimport { PersistencePromise } from './persistence_promise';\n\n/**\n * An in-memory implementation of IndexManager.\n */\nexport class MemoryIndexManager implements IndexManager {\n  private collectionParentIndex = new MemoryCollectionParentIndex();\n\n  addToCollectionParentIndex(\n    transaction: PersistenceTransaction,\n    collectionPath: ResourcePath\n  ): PersistencePromise<void> {\n    this.collectionParentIndex.add(collectionPath);\n    return PersistencePromise.resolve();\n  }\n\n  getCollectionParents(\n    transaction: PersistenceTransaction,\n    collectionId: string\n  ): PersistencePromise<ResourcePath[]> {\n    return PersistencePromise.resolve(\n      this.collectionParentIndex.getEntries(collectionId)\n    );\n  }\n}\n\n/**\n * Internal implementation of the collection-parent index exposed by MemoryIndexManager.\n * Also used for in-memory caching by IndexedDbIndexManager and initial index population\n * in indexeddb_schema.ts\n */\nexport class MemoryCollectionParentIndex {\n  private index = {} as {\n    [collectionId: string]: SortedSet<ResourcePath>;\n  };\n\n  // Returns false if the entry already existed.\n  add(collectionPath: ResourcePath): boolean {\n    debugAssert(collectionPath.length % 2 === 1, 'Expected a collection path.');\n    const collectionId = collectionPath.lastSegment();\n    const parentPath = collectionPath.popLast();\n    const existingParents =\n      this.index[collectionId] ||\n      new SortedSet<ResourcePath>(ResourcePath.comparator);\n    const added = !existingParents.has(parentPath);\n    this.index[collectionId] = existingParents.add(parentPath);\n    return added;\n  }\n\n  has(collectionPath: ResourcePath): boolean {\n    const collectionId = collectionPath.lastSegment();\n    const parentPath = collectionPath.popLast();\n    const existingParents = this.index[collectionId];\n    return existingParents && existingParents.has(parentPath);\n  }\n\n  getEntries(collectionId: string): ResourcePath[] {\n    const parentPaths =\n      this.index[collectionId] ||\n      new SortedSet<ResourcePath>(ResourcePath.comparator);\n    return parentPaths.toArray();\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { BatchId, ListenSequenceNumber, TargetId } from '../core/types';\nimport { ResourcePath } from '../model/path';\nimport * as api from '../protos/firestore_proto_api';\nimport { hardAssert, debugAssert } from '../util/assert';\n\nimport { SnapshotVersion } from '../core/snapshot_version';\nimport { BATCHID_UNKNOWN } from '../model/mutation_batch';\nimport {\n  decodeResourcePath,\n  encodeResourcePath,\n  EncodedResourcePath\n} from './encoded_resource_path';\nimport { removeMutationBatch } from './indexeddb_mutation_queue';\nimport { getHighestListenSequenceNumber } from './indexeddb_target_cache';\nimport { dbDocumentSize } from './indexeddb_remote_document_cache';\nimport { LocalSerializer } from './local_serializer';\nimport { MemoryCollectionParentIndex } from './memory_index_manager';\nimport { PersistencePromise } from './persistence_promise';\nimport { SimpleDbSchemaConverter, SimpleDbTransaction } from './simple_db';\n\n/**\n * Schema Version for the Web client:\n * 1.  Initial version including Mutation Queue, Query Cache, and Remote\n *     Document Cache\n * 2.  Used to ensure a targetGlobal object exists and add targetCount to it. No\n *     longer required because migration 3 unconditionally clears it.\n * 3.  Dropped and re-created Query Cache to deal with cache corruption related\n *     to limbo resolution. Addresses\n *     https://github.com/firebase/firebase-ios-sdk/issues/1548\n * 4.  Multi-Tab Support.\n * 5.  Removal of held write acks.\n * 6.  Create document global for tracking document cache size.\n * 7.  Ensure every cached document has a sentinel row with a sequence number.\n * 8.  Add collection-parent index for Collection Group queries.\n * 9.  Change RemoteDocumentChanges store to be keyed by readTime rather than\n *     an auto-incrementing ID. This is required for Index-Free queries.\n * 10. Rewrite the canonical IDs to the explicit Protobuf-based format.\n */\nexport const SCHEMA_VERSION = 10;\n\n/** Performs database creation and schema upgrades. */\nexport class SchemaConverter implements SimpleDbSchemaConverter {\n  constructor(private readonly serializer: LocalSerializer) {}\n\n  /**\n   * Performs database creation and schema upgrades.\n   *\n   * Note that in production, this method is only ever used to upgrade the schema\n   * to SCHEMA_VERSION. Different values of toVersion are only used for testing\n   * and local feature development.\n   */\n  createOrUpgrade(\n    db: IDBDatabase,\n    txn: IDBTransaction,\n    fromVersion: number,\n    toVersion: number\n  ): PersistencePromise<void> {\n    hardAssert(\n      fromVersion < toVersion &&\n        fromVersion >= 0 &&\n        toVersion <= SCHEMA_VERSION,\n      `Unexpected schema upgrade from v${fromVersion} to v${toVersion}.`\n    );\n\n    const simpleDbTransaction = new SimpleDbTransaction(txn);\n\n    if (fromVersion < 1 && toVersion >= 1) {\n      createPrimaryClientStore(db);\n      createMutationQueue(db);\n      createQueryCache(db);\n      createRemoteDocumentCache(db);\n    }\n\n    // Migration 2 to populate the targetGlobal object no longer needed since\n    // migration 3 unconditionally clears it.\n\n    let p = PersistencePromise.resolve();\n    if (fromVersion < 3 && toVersion >= 3) {\n      // Brand new clients don't need to drop and recreate--only clients that\n      // potentially have corrupt data.\n      if (fromVersion !== 0) {\n        dropQueryCache(db);\n        createQueryCache(db);\n      }\n      p = p.next(() => writeEmptyTargetGlobalEntry(simpleDbTransaction));\n    }\n\n    if (fromVersion < 4 && toVersion >= 4) {\n      if (fromVersion !== 0) {\n        // Schema version 3 uses auto-generated keys to generate globally unique\n        // mutation batch IDs (this was previously ensured internally by the\n        // client). To migrate to the new schema, we have to read all mutations\n        // and write them back out. We preserve the existing batch IDs to guarantee\n        // consistency with other object stores. Any further mutation batch IDs will\n        // be auto-generated.\n        p = p.next(() =>\n          upgradeMutationBatchSchemaAndMigrateData(db, simpleDbTransaction)\n        );\n      }\n\n      p = p.next(() => {\n        createClientMetadataStore(db);\n      });\n    }\n\n    if (fromVersion < 5 && toVersion >= 5) {\n      p = p.next(() => this.removeAcknowledgedMutations(simpleDbTransaction));\n    }\n\n    if (fromVersion < 6 && toVersion >= 6) {\n      p = p.next(() => {\n        createDocumentGlobalStore(db);\n        return this.addDocumentGlobal(simpleDbTransaction);\n      });\n    }\n\n    if (fromVersion < 7 && toVersion >= 7) {\n      p = p.next(() => this.ensureSequenceNumbers(simpleDbTransaction));\n    }\n\n    if (fromVersion < 8 && toVersion >= 8) {\n      p = p.next(() =>\n        this.createCollectionParentIndex(db, simpleDbTransaction)\n      );\n    }\n\n    if (fromVersion < 9 && toVersion >= 9) {\n      p = p.next(() => {\n        // Multi-Tab used to manage its own changelog, but this has been moved\n        // to the DbRemoteDocument object store itself. Since the previous change\n        // log only contained transient data, we can drop its object store.\n        dropRemoteDocumentChangesStore(db);\n        createRemoteDocumentReadTimeIndex(txn);\n      });\n    }\n\n    if (fromVersion < 10 && toVersion >= 10) {\n      p = p.next(() => this.rewriteCanonicalIds(simpleDbTransaction));\n    }\n    return p;\n  }\n\n  private addDocumentGlobal(\n    txn: SimpleDbTransaction\n  ): PersistencePromise<void> {\n    let byteCount = 0;\n    return txn\n      .store<DbRemoteDocumentKey, DbRemoteDocument>(DbRemoteDocument.store)\n      .iterate((_, doc) => {\n        byteCount += dbDocumentSize(doc);\n      })\n      .next(() => {\n        const metadata = new DbRemoteDocumentGlobal(byteCount);\n        return txn\n          .store<DbRemoteDocumentGlobalKey, DbRemoteDocumentGlobal>(\n            DbRemoteDocumentGlobal.store\n          )\n          .put(DbRemoteDocumentGlobal.key, metadata);\n      });\n  }\n\n  private removeAcknowledgedMutations(\n    txn: SimpleDbTransaction\n  ): PersistencePromise<void> {\n    const queuesStore = txn.store<DbMutationQueueKey, DbMutationQueue>(\n      DbMutationQueue.store\n    );\n    const mutationsStore = txn.store<DbMutationBatchKey, DbMutationBatch>(\n      DbMutationBatch.store\n    );\n\n    return queuesStore.loadAll().next(queues => {\n      return PersistencePromise.forEach(queues, (queue: DbMutationQueue) => {\n        const range = IDBKeyRange.bound(\n          [queue.userId, BATCHID_UNKNOWN],\n          [queue.userId, queue.lastAcknowledgedBatchId]\n        );\n\n        return mutationsStore\n          .loadAll(DbMutationBatch.userMutationsIndex, range)\n          .next(dbBatches => {\n            return PersistencePromise.forEach(\n              dbBatches,\n              (dbBatch: DbMutationBatch) => {\n                hardAssert(\n                  dbBatch.userId === queue.userId,\n                  `Cannot process batch ${dbBatch.batchId} from unexpected user`\n                );\n                const batch = this.serializer.fromDbMutationBatch(dbBatch);\n\n                return removeMutationBatch(\n                  txn,\n                  queue.userId,\n                  batch\n                ).next(() => {});\n              }\n            );\n          });\n      });\n    });\n  }\n\n  /**\n   * Ensures that every document in the remote document cache has a corresponding sentinel row\n   * with a sequence number. Missing rows are given the most recently used sequence number.\n   */\n  private ensureSequenceNumbers(\n    txn: SimpleDbTransaction\n  ): PersistencePromise<void> {\n    const documentTargetStore = txn.store<\n      DbTargetDocumentKey,\n      DbTargetDocument\n    >(DbTargetDocument.store);\n    const documentsStore = txn.store<DbRemoteDocumentKey, DbRemoteDocument>(\n      DbRemoteDocument.store\n    );\n\n    return getHighestListenSequenceNumber(txn).next(currentSequenceNumber => {\n      const writeSentinelKey = (\n        path: ResourcePath\n      ): PersistencePromise<void> => {\n        return documentTargetStore.put(\n          new DbTargetDocument(\n            0,\n            encodeResourcePath(path),\n            currentSequenceNumber\n          )\n        );\n      };\n\n      const promises: Array<PersistencePromise<void>> = [];\n      return documentsStore\n        .iterate((key, doc) => {\n          const path = new ResourcePath(key);\n          const docSentinelKey = sentinelKey(path);\n          promises.push(\n            documentTargetStore.get(docSentinelKey).next(maybeSentinel => {\n              if (!maybeSentinel) {\n                return writeSentinelKey(path);\n              } else {\n                return PersistencePromise.resolve();\n              }\n            })\n          );\n        })\n        .next(() => PersistencePromise.waitFor(promises));\n    });\n  }\n\n  private createCollectionParentIndex(\n    db: IDBDatabase,\n    txn: SimpleDbTransaction\n  ): PersistencePromise<void> {\n    // Create the index.\n    db.createObjectStore(DbCollectionParent.store, {\n      keyPath: DbCollectionParent.keyPath\n    });\n\n    const collectionParentsStore = txn.store<\n      DbCollectionParentKey,\n      DbCollectionParent\n    >(DbCollectionParent.store);\n\n    // Helper to add an index entry iff we haven't already written it.\n    const cache = new MemoryCollectionParentIndex();\n    const addEntry = (\n      collectionPath: ResourcePath\n    ): PersistencePromise<void> | undefined => {\n      if (cache.add(collectionPath)) {\n        const collectionId = collectionPath.lastSegment();\n        const parentPath = collectionPath.popLast();\n        return collectionParentsStore.put({\n          collectionId,\n          parent: encodeResourcePath(parentPath)\n        });\n      }\n    };\n\n    // Index existing remote documents.\n    return txn\n      .store<DbRemoteDocumentKey, DbRemoteDocument>(DbRemoteDocument.store)\n      .iterate({ keysOnly: true }, (pathSegments, _) => {\n        const path = new ResourcePath(pathSegments);\n        return addEntry(path.popLast());\n      })\n      .next(() => {\n        // Index existing mutations.\n        return txn\n          .store<DbDocumentMutationKey, DbDocumentMutation>(\n            DbDocumentMutation.store\n          )\n          .iterate({ keysOnly: true }, ([userID, encodedPath, batchId], _) => {\n            const path = decodeResourcePath(encodedPath);\n            return addEntry(path.popLast());\n          });\n      });\n  }\n\n  private rewriteCanonicalIds(\n    txn: SimpleDbTransaction\n  ): PersistencePromise<void> {\n    const targetStore = txn.store<DbTargetKey, DbTarget>(DbTarget.store);\n    return targetStore.iterate((key, originalDbTarget) => {\n      const originalTargetData = this.serializer.fromDbTarget(originalDbTarget);\n      const updatedDbTarget = this.serializer.toDbTarget(originalTargetData);\n      return targetStore.put(updatedDbTarget);\n    });\n  }\n}\n\nfunction sentinelKey(path: ResourcePath): DbTargetDocumentKey {\n  return [0, encodeResourcePath(path)];\n}\n\n/**\n * Wrapper class to store timestamps (seconds and nanos) in IndexedDb objects.\n */\nexport class DbTimestamp {\n  constructor(public seconds: number, public nanoseconds: number) {}\n}\n\n/** A timestamp type that can be used in IndexedDb keys. */\nexport type DbTimestampKey = [/* seconds */ number, /* nanos */ number];\n\n// The key for the singleton object in the DbPrimaryClient is a single string.\nexport type DbPrimaryClientKey = typeof DbPrimaryClient.key;\n\n/**\n * A singleton object to be stored in the 'owner' store in IndexedDb.\n *\n * A given database can have a single primary tab assigned at a given time. That\n * tab must validate that it is still holding the primary lease before every\n * operation that requires locked access. The primary tab should regularly\n * write an updated timestamp to this lease to prevent other tabs from\n * \"stealing\" the primary lease\n */\nexport class DbPrimaryClient {\n  /**\n   * Name of the IndexedDb object store.\n   *\n   * Note that the name 'owner' is chosen to ensure backwards compatibility with\n   * older clients that only supported single locked access to the persistence\n   * layer.\n   */\n  static store = 'owner';\n\n  /**\n   * The key string used for the single object that exists in the\n   * DbPrimaryClient store.\n   */\n  static key = 'owner';\n\n  constructor(\n    public ownerId: string,\n    /** Whether to allow shared access from multiple tabs. */\n    public allowTabSynchronization: boolean,\n    public leaseTimestampMs: number\n  ) {}\n}\n\nfunction createPrimaryClientStore(db: IDBDatabase): void {\n  db.createObjectStore(DbPrimaryClient.store);\n}\n\n/** Object keys in the 'mutationQueues' store are userId strings. */\nexport type DbMutationQueueKey = string;\n\n/**\n * An object to be stored in the 'mutationQueues' store in IndexedDb.\n *\n * Each user gets a single queue of MutationBatches to apply to the server.\n * DbMutationQueue tracks the metadata about the queue.\n */\nexport class DbMutationQueue {\n  /** Name of the IndexedDb object store.  */\n  static store = 'mutationQueues';\n\n  /** Keys are automatically assigned via the userId property. */\n  static keyPath = 'userId';\n\n  constructor(\n    /**\n     * The normalized user ID to which this queue belongs.\n     */\n    public userId: string,\n    /**\n     * An identifier for the highest numbered batch that has been acknowledged\n     * by the server. All MutationBatches in this queue with batchIds less\n     * than or equal to this value are considered to have been acknowledged by\n     * the server.\n     *\n     * NOTE: this is deprecated and no longer used by the code.\n     */\n    public lastAcknowledgedBatchId: number,\n    /**\n     * A stream token that was previously sent by the server.\n     *\n     * See StreamingWriteRequest in datastore.proto for more details about\n     * usage.\n     *\n     * After sending this token, earlier tokens may not be used anymore so\n     * only a single stream token is retained.\n     */\n    public lastStreamToken: string\n  ) {}\n}\n\n/** The 'mutations' store  is keyed by batch ID. */\nexport type DbMutationBatchKey = BatchId;\n\n/**\n * An object to be stored in the 'mutations' store in IndexedDb.\n *\n * Represents a batch of user-level mutations intended to be sent to the server\n * in a single write. Each user-level batch gets a separate DbMutationBatch\n * with a new batchId.\n */\nexport class DbMutationBatch {\n  /** Name of the IndexedDb object store.  */\n  static store = 'mutations';\n\n  /** Keys are automatically assigned via the userId, batchId properties. */\n  static keyPath = 'batchId';\n\n  /** The index name for lookup of mutations by user. */\n  static userMutationsIndex = 'userMutationsIndex';\n\n  /** The user mutations index is keyed by [userId, batchId] pairs. */\n  static userMutationsKeyPath = ['userId', 'batchId'];\n\n  constructor(\n    /**\n     * The normalized user ID to which this batch belongs.\n     */\n    public userId: string,\n    /**\n     * An identifier for this batch, allocated using an auto-generated key.\n     */\n    public batchId: BatchId,\n    /**\n     * The local write time of the batch, stored as milliseconds since the\n     * epoch.\n     */\n    public localWriteTimeMs: number,\n    /**\n     * A list of \"mutations\" that represent a partial base state from when this\n     * write batch was initially created. During local application of the write\n     * batch, these baseMutations are applied prior to the real writes in order\n     * to override certain document fields from the remote document cache. This\n     * is necessary in the case of non-idempotent writes (e.g. `increment()`\n     * transforms) to make sure that the local view of the modified documents\n     * doesn't flicker if the remote document cache receives the result of the\n     * non-idempotent write before the write is removed from the queue.\n     *\n     * These mutations are never sent to the backend.\n     */\n    public baseMutations: api.Write[] | undefined,\n    /**\n     * A list of mutations to apply. All mutations will be applied atomically.\n     *\n     * Mutations are serialized via JsonProtoSerializer.toMutation().\n     */\n    public mutations: api.Write[]\n  ) {}\n}\n\n/**\n * The key for a db document mutation, which is made up of a userID, path, and\n * batchId. Note that the path must be serialized into a form that indexedDB can\n * sort.\n */\nexport type DbDocumentMutationKey = [string, EncodedResourcePath, BatchId];\n\nfunction createMutationQueue(db: IDBDatabase): void {\n  db.createObjectStore(DbMutationQueue.store, {\n    keyPath: DbMutationQueue.keyPath\n  });\n\n  const mutationBatchesStore = db.createObjectStore(DbMutationBatch.store, {\n    keyPath: DbMutationBatch.keyPath,\n    autoIncrement: true\n  });\n  mutationBatchesStore.createIndex(\n    DbMutationBatch.userMutationsIndex,\n    DbMutationBatch.userMutationsKeyPath,\n    { unique: true }\n  );\n\n  db.createObjectStore(DbDocumentMutation.store);\n}\n\n/**\n * Upgrade function to migrate the 'mutations' store from V1 to V3. Loads\n * and rewrites all data.\n */\nfunction upgradeMutationBatchSchemaAndMigrateData(\n  db: IDBDatabase,\n  txn: SimpleDbTransaction\n): PersistencePromise<void> {\n  const v1MutationsStore = txn.store<[string, number], DbMutationBatch>(\n    DbMutationBatch.store\n  );\n  return v1MutationsStore.loadAll().next(existingMutations => {\n    db.deleteObjectStore(DbMutationBatch.store);\n\n    const mutationsStore = db.createObjectStore(DbMutationBatch.store, {\n      keyPath: DbMutationBatch.keyPath,\n      autoIncrement: true\n    });\n    mutationsStore.createIndex(\n      DbMutationBatch.userMutationsIndex,\n      DbMutationBatch.userMutationsKeyPath,\n      { unique: true }\n    );\n\n    const v3MutationsStore = txn.store<DbMutationBatchKey, DbMutationBatch>(\n      DbMutationBatch.store\n    );\n    const writeAll = existingMutations.map(mutation =>\n      v3MutationsStore.put(mutation)\n    );\n\n    return PersistencePromise.waitFor(writeAll);\n  });\n}\n\n/**\n * An object to be stored in the 'documentMutations' store in IndexedDb.\n *\n * A manually maintained index of all the mutation batches that affect a given\n * document key. The rows in this table are references based on the contents of\n * DbMutationBatch.mutations.\n */\nexport class DbDocumentMutation {\n  static store = 'documentMutations';\n\n  /**\n   * Creates a [userId] key for use in the DbDocumentMutations index to iterate\n   * over all of a user's document mutations.\n   */\n  static prefixForUser(userId: string): [string] {\n    return [userId];\n  }\n\n  /**\n   * Creates a [userId, encodedPath] key for use in the DbDocumentMutations\n   * index to iterate over all at document mutations for a given path or lower.\n   */\n  static prefixForPath(\n    userId: string,\n    path: ResourcePath\n  ): [string, EncodedResourcePath] {\n    return [userId, encodeResourcePath(path)];\n  }\n\n  /**\n   * Creates a full index key of [userId, encodedPath, batchId] for inserting\n   * and deleting into the DbDocumentMutations index.\n   */\n  static key(\n    userId: string,\n    path: ResourcePath,\n    batchId: BatchId\n  ): DbDocumentMutationKey {\n    return [userId, encodeResourcePath(path), batchId];\n  }\n\n  /**\n   * Because we store all the useful information for this store in the key,\n   * there is no useful information to store as the value. The raw (unencoded)\n   * path cannot be stored because IndexedDb doesn't store prototype\n   * information.\n   */\n  static PLACEHOLDER = new DbDocumentMutation();\n\n  private constructor() {}\n}\n\n/**\n * A key in the 'remoteDocuments' object store is a string array containing the\n * segments that make up the path.\n */\nexport type DbRemoteDocumentKey = string[];\n\nfunction createRemoteDocumentCache(db: IDBDatabase): void {\n  db.createObjectStore(DbRemoteDocument.store);\n}\n\n/**\n * Represents the known absence of a document at a particular version.\n * Stored in IndexedDb as part of a DbRemoteDocument object.\n */\nexport class DbNoDocument {\n  constructor(public path: string[], public readTime: DbTimestamp) {}\n}\n\n/**\n * Represents a document that is known to exist but whose data is unknown.\n * Stored in IndexedDb as part of a DbRemoteDocument object.\n */\nexport class DbUnknownDocument {\n  constructor(public path: string[], public version: DbTimestamp) {}\n}\n\n/**\n * An object to be stored in the 'remoteDocuments' store in IndexedDb.\n * It represents either:\n *\n * - A complete document.\n * - A \"no document\" representing a document that is known not to exist (at\n * some version).\n * - An \"unknown document\" representing a document that is known to exist (at\n * some version) but whose contents are unknown.\n *\n * Note: This is the persisted equivalent of a MaybeDocument and could perhaps\n * be made more general if necessary.\n */\nexport class DbRemoteDocument {\n  static store = 'remoteDocuments';\n\n  /**\n   * An index that provides access to all entries sorted by read time (which\n   * corresponds to the last modification time of each row).\n   *\n   * This index is used to provide a changelog for Multi-Tab.\n   */\n  static readTimeIndex = 'readTimeIndex';\n\n  static readTimeIndexPath = 'readTime';\n\n  /**\n   * An index that provides access to documents in a collection sorted by read\n   * time.\n   *\n   * This index is used to allow the RemoteDocumentCache to fetch newly changed\n   * documents in a collection.\n   */\n  static collectionReadTimeIndex = 'collectionReadTimeIndex';\n\n  static collectionReadTimeIndexPath = ['parentPath', 'readTime'];\n\n  // TODO: We are currently storing full document keys almost three times\n  // (once as part of the primary key, once - partly - as `parentPath` and once\n  // inside the encoded documents). During our next migration, we should\n  // rewrite the primary key as parentPath + document ID which would allow us\n  // to drop one value.\n\n  constructor(\n    /**\n     * Set to an instance of DbUnknownDocument if the data for a document is\n     * not known, but it is known that a document exists at the specified\n     * version (e.g. it had a successful update applied to it)\n     */\n    public unknownDocument: DbUnknownDocument | null | undefined,\n    /**\n     * Set to an instance of a DbNoDocument if it is known that no document\n     * exists.\n     */\n    public noDocument: DbNoDocument | null,\n    /**\n     * Set to an instance of a Document if there's a cached version of the\n     * document.\n     */\n    public document: api.Document | null,\n    /**\n     * Documents that were written to the remote document store based on\n     * a write acknowledgment are marked with `hasCommittedMutations`. These\n     * documents are potentially inconsistent with the backend's copy and use\n     * the write's commit version as their document version.\n     */\n    public hasCommittedMutations: boolean | undefined,\n\n    /**\n     * When the document was read from the backend. Undefined for data written\n     * prior to schema version 9.\n     */\n    public readTime: DbTimestampKey | undefined,\n\n    /**\n     * The path of the collection this document is part of. Undefined for data\n     * written prior to schema version 9.\n     */\n    public parentPath: string[] | undefined\n  ) {}\n}\n\n/**\n * Contains a single entry that has metadata about the remote document cache.\n */\nexport class DbRemoteDocumentGlobal {\n  static store = 'remoteDocumentGlobal';\n\n  static key = 'remoteDocumentGlobalKey';\n\n  /**\n   * @param byteSize Approximately the total size in bytes of all the documents in the document\n   * cache.\n   */\n  constructor(public byteSize: number) {}\n}\n\nexport type DbRemoteDocumentGlobalKey = typeof DbRemoteDocumentGlobal.key;\n\nfunction createDocumentGlobalStore(db: IDBDatabase): void {\n  db.createObjectStore(DbRemoteDocumentGlobal.store);\n}\n\n/**\n * A key in the 'targets' object store is a targetId of the query.\n */\nexport type DbTargetKey = TargetId;\n\n/**\n * The persisted type for a query nested with in the 'targets' store in\n * IndexedDb. We use the proto definitions for these two kinds of queries in\n * order to avoid writing extra serialization logic.\n */\nexport type DbQuery = api.QueryTarget | api.DocumentsTarget;\n\n/**\n * An object to be stored in the 'targets' store in IndexedDb.\n *\n * This is based on and should be kept in sync with the proto used in the iOS\n * client.\n *\n * Each query the client listens to against the server is tracked on disk so\n * that the query can be efficiently resumed on restart.\n */\nexport class DbTarget {\n  static store = 'targets';\n\n  /** Keys are automatically assigned via the targetId property. */\n  static keyPath = 'targetId';\n\n  /** The name of the queryTargets index. */\n  static queryTargetsIndexName = 'queryTargetsIndex';\n\n  /**\n   * The index of all canonicalIds to the targets that they match. This is not\n   * a unique mapping because canonicalId does not promise a unique name for all\n   * possible queries, so we append the targetId to make the mapping unique.\n   */\n  static queryTargetsKeyPath = ['canonicalId', 'targetId'];\n\n  constructor(\n    /**\n     * An auto-generated sequential numeric identifier for the query.\n     *\n     * Queries are stored using their canonicalId as the key, but these\n     * canonicalIds can be quite long so we additionally assign a unique\n     * queryId which can be used by referenced data structures (e.g.\n     * indexes) to minimize the on-disk cost.\n     */\n    public targetId: TargetId,\n    /**\n     * The canonical string representing this query. This is not unique.\n     */\n    public canonicalId: string,\n    /**\n     * The last readTime received from the Watch Service for this query.\n     *\n     * This is the same value as TargetChange.read_time in the protos.\n     */\n    public readTime: DbTimestamp,\n    /**\n     * An opaque, server-assigned token that allows watching a query to be\n     * resumed after disconnecting without retransmitting all the data\n     * that matches the query. The resume token essentially identifies a\n     * point in time from which the server should resume sending results.\n     *\n     * This is related to the snapshotVersion in that the resumeToken\n     * effectively also encodes that value, but the resumeToken is opaque\n     * and sometimes encodes additional information.\n     *\n     * A consequence of this is that the resumeToken should be used when\n     * asking the server to reason about where this client is in the watch\n     * stream, but the client should use the snapshotVersion for its own\n     * purposes.\n     *\n     * This is the same value as TargetChange.resume_token in the protos.\n     */\n    public resumeToken: string,\n    /**\n     * A sequence number representing the last time this query was\n     * listened to, used for garbage collection purposes.\n     *\n     * Conventionally this would be a timestamp value, but device-local\n     * clocks are unreliable and they must be able to create new listens\n     * even while disconnected. Instead this should be a monotonically\n     * increasing number that's incremented on each listen call.\n     *\n     * This is different from the queryId since the queryId is an\n     * immutable identifier assigned to the Query on first use while\n     * lastListenSequenceNumber is updated every time the query is\n     * listened to.\n     */\n    public lastListenSequenceNumber: number,\n    /**\n     * Denotes the maximum snapshot version at which the associated query view\n     * contained no limbo documents.  Undefined for data written prior to\n     * schema version 9.\n     */\n    public lastLimboFreeSnapshotVersion: DbTimestamp | undefined,\n    /**\n     * The query for this target.\n     *\n     * Because canonical ids are not unique we must store the actual query. We\n     * use the proto to have an object we can persist without having to\n     * duplicate translation logic to and from a `Query` object.\n     */\n    public query: DbQuery\n  ) {}\n}\n\n/**\n * The key for a DbTargetDocument, containing a targetId and an encoded resource\n * path.\n */\nexport type DbTargetDocumentKey = [TargetId, EncodedResourcePath];\n\n/**\n * An object representing an association between a target and a document, or a\n * sentinel row marking the last sequence number at which a document was used.\n * Each document cached must have a corresponding sentinel row before lru\n * garbage collection is enabled.\n *\n * The target associations and sentinel rows are co-located so that orphaned\n * documents and their sequence numbers can be identified efficiently via a scan\n * of this store.\n */\nexport class DbTargetDocument {\n  /** Name of the IndexedDb object store.  */\n  static store = 'targetDocuments';\n\n  /** Keys are automatically assigned via the targetId, path properties. */\n  static keyPath = ['targetId', 'path'];\n\n  /** The index name for the reverse index. */\n  static documentTargetsIndex = 'documentTargetsIndex';\n\n  /** We also need to create the reverse index for these properties. */\n  static documentTargetsKeyPath = ['path', 'targetId'];\n\n  constructor(\n    /**\n     * The targetId identifying a target or 0 for a sentinel row.\n     */\n    public targetId: TargetId,\n    /**\n     * The path to the document, as encoded in the key.\n     */\n    public path: EncodedResourcePath,\n    /**\n     * If this is a sentinel row, this should be the sequence number of the last\n     * time the document specified by `path` was used. Otherwise, it should be\n     * `undefined`.\n     */\n    public sequenceNumber?: ListenSequenceNumber\n  ) {\n    debugAssert(\n      (targetId === 0) === (sequenceNumber !== undefined),\n      'A target-document row must either have targetId == 0 and a defined sequence number, or a non-zero targetId and no sequence number'\n    );\n  }\n}\n\n/**\n * The type to represent the single allowed key for the DbTargetGlobal store.\n */\nexport type DbTargetGlobalKey = typeof DbTargetGlobal.key;\n\n/**\n * A record of global state tracked across all Targets, tracked separately\n * to avoid the need for extra indexes.\n *\n * This should be kept in-sync with the proto used in the iOS client.\n */\nexport class DbTargetGlobal {\n  /**\n   * The key string used for the single object that exists in the\n   * DbTargetGlobal store.\n   */\n  static key = 'targetGlobalKey';\n  static store = 'targetGlobal';\n\n  constructor(\n    /**\n     * The highest numbered target id across all targets.\n     *\n     * See DbTarget.targetId.\n     */\n    public highestTargetId: TargetId,\n    /**\n     * The highest numbered lastListenSequenceNumber across all targets.\n     *\n     * See DbTarget.lastListenSequenceNumber.\n     */\n    public highestListenSequenceNumber: number,\n    /**\n     * A global snapshot version representing the last consistent snapshot we\n     * received from the backend. This is monotonically increasing and any\n     * snapshots received from the backend prior to this version (e.g. for\n     * targets resumed with a resumeToken) should be suppressed (buffered)\n     * until the backend has caught up to this snapshot version again. This\n     * prevents our cache from ever going backwards in time.\n     */\n    public lastRemoteSnapshotVersion: DbTimestamp,\n    /**\n     * The number of targets persisted.\n     */\n    public targetCount: number\n  ) {}\n}\n\n/**\n * The key for a DbCollectionParent entry, containing the collection ID\n * and the parent path that contains it. Note that the parent path will be an\n * empty path in the case of root-level collections.\n */\nexport type DbCollectionParentKey = [string, EncodedResourcePath];\n\n/**\n * An object representing an association between a Collection id (e.g. 'messages')\n * to a parent path (e.g. '/chats/123') that contains it as a (sub)collection.\n * This is used to efficiently find all collections to query when performing\n * a Collection Group query.\n */\nexport class DbCollectionParent {\n  /** Name of the IndexedDb object store. */\n  static store = 'collectionParents';\n\n  /** Keys are automatically assigned via the collectionId, parent properties. */\n  static keyPath = ['collectionId', 'parent'];\n\n  constructor(\n    /**\n     * The collectionId (e.g. 'messages')\n     */\n    public collectionId: string,\n    /**\n     * The path to the parent (either a document location or an empty path for\n     * a root-level collection).\n     */\n    public parent: EncodedResourcePath\n  ) {}\n}\n\nfunction createQueryCache(db: IDBDatabase): void {\n  const targetDocumentsStore = db.createObjectStore(DbTargetDocument.store, {\n    keyPath: DbTargetDocument.keyPath\n  });\n  targetDocumentsStore.createIndex(\n    DbTargetDocument.documentTargetsIndex,\n    DbTargetDocument.documentTargetsKeyPath,\n    { unique: true }\n  );\n\n  const targetStore = db.createObjectStore(DbTarget.store, {\n    keyPath: DbTarget.keyPath\n  });\n\n  // NOTE: This is unique only because the TargetId is the suffix.\n  targetStore.createIndex(\n    DbTarget.queryTargetsIndexName,\n    DbTarget.queryTargetsKeyPath,\n    { unique: true }\n  );\n  db.createObjectStore(DbTargetGlobal.store);\n}\n\nfunction dropQueryCache(db: IDBDatabase): void {\n  db.deleteObjectStore(DbTargetDocument.store);\n  db.deleteObjectStore(DbTarget.store);\n  db.deleteObjectStore(DbTargetGlobal.store);\n}\n\nfunction dropRemoteDocumentChangesStore(db: IDBDatabase): void {\n  if (db.objectStoreNames.contains('remoteDocumentChanges')) {\n    db.deleteObjectStore('remoteDocumentChanges');\n  }\n}\n\n/**\n * Creates the target global singleton row.\n *\n * @param {IDBTransaction} txn The version upgrade transaction for indexeddb\n */\nfunction writeEmptyTargetGlobalEntry(\n  txn: SimpleDbTransaction\n): PersistencePromise<void> {\n  const globalStore = txn.store<DbTargetGlobalKey, DbTargetGlobal>(\n    DbTargetGlobal.store\n  );\n  const metadata = new DbTargetGlobal(\n    /*highestTargetId=*/ 0,\n    /*lastListenSequenceNumber=*/ 0,\n    SnapshotVersion.MIN.toTimestamp(),\n    /*targetCount=*/ 0\n  );\n  return globalStore.put(DbTargetGlobal.key, metadata);\n}\n\n/**\n * Creates indices on the RemoteDocuments store used for both multi-tab\n * and Index-Free queries.\n */\nfunction createRemoteDocumentReadTimeIndex(txn: IDBTransaction): void {\n  const remoteDocumentStore = txn.objectStore(DbRemoteDocument.store);\n  remoteDocumentStore.createIndex(\n    DbRemoteDocument.readTimeIndex,\n    DbRemoteDocument.readTimeIndexPath,\n    { unique: false }\n  );\n  remoteDocumentStore.createIndex(\n    DbRemoteDocument.collectionReadTimeIndex,\n    DbRemoteDocument.collectionReadTimeIndexPath,\n    { unique: false }\n  );\n}\n\n/**\n * A record of the metadata state of each client.\n *\n * PORTING NOTE: This is used to synchronize multi-tab state and does not need\n * to be ported to iOS or Android.\n */\nexport class DbClientMetadata {\n  /** Name of the IndexedDb object store. */\n  static store = 'clientMetadata';\n\n  /** Keys are automatically assigned via the clientId properties. */\n  static keyPath = 'clientId';\n\n  constructor(\n    // Note: Previous schema versions included a field\n    // \"lastProcessedDocumentChangeId\". Don't use anymore.\n\n    /** The auto-generated client id assigned at client startup. */\n    public clientId: string,\n    /** The last time this state was updated. */\n    public updateTimeMs: number,\n    /** Whether the client's network connection is enabled. */\n    public networkEnabled: boolean,\n    /** Whether this client is running in a foreground tab. */\n    public inForeground: boolean\n  ) {}\n}\n\n/** Object keys in the 'clientMetadata' store are clientId strings. */\nexport type DbClientMetadataKey = string;\n\nfunction createClientMetadataStore(db: IDBDatabase): void {\n  db.createObjectStore(DbClientMetadata.store, {\n    keyPath: DbClientMetadata.keyPath\n  });\n}\n\n// Visible for testing\nexport const V1_STORES = [\n  DbMutationQueue.store,\n  DbMutationBatch.store,\n  DbDocumentMutation.store,\n  DbRemoteDocument.store,\n  DbTarget.store,\n  DbPrimaryClient.store,\n  DbTargetGlobal.store,\n  DbTargetDocument.store\n];\n\n// V2 is no longer usable (see comment at top of file)\n\n// Visible for testing\nexport const V3_STORES = V1_STORES;\n\n// Visible for testing\n// Note: DbRemoteDocumentChanges is no longer used and dropped with v9.\nexport const V4_STORES = [...V3_STORES, DbClientMetadata.store];\n\n// V5 does not change the set of stores.\n\nexport const V6_STORES = [...V4_STORES, DbRemoteDocumentGlobal.store];\n\n// V7 does not change the set of stores.\n\nexport const V8_STORES = [...V6_STORES, DbCollectionParent.store];\n\n// V9 does not change the set of stores.\n\n// V10 does not change the set of stores.\n\n/**\n * The list of all default IndexedDB stores used throughout the SDK. This is\n * used when creating transactions so that access across all stores is done\n * atomically.\n */\nexport const ALL_STORES = V8_STORES;\n","/**\n * @license\n * Copyright 2019 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { ResourcePath } from '../model/path';\nimport { debugAssert } from '../util/assert';\nimport { immediateSuccessor } from '../util/misc';\nimport {\n  decodeResourcePath,\n  encodeResourcePath\n} from './encoded_resource_path';\nimport { IndexManager } from './index_manager';\nimport { IndexedDbPersistence } from './indexeddb_persistence';\nimport { DbCollectionParent, DbCollectionParentKey } from './indexeddb_schema';\nimport { MemoryCollectionParentIndex } from './memory_index_manager';\nimport { PersistenceTransaction } from './persistence';\nimport { PersistencePromise } from './persistence_promise';\nimport { SimpleDbStore } from './simple_db';\n\n/**\n * A persisted implementation of IndexManager.\n */\nexport class IndexedDbIndexManager implements IndexManager {\n  /**\n   * An in-memory copy of the index entries we've already written since the SDK\n   * launched. Used to avoid re-writing the same entry repeatedly.\n   *\n   * This is *NOT* a complete cache of what's in persistence and so can never be used to\n   * satisfy reads.\n   */\n  private collectionParentsCache = new MemoryCollectionParentIndex();\n\n  /**\n   * Adds a new entry to the collection parent index.\n   *\n   * Repeated calls for the same collectionPath should be avoided within a\n   * transaction as IndexedDbIndexManager only caches writes once a transaction\n   * has been committed.\n   */\n  addToCollectionParentIndex(\n    transaction: PersistenceTransaction,\n    collectionPath: ResourcePath\n  ): PersistencePromise<void> {\n    debugAssert(collectionPath.length % 2 === 1, 'Expected a collection path.');\n    if (!this.collectionParentsCache.has(collectionPath)) {\n      const collectionId = collectionPath.lastSegment();\n      const parentPath = collectionPath.popLast();\n\n      transaction.addOnCommittedListener(() => {\n        // Add the collection to the in memory cache only if the transaction was\n        // successfully committed.\n        this.collectionParentsCache.add(collectionPath);\n      });\n\n      const collectionParent: DbCollectionParent = {\n        collectionId,\n        parent: encodeResourcePath(parentPath)\n      };\n      return collectionParentsStore(transaction).put(collectionParent);\n    }\n    return PersistencePromise.resolve();\n  }\n\n  getCollectionParents(\n    transaction: PersistenceTransaction,\n    collectionId: string\n  ): PersistencePromise<ResourcePath[]> {\n    const parentPaths = [] as ResourcePath[];\n    const range = IDBKeyRange.bound(\n      [collectionId, ''],\n      [immediateSuccessor(collectionId), ''],\n      /*lowerOpen=*/ false,\n      /*upperOpen=*/ true\n    );\n    return collectionParentsStore(transaction)\n      .loadAll(range)\n      .next(entries => {\n        for (const entry of entries) {\n          // This collectionId guard shouldn't be necessary (and isn't as long\n          // as we're running in a real browser), but there's a bug in\n          // indexeddbshim that breaks our range in our tests running in node:\n          // https://github.com/axemclion/IndexedDBShim/issues/334\n          if (entry.collectionId !== collectionId) {\n            break;\n          }\n          parentPaths.push(decodeResourcePath(entry.parent));\n        }\n        return parentPaths;\n      });\n  }\n}\n\n/**\n * Helper to get a typed SimpleDbStore for the collectionParents\n * document store.\n */\nfunction collectionParentsStore(\n  txn: PersistenceTransaction\n): SimpleDbStore<DbCollectionParentKey, DbCollectionParent> {\n  return IndexedDbPersistence.getStore<\n    DbCollectionParentKey,\n    DbCollectionParent\n  >(txn, DbCollectionParent.store);\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Timestamp } from '../api/timestamp';\nimport { SnapshotVersion } from '../core/snapshot_version';\nimport {\n  Document,\n  MaybeDocument,\n  NoDocument,\n  UnknownDocument\n} from '../model/document';\nimport { DocumentKey } from '../model/document_key';\nimport { MutationBatch } from '../model/mutation_batch';\nimport * as api from '../protos/firestore_proto_api';\nimport { JsonProtoSerializer } from '../remote/serializer';\nimport { debugAssert, fail } from '../util/assert';\nimport { ByteString } from '../util/byte_string';\nimport { Target } from '../core/target';\nimport {\n  DbMutationBatch,\n  DbNoDocument,\n  DbQuery,\n  DbRemoteDocument,\n  DbTarget,\n  DbTimestamp,\n  DbTimestampKey,\n  DbUnknownDocument\n} from './indexeddb_schema';\nimport { TargetData, TargetPurpose } from './target_data';\n\n/** Serializer for values stored in the LocalStore. */\nexport class LocalSerializer {\n  constructor(private remoteSerializer: JsonProtoSerializer) {}\n\n  /** Decodes a remote document from storage locally to a Document. */\n  fromDbRemoteDocument(remoteDoc: DbRemoteDocument): MaybeDocument {\n    if (remoteDoc.document) {\n      return this.remoteSerializer.fromDocument(\n        remoteDoc.document,\n        !!remoteDoc.hasCommittedMutations\n      );\n    } else if (remoteDoc.noDocument) {\n      const key = DocumentKey.fromSegments(remoteDoc.noDocument.path);\n      const version = this.fromDbTimestamp(remoteDoc.noDocument.readTime);\n      return new NoDocument(key, version, {\n        hasCommittedMutations: !!remoteDoc.hasCommittedMutations\n      });\n    } else if (remoteDoc.unknownDocument) {\n      const key = DocumentKey.fromSegments(remoteDoc.unknownDocument.path);\n      const version = this.fromDbTimestamp(remoteDoc.unknownDocument.version);\n      return new UnknownDocument(key, version);\n    } else {\n      return fail('Unexpected DbRemoteDocument');\n    }\n  }\n\n  /** Encodes a document for storage locally. */\n  toDbRemoteDocument(\n    maybeDoc: MaybeDocument,\n    readTime: SnapshotVersion\n  ): DbRemoteDocument {\n    const dbReadTime = this.toDbTimestampKey(readTime);\n    const parentPath = maybeDoc.key.path.popLast().toArray();\n    if (maybeDoc instanceof Document) {\n      const doc = this.remoteSerializer.toDocument(maybeDoc);\n      const hasCommittedMutations = maybeDoc.hasCommittedMutations;\n      return new DbRemoteDocument(\n        /* unknownDocument= */ null,\n        /* noDocument= */ null,\n        doc,\n        hasCommittedMutations,\n        dbReadTime,\n        parentPath\n      );\n    } else if (maybeDoc instanceof NoDocument) {\n      const path = maybeDoc.key.path.toArray();\n      const readTime = this.toDbTimestamp(maybeDoc.version);\n      const hasCommittedMutations = maybeDoc.hasCommittedMutations;\n      return new DbRemoteDocument(\n        /* unknownDocument= */ null,\n        new DbNoDocument(path, readTime),\n        /* document= */ null,\n        hasCommittedMutations,\n        dbReadTime,\n        parentPath\n      );\n    } else if (maybeDoc instanceof UnknownDocument) {\n      const path = maybeDoc.key.path.toArray();\n      const readTime = this.toDbTimestamp(maybeDoc.version);\n      return new DbRemoteDocument(\n        new DbUnknownDocument(path, readTime),\n        /* noDocument= */ null,\n        /* document= */ null,\n        /* hasCommittedMutations= */ true,\n        dbReadTime,\n        parentPath\n      );\n    } else {\n      return fail('Unexpected MaybeDocument');\n    }\n  }\n\n  toDbTimestampKey(snapshotVersion: SnapshotVersion): DbTimestampKey {\n    const timestamp = snapshotVersion.toTimestamp();\n    return [timestamp.seconds, timestamp.nanoseconds];\n  }\n\n  fromDbTimestampKey(dbTimestampKey: DbTimestampKey): SnapshotVersion {\n    const timestamp = new Timestamp(dbTimestampKey[0], dbTimestampKey[1]);\n    return SnapshotVersion.fromTimestamp(timestamp);\n  }\n\n  private toDbTimestamp(snapshotVersion: SnapshotVersion): DbTimestamp {\n    const timestamp = snapshotVersion.toTimestamp();\n    return new DbTimestamp(timestamp.seconds, timestamp.nanoseconds);\n  }\n\n  private fromDbTimestamp(dbTimestamp: DbTimestamp): SnapshotVersion {\n    const timestamp = new Timestamp(\n      dbTimestamp.seconds,\n      dbTimestamp.nanoseconds\n    );\n    return SnapshotVersion.fromTimestamp(timestamp);\n  }\n\n  /** Encodes a batch of mutations into a DbMutationBatch for local storage. */\n  toDbMutationBatch(userId: string, batch: MutationBatch): DbMutationBatch {\n    const serializedBaseMutations = batch.baseMutations.map(m =>\n      this.remoteSerializer.toMutation(m)\n    );\n    const serializedMutations = batch.mutations.map(m =>\n      this.remoteSerializer.toMutation(m)\n    );\n    return new DbMutationBatch(\n      userId,\n      batch.batchId,\n      batch.localWriteTime.toMillis(),\n      serializedBaseMutations,\n      serializedMutations\n    );\n  }\n\n  /** Decodes a DbMutationBatch into a MutationBatch */\n  fromDbMutationBatch(dbBatch: DbMutationBatch): MutationBatch {\n    const baseMutations = (dbBatch.baseMutations || []).map(m =>\n      this.remoteSerializer.fromMutation(m)\n    );\n    const mutations = dbBatch.mutations.map(m =>\n      this.remoteSerializer.fromMutation(m)\n    );\n    const timestamp = Timestamp.fromMillis(dbBatch.localWriteTimeMs);\n    return new MutationBatch(\n      dbBatch.batchId,\n      timestamp,\n      baseMutations,\n      mutations\n    );\n  }\n\n  /** Decodes a DbTarget into TargetData */\n  fromDbTarget(dbTarget: DbTarget): TargetData {\n    const version = this.fromDbTimestamp(dbTarget.readTime);\n    const lastLimboFreeSnapshotVersion =\n      dbTarget.lastLimboFreeSnapshotVersion !== undefined\n        ? this.fromDbTimestamp(dbTarget.lastLimboFreeSnapshotVersion)\n        : SnapshotVersion.MIN;\n\n    let target: Target;\n    if (isDocumentQuery(dbTarget.query)) {\n      target = this.remoteSerializer.fromDocumentsTarget(dbTarget.query);\n    } else {\n      target = this.remoteSerializer.fromQueryTarget(dbTarget.query);\n    }\n    return new TargetData(\n      target,\n      dbTarget.targetId,\n      TargetPurpose.Listen,\n      dbTarget.lastListenSequenceNumber,\n      version,\n      lastLimboFreeSnapshotVersion,\n      ByteString.fromBase64String(dbTarget.resumeToken)\n    );\n  }\n\n  /** Encodes TargetData into a DbTarget for storage locally. */\n  toDbTarget(targetData: TargetData): DbTarget {\n    debugAssert(\n      TargetPurpose.Listen === targetData.purpose,\n      'Only queries with purpose ' +\n        TargetPurpose.Listen +\n        ' may be stored, got ' +\n        targetData.purpose\n    );\n    const dbTimestamp = this.toDbTimestamp(targetData.snapshotVersion);\n    const dbLastLimboFreeTimestamp = this.toDbTimestamp(\n      targetData.lastLimboFreeSnapshotVersion\n    );\n    let queryProto: DbQuery;\n    if (targetData.target.isDocumentQuery()) {\n      queryProto = this.remoteSerializer.toDocumentsTarget(targetData.target);\n    } else {\n      queryProto = this.remoteSerializer.toQueryTarget(targetData.target);\n    }\n\n    // We can't store the resumeToken as a ByteString in IndexedDb, so we\n    // convert it to a base64 string for storage.\n    const resumeToken = targetData.resumeToken.toBase64();\n\n    // lastListenSequenceNumber is always 0 until we do real GC.\n    return new DbTarget(\n      targetData.targetId,\n      targetData.target.canonicalId(),\n      dbTimestamp,\n      resumeToken,\n      targetData.sequenceNumber,\n      dbLastLimboFreeTimestamp,\n      queryProto\n    );\n  }\n}\n\n/**\n * A helper function for figuring out what kind of query has been stored.\n */\nfunction isDocumentQuery(dbQuery: DbQuery): dbQuery is api.DocumentsTarget {\n  return (dbQuery as api.DocumentsTarget).documents !== undefined;\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { User } from '../auth/user';\nimport { DatabaseInfo } from '../core/database_info';\nimport { ListenSequence, SequenceNumberSyncer } from '../core/listen_sequence';\nimport { ListenSequenceNumber, TargetId } from '../core/types';\nimport { DocumentKey } from '../model/document_key';\nimport { Platform } from '../platform/platform';\nimport { JsonProtoSerializer } from '../remote/serializer';\nimport { debugAssert, fail } from '../util/assert';\nimport { AsyncQueue, TimerId } from '../util/async_queue';\nimport { Code, FirestoreError } from '../util/error';\nimport { logDebug, logError } from '../util/log';\nimport { CancelablePromise } from '../util/promise';\nimport {\n  decodeResourcePath,\n  encodeResourcePath,\n  EncodedResourcePath\n} from './encoded_resource_path';\nimport { IndexedDbIndexManager } from './indexeddb_index_manager';\nimport {\n  IndexedDbMutationQueue,\n  mutationQueuesContainKey\n} from './indexeddb_mutation_queue';\nimport { IndexedDbRemoteDocumentCache } from './indexeddb_remote_document_cache';\nimport {\n  ALL_STORES,\n  DbClientMetadata,\n  DbClientMetadataKey,\n  DbPrimaryClient,\n  DbPrimaryClientKey,\n  DbTargetDocument,\n  DbTargetGlobal,\n  SCHEMA_VERSION,\n  SchemaConverter\n} from './indexeddb_schema';\nimport {\n  documentTargetStore,\n  getHighestListenSequenceNumber,\n  IndexedDbTargetCache\n} from './indexeddb_target_cache';\nimport { LocalSerializer } from './local_serializer';\nimport {\n  ActiveTargets,\n  LruDelegate,\n  LruGarbageCollector,\n  LruParams\n} from './lru_garbage_collector';\nimport { MutationQueue } from './mutation_queue';\nimport {\n  Persistence,\n  PersistenceTransaction,\n  PersistenceTransactionMode,\n  PRIMARY_LEASE_LOST_ERROR_MSG,\n  PrimaryStateListener,\n  ReferenceDelegate\n} from './persistence';\nimport { PersistencePromise } from './persistence_promise';\nimport { ReferenceSet } from './reference_set';\nimport { ClientId } from './shared_client_state';\nimport { TargetData } from './target_data';\nimport { SimpleDb, SimpleDbStore, SimpleDbTransaction } from './simple_db';\n\nconst LOG_TAG = 'IndexedDbPersistence';\n\n/**\n * Oldest acceptable age in milliseconds for client metadata before the client\n * is considered inactive and its associated data is garbage collected.\n */\nconst MAX_CLIENT_AGE_MS = 30 * 60 * 1000; // 30 minutes\n\n/**\n * Oldest acceptable metadata age for clients that may participate in the\n * primary lease election. Clients that have not updated their client metadata\n * within 5 seconds are not eligible to receive a primary lease.\n */\nconst MAX_PRIMARY_ELIGIBLE_AGE_MS = 5000;\n\n/**\n * The interval at which clients will update their metadata, including\n * refreshing their primary lease if held or potentially trying to acquire it if\n * not held.\n *\n * Primary clients may opportunistically refresh their metadata earlier\n * if they're already performing an IndexedDB operation.\n */\nconst CLIENT_METADATA_REFRESH_INTERVAL_MS = 4000;\n/** User-facing error when the primary lease is required but not available. */\nconst PRIMARY_LEASE_EXCLUSIVE_ERROR_MSG =\n  'Another tab has exclusive access to the persistence layer. ' +\n  'To allow shared access, make sure to invoke ' +\n  '`enablePersistence()` with `synchronizeTabs:true` in all tabs.';\nconst UNSUPPORTED_PLATFORM_ERROR_MSG =\n  'This platform is either missing' +\n  ' IndexedDB or is known to have an incomplete implementation. Offline' +\n  ' persistence has been disabled.';\n\n// The format of the LocalStorage key that stores zombied client is:\n//     firestore_zombie_<persistence_prefix>_<instance_key>\nconst ZOMBIED_CLIENTS_KEY_PREFIX = 'firestore_zombie';\n\nexport class IndexedDbTransaction extends PersistenceTransaction {\n  constructor(\n    readonly simpleDbTransaction: SimpleDbTransaction,\n    readonly currentSequenceNumber: ListenSequenceNumber\n  ) {\n    super();\n  }\n}\n\n/**\n * An IndexedDB-backed instance of Persistence. Data is stored persistently\n * across sessions.\n *\n * On Web only, the Firestore SDKs support shared access to its persistence\n * layer. This allows multiple browser tabs to read and write to IndexedDb and\n * to synchronize state even without network connectivity. Shared access is\n * currently optional and not enabled unless all clients invoke\n * `enablePersistence()` with `{synchronizeTabs:true}`.\n *\n * In multi-tab mode, if multiple clients are active at the same time, the SDK\n * will designate one client as the primary client. An effort is made to pick\n * a visible, network-connected and active client, and this client is\n * responsible for letting other clients know about its presence. The primary\n * client writes a unique client-generated identifier (the client ID) to\n * IndexedDbs owner store every 4 seconds. If the primary client fails to\n * update this entry, another client can acquire the lease and take over as\n * primary.\n *\n * Some persistence operations in the SDK are designated as primary-client only\n * operations. This includes the acknowledgment of mutations and all updates of\n * remote documents. The effects of these operations are written to persistence\n * and then broadcast to other tabs via LocalStorage (see\n * `WebStorageSharedClientState`), which then refresh their state from\n * persistence.\n *\n * Similarly, the primary client listens to notifications sent by secondary\n * clients to discover persistence changes written by secondary clients, such as\n * the addition of new mutations and query targets.\n *\n * If multi-tab is not enabled and another tab already obtained the primary\n * lease, IndexedDbPersistence enters a failed state and all subsequent\n * operations will automatically fail.\n *\n * Additionally, there is an optimization so that when a tab is closed, the\n * primary lease is released immediately (this is especially important to make\n * sure that a refreshed tab is able to immediately re-acquire the primary\n * lease). Unfortunately, IndexedDB cannot be reliably used in window.unload\n * since it is an asynchronous API. So in addition to attempting to give up the\n * lease, the leaseholder writes its client ID to a \"zombiedClient\" entry in\n * LocalStorage which acts as an indicator that another tab should go ahead and\n * take the primary lease immediately regardless of the current lease timestamp.\n *\n * TODO(b/114226234): Remove `synchronizeTabs` section when multi-tab is no\n * longer optional.\n */\nexport class IndexedDbPersistence implements Persistence {\n  static getStore<Key extends IDBValidKey, Value>(\n    txn: PersistenceTransaction,\n    store: string\n  ): SimpleDbStore<Key, Value> {\n    if (txn instanceof IndexedDbTransaction) {\n      return SimpleDb.getStore<Key, Value>(txn.simpleDbTransaction, store);\n    } else {\n      throw fail(\n        'IndexedDbPersistence must use instances of IndexedDbTransaction'\n      );\n    }\n  }\n\n  /**\n   * The name of the main (and currently only) IndexedDB database. this name is\n   * appended to the prefix provided to the IndexedDbPersistence constructor.\n   */\n  static MAIN_DATABASE = 'main';\n\n  static async createIndexedDbPersistence(options: {\n    allowTabSynchronization: boolean;\n    persistenceKey: string;\n    clientId: ClientId;\n    platform: Platform;\n    lruParams: LruParams;\n    queue: AsyncQueue;\n    serializer: JsonProtoSerializer;\n    sequenceNumberSyncer: SequenceNumberSyncer;\n  }): Promise<IndexedDbPersistence> {\n    if (!IndexedDbPersistence.isAvailable()) {\n      throw new FirestoreError(\n        Code.UNIMPLEMENTED,\n        UNSUPPORTED_PLATFORM_ERROR_MSG\n      );\n    }\n\n    const persistence = new IndexedDbPersistence(\n      options.allowTabSynchronization,\n      options.persistenceKey,\n      options.clientId,\n      options.platform,\n      options.lruParams,\n      options.queue,\n      options.serializer,\n      options.sequenceNumberSyncer\n    );\n    await persistence.start();\n    return persistence;\n  }\n\n  private readonly document: Document | null;\n  private readonly window: Window;\n\n  // Technically these types should be `| undefined` because they are\n  // initialized asynchronously by start(), but that would be more misleading\n  // than useful.\n  private simpleDb!: SimpleDb;\n  private listenSequence!: ListenSequence;\n\n  private _started = false;\n  private isPrimary = false;\n  private networkEnabled = true;\n  private dbName: string;\n\n  /** Our window.unload handler, if registered. */\n  private windowUnloadHandler: (() => void) | null = null;\n  private inForeground = false;\n\n  private serializer: LocalSerializer;\n\n  /** Our 'visibilitychange' listener if registered. */\n  private documentVisibilityHandler: ((e?: Event) => void) | null = null;\n\n  /** The client metadata refresh task. */\n  private clientMetadataRefresher: CancelablePromise<void> | null = null;\n\n  /** The last time we garbage collected the client metadata object store. */\n  private lastGarbageCollectionTime = Number.NEGATIVE_INFINITY;\n\n  /** A listener to notify on primary state changes. */\n  private primaryStateListener: PrimaryStateListener = _ => Promise.resolve();\n\n  private readonly targetCache: IndexedDbTargetCache;\n  private readonly indexManager: IndexedDbIndexManager;\n  private readonly remoteDocumentCache: IndexedDbRemoteDocumentCache;\n  private readonly webStorage: Storage;\n  readonly referenceDelegate: IndexedDbLruDelegate;\n\n  private constructor(\n    private readonly allowTabSynchronization: boolean,\n    private readonly persistenceKey: string,\n    private readonly clientId: ClientId,\n    platform: Platform,\n    lruParams: LruParams,\n    private readonly queue: AsyncQueue,\n    serializer: JsonProtoSerializer,\n    private readonly sequenceNumberSyncer: SequenceNumberSyncer\n  ) {\n    this.referenceDelegate = new IndexedDbLruDelegate(this, lruParams);\n    this.dbName = persistenceKey + IndexedDbPersistence.MAIN_DATABASE;\n    this.serializer = new LocalSerializer(serializer);\n    this.document = platform.document;\n    this.targetCache = new IndexedDbTargetCache(\n      this.referenceDelegate,\n      this.serializer\n    );\n    this.indexManager = new IndexedDbIndexManager();\n    this.remoteDocumentCache = new IndexedDbRemoteDocumentCache(\n      this.serializer,\n      this.indexManager\n    );\n    if (platform.window && platform.window.localStorage) {\n      this.window = platform.window;\n      this.webStorage = this.window.localStorage;\n    } else {\n      throw new FirestoreError(\n        Code.UNIMPLEMENTED,\n        'IndexedDB persistence is only available on platforms that support LocalStorage.'\n      );\n    }\n  }\n\n  /**\n   * Attempt to start IndexedDb persistence.\n   *\n   * @return {Promise<void>} Whether persistence was enabled.\n   */\n  private start(): Promise<void> {\n    debugAssert(!this.started, 'IndexedDbPersistence double-started!');\n    debugAssert(this.window !== null, \"Expected 'window' to be defined\");\n\n    return SimpleDb.openOrCreate(\n      this.dbName,\n      SCHEMA_VERSION,\n      new SchemaConverter(this.serializer)\n    )\n      .then(db => {\n        this.simpleDb = db;\n        // NOTE: This is expected to fail sometimes (in the case of another tab already\n        // having the persistence lock), so it's the first thing we should do.\n        return this.updateClientMetadataAndTryBecomePrimary();\n      })\n      .then(() => {\n        this.attachVisibilityHandler();\n        this.attachWindowUnloadHook();\n\n        this.scheduleClientMetadataAndPrimaryLeaseRefreshes();\n\n        return this.simpleDb.runTransaction(\n          'readonly',\n          [DbTargetGlobal.store],\n          txn => getHighestListenSequenceNumber(txn)\n        );\n      })\n      .then(highestListenSequenceNumber => {\n        this.listenSequence = new ListenSequence(\n          highestListenSequenceNumber,\n          this.sequenceNumberSyncer\n        );\n      })\n      .then(() => {\n        this._started = true;\n      })\n      .catch(reason => {\n        this.simpleDb && this.simpleDb.close();\n        return Promise.reject(reason);\n      });\n  }\n\n  setPrimaryStateListener(\n    primaryStateListener: PrimaryStateListener\n  ): Promise<void> {\n    this.primaryStateListener = async primaryState => {\n      if (this.started) {\n        return primaryStateListener(primaryState);\n      }\n    };\n    return primaryStateListener(this.isPrimary);\n  }\n\n  setDatabaseDeletedListener(\n    databaseDeletedListener: () => Promise<void>\n  ): void {\n    this.simpleDb.setVersionChangeListener(async event => {\n      // Check if an attempt is made to delete IndexedDB.\n      if (event.newVersion === null) {\n        await databaseDeletedListener();\n      }\n    });\n  }\n\n  setNetworkEnabled(networkEnabled: boolean): void {\n    if (this.networkEnabled !== networkEnabled) {\n      this.networkEnabled = networkEnabled;\n      // Schedule a primary lease refresh for immediate execution. The eventual\n      // lease update will be propagated via `primaryStateListener`.\n      this.queue.enqueueAndForget(async () => {\n        if (this.started) {\n          await this.updateClientMetadataAndTryBecomePrimary();\n        }\n      });\n    }\n  }\n\n  /**\n   * Updates the client metadata in IndexedDb and attempts to either obtain or\n   * extend the primary lease for the local client. Asynchronously notifies the\n   * primary state listener if the client either newly obtained or released its\n   * primary lease.\n   */\n  private updateClientMetadataAndTryBecomePrimary(): Promise<void> {\n    return this.simpleDb\n      .runTransaction('readwrite', ALL_STORES, txn => {\n        const metadataStore = clientMetadataStore(txn);\n        return metadataStore\n          .put(\n            new DbClientMetadata(\n              this.clientId,\n              Date.now(),\n              this.networkEnabled,\n              this.inForeground\n            )\n          )\n          .next(() => {\n            if (this.isPrimary) {\n              return this.verifyPrimaryLease(txn).next(success => {\n                if (!success) {\n                  this.isPrimary = false;\n                  this.queue.enqueueAndForget(() =>\n                    this.primaryStateListener(false)\n                  );\n                }\n              });\n            }\n          })\n          .next(() => this.canActAsPrimary(txn))\n          .next(canActAsPrimary => {\n            if (this.isPrimary && !canActAsPrimary) {\n              return this.releasePrimaryLeaseIfHeld(txn).next(() => false);\n            } else if (canActAsPrimary) {\n              return this.acquireOrExtendPrimaryLease(txn).next(() => true);\n            } else {\n              return /* canActAsPrimary= */ false;\n            }\n          });\n      })\n      .catch(e => {\n        if (!this.allowTabSynchronization) {\n          throw e;\n        }\n\n        logDebug(\n          LOG_TAG,\n          'Releasing owner lease after error during lease refresh',\n          e\n        );\n        return /* isPrimary= */ false;\n      })\n      .then(isPrimary => {\n        if (this.isPrimary !== isPrimary) {\n          this.queue.enqueueAndForget(() =>\n            this.primaryStateListener(isPrimary)\n          );\n        }\n        this.isPrimary = isPrimary;\n      });\n  }\n\n  private verifyPrimaryLease(\n    txn: SimpleDbTransaction\n  ): PersistencePromise<boolean> {\n    const store = primaryClientStore(txn);\n    return store.get(DbPrimaryClient.key).next(primaryClient => {\n      return PersistencePromise.resolve(this.isLocalClient(primaryClient));\n    });\n  }\n\n  private removeClientMetadata(\n    txn: SimpleDbTransaction\n  ): PersistencePromise<void> {\n    const metadataStore = clientMetadataStore(txn);\n    return metadataStore.delete(this.clientId);\n  }\n\n  /**\n   * If the garbage collection threshold has passed, prunes the\n   * RemoteDocumentChanges and the ClientMetadata store based on the last update\n   * time of all clients.\n   */\n  private async maybeGarbageCollectMultiClientState(): Promise<void> {\n    if (\n      this.isPrimary &&\n      !this.isWithinAge(this.lastGarbageCollectionTime, MAX_CLIENT_AGE_MS)\n    ) {\n      this.lastGarbageCollectionTime = Date.now();\n\n      const inactiveClients = await this.runTransaction(\n        'maybeGarbageCollectMultiClientState',\n        'readwrite-primary',\n        txn => {\n          const metadataStore = IndexedDbPersistence.getStore<\n            DbClientMetadataKey,\n            DbClientMetadata\n          >(txn, DbClientMetadata.store);\n\n          return metadataStore.loadAll().next(existingClients => {\n            const active = this.filterActiveClients(\n              existingClients,\n              MAX_CLIENT_AGE_MS\n            );\n            const inactive = existingClients.filter(\n              client => active.indexOf(client) === -1\n            );\n\n            // Delete metadata for clients that are no longer considered active.\n            return PersistencePromise.forEach(\n              inactive,\n              (inactiveClient: DbClientMetadata) =>\n                metadataStore.delete(inactiveClient.clientId)\n            ).next(() => inactive);\n          });\n        }\n      ).catch(() => {\n        // Ignore primary lease violations or any other type of error. The next\n        // primary will run `maybeGarbageCollectMultiClientState()` again.\n        // We don't use `ignoreIfPrimaryLeaseLoss()` since we don't want to depend\n        // on LocalStore.\n        return [];\n      });\n\n      // Delete potential leftover entries that may continue to mark the\n      // inactive clients as zombied in LocalStorage.\n      // Ideally we'd delete the IndexedDb and LocalStorage zombie entries for\n      // the client atomically, but we can't. So we opt to delete the IndexedDb\n      // entries first to avoid potentially reviving a zombied client.\n      inactiveClients.forEach(inactiveClient => {\n        this.window.localStorage.removeItem(\n          this.zombiedClientLocalStorageKey(inactiveClient.clientId)\n        );\n      });\n    }\n  }\n\n  /**\n   * Schedules a recurring timer to update the client metadata and to either\n   * extend or acquire the primary lease if the client is eligible.\n   */\n  private scheduleClientMetadataAndPrimaryLeaseRefreshes(): void {\n    this.clientMetadataRefresher = this.queue.enqueueAfterDelay(\n      TimerId.ClientMetadataRefresh,\n      CLIENT_METADATA_REFRESH_INTERVAL_MS,\n      () => {\n        return this.updateClientMetadataAndTryBecomePrimary()\n          .then(() => this.maybeGarbageCollectMultiClientState())\n          .then(() => this.scheduleClientMetadataAndPrimaryLeaseRefreshes());\n      }\n    );\n  }\n\n  /** Checks whether `client` is the local client. */\n  private isLocalClient(client: DbPrimaryClient | null): boolean {\n    return client ? client.ownerId === this.clientId : false;\n  }\n\n  /**\n   * Evaluate the state of all active clients and determine whether the local\n   * client is or can act as the holder of the primary lease. Returns whether\n   * the client is eligible for the lease, but does not actually acquire it.\n   * May return 'false' even if there is no active leaseholder and another\n   * (foreground) client should become leaseholder instead.\n   */\n  private canActAsPrimary(\n    txn: SimpleDbTransaction\n  ): PersistencePromise<boolean> {\n    const store = primaryClientStore(txn);\n    return store\n      .get(DbPrimaryClient.key)\n      .next(currentPrimary => {\n        const currentLeaseIsValid =\n          currentPrimary !== null &&\n          this.isWithinAge(\n            currentPrimary.leaseTimestampMs,\n            MAX_PRIMARY_ELIGIBLE_AGE_MS\n          ) &&\n          !this.isClientZombied(currentPrimary.ownerId);\n\n        // A client is eligible for the primary lease if:\n        // - its network is enabled and the client's tab is in the foreground.\n        // - its network is enabled and no other client's tab is in the\n        //   foreground.\n        // - every clients network is disabled and the client's tab is in the\n        //   foreground.\n        // - every clients network is disabled and no other client's tab is in\n        //   the foreground.\n        if (currentLeaseIsValid) {\n          if (this.isLocalClient(currentPrimary) && this.networkEnabled) {\n            return true;\n          }\n\n          if (!this.isLocalClient(currentPrimary)) {\n            if (!currentPrimary!.allowTabSynchronization) {\n              // Fail the `canActAsPrimary` check if the current leaseholder has\n              // not opted into multi-tab synchronization. If this happens at\n              // client startup, we reject the Promise returned by\n              // `enablePersistence()` and the user can continue to use Firestore\n              // with in-memory persistence.\n              // If this fails during a lease refresh, we will instead block the\n              // AsyncQueue from executing further operations. Note that this is\n              // acceptable since mixing & matching different `synchronizeTabs`\n              // settings is not supported.\n              //\n              // TODO(b/114226234): Remove this check when `synchronizeTabs` can\n              // no longer be turned off.\n              throw new FirestoreError(\n                Code.FAILED_PRECONDITION,\n                PRIMARY_LEASE_EXCLUSIVE_ERROR_MSG\n              );\n            }\n\n            return false;\n          }\n        }\n\n        if (this.networkEnabled && this.inForeground) {\n          return true;\n        }\n\n        return clientMetadataStore(txn)\n          .loadAll()\n          .next(existingClients => {\n            // Process all existing clients and determine whether at least one of\n            // them is better suited to obtain the primary lease.\n            const preferredCandidate = this.filterActiveClients(\n              existingClients,\n              MAX_PRIMARY_ELIGIBLE_AGE_MS\n            ).find(otherClient => {\n              if (this.clientId !== otherClient.clientId) {\n                const otherClientHasBetterNetworkState =\n                  !this.networkEnabled && otherClient.networkEnabled;\n                const otherClientHasBetterVisibility =\n                  !this.inForeground && otherClient.inForeground;\n                const otherClientHasSameNetworkState =\n                  this.networkEnabled === otherClient.networkEnabled;\n                if (\n                  otherClientHasBetterNetworkState ||\n                  (otherClientHasBetterVisibility &&\n                    otherClientHasSameNetworkState)\n                ) {\n                  return true;\n                }\n              }\n              return false;\n            });\n            return preferredCandidate === undefined;\n          });\n      })\n      .next(canActAsPrimary => {\n        if (this.isPrimary !== canActAsPrimary) {\n          logDebug(\n            LOG_TAG,\n            `Client ${\n              canActAsPrimary ? 'is' : 'is not'\n            } eligible for a primary lease.`\n          );\n        }\n        return canActAsPrimary;\n      });\n  }\n\n  async shutdown(): Promise<void> {\n    // The shutdown() operations are idempotent and can be called even when\n    // start() aborted (e.g. because it couldn't acquire the persistence lease).\n    this._started = false;\n\n    this.markClientZombied();\n    if (this.clientMetadataRefresher) {\n      this.clientMetadataRefresher.cancel();\n      this.clientMetadataRefresher = null;\n    }\n    this.detachVisibilityHandler();\n    this.detachWindowUnloadHook();\n    await this.simpleDb.runTransaction(\n      'readwrite',\n      [DbPrimaryClient.store, DbClientMetadata.store],\n      txn => {\n        return this.releasePrimaryLeaseIfHeld(txn).next(() =>\n          this.removeClientMetadata(txn)\n        );\n      }\n    );\n    this.simpleDb.close();\n\n    // Remove the entry marking the client as zombied from LocalStorage since\n    // we successfully deleted its metadata from IndexedDb.\n    this.removeClientZombiedEntry();\n  }\n\n  /**\n   * Returns clients that are not zombied and have an updateTime within the\n   * provided threshold.\n   */\n  private filterActiveClients(\n    clients: DbClientMetadata[],\n    activityThresholdMs: number\n  ): DbClientMetadata[] {\n    return clients.filter(\n      client =>\n        this.isWithinAge(client.updateTimeMs, activityThresholdMs) &&\n        !this.isClientZombied(client.clientId)\n    );\n  }\n\n  getActiveClients(): Promise<ClientId[]> {\n    return this.simpleDb.runTransaction(\n      'readonly',\n      [DbClientMetadata.store],\n      txn => {\n        return clientMetadataStore(txn)\n          .loadAll()\n          .next(clients =>\n            this.filterActiveClients(clients, MAX_CLIENT_AGE_MS).map(\n              clientMetadata => clientMetadata.clientId\n            )\n          );\n      }\n    );\n  }\n\n  static async clearPersistence(persistenceKey: string): Promise<void> {\n    if (!IndexedDbPersistence.isAvailable()) {\n      return Promise.resolve();\n    }\n    const dbName = persistenceKey + IndexedDbPersistence.MAIN_DATABASE;\n    await SimpleDb.delete(dbName);\n  }\n\n  get started(): boolean {\n    return this._started;\n  }\n\n  getMutationQueue(user: User): MutationQueue {\n    debugAssert(\n      this.started,\n      'Cannot initialize MutationQueue before persistence is started.'\n    );\n    return IndexedDbMutationQueue.forUser(\n      user,\n      this.serializer,\n      this.indexManager,\n      this.referenceDelegate\n    );\n  }\n\n  getTargetCache(): IndexedDbTargetCache {\n    debugAssert(\n      this.started,\n      'Cannot initialize TargetCache before persistence is started.'\n    );\n    return this.targetCache;\n  }\n\n  getRemoteDocumentCache(): IndexedDbRemoteDocumentCache {\n    debugAssert(\n      this.started,\n      'Cannot initialize RemoteDocumentCache before persistence is started.'\n    );\n    return this.remoteDocumentCache;\n  }\n\n  getIndexManager(): IndexedDbIndexManager {\n    debugAssert(\n      this.started,\n      'Cannot initialize IndexManager before persistence is started.'\n    );\n    return this.indexManager;\n  }\n\n  runTransaction<T>(\n    action: string,\n    mode: PersistenceTransactionMode,\n    transactionOperation: (\n      transaction: PersistenceTransaction\n    ) => PersistencePromise<T>\n  ): Promise<T> {\n    logDebug(LOG_TAG, 'Starting transaction:', action);\n\n    const simpleDbMode = mode === 'readonly' ? 'readonly' : 'readwrite';\n\n    let persistenceTransaction: PersistenceTransaction;\n\n    // Do all transactions as readwrite against all object stores, since we\n    // are the only reader/writer.\n    return this.simpleDb\n      .runTransaction(simpleDbMode, ALL_STORES, simpleDbTxn => {\n        persistenceTransaction = new IndexedDbTransaction(\n          simpleDbTxn,\n          this.listenSequence.next()\n        );\n\n        if (mode === 'readwrite-primary') {\n          // While we merely verify that we have (or can acquire) the lease\n          // immediately, we wait to extend the primary lease until after\n          // executing transactionOperation(). This ensures that even if the\n          // transactionOperation takes a long time, we'll use a recent\n          // leaseTimestampMs in the extended (or newly acquired) lease.\n          return this.verifyPrimaryLease(simpleDbTxn)\n            .next(holdsPrimaryLease => {\n              if (holdsPrimaryLease) {\n                return /* holdsPrimaryLease= */ true;\n              }\n              return this.canActAsPrimary(simpleDbTxn);\n            })\n            .next(holdsPrimaryLease => {\n              if (!holdsPrimaryLease) {\n                logError(\n                  `Failed to obtain primary lease for action '${action}'.`\n                );\n                this.isPrimary = false;\n                this.queue.enqueueAndForget(() =>\n                  this.primaryStateListener(false)\n                );\n                throw new FirestoreError(\n                  Code.FAILED_PRECONDITION,\n                  PRIMARY_LEASE_LOST_ERROR_MSG\n                );\n              }\n              return transactionOperation(persistenceTransaction);\n            })\n            .next(result => {\n              return this.acquireOrExtendPrimaryLease(simpleDbTxn).next(\n                () => result\n              );\n            });\n        } else {\n          return this.verifyAllowTabSynchronization(simpleDbTxn).next(() =>\n            transactionOperation(persistenceTransaction)\n          );\n        }\n      })\n      .then(result => {\n        persistenceTransaction.raiseOnCommittedEvent();\n        return result;\n      });\n  }\n\n  /**\n   * Verifies that the current tab is the primary leaseholder or alternatively\n   * that the leaseholder has opted into multi-tab synchronization.\n   */\n  // TODO(b/114226234): Remove this check when `synchronizeTabs` can no longer\n  // be turned off.\n  private verifyAllowTabSynchronization(\n    txn: SimpleDbTransaction\n  ): PersistencePromise<void> {\n    const store = primaryClientStore(txn);\n    return store.get(DbPrimaryClient.key).next(currentPrimary => {\n      const currentLeaseIsValid =\n        currentPrimary !== null &&\n        this.isWithinAge(\n          currentPrimary.leaseTimestampMs,\n          MAX_PRIMARY_ELIGIBLE_AGE_MS\n        ) &&\n        !this.isClientZombied(currentPrimary.ownerId);\n\n      if (currentLeaseIsValid && !this.isLocalClient(currentPrimary)) {\n        if (!currentPrimary!.allowTabSynchronization) {\n          throw new FirestoreError(\n            Code.FAILED_PRECONDITION,\n            PRIMARY_LEASE_EXCLUSIVE_ERROR_MSG\n          );\n        }\n      }\n    });\n  }\n\n  /**\n   * Obtains or extends the new primary lease for the local client. This\n   * method does not verify that the client is eligible for this lease.\n   */\n  private acquireOrExtendPrimaryLease(\n    txn: SimpleDbTransaction\n  ): PersistencePromise<void> {\n    const newPrimary = new DbPrimaryClient(\n      this.clientId,\n      this.allowTabSynchronization,\n      Date.now()\n    );\n    return primaryClientStore(txn).put(DbPrimaryClient.key, newPrimary);\n  }\n\n  static isAvailable(): boolean {\n    return SimpleDb.isAvailable();\n  }\n\n  /**\n   * Generates a string used as a prefix when storing data in IndexedDB and\n   * LocalStorage.\n   */\n  static buildStoragePrefix(databaseInfo: DatabaseInfo): string {\n    // Use two different prefix formats:\n    //\n    //   * firestore / persistenceKey / projectID . databaseID / ...\n    //   * firestore / persistenceKey / projectID / ...\n    //\n    // projectIDs are DNS-compatible names and cannot contain dots\n    // so there's no danger of collisions.\n    let database = databaseInfo.databaseId.projectId;\n    if (!databaseInfo.databaseId.isDefaultDatabase) {\n      database += '.' + databaseInfo.databaseId.database;\n    }\n\n    return 'firestore/' + databaseInfo.persistenceKey + '/' + database + '/';\n  }\n\n  /** Checks the primary lease and removes it if we are the current primary. */\n  private releasePrimaryLeaseIfHeld(\n    txn: SimpleDbTransaction\n  ): PersistencePromise<void> {\n    const store = primaryClientStore(txn);\n    return store.get(DbPrimaryClient.key).next(primaryClient => {\n      if (this.isLocalClient(primaryClient)) {\n        logDebug(LOG_TAG, 'Releasing primary lease.');\n        return store.delete(DbPrimaryClient.key);\n      } else {\n        return PersistencePromise.resolve();\n      }\n    });\n  }\n\n  /** Verifies that `updateTimeMs` is within `maxAgeMs`. */\n  private isWithinAge(updateTimeMs: number, maxAgeMs: number): boolean {\n    const now = Date.now();\n    const minAcceptable = now - maxAgeMs;\n    const maxAcceptable = now;\n    if (updateTimeMs < minAcceptable) {\n      return false;\n    } else if (updateTimeMs > maxAcceptable) {\n      logError(\n        `Detected an update time that is in the future: ${updateTimeMs} > ${maxAcceptable}`\n      );\n      return false;\n    }\n\n    return true;\n  }\n\n  private attachVisibilityHandler(): void {\n    if (\n      this.document !== null &&\n      typeof this.document.addEventListener === 'function'\n    ) {\n      this.documentVisibilityHandler = () => {\n        this.queue.enqueueAndForget(() => {\n          this.inForeground = this.document!.visibilityState === 'visible';\n          return this.updateClientMetadataAndTryBecomePrimary();\n        });\n      };\n\n      this.document.addEventListener(\n        'visibilitychange',\n        this.documentVisibilityHandler\n      );\n\n      this.inForeground = this.document.visibilityState === 'visible';\n    }\n  }\n\n  private detachVisibilityHandler(): void {\n    if (this.documentVisibilityHandler) {\n      debugAssert(\n        this.document !== null &&\n          typeof this.document.addEventListener === 'function',\n        \"Expected 'document.addEventListener' to be a function\"\n      );\n      this.document.removeEventListener(\n        'visibilitychange',\n        this.documentVisibilityHandler\n      );\n      this.documentVisibilityHandler = null;\n    }\n  }\n\n  /**\n   * Attaches a window.unload handler that will synchronously write our\n   * clientId to a \"zombie client id\" location in LocalStorage. This can be used\n   * by tabs trying to acquire the primary lease to determine that the lease\n   * is no longer valid even if the timestamp is recent. This is particularly\n   * important for the refresh case (so the tab correctly re-acquires the\n   * primary lease). LocalStorage is used for this rather than IndexedDb because\n   * it is a synchronous API and so can be used reliably from  an unload\n   * handler.\n   */\n  private attachWindowUnloadHook(): void {\n    if (typeof this.window.addEventListener === 'function') {\n      this.windowUnloadHandler = () => {\n        // Note: In theory, this should be scheduled on the AsyncQueue since it\n        // accesses internal state. We execute this code directly during shutdown\n        // to make sure it gets a chance to run.\n        this.markClientZombied();\n\n        this.queue.enqueueAndForget(() => {\n          // Attempt graceful shutdown (including releasing our primary lease),\n          // but there's no guarantee it will complete.\n          return this.shutdown();\n        });\n      };\n      this.window.addEventListener('unload', this.windowUnloadHandler);\n    }\n  }\n\n  private detachWindowUnloadHook(): void {\n    if (this.windowUnloadHandler) {\n      debugAssert(\n        typeof this.window.removeEventListener === 'function',\n        \"Expected 'window.removeEventListener' to be a function\"\n      );\n      this.window.removeEventListener('unload', this.windowUnloadHandler);\n      this.windowUnloadHandler = null;\n    }\n  }\n\n  /**\n   * Returns whether a client is \"zombied\" based on its LocalStorage entry.\n   * Clients become zombied when their tab closes without running all of the\n   * cleanup logic in `shutdown()`.\n   */\n  private isClientZombied(clientId: ClientId): boolean {\n    try {\n      const isZombied =\n        this.webStorage.getItem(this.zombiedClientLocalStorageKey(clientId)) !==\n        null;\n      logDebug(\n        LOG_TAG,\n        `Client '${clientId}' ${\n          isZombied ? 'is' : 'is not'\n        } zombied in LocalStorage`\n      );\n      return isZombied;\n    } catch (e) {\n      // Gracefully handle if LocalStorage isn't working.\n      logError(LOG_TAG, 'Failed to get zombied client id.', e);\n      return false;\n    }\n  }\n\n  /**\n   * Record client as zombied (a client that had its tab closed). Zombied\n   * clients are ignored during primary tab selection.\n   */\n  private markClientZombied(): void {\n    try {\n      this.webStorage.setItem(\n        this.zombiedClientLocalStorageKey(this.clientId),\n        String(Date.now())\n      );\n    } catch (e) {\n      // Gracefully handle if LocalStorage isn't available / working.\n      logError('Failed to set zombie client id.', e);\n    }\n  }\n\n  /** Removes the zombied client entry if it exists. */\n  private removeClientZombiedEntry(): void {\n    try {\n      this.webStorage.removeItem(\n        this.zombiedClientLocalStorageKey(this.clientId)\n      );\n    } catch (e) {\n      // Ignore\n    }\n  }\n\n  private zombiedClientLocalStorageKey(clientId: ClientId): string {\n    return `${ZOMBIED_CLIENTS_KEY_PREFIX}_${this.persistenceKey}_${clientId}`;\n  }\n}\n\n/**\n * Helper to get a typed SimpleDbStore for the primary client object store.\n */\nfunction primaryClientStore(\n  txn: SimpleDbTransaction\n): SimpleDbStore<DbPrimaryClientKey, DbPrimaryClient> {\n  return txn.store<DbPrimaryClientKey, DbPrimaryClient>(DbPrimaryClient.store);\n}\n\n/**\n * Helper to get a typed SimpleDbStore for the client metadata object store.\n */\nfunction clientMetadataStore(\n  txn: SimpleDbTransaction\n): SimpleDbStore<DbClientMetadataKey, DbClientMetadata> {\n  return txn.store<DbClientMetadataKey, DbClientMetadata>(\n    DbClientMetadata.store\n  );\n}\n\n/** Provides LRU functionality for IndexedDB persistence. */\nexport class IndexedDbLruDelegate implements ReferenceDelegate, LruDelegate {\n  private inMemoryPins: ReferenceSet | null = null;\n\n  readonly garbageCollector: LruGarbageCollector;\n\n  constructor(private readonly db: IndexedDbPersistence, params: LruParams) {\n    this.garbageCollector = new LruGarbageCollector(this, params);\n  }\n\n  getSequenceNumberCount(\n    txn: PersistenceTransaction\n  ): PersistencePromise<number> {\n    const docCountPromise = this.orphanedDocmentCount(txn);\n    const targetCountPromise = this.db.getTargetCache().getTargetCount(txn);\n    return targetCountPromise.next(targetCount =>\n      docCountPromise.next(docCount => targetCount + docCount)\n    );\n  }\n\n  private orphanedDocmentCount(\n    txn: PersistenceTransaction\n  ): PersistencePromise<number> {\n    let orphanedCount = 0;\n    return this.forEachOrphanedDocumentSequenceNumber(txn, _ => {\n      orphanedCount++;\n    }).next(() => orphanedCount);\n  }\n\n  forEachTarget(\n    txn: PersistenceTransaction,\n    f: (q: TargetData) => void\n  ): PersistencePromise<void> {\n    return this.db.getTargetCache().forEachTarget(txn, f);\n  }\n\n  forEachOrphanedDocumentSequenceNumber(\n    txn: PersistenceTransaction,\n    f: (sequenceNumber: ListenSequenceNumber) => void\n  ): PersistencePromise<void> {\n    return this.forEachOrphanedDocument(txn, (docKey, sequenceNumber) =>\n      f(sequenceNumber)\n    );\n  }\n\n  setInMemoryPins(inMemoryPins: ReferenceSet): void {\n    this.inMemoryPins = inMemoryPins;\n  }\n\n  addReference(\n    txn: PersistenceTransaction,\n    key: DocumentKey\n  ): PersistencePromise<void> {\n    return writeSentinelKey(txn, key);\n  }\n\n  removeReference(\n    txn: PersistenceTransaction,\n    key: DocumentKey\n  ): PersistencePromise<void> {\n    return writeSentinelKey(txn, key);\n  }\n\n  removeTargets(\n    txn: PersistenceTransaction,\n    upperBound: ListenSequenceNumber,\n    activeTargetIds: ActiveTargets\n  ): PersistencePromise<number> {\n    return this.db\n      .getTargetCache()\n      .removeTargets(txn, upperBound, activeTargetIds);\n  }\n\n  removeMutationReference(\n    txn: PersistenceTransaction,\n    key: DocumentKey\n  ): PersistencePromise<void> {\n    return writeSentinelKey(txn, key);\n  }\n\n  /**\n   * Returns true if anything would prevent this document from being garbage\n   * collected, given that the document in question is not present in any\n   * targets and has a sequence number less than or equal to the upper bound for\n   * the collection run.\n   */\n  private isPinned(\n    txn: PersistenceTransaction,\n    docKey: DocumentKey\n  ): PersistencePromise<boolean> {\n    if (this.inMemoryPins!.containsKey(docKey)) {\n      return PersistencePromise.resolve<boolean>(true);\n    } else {\n      return mutationQueuesContainKey(txn, docKey);\n    }\n  }\n\n  removeOrphanedDocuments(\n    txn: PersistenceTransaction,\n    upperBound: ListenSequenceNumber\n  ): PersistencePromise<number> {\n    const documentCache = this.db.getRemoteDocumentCache();\n    const changeBuffer = documentCache.newChangeBuffer();\n\n    const promises: Array<PersistencePromise<void>> = [];\n    let documentCount = 0;\n\n    const iteration = this.forEachOrphanedDocument(\n      txn,\n      (docKey, sequenceNumber) => {\n        if (sequenceNumber <= upperBound) {\n          const p = this.isPinned(txn, docKey).next(isPinned => {\n            if (!isPinned) {\n              documentCount++;\n              // Our size accounting requires us to read all documents before\n              // removing them.\n              return changeBuffer.getEntry(txn, docKey).next(() => {\n                changeBuffer.removeEntry(docKey);\n                return documentTargetStore(txn).delete(sentinelKey(docKey));\n              });\n            }\n          });\n          promises.push(p);\n        }\n      }\n    );\n\n    return iteration\n      .next(() => PersistencePromise.waitFor(promises))\n      .next(() => changeBuffer.apply(txn))\n      .next(() => documentCount);\n  }\n\n  removeTarget(\n    txn: PersistenceTransaction,\n    targetData: TargetData\n  ): PersistencePromise<void> {\n    const updated = targetData.withSequenceNumber(txn.currentSequenceNumber);\n    return this.db.getTargetCache().updateTargetData(txn, updated);\n  }\n\n  updateLimboDocument(\n    txn: PersistenceTransaction,\n    key: DocumentKey\n  ): PersistencePromise<void> {\n    return writeSentinelKey(txn, key);\n  }\n\n  /**\n   * Call provided function for each document in the cache that is 'orphaned'. Orphaned\n   * means not a part of any target, so the only entry in the target-document index for\n   * that document will be the sentinel row (targetId 0), which will also have the sequence\n   * number for the last time the document was accessed.\n   */\n  private forEachOrphanedDocument(\n    txn: PersistenceTransaction,\n    f: (docKey: DocumentKey, sequenceNumber: ListenSequenceNumber) => void\n  ): PersistencePromise<void> {\n    const store = documentTargetStore(txn);\n    let nextToReport: ListenSequenceNumber = ListenSequence.INVALID;\n    let nextPath: EncodedResourcePath;\n    return store\n      .iterate(\n        {\n          index: DbTargetDocument.documentTargetsIndex\n        },\n        ([targetId, docKey], { path, sequenceNumber }) => {\n          if (targetId === 0) {\n            // if nextToReport is valid, report it, this is a new key so the\n            // last one must not be a member of any targets.\n            if (nextToReport !== ListenSequence.INVALID) {\n              f(new DocumentKey(decodeResourcePath(nextPath)), nextToReport);\n            }\n            // set nextToReport to be this sequence number. It's the next one we\n            // might report, if we don't find any targets for this document.\n            // Note that the sequence number must be defined when the targetId\n            // is 0.\n            nextToReport = sequenceNumber!;\n            nextPath = path;\n          } else {\n            // set nextToReport to be invalid, we know we don't need to report\n            // this one since we found a target for it.\n            nextToReport = ListenSequence.INVALID;\n          }\n        }\n      )\n      .next(() => {\n        // Since we report sequence numbers after getting to the next key, we\n        // need to check if the last key we iterated over was an orphaned\n        // document and report it.\n        if (nextToReport !== ListenSequence.INVALID) {\n          f(new DocumentKey(decodeResourcePath(nextPath)), nextToReport);\n        }\n      });\n  }\n\n  getCacheSize(txn: PersistenceTransaction): PersistencePromise<number> {\n    return this.db.getRemoteDocumentCache().getSize(txn);\n  }\n}\n\nfunction sentinelKey(key: DocumentKey): [TargetId, EncodedResourcePath] {\n  return [0, encodeResourcePath(key.path)];\n}\n\n/**\n * @return A value suitable for writing a sentinel row in the target-document\n * store.\n */\nfunction sentinelRow(\n  key: DocumentKey,\n  sequenceNumber: ListenSequenceNumber\n): DbTargetDocument {\n  return new DbTargetDocument(0, encodeResourcePath(key.path), sequenceNumber);\n}\n\nfunction writeSentinelKey(\n  txn: PersistenceTransaction,\n  key: DocumentKey\n): PersistencePromise<void> {\n  return documentTargetStore(txn).put(\n    sentinelRow(key, txn.currentSequenceNumber)\n  );\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Timestamp } from '../api/timestamp';\nimport { Query } from '../core/query';\nimport { BatchId } from '../core/types';\nimport { DocumentKeySet } from '../model/collections';\nimport { DocumentKey } from '../model/document_key';\nimport { Mutation } from '../model/mutation';\nimport { MutationBatch, BATCHID_UNKNOWN } from '../model/mutation_batch';\nimport { hardAssert, debugAssert } from '../util/assert';\nimport { primitiveComparator } from '../util/misc';\nimport { ByteString } from '../util/byte_string';\nimport { SortedMap } from '../util/sorted_map';\nimport { SortedSet } from '../util/sorted_set';\n\nimport { IndexManager } from './index_manager';\nimport { MutationQueue } from './mutation_queue';\nimport { PersistenceTransaction, ReferenceDelegate } from './persistence';\nimport { PersistencePromise } from './persistence_promise';\nimport { DocReference } from './reference_set';\n\nexport class MemoryMutationQueue implements MutationQueue {\n  /**\n   * The set of all mutations that have been sent but not yet been applied to\n   * the backend.\n   */\n  private mutationQueue: MutationBatch[] = [];\n\n  /** Next value to use when assigning sequential IDs to each mutation batch. */\n  private nextBatchId: BatchId = 1;\n\n  /** The last received stream token from the server, used to acknowledge which\n   * responses the client has processed. Stream tokens are opaque checkpoint\n   * markers whose only real value is their inclusion in the next request.\n   */\n  private lastStreamToken: ByteString = ByteString.EMPTY_BYTE_STRING;\n\n  /** An ordered mapping between documents and the mutations batch IDs. */\n  private batchesByDocumentKey = new SortedSet(DocReference.compareByKey);\n\n  constructor(\n    private readonly indexManager: IndexManager,\n    private readonly referenceDelegate: ReferenceDelegate\n  ) {}\n\n  checkEmpty(transaction: PersistenceTransaction): PersistencePromise<boolean> {\n    return PersistencePromise.resolve(this.mutationQueue.length === 0);\n  }\n\n  acknowledgeBatch(\n    transaction: PersistenceTransaction,\n    batch: MutationBatch,\n    streamToken: ByteString\n  ): PersistencePromise<void> {\n    const batchId = batch.batchId;\n    const batchIndex = this.indexOfExistingBatchId(batchId, 'acknowledged');\n    hardAssert(\n      batchIndex === 0,\n      'Can only acknowledge the first batch in the mutation queue'\n    );\n\n    // Verify that the batch in the queue is the one to be acknowledged.\n    const check = this.mutationQueue[batchIndex];\n    debugAssert(\n      batchId === check.batchId,\n      'Queue ordering failure: expected batch ' +\n        batchId +\n        ', got batch ' +\n        check.batchId\n    );\n\n    this.lastStreamToken = streamToken;\n    return PersistencePromise.resolve();\n  }\n\n  getLastStreamToken(\n    transaction: PersistenceTransaction\n  ): PersistencePromise<ByteString> {\n    return PersistencePromise.resolve(this.lastStreamToken);\n  }\n\n  setLastStreamToken(\n    transaction: PersistenceTransaction,\n    streamToken: ByteString\n  ): PersistencePromise<void> {\n    this.lastStreamToken = streamToken;\n    return PersistencePromise.resolve();\n  }\n\n  addMutationBatch(\n    transaction: PersistenceTransaction,\n    localWriteTime: Timestamp,\n    baseMutations: Mutation[],\n    mutations: Mutation[]\n  ): PersistencePromise<MutationBatch> {\n    debugAssert(mutations.length !== 0, 'Mutation batches should not be empty');\n\n    const batchId = this.nextBatchId;\n    this.nextBatchId++;\n\n    if (this.mutationQueue.length > 0) {\n      const prior = this.mutationQueue[this.mutationQueue.length - 1];\n      debugAssert(\n        prior.batchId < batchId,\n        'Mutation batchIDs must be monotonically increasing order'\n      );\n    }\n\n    const batch = new MutationBatch(\n      batchId,\n      localWriteTime,\n      baseMutations,\n      mutations\n    );\n    this.mutationQueue.push(batch);\n\n    // Track references by document key and index collection parents.\n    for (const mutation of mutations) {\n      this.batchesByDocumentKey = this.batchesByDocumentKey.add(\n        new DocReference(mutation.key, batchId)\n      );\n\n      this.indexManager.addToCollectionParentIndex(\n        transaction,\n        mutation.key.path.popLast()\n      );\n    }\n\n    return PersistencePromise.resolve(batch);\n  }\n\n  lookupMutationBatch(\n    transaction: PersistenceTransaction,\n    batchId: BatchId\n  ): PersistencePromise<MutationBatch | null> {\n    return PersistencePromise.resolve(this.findMutationBatch(batchId));\n  }\n\n  lookupMutationKeys(\n    transaction: PersistenceTransaction,\n    batchId: BatchId\n  ): PersistencePromise<DocumentKeySet | null> {\n    const mutationBatch = this.findMutationBatch(batchId);\n    debugAssert(mutationBatch != null, 'Failed to find local mutation batch.');\n    return PersistencePromise.resolve<DocumentKeySet | null>(\n      mutationBatch.keys()\n    );\n  }\n\n  getNextMutationBatchAfterBatchId(\n    transaction: PersistenceTransaction,\n    batchId: BatchId\n  ): PersistencePromise<MutationBatch | null> {\n    const nextBatchId = batchId + 1;\n\n    // The requested batchId may still be out of range so normalize it to the\n    // start of the queue.\n    const rawIndex = this.indexOfBatchId(nextBatchId);\n    const index = rawIndex < 0 ? 0 : rawIndex;\n    return PersistencePromise.resolve(\n      this.mutationQueue.length > index ? this.mutationQueue[index] : null\n    );\n  }\n\n  getHighestUnacknowledgedBatchId(): PersistencePromise<BatchId> {\n    return PersistencePromise.resolve(\n      this.mutationQueue.length === 0 ? BATCHID_UNKNOWN : this.nextBatchId - 1\n    );\n  }\n\n  getAllMutationBatches(\n    transaction: PersistenceTransaction\n  ): PersistencePromise<MutationBatch[]> {\n    return PersistencePromise.resolve(this.mutationQueue.slice());\n  }\n\n  getAllMutationBatchesAffectingDocumentKey(\n    transaction: PersistenceTransaction,\n    documentKey: DocumentKey\n  ): PersistencePromise<MutationBatch[]> {\n    const start = new DocReference(documentKey, 0);\n    const end = new DocReference(documentKey, Number.POSITIVE_INFINITY);\n    const result: MutationBatch[] = [];\n    this.batchesByDocumentKey.forEachInRange([start, end], ref => {\n      debugAssert(\n        documentKey.isEqual(ref.key),\n        \"Should only iterate over a single key's batches\"\n      );\n      const batch = this.findMutationBatch(ref.targetOrBatchId);\n      debugAssert(\n        batch !== null,\n        'Batches in the index must exist in the main table'\n      );\n      result.push(batch!);\n    });\n\n    return PersistencePromise.resolve(result);\n  }\n\n  getAllMutationBatchesAffectingDocumentKeys(\n    transaction: PersistenceTransaction,\n    documentKeys: SortedMap<DocumentKey, unknown>\n  ): PersistencePromise<MutationBatch[]> {\n    let uniqueBatchIDs = new SortedSet<number>(primitiveComparator);\n\n    documentKeys.forEach(documentKey => {\n      const start = new DocReference(documentKey, 0);\n      const end = new DocReference(documentKey, Number.POSITIVE_INFINITY);\n      this.batchesByDocumentKey.forEachInRange([start, end], ref => {\n        debugAssert(\n          documentKey.isEqual(ref.key),\n          \"For each key, should only iterate over a single key's batches\"\n        );\n\n        uniqueBatchIDs = uniqueBatchIDs.add(ref.targetOrBatchId);\n      });\n    });\n\n    return PersistencePromise.resolve(this.findMutationBatches(uniqueBatchIDs));\n  }\n\n  getAllMutationBatchesAffectingQuery(\n    transaction: PersistenceTransaction,\n    query: Query\n  ): PersistencePromise<MutationBatch[]> {\n    debugAssert(\n      !query.isCollectionGroupQuery(),\n      'CollectionGroup queries should be handled in LocalDocumentsView'\n    );\n    // Use the query path as a prefix for testing if a document matches the\n    // query.\n    const prefix = query.path;\n    const immediateChildrenPathLength = prefix.length + 1;\n\n    // Construct a document reference for actually scanning the index. Unlike\n    // the prefix the document key in this reference must have an even number of\n    // segments. The empty segment can be used a suffix of the query path\n    // because it precedes all other segments in an ordered traversal.\n    let startPath = prefix;\n    if (!DocumentKey.isDocumentKey(startPath)) {\n      startPath = startPath.child('');\n    }\n\n    const start = new DocReference(new DocumentKey(startPath), 0);\n\n    // Find unique batchIDs referenced by all documents potentially matching the\n    // query.\n    let uniqueBatchIDs = new SortedSet<number>(primitiveComparator);\n\n    this.batchesByDocumentKey.forEachWhile(ref => {\n      const rowKeyPath = ref.key.path;\n      if (!prefix.isPrefixOf(rowKeyPath)) {\n        return false;\n      } else {\n        // Rows with document keys more than one segment longer than the query\n        // path can't be matches. For example, a query on 'rooms' can't match\n        // the document /rooms/abc/messages/xyx.\n        // TODO(mcg): we'll need a different scanner when we implement\n        // ancestor queries.\n        if (rowKeyPath.length === immediateChildrenPathLength) {\n          uniqueBatchIDs = uniqueBatchIDs.add(ref.targetOrBatchId);\n        }\n        return true;\n      }\n    }, start);\n\n    return PersistencePromise.resolve(this.findMutationBatches(uniqueBatchIDs));\n  }\n\n  private findMutationBatches(batchIDs: SortedSet<number>): MutationBatch[] {\n    // Construct an array of matching batches, sorted by batchID to ensure that\n    // multiple mutations affecting the same document key are applied in order.\n    const result: MutationBatch[] = [];\n    batchIDs.forEach(batchId => {\n      const batch = this.findMutationBatch(batchId);\n      if (batch !== null) {\n        result.push(batch);\n      }\n    });\n    return result;\n  }\n\n  removeMutationBatch(\n    transaction: PersistenceTransaction,\n    batch: MutationBatch\n  ): PersistencePromise<void> {\n    // Find the position of the first batch for removal.\n    const batchIndex = this.indexOfExistingBatchId(batch.batchId, 'removed');\n    hardAssert(\n      batchIndex === 0,\n      'Can only remove the first entry of the mutation queue'\n    );\n    this.mutationQueue.shift();\n\n    let references = this.batchesByDocumentKey;\n    return PersistencePromise.forEach(batch.mutations, (mutation: Mutation) => {\n      const ref = new DocReference(mutation.key, batch.batchId);\n      references = references.delete(ref);\n      return this.referenceDelegate.removeMutationReference(\n        transaction,\n        mutation.key\n      );\n    }).next(() => {\n      this.batchesByDocumentKey = references;\n    });\n  }\n\n  removeCachedMutationKeys(batchId: BatchId): void {\n    // No-op since the memory mutation queue does not maintain a separate cache.\n  }\n\n  containsKey(\n    txn: PersistenceTransaction,\n    key: DocumentKey\n  ): PersistencePromise<boolean> {\n    const ref = new DocReference(key, 0);\n    const firstRef = this.batchesByDocumentKey.firstAfterOrEqual(ref);\n    return PersistencePromise.resolve(key.isEqual(firstRef && firstRef.key));\n  }\n\n  performConsistencyCheck(\n    txn: PersistenceTransaction\n  ): PersistencePromise<void> {\n    if (this.mutationQueue.length === 0) {\n      debugAssert(\n        this.batchesByDocumentKey.isEmpty(),\n        'Document leak -- detected dangling mutation references when queue is empty.'\n      );\n    }\n    return PersistencePromise.resolve();\n  }\n\n  /**\n   * Finds the index of the given batchId in the mutation queue and asserts that\n   * the resulting index is within the bounds of the queue.\n   *\n   * @param batchId The batchId to search for\n   * @param action A description of what the caller is doing, phrased in passive\n   * form (e.g. \"acknowledged\" in a routine that acknowledges batches).\n   */\n  private indexOfExistingBatchId(batchId: BatchId, action: string): number {\n    const index = this.indexOfBatchId(batchId);\n    debugAssert(\n      index >= 0 && index < this.mutationQueue.length,\n      'Batches must exist to be ' + action\n    );\n    return index;\n  }\n\n  /**\n   * Finds the index of the given batchId in the mutation queue. This operation\n   * is O(1).\n   *\n   * @return The computed index of the batch with the given batchId, based on\n   * the state of the queue. Note this index can be negative if the requested\n   * batchId has already been remvoed from the queue or past the end of the\n   * queue if the batchId is larger than the last added batch.\n   */\n  private indexOfBatchId(batchId: BatchId): number {\n    if (this.mutationQueue.length === 0) {\n      // As an index this is past the end of the queue\n      return 0;\n    }\n\n    // Examine the front of the queue to figure out the difference between the\n    // batchId and indexes in the array. Note that since the queue is ordered\n    // by batchId, if the first batch has a larger batchId then the requested\n    // batchId doesn't exist in the queue.\n    const firstBatchId = this.mutationQueue[0].batchId;\n    return batchId - firstBatchId;\n  }\n\n  /**\n   * A version of lookupMutationBatch that doesn't return a promise, this makes\n   * other functions that uses this code easier to read and more efficent.\n   */\n  private findMutationBatch(batchId: BatchId): MutationBatch | null {\n    const index = this.indexOfBatchId(batchId);\n    if (index < 0 || index >= this.mutationQueue.length) {\n      return null;\n    }\n\n    const batch = this.mutationQueue[index];\n    debugAssert(batch.batchId === batchId, 'If found batch must match');\n    return batch;\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Query } from '../core/query';\nimport {\n  DocumentKeySet,\n  DocumentMap,\n  documentMap,\n  DocumentSizeEntry,\n  MaybeDocumentMap,\n  NullableMaybeDocumentMap,\n  nullableMaybeDocumentMap\n} from '../model/collections';\nimport { Document, MaybeDocument } from '../model/document';\nimport { DocumentKey } from '../model/document_key';\n\nimport { SnapshotVersion } from '../core/snapshot_version';\nimport { debugAssert } from '../util/assert';\nimport { SortedMap } from '../util/sorted_map';\nimport { IndexManager } from './index_manager';\nimport { PersistenceTransaction } from './persistence';\nimport { PersistencePromise } from './persistence_promise';\nimport { RemoteDocumentCache } from './remote_document_cache';\nimport { RemoteDocumentChangeBuffer } from './remote_document_change_buffer';\n\nexport type DocumentSizer = (doc: MaybeDocument) => number;\n\n/** Miscellaneous collection types / constants. */\ninterface MemoryRemoteDocumentCacheEntry extends DocumentSizeEntry {\n  readTime: SnapshotVersion;\n}\n\ntype DocumentEntryMap = SortedMap<DocumentKey, MemoryRemoteDocumentCacheEntry>;\nfunction documentEntryMap(): DocumentEntryMap {\n  return new SortedMap<DocumentKey, MemoryRemoteDocumentCacheEntry>(\n    DocumentKey.comparator\n  );\n}\n\nexport class MemoryRemoteDocumentCache implements RemoteDocumentCache {\n  /** Underlying cache of documents and their read times. */\n  private docs = documentEntryMap();\n\n  /** Size of all cached documents. */\n  private size = 0;\n\n  /**\n   * @param sizer Used to assess the size of a document. For eager GC, this is expected to just\n   * return 0 to avoid unnecessarily doing the work of calculating the size.\n   */\n  constructor(\n    private readonly indexManager: IndexManager,\n    private readonly sizer: DocumentSizer\n  ) {}\n\n  /**\n   * Adds the supplied entry to the cache and updates the cache size as appropriate.\n   *\n   * All calls of `addEntry`  are required to go through the RemoteDocumentChangeBuffer\n   * returned by `newChangeBuffer()`.\n   */\n  private addEntry(\n    transaction: PersistenceTransaction,\n    doc: MaybeDocument,\n    readTime: SnapshotVersion\n  ): PersistencePromise<void> {\n    debugAssert(\n      !readTime.isEqual(SnapshotVersion.MIN),\n      'Cannot add a document with a read time of zero'\n    );\n\n    const key = doc.key;\n    const entry = this.docs.get(key);\n    const previousSize = entry ? entry.size : 0;\n    const currentSize = this.sizer(doc);\n\n    this.docs = this.docs.insert(key, {\n      maybeDocument: doc,\n      size: currentSize,\n      readTime\n    });\n\n    this.size += currentSize - previousSize;\n\n    return this.indexManager.addToCollectionParentIndex(\n      transaction,\n      key.path.popLast()\n    );\n  }\n\n  /**\n   * Removes the specified entry from the cache and updates the cache size as appropriate.\n   *\n   * All calls of `removeEntry` are required to go through the RemoteDocumentChangeBuffer\n   * returned by `newChangeBuffer()`.\n   */\n  private removeEntry(documentKey: DocumentKey): void {\n    const entry = this.docs.get(documentKey);\n    if (entry) {\n      this.docs = this.docs.remove(documentKey);\n      this.size -= entry.size;\n    }\n  }\n\n  getEntry(\n    transaction: PersistenceTransaction,\n    documentKey: DocumentKey\n  ): PersistencePromise<MaybeDocument | null> {\n    const entry = this.docs.get(documentKey);\n    return PersistencePromise.resolve(entry ? entry.maybeDocument : null);\n  }\n\n  getEntries(\n    transaction: PersistenceTransaction,\n    documentKeys: DocumentKeySet\n  ): PersistencePromise<NullableMaybeDocumentMap> {\n    let results = nullableMaybeDocumentMap();\n    documentKeys.forEach(documentKey => {\n      const entry = this.docs.get(documentKey);\n      results = results.insert(documentKey, entry ? entry.maybeDocument : null);\n    });\n    return PersistencePromise.resolve(results);\n  }\n\n  getDocumentsMatchingQuery(\n    transaction: PersistenceTransaction,\n    query: Query,\n    sinceReadTime: SnapshotVersion\n  ): PersistencePromise<DocumentMap> {\n    debugAssert(\n      !query.isCollectionGroupQuery(),\n      'CollectionGroup queries should be handled in LocalDocumentsView'\n    );\n    let results = documentMap();\n\n    // Documents are ordered by key, so we can use a prefix scan to narrow down\n    // the documents we need to match the query against.\n    const prefix = new DocumentKey(query.path.child(''));\n    const iterator = this.docs.getIteratorFrom(prefix);\n    while (iterator.hasNext()) {\n      const {\n        key,\n        value: { maybeDocument, readTime }\n      } = iterator.getNext();\n      if (!query.path.isPrefixOf(key.path)) {\n        break;\n      }\n      if (readTime.compareTo(sinceReadTime) <= 0) {\n        continue;\n      }\n      if (maybeDocument instanceof Document && query.matches(maybeDocument)) {\n        results = results.insert(maybeDocument.key, maybeDocument);\n      }\n    }\n    return PersistencePromise.resolve(results);\n  }\n\n  forEachDocumentKey(\n    transaction: PersistenceTransaction,\n    f: (key: DocumentKey) => PersistencePromise<void>\n  ): PersistencePromise<void> {\n    return PersistencePromise.forEach(this.docs, (key: DocumentKey) => f(key));\n  }\n\n  getNewDocumentChanges(\n    transaction: PersistenceTransaction,\n    sinceReadTime: SnapshotVersion\n  ): PersistencePromise<{\n    changedDocs: MaybeDocumentMap;\n    readTime: SnapshotVersion;\n  }> {\n    throw new Error(\n      'getNewDocumentChanges() is not supported with MemoryPersistence'\n    );\n  }\n\n  getLastReadTime(\n    transaction: PersistenceTransaction\n  ): PersistencePromise<SnapshotVersion> {\n    return PersistencePromise.resolve(SnapshotVersion.MIN);\n  }\n\n  newChangeBuffer(options?: {\n    trackRemovals: boolean;\n  }): RemoteDocumentChangeBuffer {\n    // `trackRemovals` is ignores since the MemoryRemoteDocumentCache keeps\n    // a separate changelog and does not need special handling for removals.\n    return new MemoryRemoteDocumentCache.RemoteDocumentChangeBuffer(this);\n  }\n\n  getSize(txn: PersistenceTransaction): PersistencePromise<number> {\n    return PersistencePromise.resolve(this.size);\n  }\n\n  /**\n   * Handles the details of adding and updating documents in the MemoryRemoteDocumentCache.\n   */\n  private static RemoteDocumentChangeBuffer = class extends RemoteDocumentChangeBuffer {\n    constructor(private readonly documentCache: MemoryRemoteDocumentCache) {\n      super();\n    }\n\n    protected applyChanges(\n      transaction: PersistenceTransaction\n    ): PersistencePromise<void> {\n      const promises: Array<PersistencePromise<void>> = [];\n      this.changes.forEach((key, doc) => {\n        if (doc) {\n          promises.push(\n            this.documentCache.addEntry(transaction, doc, this.readTime)\n          );\n        } else {\n          this.documentCache.removeEntry(key);\n        }\n      });\n      return PersistencePromise.waitFor(promises);\n    }\n\n    protected getFromCache(\n      transaction: PersistenceTransaction,\n      documentKey: DocumentKey\n    ): PersistencePromise<MaybeDocument | null> {\n      return this.documentCache.getEntry(transaction, documentKey);\n    }\n\n    protected getAllFromCache(\n      transaction: PersistenceTransaction,\n      documentKeys: DocumentKeySet\n    ): PersistencePromise<NullableMaybeDocumentMap> {\n      return this.documentCache.getEntries(transaction, documentKeys);\n    }\n  };\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { SnapshotVersion } from '../core/snapshot_version';\nimport { TargetIdGenerator } from '../core/target_id_generator';\nimport { ListenSequenceNumber, TargetId } from '../core/types';\nimport { DocumentKeySet } from '../model/collections';\nimport { DocumentKey } from '../model/document_key';\nimport { debugAssert, fail } from '../util/assert';\nimport { ObjectMap } from '../util/obj_map';\n\nimport { ActiveTargets } from './lru_garbage_collector';\nimport { MemoryPersistence } from './memory_persistence';\nimport { PersistenceTransaction } from './persistence';\nimport { PersistencePromise } from './persistence_promise';\nimport { ReferenceSet } from './reference_set';\nimport { TargetCache } from './target_cache';\nimport { TargetData } from './target_data';\nimport { Target } from '../core/target';\n\nexport class MemoryTargetCache implements TargetCache {\n  /**\n   * Maps a target to the data about that target\n   */\n  private targets = new ObjectMap<Target, TargetData>(t => t.canonicalId());\n\n  /** The last received snapshot version. */\n  private lastRemoteSnapshotVersion = SnapshotVersion.MIN;\n  /** The highest numbered target ID encountered. */\n  private highestTargetId: TargetId = 0;\n  /** The highest sequence number encountered. */\n  private highestSequenceNumber: ListenSequenceNumber = 0;\n  /**\n   * A ordered bidirectional mapping between documents and the remote target\n   * IDs.\n   */\n  private references = new ReferenceSet();\n\n  private targetCount = 0;\n\n  private targetIdGenerator = TargetIdGenerator.forTargetCache();\n\n  constructor(private readonly persistence: MemoryPersistence) {}\n\n  forEachTarget(\n    txn: PersistenceTransaction,\n    f: (q: TargetData) => void\n  ): PersistencePromise<void> {\n    this.targets.forEach((_, targetData) => f(targetData));\n    return PersistencePromise.resolve();\n  }\n\n  getLastRemoteSnapshotVersion(\n    transaction: PersistenceTransaction\n  ): PersistencePromise<SnapshotVersion> {\n    return PersistencePromise.resolve(this.lastRemoteSnapshotVersion);\n  }\n\n  getHighestSequenceNumber(\n    transaction: PersistenceTransaction\n  ): PersistencePromise<ListenSequenceNumber> {\n    return PersistencePromise.resolve(this.highestSequenceNumber);\n  }\n\n  allocateTargetId(\n    transaction: PersistenceTransaction\n  ): PersistencePromise<TargetId> {\n    this.highestTargetId = this.targetIdGenerator.next();\n    return PersistencePromise.resolve(this.highestTargetId);\n  }\n\n  setTargetsMetadata(\n    transaction: PersistenceTransaction,\n    highestListenSequenceNumber: number,\n    lastRemoteSnapshotVersion?: SnapshotVersion\n  ): PersistencePromise<void> {\n    if (lastRemoteSnapshotVersion) {\n      this.lastRemoteSnapshotVersion = lastRemoteSnapshotVersion;\n    }\n    if (highestListenSequenceNumber > this.highestSequenceNumber) {\n      this.highestSequenceNumber = highestListenSequenceNumber;\n    }\n    return PersistencePromise.resolve();\n  }\n\n  private saveTargetData(targetData: TargetData): void {\n    this.targets.set(targetData.target, targetData);\n    const targetId = targetData.targetId;\n    if (targetId > this.highestTargetId) {\n      this.targetIdGenerator = new TargetIdGenerator(targetId);\n      this.highestTargetId = targetId;\n    }\n    if (targetData.sequenceNumber > this.highestSequenceNumber) {\n      this.highestSequenceNumber = targetData.sequenceNumber;\n    }\n  }\n\n  addTargetData(\n    transaction: PersistenceTransaction,\n    targetData: TargetData\n  ): PersistencePromise<void> {\n    debugAssert(\n      !this.targets.has(targetData.target),\n      'Adding a target that already exists'\n    );\n    this.saveTargetData(targetData);\n    this.targetCount += 1;\n    return PersistencePromise.resolve();\n  }\n\n  updateTargetData(\n    transaction: PersistenceTransaction,\n    targetData: TargetData\n  ): PersistencePromise<void> {\n    debugAssert(\n      this.targets.has(targetData.target),\n      'Updating a non-existent target'\n    );\n    this.saveTargetData(targetData);\n    return PersistencePromise.resolve();\n  }\n\n  removeTargetData(\n    transaction: PersistenceTransaction,\n    targetData: TargetData\n  ): PersistencePromise<void> {\n    debugAssert(this.targetCount > 0, 'Removing a target from an empty cache');\n    debugAssert(\n      this.targets.has(targetData.target),\n      'Removing a non-existent target from the cache'\n    );\n    this.targets.delete(targetData.target);\n    this.references.removeReferencesForId(targetData.targetId);\n    this.targetCount -= 1;\n    return PersistencePromise.resolve();\n  }\n\n  removeTargets(\n    transaction: PersistenceTransaction,\n    upperBound: ListenSequenceNumber,\n    activeTargetIds: ActiveTargets\n  ): PersistencePromise<number> {\n    let count = 0;\n    const removals: Array<PersistencePromise<void>> = [];\n    this.targets.forEach((key, targetData) => {\n      if (\n        targetData.sequenceNumber <= upperBound &&\n        activeTargetIds.get(targetData.targetId) === null\n      ) {\n        this.targets.delete(key);\n        removals.push(\n          this.removeMatchingKeysForTargetId(transaction, targetData.targetId)\n        );\n        count++;\n      }\n    });\n    return PersistencePromise.waitFor(removals).next(() => count);\n  }\n\n  getTargetCount(\n    transaction: PersistenceTransaction\n  ): PersistencePromise<number> {\n    return PersistencePromise.resolve(this.targetCount);\n  }\n\n  getTargetData(\n    transaction: PersistenceTransaction,\n    target: Target\n  ): PersistencePromise<TargetData | null> {\n    const targetData = this.targets.get(target) || null;\n    return PersistencePromise.resolve(targetData);\n  }\n\n  getTargetDataForTarget(\n    transaction: PersistenceTransaction,\n    targetId: TargetId\n  ): never {\n    // This method is only needed for multi-tab and we can't implement it\n    // efficiently without additional data structures.\n    return fail('Not yet implemented.');\n  }\n\n  addMatchingKeys(\n    txn: PersistenceTransaction,\n    keys: DocumentKeySet,\n    targetId: TargetId\n  ): PersistencePromise<void> {\n    this.references.addReferences(keys, targetId);\n    const referenceDelegate = this.persistence.referenceDelegate;\n    const promises: Array<PersistencePromise<void>> = [];\n    if (referenceDelegate) {\n      keys.forEach(key => {\n        promises.push(referenceDelegate.addReference(txn, key));\n      });\n    }\n    return PersistencePromise.waitFor(promises);\n  }\n\n  removeMatchingKeys(\n    txn: PersistenceTransaction,\n    keys: DocumentKeySet,\n    targetId: TargetId\n  ): PersistencePromise<void> {\n    this.references.removeReferences(keys, targetId);\n    const referenceDelegate = this.persistence.referenceDelegate;\n    const promises: Array<PersistencePromise<void>> = [];\n    if (referenceDelegate) {\n      keys.forEach(key => {\n        promises.push(referenceDelegate.removeReference(txn, key));\n      });\n    }\n    return PersistencePromise.waitFor(promises);\n  }\n\n  removeMatchingKeysForTargetId(\n    txn: PersistenceTransaction,\n    targetId: TargetId\n  ): PersistencePromise<void> {\n    this.references.removeReferencesForId(targetId);\n    return PersistencePromise.resolve();\n  }\n\n  getMatchingKeysForTargetId(\n    txn: PersistenceTransaction,\n    targetId: TargetId\n  ): PersistencePromise<DocumentKeySet> {\n    const matchingKeys = this.references.referencesForId(targetId);\n    return PersistencePromise.resolve(matchingKeys);\n  }\n\n  containsKey(\n    txn: PersistenceTransaction,\n    key: DocumentKey\n  ): PersistencePromise<boolean> {\n    return PersistencePromise.resolve(this.references.containsKey(key));\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { User } from '../auth/user';\nimport { Document, MaybeDocument } from '../model/document';\nimport { DocumentKey } from '../model/document_key';\nimport { fail } from '../util/assert';\nimport { logDebug } from '../util/log';\nimport { ObjectMap } from '../util/obj_map';\nimport { encodeResourcePath } from './encoded_resource_path';\nimport {\n  ActiveTargets,\n  LruDelegate,\n  LruGarbageCollector,\n  LruParams\n} from './lru_garbage_collector';\nimport { ListenSequence } from '../core/listen_sequence';\nimport { ListenSequenceNumber } from '../core/types';\nimport { estimateByteSize } from '../model/values';\nimport { MemoryIndexManager } from './memory_index_manager';\nimport { MemoryMutationQueue } from './memory_mutation_queue';\nimport { MemoryRemoteDocumentCache } from './memory_remote_document_cache';\nimport { MemoryTargetCache } from './memory_target_cache';\nimport { MutationQueue } from './mutation_queue';\nimport {\n  Persistence,\n  PersistenceTransaction,\n  PersistenceTransactionMode,\n  PrimaryStateListener,\n  ReferenceDelegate\n} from './persistence';\nimport { PersistencePromise } from './persistence_promise';\nimport { ReferenceSet } from './reference_set';\nimport { ClientId } from './shared_client_state';\nimport { TargetData } from './target_data';\n\nconst LOG_TAG = 'MemoryPersistence';\n/**\n * A memory-backed instance of Persistence. Data is stored only in RAM and\n * not persisted across sessions.\n */\nexport class MemoryPersistence implements Persistence {\n  /**\n   * Note that these are retained here to make it easier to write tests\n   * affecting both the in-memory and IndexedDB-backed persistence layers. Tests\n   * can create a new LocalStore wrapping this Persistence instance and this\n   * will make the in-memory persistence layer behave as if it were actually\n   * persisting values.\n   */\n  private readonly indexManager: MemoryIndexManager;\n  private mutationQueues: { [user: string]: MemoryMutationQueue } = {};\n  private readonly remoteDocumentCache: MemoryRemoteDocumentCache;\n  private readonly targetCache: MemoryTargetCache;\n  private readonly listenSequence = new ListenSequence(0);\n\n  private _started = false;\n\n  readonly referenceDelegate: MemoryReferenceDelegate;\n\n  /**\n   * The constructor accepts a factory for creating a reference delegate. This\n   * allows both the delegate and this instance to have strong references to\n   * each other without having nullable fields that would then need to be\n   * checked or asserted on every access.\n   */\n  constructor(\n    private readonly clientId: ClientId,\n    referenceDelegateFactory: (p: MemoryPersistence) => MemoryReferenceDelegate\n  ) {\n    this._started = true;\n    this.referenceDelegate = referenceDelegateFactory(this);\n    this.targetCache = new MemoryTargetCache(this);\n    const sizer = (doc: MaybeDocument): number =>\n      this.referenceDelegate.documentSize(doc);\n    this.indexManager = new MemoryIndexManager();\n    this.remoteDocumentCache = new MemoryRemoteDocumentCache(\n      this.indexManager,\n      sizer\n    );\n  }\n\n  shutdown(): Promise<void> {\n    // No durable state to ensure is closed on shutdown.\n    this._started = false;\n    return Promise.resolve();\n  }\n\n  get started(): boolean {\n    return this._started;\n  }\n\n  async getActiveClients(): Promise<ClientId[]> {\n    return [this.clientId];\n  }\n\n  setPrimaryStateListener(\n    primaryStateListener: PrimaryStateListener\n  ): Promise<void> {\n    // All clients using memory persistence act as primary.\n    return primaryStateListener(true);\n  }\n\n  setDatabaseDeletedListener(): void {\n    // No op.\n  }\n\n  setNetworkEnabled(networkEnabled: boolean): void {\n    // No op.\n  }\n\n  getIndexManager(): MemoryIndexManager {\n    return this.indexManager;\n  }\n\n  getMutationQueue(user: User): MutationQueue {\n    let queue = this.mutationQueues[user.toKey()];\n    if (!queue) {\n      queue = new MemoryMutationQueue(\n        this.indexManager,\n        this.referenceDelegate\n      );\n      this.mutationQueues[user.toKey()] = queue;\n    }\n    return queue;\n  }\n\n  getTargetCache(): MemoryTargetCache {\n    return this.targetCache;\n  }\n\n  getRemoteDocumentCache(): MemoryRemoteDocumentCache {\n    return this.remoteDocumentCache;\n  }\n\n  runTransaction<T>(\n    action: string,\n    mode: PersistenceTransactionMode,\n    transactionOperation: (\n      transaction: PersistenceTransaction\n    ) => PersistencePromise<T>\n  ): Promise<T> {\n    logDebug(LOG_TAG, 'Starting transaction:', action);\n    const txn = new MemoryTransaction(this.listenSequence.next());\n    this.referenceDelegate.onTransactionStarted();\n    return transactionOperation(txn)\n      .next(result => {\n        return this.referenceDelegate\n          .onTransactionCommitted(txn)\n          .next(() => result);\n      })\n      .toPromise()\n      .then(result => {\n        txn.raiseOnCommittedEvent();\n        return result;\n      });\n  }\n\n  mutationQueuesContainKey(\n    transaction: PersistenceTransaction,\n    key: DocumentKey\n  ): PersistencePromise<boolean> {\n    return PersistencePromise.or(\n      Object.values(this.mutationQueues).map(queue => () =>\n        queue.containsKey(transaction, key)\n      )\n    );\n  }\n}\n\n/**\n * Memory persistence is not actually transactional, but future implementations\n * may have transaction-scoped state.\n */\nexport class MemoryTransaction extends PersistenceTransaction {\n  constructor(readonly currentSequenceNumber: ListenSequenceNumber) {\n    super();\n  }\n}\n\nexport interface MemoryReferenceDelegate extends ReferenceDelegate {\n  documentSize(doc: MaybeDocument): number;\n  onTransactionStarted(): void;\n  onTransactionCommitted(txn: PersistenceTransaction): PersistencePromise<void>;\n}\n\nexport class MemoryEagerDelegate implements MemoryReferenceDelegate {\n  private inMemoryPins: ReferenceSet | null = null;\n  private _orphanedDocuments: Set<DocumentKey> | null = null;\n\n  private constructor(private readonly persistence: MemoryPersistence) {}\n\n  static factory(persistence: MemoryPersistence): MemoryEagerDelegate {\n    return new MemoryEagerDelegate(persistence);\n  }\n\n  private get orphanedDocuments(): Set<DocumentKey> {\n    if (!this._orphanedDocuments) {\n      throw fail('orphanedDocuments is only valid during a transaction.');\n    } else {\n      return this._orphanedDocuments;\n    }\n  }\n\n  setInMemoryPins(inMemoryPins: ReferenceSet): void {\n    this.inMemoryPins = inMemoryPins;\n  }\n\n  addReference(\n    txn: PersistenceTransaction,\n    key: DocumentKey\n  ): PersistencePromise<void> {\n    this.orphanedDocuments.delete(key);\n    return PersistencePromise.resolve();\n  }\n\n  removeReference(\n    txn: PersistenceTransaction,\n    key: DocumentKey\n  ): PersistencePromise<void> {\n    this.orphanedDocuments.add(key);\n    return PersistencePromise.resolve();\n  }\n\n  removeMutationReference(\n    txn: PersistenceTransaction,\n    key: DocumentKey\n  ): PersistencePromise<void> {\n    this.orphanedDocuments.add(key);\n    return PersistencePromise.resolve();\n  }\n\n  removeTarget(\n    txn: PersistenceTransaction,\n    targetData: TargetData\n  ): PersistencePromise<void> {\n    const cache = this.persistence.getTargetCache();\n    return cache\n      .getMatchingKeysForTargetId(txn, targetData.targetId)\n      .next(keys => {\n        keys.forEach(key => this.orphanedDocuments.add(key));\n      })\n      .next(() => cache.removeTargetData(txn, targetData));\n  }\n\n  onTransactionStarted(): void {\n    this._orphanedDocuments = new Set<DocumentKey>();\n  }\n\n  onTransactionCommitted(\n    txn: PersistenceTransaction\n  ): PersistencePromise<void> {\n    // Remove newly orphaned documents.\n    const cache = this.persistence.getRemoteDocumentCache();\n    const changeBuffer = cache.newChangeBuffer();\n    return PersistencePromise.forEach(\n      this.orphanedDocuments,\n      (key: DocumentKey) => {\n        return this.isReferenced(txn, key).next(isReferenced => {\n          if (!isReferenced) {\n            changeBuffer.removeEntry(key);\n          }\n        });\n      }\n    ).next(() => {\n      this._orphanedDocuments = null;\n      return changeBuffer.apply(txn);\n    });\n  }\n\n  updateLimboDocument(\n    txn: PersistenceTransaction,\n    key: DocumentKey\n  ): PersistencePromise<void> {\n    return this.isReferenced(txn, key).next(isReferenced => {\n      if (isReferenced) {\n        this.orphanedDocuments.delete(key);\n      } else {\n        this.orphanedDocuments.add(key);\n      }\n    });\n  }\n\n  documentSize(doc: MaybeDocument): number {\n    // For eager GC, we don't care about the document size, there are no size thresholds.\n    return 0;\n  }\n\n  private isReferenced(\n    txn: PersistenceTransaction,\n    key: DocumentKey\n  ): PersistencePromise<boolean> {\n    return PersistencePromise.or([\n      () => this.persistence.getTargetCache().containsKey(txn, key),\n      () => this.persistence.mutationQueuesContainKey(txn, key),\n      () => PersistencePromise.resolve(this.inMemoryPins!.containsKey(key))\n    ]);\n  }\n}\n\nexport class MemoryLruDelegate implements ReferenceDelegate, LruDelegate {\n  private inMemoryPins: ReferenceSet | null = null;\n  private orphanedSequenceNumbers: ObjectMap<\n    DocumentKey,\n    ListenSequenceNumber\n  > = new ObjectMap(k => encodeResourcePath(k.path));\n\n  readonly garbageCollector: LruGarbageCollector;\n\n  constructor(\n    private readonly persistence: MemoryPersistence,\n    lruParams: LruParams\n  ) {\n    this.garbageCollector = new LruGarbageCollector(this, lruParams);\n  }\n\n  // No-ops, present so memory persistence doesn't have to care which delegate\n  // it has.\n  onTransactionStarted(): void {}\n\n  onTransactionCommitted(\n    txn: PersistenceTransaction\n  ): PersistencePromise<void> {\n    return PersistencePromise.resolve();\n  }\n\n  forEachTarget(\n    txn: PersistenceTransaction,\n    f: (q: TargetData) => void\n  ): PersistencePromise<void> {\n    return this.persistence.getTargetCache().forEachTarget(txn, f);\n  }\n\n  getSequenceNumberCount(\n    txn: PersistenceTransaction\n  ): PersistencePromise<number> {\n    const docCountPromise = this.orphanedDocumentCount(txn);\n    const targetCountPromise = this.persistence\n      .getTargetCache()\n      .getTargetCount(txn);\n    return targetCountPromise.next(targetCount =>\n      docCountPromise.next(docCount => targetCount + docCount)\n    );\n  }\n\n  private orphanedDocumentCount(\n    txn: PersistenceTransaction\n  ): PersistencePromise<number> {\n    let orphanedCount = 0;\n    return this.forEachOrphanedDocumentSequenceNumber(txn, _ => {\n      orphanedCount++;\n    }).next(() => orphanedCount);\n  }\n\n  forEachOrphanedDocumentSequenceNumber(\n    txn: PersistenceTransaction,\n    f: (sequenceNumber: ListenSequenceNumber) => void\n  ): PersistencePromise<void> {\n    return PersistencePromise.forEach(\n      this.orphanedSequenceNumbers,\n      (key, sequenceNumber) => {\n        // Pass in the exact sequence number as the upper bound so we know it won't be pinned by\n        // being too recent.\n        return this.isPinned(txn, key, sequenceNumber).next(isPinned => {\n          if (!isPinned) {\n            return f(sequenceNumber);\n          } else {\n            return PersistencePromise.resolve();\n          }\n        });\n      }\n    );\n  }\n\n  setInMemoryPins(inMemoryPins: ReferenceSet): void {\n    this.inMemoryPins = inMemoryPins;\n  }\n\n  removeTargets(\n    txn: PersistenceTransaction,\n    upperBound: ListenSequenceNumber,\n    activeTargetIds: ActiveTargets\n  ): PersistencePromise<number> {\n    return this.persistence\n      .getTargetCache()\n      .removeTargets(txn, upperBound, activeTargetIds);\n  }\n\n  removeOrphanedDocuments(\n    txn: PersistenceTransaction,\n    upperBound: ListenSequenceNumber\n  ): PersistencePromise<number> {\n    let count = 0;\n    const cache = this.persistence.getRemoteDocumentCache();\n    const changeBuffer = cache.newChangeBuffer();\n    const p = cache.forEachDocumentKey(txn, key => {\n      return this.isPinned(txn, key, upperBound).next(isPinned => {\n        if (!isPinned) {\n          count++;\n          changeBuffer.removeEntry(key);\n        }\n      });\n    });\n    return p.next(() => changeBuffer.apply(txn)).next(() => count);\n  }\n\n  removeMutationReference(\n    txn: PersistenceTransaction,\n    key: DocumentKey\n  ): PersistencePromise<void> {\n    this.orphanedSequenceNumbers.set(key, txn.currentSequenceNumber);\n    return PersistencePromise.resolve();\n  }\n\n  removeTarget(\n    txn: PersistenceTransaction,\n    targetData: TargetData\n  ): PersistencePromise<void> {\n    const updated = targetData.withSequenceNumber(txn.currentSequenceNumber);\n    return this.persistence.getTargetCache().updateTargetData(txn, updated);\n  }\n\n  addReference(\n    txn: PersistenceTransaction,\n    key: DocumentKey\n  ): PersistencePromise<void> {\n    this.orphanedSequenceNumbers.set(key, txn.currentSequenceNumber);\n    return PersistencePromise.resolve();\n  }\n\n  removeReference(\n    txn: PersistenceTransaction,\n    key: DocumentKey\n  ): PersistencePromise<void> {\n    this.orphanedSequenceNumbers.set(key, txn.currentSequenceNumber);\n    return PersistencePromise.resolve();\n  }\n\n  updateLimboDocument(\n    txn: PersistenceTransaction,\n    key: DocumentKey\n  ): PersistencePromise<void> {\n    this.orphanedSequenceNumbers.set(key, txn.currentSequenceNumber);\n    return PersistencePromise.resolve();\n  }\n\n  documentSize(maybeDoc: MaybeDocument): number {\n    let documentSize = maybeDoc.key.toString().length;\n    if (maybeDoc instanceof Document) {\n      documentSize += estimateByteSize(maybeDoc.toProto());\n    }\n    return documentSize;\n  }\n\n  private isPinned(\n    txn: PersistenceTransaction,\n    key: DocumentKey,\n    upperBound: ListenSequenceNumber\n  ): PersistencePromise<boolean> {\n    return PersistencePromise.or([\n      () => this.persistence.mutationQueuesContainKey(txn, key),\n      () => PersistencePromise.resolve(this.inMemoryPins!.containsKey(key)),\n      () => this.persistence.getTargetCache().containsKey(txn, key),\n      () => {\n        const orphanedAt = this.orphanedSequenceNumbers.get(key);\n        return PersistencePromise.resolve(\n          orphanedAt !== undefined && orphanedAt > upperBound\n        );\n      }\n    ]);\n  }\n\n  getCacheSize(txn: PersistenceTransaction): PersistencePromise<number> {\n    return this.persistence.getRemoteDocumentCache().getSize(txn);\n  }\n}\n","/**\n * @license\n * Copyright 2020 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  ClientId,\n  MemorySharedClientState,\n  SharedClientState,\n  WebStorageSharedClientState\n} from '../local/shared_client_state';\nimport { LocalStore } from '../local/local_store';\nimport { SyncEngine } from './sync_engine';\nimport { RemoteStore } from '../remote/remote_store';\nimport { EventManager } from './event_manager';\nimport { AsyncQueue } from '../util/async_queue';\nimport { DatabaseInfo } from './database_info';\nimport { Platform } from '../platform/platform';\nimport { Datastore } from '../remote/datastore';\nimport { User } from '../auth/user';\nimport { PersistenceSettings } from './firestore_client';\nimport { debugAssert } from '../util/assert';\nimport { GarbageCollectionScheduler, Persistence } from '../local/persistence';\nimport { Code, FirestoreError } from '../util/error';\nimport { OnlineStateSource } from './types';\nimport { LruParams, LruScheduler } from '../local/lru_garbage_collector';\nimport { IndexFreeQueryEngine } from '../local/index_free_query_engine';\nimport { IndexedDbPersistence } from '../local/indexeddb_persistence';\nimport {\n  MemoryEagerDelegate,\n  MemoryPersistence,\n  MemoryReferenceDelegate\n} from '../local/memory_persistence';\n\n/**\n * Initializes and wires up all core components for Firestore. Implementations\n * override `initialize()` to provide all components.\n */\nexport interface ComponentProvider {\n  persistence: Persistence;\n  sharedClientState: SharedClientState;\n  localStore: LocalStore;\n  syncEngine: SyncEngine;\n  gcScheduler: GarbageCollectionScheduler | null;\n  remoteStore: RemoteStore;\n  eventManager: EventManager;\n\n  initialize(\n    asyncQueue: AsyncQueue,\n    databaseInfo: DatabaseInfo,\n    platform: Platform,\n    datastore: Datastore,\n    clientId: ClientId,\n    initialUser: User,\n    maxConcurrentLimboResolutions: number,\n    persistenceSettings: PersistenceSettings\n  ): Promise<void>;\n\n  clearPersistence(databaseId: DatabaseInfo): Promise<void>;\n}\n\n/**\n * Provides all components needed for Firestore with IndexedDB persistence.\n */\nexport class IndexedDbComponentProvider implements ComponentProvider {\n  persistence!: IndexedDbPersistence;\n  sharedClientState!: SharedClientState;\n  localStore!: LocalStore;\n  syncEngine!: SyncEngine;\n  gcScheduler!: GarbageCollectionScheduler | null;\n  remoteStore!: RemoteStore;\n  eventManager!: EventManager;\n\n  async initialize(\n    asyncQueue: AsyncQueue,\n    databaseInfo: DatabaseInfo,\n    platform: Platform,\n    datastore: Datastore,\n    clientId: ClientId,\n    initialUser: User,\n    maxConcurrentLimboResolutions: number,\n    persistenceSettings: PersistenceSettings\n  ): Promise<void> {\n    debugAssert(\n      persistenceSettings.durable,\n      'IndexedDbComponentProvider can only provide durable persistence'\n    );\n    debugAssert(!this.sharedClientState, 'initialize() already called');\n\n    const persistenceKey = IndexedDbPersistence.buildStoragePrefix(\n      databaseInfo\n    );\n\n    const serializer = platform.newSerializer(databaseInfo.databaseId);\n    if (!WebStorageSharedClientState.isAvailable(platform)) {\n      throw new FirestoreError(\n        Code.UNIMPLEMENTED,\n        'IndexedDB persistence is only available on platforms that support LocalStorage.'\n      );\n    }\n\n    this.sharedClientState = persistenceSettings.synchronizeTabs\n      ? new WebStorageSharedClientState(\n          asyncQueue,\n          platform,\n          persistenceKey,\n          clientId,\n          initialUser\n        )\n      : new MemorySharedClientState();\n    this.sharedClientState.onlineStateHandler = onlineState =>\n      this.syncEngine.applyOnlineStateChange(\n        onlineState,\n        OnlineStateSource.SharedClientState\n      );\n\n    this.persistence = await IndexedDbPersistence.createIndexedDbPersistence({\n      allowTabSynchronization: persistenceSettings.synchronizeTabs,\n      persistenceKey,\n      clientId,\n      platform,\n      queue: asyncQueue,\n      serializer,\n      lruParams: LruParams.withCacheSize(persistenceSettings.cacheSizeBytes),\n      sequenceNumberSyncer: this.sharedClientState\n    });\n\n    const garbageCollector = this.persistence.referenceDelegate\n      .garbageCollector;\n\n    this.gcScheduler = new LruScheduler(garbageCollector, asyncQueue);\n    this.localStore = new LocalStore(\n      this.persistence,\n      new IndexFreeQueryEngine(),\n      initialUser\n    );\n    this.remoteStore = new RemoteStore(\n      this.localStore,\n      datastore,\n      asyncQueue,\n      onlineState =>\n        this.syncEngine.applyOnlineStateChange(\n          onlineState,\n          OnlineStateSource.RemoteStore\n        ),\n      platform.newConnectivityMonitor()\n    );\n    this.syncEngine = new SyncEngine(\n      this.localStore,\n      this.remoteStore,\n      this.sharedClientState,\n      initialUser,\n      maxConcurrentLimboResolutions\n    );\n    this.eventManager = new EventManager(this.syncEngine);\n\n    this.remoteStore.syncEngine = this.syncEngine;\n    this.sharedClientState.syncEngine = this.syncEngine;\n\n    await this.sharedClientState.start();\n    await this.remoteStore.start();\n    await this.localStore.start();\n\n    // NOTE: This will immediately call the listener, so we make sure to\n    // set it after localStore / remoteStore are started.\n    await this.persistence.setPrimaryStateListener(async isPrimary => {\n      await this.syncEngine.applyPrimaryState(isPrimary);\n      if (isPrimary && !this.gcScheduler!.started) {\n        this.gcScheduler!.start(this.localStore);\n      } else if (!isPrimary) {\n        this.gcScheduler!.stop();\n      }\n    });\n  }\n\n  clearPersistence(databaseInfo: DatabaseInfo): Promise<void> {\n    const persistenceKey = IndexedDbPersistence.buildStoragePrefix(\n      databaseInfo\n    );\n    return IndexedDbPersistence.clearPersistence(persistenceKey);\n  }\n}\n\nconst MEMORY_ONLY_PERSISTENCE_ERROR_MESSAGE =\n  'You are using the memory-only build of Firestore. Persistence support is ' +\n  'only available via the @firebase/firestore bundle or the ' +\n  'firebase-firestore.js build.';\n\n/**\n * Provides all components needed for Firestore with in-memory persistence.\n */\nexport class MemoryComponentProvider implements ComponentProvider {\n  persistence!: Persistence;\n  sharedClientState!: SharedClientState;\n  localStore!: LocalStore;\n  syncEngine!: SyncEngine;\n  gcScheduler!: GarbageCollectionScheduler | null;\n  remoteStore!: RemoteStore;\n  eventManager!: EventManager;\n\n  constructor(\n    readonly referenceDelegateFactory: (\n      p: MemoryPersistence\n    ) => MemoryReferenceDelegate = MemoryEagerDelegate.factory\n  ) {}\n\n  async initialize(\n    asyncQueue: AsyncQueue,\n    databaseInfo: DatabaseInfo,\n    platform: Platform,\n    datastore: Datastore,\n    clientId: ClientId,\n    initialUser: User,\n    maxConcurrentLimboResolutions: number,\n    persistenceSettings: PersistenceSettings\n  ): Promise<void> {\n    if (persistenceSettings.durable) {\n      throw new FirestoreError(\n        Code.FAILED_PRECONDITION,\n        MEMORY_ONLY_PERSISTENCE_ERROR_MESSAGE\n      );\n    }\n\n    this.persistence = new MemoryPersistence(\n      clientId,\n      this.referenceDelegateFactory\n    );\n    this.gcScheduler = null;\n    this.sharedClientState = new MemorySharedClientState();\n    this.localStore = new LocalStore(\n      this.persistence,\n      new IndexFreeQueryEngine(),\n      initialUser\n    );\n    this.remoteStore = new RemoteStore(\n      this.localStore,\n      datastore,\n      asyncQueue,\n      onlineState =>\n        this.syncEngine.applyOnlineStateChange(\n          onlineState,\n          OnlineStateSource.RemoteStore\n        ),\n      platform.newConnectivityMonitor()\n    );\n    this.syncEngine = new SyncEngine(\n      this.localStore,\n      this.remoteStore,\n      this.sharedClientState,\n      initialUser,\n      maxConcurrentLimboResolutions\n    );\n    this.eventManager = new EventManager(this.syncEngine);\n\n    this.remoteStore.syncEngine = this.syncEngine;\n\n    await this.remoteStore.start();\n    await this.remoteStore.applyPrimaryState(true);\n    await this.syncEngine.applyPrimaryState(true);\n  }\n\n  clearPersistence(): never {\n    throw new FirestoreError(\n      Code.FAILED_PRECONDITION,\n      MEMORY_ONLY_PERSISTENCE_ERROR_MESSAGE\n    );\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { CredentialsProvider } from '../api/credentials';\nimport { User } from '../auth/user';\nimport { LocalStore } from '../local/local_store';\nimport { GarbageCollectionScheduler, Persistence } from '../local/persistence';\nimport { Document, MaybeDocument, NoDocument } from '../model/document';\nimport { DocumentKey } from '../model/document_key';\nimport { Mutation } from '../model/mutation';\nimport { Platform } from '../platform/platform';\nimport { Datastore } from '../remote/datastore';\nimport { RemoteStore } from '../remote/remote_store';\nimport { AsyncQueue } from '../util/async_queue';\nimport { Code, FirestoreError } from '../util/error';\nimport { logDebug } from '../util/log';\nimport { Deferred } from '../util/promise';\nimport {\n  EventManager,\n  ListenOptions,\n  Observer,\n  QueryListener\n} from './event_manager';\nimport { SyncEngine } from './sync_engine';\nimport { View } from './view';\n\nimport { SharedClientState } from '../local/shared_client_state';\nimport { AutoId } from '../util/misc';\nimport { DatabaseId, DatabaseInfo } from './database_info';\nimport { Query } from './query';\nimport { Transaction } from './transaction';\nimport { ViewSnapshot } from './view_snapshot';\nimport {\n  ComponentProvider,\n  MemoryComponentProvider\n} from './component_provider';\n\nconst LOG_TAG = 'FirestoreClient';\nconst MAX_CONCURRENT_LIMBO_RESOLUTIONS = 100;\n\n/** DOMException error code constants. */\nconst DOM_EXCEPTION_INVALID_STATE = 11;\nconst DOM_EXCEPTION_ABORTED = 20;\nconst DOM_EXCEPTION_QUOTA_EXCEEDED = 22;\n\nexport type PersistenceSettings =\n  | {\n      readonly durable: false;\n    }\n  | {\n      readonly durable: true;\n      readonly cacheSizeBytes: number;\n      readonly synchronizeTabs: boolean;\n    };\n\n/**\n * FirestoreClient is a top-level class that constructs and owns all of the\n * pieces of the client SDK architecture. It is responsible for creating the\n * async queue that is shared by all of the other components in the system.\n */\nexport class FirestoreClient {\n  // NOTE: These should technically have '|undefined' in the types, since\n  // they're initialized asynchronously rather than in the constructor, but\n  // given that all work is done on the async queue and we assert that\n  // initialization completes before any other work is queued, we're cheating\n  // with the types rather than littering the code with '!' or unnecessary\n  // undefined checks.\n  private eventMgr!: EventManager;\n  private persistence!: Persistence;\n  private localStore!: LocalStore;\n  private remoteStore!: RemoteStore;\n  private syncEngine!: SyncEngine;\n  private gcScheduler!: GarbageCollectionScheduler | null;\n\n  // PORTING NOTE: SharedClientState is only used for multi-tab web.\n  private sharedClientState!: SharedClientState;\n\n  private readonly clientId = AutoId.newId();\n\n  constructor(\n    private platform: Platform,\n    private databaseInfo: DatabaseInfo,\n    private credentials: CredentialsProvider,\n    /**\n     * Asynchronous queue responsible for all of our internal processing. When\n     * we get incoming work from the user (via public API) or the network\n     * (incoming GRPC messages), we should always schedule onto this queue.\n     * This ensures all of our work is properly serialized (e.g. we don't\n     * start processing a new operation while the previous one is waiting for\n     * an async I/O to complete).\n     */\n    private asyncQueue: AsyncQueue\n  ) {}\n\n  /**\n   * Starts up the FirestoreClient, returning only whether or not enabling\n   * persistence succeeded.\n   *\n   * The intent here is to \"do the right thing\" as far as users are concerned.\n   * Namely, in cases where offline persistence is requested and possible,\n   * enable it, but otherwise fall back to persistence disabled. For the most\n   * part we expect this to succeed one way or the other so we don't expect our\n   * users to actually wait on the firestore.enablePersistence Promise since\n   * they generally won't care.\n   *\n   * Of course some users actually do care about whether or not persistence\n   * was successfully enabled, so the Promise returned from this method\n   * indicates this outcome.\n   *\n   * This presents a problem though: even before enablePersistence resolves or\n   * rejects, users may have made calls to e.g. firestore.collection() which\n   * means that the FirestoreClient in there will be available and will be\n   * enqueuing actions on the async queue.\n   *\n   * Meanwhile any failure of an operation on the async queue causes it to\n   * panic and reject any further work, on the premise that unhandled errors\n   * are fatal.\n   *\n   * Consequently the fallback is handled internally here in start, and if the\n   * fallback succeeds we signal success to the async queue even though the\n   * start() itself signals failure.\n   *\n   * @param componentProvider Provider that returns all core components.\n   * @param persistenceSettings Settings object to configure offline\n   *     persistence.\n   * @returns A deferred result indicating the user-visible result of enabling\n   *     offline persistence. This method will reject this if IndexedDB fails to\n   *     start for any reason. If usePersistence is false this is\n   *     unconditionally resolved.\n   */\n  start(\n    componentProvider: ComponentProvider,\n    persistenceSettings: PersistenceSettings\n  ): Promise<void> {\n    this.verifyNotTerminated();\n    // We defer our initialization until we get the current user from\n    // setChangeListener(). We block the async queue until we got the initial\n    // user and the initialization is completed. This will prevent any scheduled\n    // work from happening before initialization is completed.\n    //\n    // If initializationDone resolved then the FirestoreClient is in a usable\n    // state.\n    const initializationDone = new Deferred<void>();\n\n    // If usePersistence is true, certain classes of errors while starting are\n    // recoverable but only by falling back to persistence disabled.\n    //\n    // If there's an error in the first case but not in recovery we cannot\n    // reject the promise blocking the async queue because this will cause the\n    // async queue to panic.\n    const persistenceResult = new Deferred<void>();\n\n    let initialized = false;\n    this.credentials.setChangeListener(user => {\n      if (!initialized) {\n        initialized = true;\n\n        logDebug(LOG_TAG, 'Initializing. user=', user.uid);\n\n        return this.initializeComponents(\n          componentProvider,\n          persistenceSettings,\n          user,\n          persistenceResult\n        ).then(initializationDone.resolve, initializationDone.reject);\n      } else {\n        this.asyncQueue.enqueueAndForget(() => {\n          return this.handleCredentialChange(user);\n        });\n      }\n    });\n\n    // Block the async queue until initialization is done\n    this.asyncQueue.enqueueAndForget(() => {\n      return initializationDone.promise;\n    });\n\n    // Return only the result of enabling persistence. Note that this does not\n    // need to await the completion of initializationDone because the result of\n    // this method should not reflect any other kind of failure to start.\n    return persistenceResult.promise;\n  }\n\n  /** Enables the network connection and requeues all pending operations. */\n  enableNetwork(): Promise<void> {\n    this.verifyNotTerminated();\n    return this.asyncQueue.enqueue(() => {\n      return this.syncEngine.enableNetwork();\n    });\n  }\n\n  /**\n   * Initializes persistent storage, attempting to use IndexedDB if\n   * usePersistence is true or memory-only if false.\n   *\n   * If IndexedDB fails because it's already open in another tab or because the\n   * platform can't possibly support our implementation then this method rejects\n   * the persistenceResult and falls back on memory-only persistence.\n   *\n   * @param componentProvider The provider that provides all core componennts\n   *     for IndexedDB or memory-backed persistence\n   * @param persistenceSettings Settings object to configure offline persistence\n   * @param user The initial user\n   * @param persistenceResult A deferred result indicating the user-visible\n   *     result of enabling offline persistence. This method will reject this if\n   *     IndexedDB fails to start for any reason. If usePersistence is false\n   *     this is unconditionally resolved.\n   * @returns a Promise indicating whether or not initialization should\n   *     continue, i.e. that one of the persistence implementations actually\n   *     succeeded.\n   */\n  private async initializeComponents(\n    componentProvider: ComponentProvider,\n    persistenceSettings: PersistenceSettings,\n    user: User,\n    persistenceResult: Deferred<void>\n  ): Promise<void> {\n    try {\n      // TODO(mrschmidt): Ideally, ComponentProvider would also initialize\n      // Datastore (without duplicating the initializing logic once per\n      // provider).\n\n      const connection = await this.platform.loadConnection(this.databaseInfo);\n      const serializer = this.platform.newSerializer(\n        this.databaseInfo.databaseId\n      );\n      const datastore = new Datastore(\n        this.asyncQueue,\n        connection,\n        this.credentials,\n        serializer\n      );\n\n      await componentProvider.initialize(\n        this.asyncQueue,\n        this.databaseInfo,\n        this.platform,\n        datastore,\n        this.clientId,\n        user,\n        MAX_CONCURRENT_LIMBO_RESOLUTIONS,\n        persistenceSettings\n      );\n\n      this.persistence = componentProvider.persistence;\n      this.sharedClientState = componentProvider.sharedClientState;\n      this.localStore = componentProvider.localStore;\n      this.remoteStore = componentProvider.remoteStore;\n      this.syncEngine = componentProvider.syncEngine;\n      this.gcScheduler = componentProvider.gcScheduler;\n      this.eventMgr = componentProvider.eventManager;\n\n      // When a user calls clearPersistence() in one client, all other clients\n      // need to be terminated to allow the delete to succeed.\n      this.persistence.setDatabaseDeletedListener(async () => {\n        await this.terminate();\n      });\n\n      persistenceResult.resolve();\n    } catch (error) {\n      // Regardless of whether or not the retry succeeds, from an user\n      // perspective, offline persistence has failed.\n      persistenceResult.reject(error);\n\n      // An unknown failure on the first stage shuts everything down.\n      if (!this.canFallback(error)) {\n        throw error;\n      }\n      console.warn(\n        'Error enabling offline persistence. Falling back to' +\n          ' persistence disabled: ' +\n          error\n      );\n      return this.initializeComponents(\n        new MemoryComponentProvider(),\n        { durable: false },\n        user,\n        persistenceResult\n      );\n    }\n  }\n\n  /**\n   * Decides whether the provided error allows us to gracefully disable\n   * persistence (as opposed to crashing the client).\n   */\n  private canFallback(error: FirestoreError | DOMException): boolean {\n    if (error.name === 'FirebaseError') {\n      return (\n        error.code === Code.FAILED_PRECONDITION ||\n        error.code === Code.UNIMPLEMENTED\n      );\n    } else if (\n      typeof DOMException !== 'undefined' &&\n      error instanceof DOMException\n    ) {\n      // There are a few known circumstances where we can open IndexedDb but\n      // trying to read/write will fail (e.g. quota exceeded). For\n      // well-understood cases, we attempt to detect these and then gracefully\n      // fall back to memory persistence.\n      // NOTE: Rather than continue to add to this list, we could decide to\n      // always fall back, with the risk that we might accidentally hide errors\n      // representing actual SDK bugs.\n      return (\n        // When the browser is out of quota we could get either quota exceeded\n        // or an aborted error depending on whether the error happened during\n        // schema migration.\n        error.code === DOM_EXCEPTION_QUOTA_EXCEEDED ||\n        error.code === DOM_EXCEPTION_ABORTED ||\n        // Firefox Private Browsing mode disables IndexedDb and returns\n        // INVALID_STATE for any usage.\n        error.code === DOM_EXCEPTION_INVALID_STATE\n      );\n    }\n\n    return true;\n  }\n\n  /**\n   * Checks that the client has not been terminated. Ensures that other methods on\n   * this class cannot be called after the client is terminated.\n   */\n  private verifyNotTerminated(): void {\n    if (this.asyncQueue.isShuttingDown) {\n      throw new FirestoreError(\n        Code.FAILED_PRECONDITION,\n        'The client has already been terminated.'\n      );\n    }\n  }\n\n  private handleCredentialChange(user: User): Promise<void> {\n    this.asyncQueue.verifyOperationInProgress();\n\n    logDebug(LOG_TAG, 'Credential Changed. Current user: ' + user.uid);\n    return this.syncEngine.handleCredentialChange(user);\n  }\n\n  /** Disables the network connection. Pending operations will not complete. */\n  disableNetwork(): Promise<void> {\n    this.verifyNotTerminated();\n    return this.asyncQueue.enqueue(() => {\n      return this.syncEngine.disableNetwork();\n    });\n  }\n\n  terminate(): Promise<void> {\n    return this.asyncQueue.enqueueAndInitiateShutdown(async () => {\n      // PORTING NOTE: LocalStore does not need an explicit shutdown on web.\n      if (this.gcScheduler) {\n        this.gcScheduler.stop();\n      }\n\n      await this.remoteStore.shutdown();\n      await this.sharedClientState.shutdown();\n      await this.persistence.shutdown();\n\n      // `removeChangeListener` must be called after shutting down the\n      // RemoteStore as it will prevent the RemoteStore from retrieving\n      // auth tokens.\n      this.credentials.removeChangeListener();\n    });\n  }\n\n  /**\n   * Returns a Promise that resolves when all writes that were pending at the time this\n   * method was called received server acknowledgement. An acknowledgement can be either acceptance\n   * or rejection.\n   */\n  waitForPendingWrites(): Promise<void> {\n    this.verifyNotTerminated();\n\n    const deferred = new Deferred<void>();\n    this.asyncQueue.enqueueAndForget(() => {\n      return this.syncEngine.registerPendingWritesCallback(deferred);\n    });\n    return deferred.promise;\n  }\n\n  listen(\n    query: Query,\n    observer: Observer<ViewSnapshot>,\n    options: ListenOptions\n  ): QueryListener {\n    this.verifyNotTerminated();\n    const listener = new QueryListener(query, observer, options);\n    this.asyncQueue.enqueueAndForget(() => {\n      return this.eventMgr.listen(listener);\n    });\n    return listener;\n  }\n\n  unlisten(listener: QueryListener): void {\n    // Checks for termination but does not raise error, allowing unlisten after\n    // termination to be a no-op.\n    if (this.clientTerminated) {\n      return;\n    }\n    this.asyncQueue.enqueueAndForget(() => {\n      return this.eventMgr.unlisten(listener);\n    });\n  }\n\n  getDocumentFromLocalCache(docKey: DocumentKey): Promise<Document | null> {\n    this.verifyNotTerminated();\n    return this.asyncQueue\n      .enqueue(() => {\n        return this.localStore.readDocument(docKey);\n      })\n      .then((maybeDoc: MaybeDocument | null) => {\n        if (maybeDoc instanceof Document) {\n          return maybeDoc;\n        } else if (maybeDoc instanceof NoDocument) {\n          return null;\n        } else {\n          throw new FirestoreError(\n            Code.UNAVAILABLE,\n            'Failed to get document from cache. (However, this document may ' +\n              \"exist on the server. Run again without setting 'source' in \" +\n              'the GetOptions to attempt to retrieve the document from the ' +\n              'server.)'\n          );\n        }\n      });\n  }\n\n  getDocumentsFromLocalCache(query: Query): Promise<ViewSnapshot> {\n    this.verifyNotTerminated();\n    return this.asyncQueue.enqueue(async () => {\n      const queryResult = await this.localStore.executeQuery(\n        query,\n        /* usePreviousResults= */ true\n      );\n      const view = new View(query, queryResult.remoteKeys);\n      const viewDocChanges = view.computeDocChanges(queryResult.documents);\n      return view.applyChanges(\n        viewDocChanges,\n        /* updateLimboDocuments= */ false\n      ).snapshot!;\n    });\n  }\n\n  write(mutations: Mutation[]): Promise<void> {\n    this.verifyNotTerminated();\n    const deferred = new Deferred<void>();\n    this.asyncQueue.enqueueAndForget(() =>\n      this.syncEngine.write(mutations, deferred)\n    );\n    return deferred.promise;\n  }\n\n  databaseId(): DatabaseId {\n    return this.databaseInfo.databaseId;\n  }\n\n  addSnapshotsInSyncListener(observer: Observer<void>): void {\n    this.verifyNotTerminated();\n    this.asyncQueue.enqueueAndForget(() => {\n      this.eventMgr.addSnapshotsInSyncListener(observer);\n      return Promise.resolve();\n    });\n  }\n\n  removeSnapshotsInSyncListener(observer: Observer<void>): void {\n    // Checks for shutdown but does not raise error, allowing remove after\n    // shutdown to be a no-op.\n    if (this.clientTerminated) {\n      return;\n    }\n    this.eventMgr.removeSnapshotsInSyncListener(observer);\n  }\n\n  get clientTerminated(): boolean {\n    // Technically, the asyncQueue is still running, but only accepting operations\n    // related to termination or supposed to be run after termination. It is effectively\n    // terminated to the eyes of users.\n    return this.asyncQueue.isShuttingDown;\n  }\n\n  transaction<T>(\n    updateFunction: (transaction: Transaction) => Promise<T>\n  ): Promise<T> {\n    this.verifyNotTerminated();\n    const deferred = new Deferred<T>();\n    this.asyncQueue.enqueueAndForget(() => {\n      this.syncEngine.runTransaction(this.asyncQueue, updateFunction, deferred);\n      return Promise.resolve();\n    });\n    return deferred.promise;\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { Observer } from '../core/event_manager';\nimport { EventHandler } from './misc';\n\n/*\n * A wrapper implementation of Observer<T> that will dispatch events\n * asynchronously. To allow immediate silencing, a mute call is added which\n * causes events scheduled to no longer be raised.\n */\nexport class AsyncObserver<T> implements Observer<T> {\n  /**\n   * When set to true, will not raise future events. Necessary to deal with\n   * async detachment of listener.\n   */\n  private muted = false;\n\n  constructor(private observer: Observer<T>) {}\n\n  next(value: T): void {\n    this.scheduleEvent(this.observer.next, value);\n  }\n\n  error(error: Error): void {\n    this.scheduleEvent(this.observer.error, error);\n  }\n\n  mute(): void {\n    this.muted = true;\n  }\n\n  private scheduleEvent<E>(eventHandler: EventHandler<E>, event: E): void {\n    if (!this.muted) {\n      setTimeout(() => {\n        if (!this.muted) {\n          eventHandler(event);\n        }\n      }, 0);\n    }\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { JsonObject } from '../model/field_value';\n\n/**\n * Observer/Subscribe interfaces.\n */\nexport type NextFn<T> = (value: T) => void;\nexport type ErrorFn = (error: Error) => void;\nexport type CompleteFn = () => void;\n\n// Allow for any of the Observer methods to be undefined.\nexport interface PartialObserver<T> {\n  next?: NextFn<T>;\n  error?: ErrorFn;\n  complete?: CompleteFn;\n}\n\nexport interface Unsubscribe {\n  (): void;\n}\n\nexport function isPartialObserver(obj: unknown): boolean {\n  return implementsAnyMethods(obj, ['next', 'error', 'complete']);\n}\n\n/**\n * Returns true if obj is an object and contains at least one of the specified\n * methods.\n */\nfunction implementsAnyMethods(obj: unknown, methods: string[]): boolean {\n  if (typeof obj !== 'object' || obj === null) {\n    return false;\n  }\n\n  const object = obj as JsonObject<unknown>;\n  for (const method of methods) {\n    if (method in object && typeof object[method] === 'function') {\n      return true;\n    }\n  }\n  return false;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport * as firestore from '@firebase/firestore-types';\n\nimport * as api from '../protos/firestore_proto_api';\n\nimport { DocumentReference, Firestore } from './database';\nimport { Blob } from './blob';\nimport { GeoPoint } from './geo_point';\nimport { Timestamp } from './timestamp';\nimport { DatabaseId } from '../core/database_info';\nimport { DocumentKey } from '../model/document_key';\nimport {\n  normalizeByteString,\n  normalizeNumber,\n  normalizeTimestamp,\n  typeOrder\n} from '../model/values';\nimport {\n  getLocalWriteTime,\n  getPreviousValue\n} from '../model/server_timestamps';\nimport { fail, hardAssert } from '../util/assert';\nimport { forEach } from '../util/obj';\nimport { TypeOrder } from '../model/field_value';\nimport { ResourcePath } from '../model/path';\nimport { isValidResourceName } from '../remote/serializer';\nimport { logError } from '../util/log';\n\nexport type ServerTimestampBehavior = 'estimate' | 'previous' | 'none';\n\n/**\n * Converts Firestore's internal types to the JavaScript types that we expose\n * to the user.\n */\nexport class UserDataWriter<T = firestore.DocumentData> {\n  constructor(\n    private readonly firestore: Firestore,\n    private readonly timestampsInSnapshots: boolean,\n    private readonly serverTimestampBehavior?: ServerTimestampBehavior,\n    private readonly converter?: firestore.FirestoreDataConverter<T>\n  ) {}\n\n  convertValue(value: api.Value): unknown {\n    switch (typeOrder(value)) {\n      case TypeOrder.NullValue:\n        return null;\n      case TypeOrder.BooleanValue:\n        return value.booleanValue!;\n      case TypeOrder.NumberValue:\n        return normalizeNumber(value.integerValue || value.doubleValue);\n      case TypeOrder.TimestampValue:\n        return this.convertTimestamp(value.timestampValue!);\n      case TypeOrder.ServerTimestampValue:\n        return this.convertServerTimestamp(value);\n      case TypeOrder.StringValue:\n        return value.stringValue!;\n      case TypeOrder.BlobValue:\n        return new Blob(normalizeByteString(value.bytesValue!));\n      case TypeOrder.RefValue:\n        return this.convertReference(value.referenceValue!);\n      case TypeOrder.GeoPointValue:\n        return new GeoPoint(\n          value.geoPointValue!.latitude!,\n          value.geoPointValue!.longitude!\n        );\n      case TypeOrder.ArrayValue:\n        return this.convertArray(value.arrayValue!);\n      case TypeOrder.ObjectValue:\n        return this.convertObject(value.mapValue!);\n      default:\n        throw fail('Invalid value type: ' + JSON.stringify(value));\n    }\n  }\n\n  private convertObject(mapValue: api.MapValue): firestore.DocumentData {\n    const result: firestore.DocumentData = {};\n    forEach(mapValue.fields || {}, (key, value) => {\n      result[key] = this.convertValue(value);\n    });\n    return result;\n  }\n\n  private convertArray(arrayValue: api.ArrayValue): unknown[] {\n    return (arrayValue.values || []).map(value => this.convertValue(value));\n  }\n\n  private convertServerTimestamp(value: api.Value): unknown {\n    switch (this.serverTimestampBehavior) {\n      case 'previous':\n        const previousValue = getPreviousValue(value);\n        if (previousValue == null) {\n          return null;\n        }\n        return this.convertValue(previousValue);\n      case 'estimate':\n        return this.convertTimestamp(getLocalWriteTime(value));\n      default:\n        return null;\n    }\n  }\n\n  private convertTimestamp(value: api.Timestamp): Timestamp | Date {\n    const normalizedValue = normalizeTimestamp(value);\n    const timestamp = new Timestamp(\n      normalizedValue.seconds,\n      normalizedValue.nanos\n    );\n    if (this.timestampsInSnapshots) {\n      return timestamp;\n    } else {\n      return timestamp.toDate();\n    }\n  }\n\n  private convertReference(name: string): DocumentReference<T> {\n    const resourcePath = ResourcePath.fromString(name);\n    hardAssert(\n      isValidResourceName(resourcePath),\n      'ReferenceValue is not valid ' + name\n    );\n    const databaseId = new DatabaseId(resourcePath.get(1), resourcePath.get(3));\n    const key = new DocumentKey(resourcePath.popFirst(5));\n\n    if (!databaseId.isEqual(this.firestore._databaseId)) {\n      // TODO(b/64130202): Somehow support foreign references.\n      logError(\n        `Document ${key} contains a document ` +\n          `reference within a different database (` +\n          `${databaseId.projectId}/${databaseId.database}) which is not ` +\n          `supported. It will be treated as a reference in the current ` +\n          `database (${this.firestore._databaseId.projectId}/${this.firestore._databaseId.database}) ` +\n          `instead.`\n      );\n    }\n\n    return new DocumentReference(key, this.firestore, this.converter);\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport * as firestore from '@firebase/firestore-types';\n\nimport * as api from '../protos/firestore_proto_api';\n\nimport { FirebaseApp } from '@firebase/app-types';\nimport { _FirebaseApp, FirebaseService } from '@firebase/app-types/private';\nimport { DatabaseId, DatabaseInfo } from '../core/database_info';\nimport { ListenOptions } from '../core/event_manager';\nimport {\n  ComponentProvider,\n  MemoryComponentProvider\n} from '../core/component_provider';\nimport { FirestoreClient, PersistenceSettings } from '../core/firestore_client';\nimport {\n  Bound,\n  Direction,\n  FieldFilter,\n  Filter,\n  Operator,\n  OrderBy,\n  Query as InternalQuery\n} from '../core/query';\nimport { Transaction as InternalTransaction } from '../core/transaction';\nimport { ChangeType, ViewSnapshot } from '../core/view_snapshot';\nimport { LruParams } from '../local/lru_garbage_collector';\nimport { Document, MaybeDocument, NoDocument } from '../model/document';\nimport { DocumentKey } from '../model/document_key';\nimport { DeleteMutation, Mutation, Precondition } from '../model/mutation';\nimport { FieldPath, ResourcePath } from '../model/path';\nimport { JsonProtoSerializer } from '../remote/serializer';\nimport { isServerTimestamp } from '../model/server_timestamps';\nimport { refValue } from '../model/values';\nimport { PlatformSupport } from '../platform/platform';\nimport { makeConstructorPrivate } from '../util/api';\nimport { debugAssert, fail } from '../util/assert';\nimport { AsyncObserver } from '../util/async_observer';\nimport { AsyncQueue } from '../util/async_queue';\nimport { Code, FirestoreError } from '../util/error';\nimport {\n  invalidClassError,\n  validateArgType,\n  validateAtLeastNumberOfArgs,\n  validateBetweenNumberOfArgs,\n  validateDefined,\n  validateExactNumberOfArgs,\n  validateNamedOptionalPropertyEquals,\n  validateNamedOptionalType,\n  validateNamedType,\n  validateOptionalArgType,\n  validateOptionalArrayElements,\n  validateOptionNames,\n  validatePositiveNumber,\n  validateStringEnum,\n  valueDescription\n} from '../util/input_validation';\nimport { logError, setLogLevel, LogLevel, getLogLevel } from '../util/log';\nimport { AutoId } from '../util/misc';\nimport { Deferred, Rejecter, Resolver } from '../util/promise';\nimport { FieldPath as ExternalFieldPath } from './field_path';\n\nimport {\n  CredentialsProvider,\n  CredentialsSettings,\n  EmptyCredentialsProvider,\n  FirebaseCredentialsProvider,\n  makeCredentialsProvider\n} from './credentials';\nimport {\n  CompleteFn,\n  ErrorFn,\n  isPartialObserver,\n  NextFn,\n  PartialObserver,\n  Unsubscribe\n} from './observer';\nimport {\n  DocumentKeyReference,\n  fieldPathFromArgument,\n  UserDataReader\n} from './user_data_reader';\nimport { UserDataWriter } from './user_data_writer';\nimport { FirebaseAuthInternalName } from '@firebase/auth-interop-types';\nimport { Provider } from '@firebase/component';\n\n// settings() defaults:\nconst DEFAULT_HOST = 'firestore.googleapis.com';\nconst DEFAULT_SSL = true;\nconst DEFAULT_TIMESTAMPS_IN_SNAPSHOTS = true;\nconst DEFAULT_FORCE_LONG_POLLING = false;\n\n/**\n * Constant used to indicate the LRU garbage collection should be disabled.\n * Set this value as the `cacheSizeBytes` on the settings passed to the\n * `Firestore` instance.\n */\nexport const CACHE_SIZE_UNLIMITED = LruParams.COLLECTION_DISABLED;\n\n// enablePersistence() defaults:\nconst DEFAULT_SYNCHRONIZE_TABS = false;\n\n/** Undocumented, private additional settings not exposed in our public API. */\ninterface PrivateSettings extends firestore.Settings {\n  // Can be a google-auth-library or gapi client.\n  credentials?: CredentialsSettings;\n}\n\n/**\n * Options that can be provided in the Firestore constructor when not using\n * Firebase (aka standalone mode).\n */\nexport interface FirestoreDatabase {\n  projectId: string;\n  database?: string;\n}\n\n/**\n * A concrete type describing all the values that can be applied via a\n * user-supplied firestore.Settings object. This is a separate type so that\n * defaults can be supplied and the value can be checked for equality.\n */\nclass FirestoreSettings {\n  /** The hostname to connect to. */\n  readonly host: string;\n\n  /** Whether to use SSL when connecting. */\n  readonly ssl: boolean;\n\n  readonly timestampsInSnapshots: boolean;\n\n  readonly cacheSizeBytes: number;\n\n  readonly forceLongPolling: boolean;\n\n  // Can be a google-auth-library or gapi client.\n  // eslint-disable-next-line @typescript-eslint/no-explicit-any\n  credentials?: any;\n\n  constructor(settings: PrivateSettings) {\n    if (settings.host === undefined) {\n      if (settings.ssl !== undefined) {\n        throw new FirestoreError(\n          Code.INVALID_ARGUMENT,\n          \"Can't provide ssl option if host option is not set\"\n        );\n      }\n      this.host = DEFAULT_HOST;\n      this.ssl = DEFAULT_SSL;\n    } else {\n      validateNamedType('settings', 'non-empty string', 'host', settings.host);\n      this.host = settings.host;\n\n      validateNamedOptionalType('settings', 'boolean', 'ssl', settings.ssl);\n      this.ssl = settings.ssl ?? DEFAULT_SSL;\n    }\n    validateOptionNames('settings', settings, [\n      'host',\n      'ssl',\n      'credentials',\n      'timestampsInSnapshots',\n      'cacheSizeBytes',\n      'experimentalForceLongPolling'\n    ]);\n\n    validateNamedOptionalType(\n      'settings',\n      'object',\n      'credentials',\n      settings.credentials\n    );\n    this.credentials = settings.credentials;\n\n    validateNamedOptionalType(\n      'settings',\n      'boolean',\n      'timestampsInSnapshots',\n      settings.timestampsInSnapshots\n    );\n\n    // Nobody should set timestampsInSnapshots anymore, but the error depends on\n    // whether they set it to true or false...\n    if (settings.timestampsInSnapshots === true) {\n      logError(\n        \"The setting 'timestampsInSnapshots: true' is no longer required \" +\n          'and should be removed.'\n      );\n    } else if (settings.timestampsInSnapshots === false) {\n      logError(\n        \"Support for 'timestampsInSnapshots: false' will be removed soon. \" +\n          'You must update your code to handle Timestamp objects.'\n      );\n    }\n    this.timestampsInSnapshots =\n      settings.timestampsInSnapshots ?? DEFAULT_TIMESTAMPS_IN_SNAPSHOTS;\n\n    validateNamedOptionalType(\n      'settings',\n      'number',\n      'cacheSizeBytes',\n      settings.cacheSizeBytes\n    );\n    if (settings.cacheSizeBytes === undefined) {\n      this.cacheSizeBytes = LruParams.DEFAULT_CACHE_SIZE_BYTES;\n    } else {\n      if (\n        settings.cacheSizeBytes !== CACHE_SIZE_UNLIMITED &&\n        settings.cacheSizeBytes < LruParams.MINIMUM_CACHE_SIZE_BYTES\n      ) {\n        throw new FirestoreError(\n          Code.INVALID_ARGUMENT,\n          `cacheSizeBytes must be at least ${LruParams.MINIMUM_CACHE_SIZE_BYTES}`\n        );\n      } else {\n        this.cacheSizeBytes = settings.cacheSizeBytes;\n      }\n    }\n\n    validateNamedOptionalType(\n      'settings',\n      'boolean',\n      'experimentalForceLongPolling',\n      settings.experimentalForceLongPolling\n    );\n    this.forceLongPolling =\n      settings.experimentalForceLongPolling === undefined\n        ? DEFAULT_FORCE_LONG_POLLING\n        : settings.experimentalForceLongPolling;\n  }\n\n  isEqual(other: FirestoreSettings): boolean {\n    return (\n      this.host === other.host &&\n      this.ssl === other.ssl &&\n      this.timestampsInSnapshots === other.timestampsInSnapshots &&\n      this.credentials === other.credentials &&\n      this.cacheSizeBytes === other.cacheSizeBytes &&\n      this.forceLongPolling === other.forceLongPolling\n    );\n  }\n}\n\n/**\n * The root reference to the database.\n */\nexport class Firestore implements firestore.FirebaseFirestore, FirebaseService {\n  // The objects that are a part of this API are exposed to third-parties as\n  // compiled javascript so we want to flag our private members with a leading\n  // underscore to discourage their use.\n  readonly _databaseId: DatabaseId;\n  private readonly _persistenceKey: string;\n  private readonly _componentProvider: ComponentProvider;\n  private _credentials: CredentialsProvider;\n  private readonly _firebaseApp: FirebaseApp | null = null;\n  private _settings: FirestoreSettings;\n\n  // The firestore client instance. This will be available as soon as\n  // configureClient is called, but any calls against it will block until\n  // setup has completed.\n  //\n  // Operations on the _firestoreClient don't block on _firestoreReady. Those\n  // are already set to synchronize on the async queue.\n  private _firestoreClient: FirestoreClient | undefined;\n\n  // Public for use in tests.\n  // TODO(mikelehen): Use modularized initialization instead.\n  readonly _queue = new AsyncQueue();\n\n  readonly _dataReader: UserDataReader;\n\n  // Note: We are using `MemoryComponentProvider` as a default\n  // ComponentProvider to ensure backwards compatibility with the format\n  // expected by the console build.\n  constructor(\n    databaseIdOrApp: FirestoreDatabase | FirebaseApp,\n    authProvider: Provider<FirebaseAuthInternalName>,\n    persistenceProvider: ComponentProvider = new MemoryComponentProvider()\n  ) {\n    if (typeof (databaseIdOrApp as FirebaseApp).options === 'object') {\n      // This is very likely a Firebase app object\n      // TODO(b/34177605): Can we somehow use instanceof?\n      const app = databaseIdOrApp as FirebaseApp;\n      this._firebaseApp = app;\n      this._databaseId = Firestore.databaseIdFromApp(app);\n      this._persistenceKey = app.name;\n      this._credentials = new FirebaseCredentialsProvider(authProvider);\n    } else {\n      const external = databaseIdOrApp as FirestoreDatabase;\n      if (!external.projectId) {\n        throw new FirestoreError(\n          Code.INVALID_ARGUMENT,\n          'Must provide projectId'\n        );\n      }\n\n      this._databaseId = new DatabaseId(external.projectId, external.database);\n      // Use a default persistenceKey that lines up with FirebaseApp.\n      this._persistenceKey = '[DEFAULT]';\n      this._credentials = new EmptyCredentialsProvider();\n    }\n\n    this._componentProvider = persistenceProvider;\n    this._settings = new FirestoreSettings({});\n    this._dataReader = this.createDataReader(this._databaseId);\n  }\n\n  settings(settingsLiteral: firestore.Settings): void {\n    validateExactNumberOfArgs('Firestore.settings', arguments, 1);\n    validateArgType('Firestore.settings', 'object', 1, settingsLiteral);\n\n    const newSettings = new FirestoreSettings(settingsLiteral);\n    if (this._firestoreClient && !this._settings.isEqual(newSettings)) {\n      throw new FirestoreError(\n        Code.FAILED_PRECONDITION,\n        'Firestore has already been started and its settings can no longer ' +\n          'be changed. You can only call settings() before calling any other ' +\n          'methods on a Firestore object.'\n      );\n    }\n\n    this._settings = newSettings;\n    if (newSettings.credentials !== undefined) {\n      this._credentials = makeCredentialsProvider(newSettings.credentials);\n    }\n  }\n\n  enableNetwork(): Promise<void> {\n    this.ensureClientConfigured();\n    return this._firestoreClient!.enableNetwork();\n  }\n\n  disableNetwork(): Promise<void> {\n    this.ensureClientConfigured();\n    return this._firestoreClient!.disableNetwork();\n  }\n\n  enablePersistence(settings?: firestore.PersistenceSettings): Promise<void> {\n    if (this._firestoreClient) {\n      throw new FirestoreError(\n        Code.FAILED_PRECONDITION,\n        'Firestore has already been started and persistence can no longer ' +\n          'be enabled. You can only call enablePersistence() before calling ' +\n          'any other methods on a Firestore object.'\n      );\n    }\n\n    let synchronizeTabs = false;\n\n    if (settings) {\n      if (settings.experimentalTabSynchronization !== undefined) {\n        logError(\n          \"The 'experimentalTabSynchronization' setting will be removed. Use 'synchronizeTabs' instead.\"\n        );\n      }\n      synchronizeTabs =\n        settings.synchronizeTabs ??\n        settings.experimentalTabSynchronization ??\n        DEFAULT_SYNCHRONIZE_TABS;\n    }\n\n    return this.configureClient(this._componentProvider, {\n      durable: true,\n      cacheSizeBytes: this._settings.cacheSizeBytes,\n      synchronizeTabs\n    });\n  }\n\n  async clearPersistence(): Promise<void> {\n    if (\n      this._firestoreClient !== undefined &&\n      !this._firestoreClient.clientTerminated\n    ) {\n      throw new FirestoreError(\n        Code.FAILED_PRECONDITION,\n        'Persistence cannot be cleared after this Firestore instance is initialized.'\n      );\n    }\n\n    const deferred = new Deferred<void>();\n    this._queue.enqueueAndForgetEvenAfterShutdown(async () => {\n      try {\n        const databaseInfo = this.makeDatabaseInfo();\n        await this._componentProvider.clearPersistence(databaseInfo);\n        deferred.resolve();\n      } catch (e) {\n        deferred.reject(e);\n      }\n    });\n    return deferred.promise;\n  }\n\n  terminate(): Promise<void> {\n    (this.app as _FirebaseApp)._removeServiceInstance('firestore');\n    return this.INTERNAL.delete();\n  }\n\n  get _isTerminated(): boolean {\n    this.ensureClientConfigured();\n    return this._firestoreClient!.clientTerminated;\n  }\n\n  waitForPendingWrites(): Promise<void> {\n    this.ensureClientConfigured();\n    return this._firestoreClient!.waitForPendingWrites();\n  }\n\n  onSnapshotsInSync(observer: PartialObserver<void>): Unsubscribe;\n  onSnapshotsInSync(onSync: () => void): Unsubscribe;\n  onSnapshotsInSync(arg: unknown): Unsubscribe {\n    this.ensureClientConfigured();\n\n    if (isPartialObserver(arg)) {\n      return this.onSnapshotsInSyncInternal(arg as PartialObserver<void>);\n    } else {\n      validateArgType('Firestore.onSnapshotsInSync', 'function', 1, arg);\n      const observer: PartialObserver<void> = {\n        next: arg as () => void\n      };\n      return this.onSnapshotsInSyncInternal(observer);\n    }\n  }\n\n  private onSnapshotsInSyncInternal(\n    observer: PartialObserver<void>\n  ): Unsubscribe {\n    const errHandler = (err: Error): void => {\n      throw fail('Uncaught Error in onSnapshotsInSync');\n    };\n    const asyncObserver = new AsyncObserver<void>({\n      next: () => {\n        if (observer.next) {\n          observer.next();\n        }\n      },\n      error: errHandler\n    });\n    this._firestoreClient!.addSnapshotsInSyncListener(asyncObserver);\n    return () => {\n      asyncObserver.mute();\n      this._firestoreClient!.removeSnapshotsInSyncListener(asyncObserver);\n    };\n  }\n\n  ensureClientConfigured(): FirestoreClient {\n    if (!this._firestoreClient) {\n      // Kick off starting the client but don't actually wait for it.\n      // eslint-disable-next-line @typescript-eslint/no-floating-promises\n      this.configureClient(new MemoryComponentProvider(), {\n        durable: false\n      });\n    }\n    return this._firestoreClient as FirestoreClient;\n  }\n\n  private makeDatabaseInfo(): DatabaseInfo {\n    return new DatabaseInfo(\n      this._databaseId,\n      this._persistenceKey,\n      this._settings.host,\n      this._settings.ssl,\n      this._settings.forceLongPolling\n    );\n  }\n\n  private configureClient(\n    componentProvider: ComponentProvider,\n    persistenceSettings: PersistenceSettings\n  ): Promise<void> {\n    debugAssert(!!this._settings.host, 'FirestoreSettings.host is not set');\n\n    debugAssert(\n      !this._firestoreClient,\n      'configureClient() called multiple times'\n    );\n\n    const databaseInfo = this.makeDatabaseInfo();\n\n    this._firestoreClient = new FirestoreClient(\n      PlatformSupport.getPlatform(),\n      databaseInfo,\n      this._credentials,\n      this._queue\n    );\n\n    return this._firestoreClient.start(componentProvider, persistenceSettings);\n  }\n\n  private createDataReader(databaseId: DatabaseId): UserDataReader {\n    const preConverter = (value: unknown): unknown => {\n      if (value instanceof DocumentReference) {\n        const thisDb = databaseId;\n        const otherDb = value.firestore._databaseId;\n        if (!otherDb.isEqual(thisDb)) {\n          throw new FirestoreError(\n            Code.INVALID_ARGUMENT,\n            'Document reference is for database ' +\n              `${otherDb.projectId}/${otherDb.database} but should be ` +\n              `for database ${thisDb.projectId}/${thisDb.database}`\n          );\n        }\n        return new DocumentKeyReference(databaseId, value._key);\n      } else {\n        return value;\n      }\n    };\n    const serializer = new JsonProtoSerializer(databaseId, {\n      useProto3Json: PlatformSupport.getPlatform().useProto3Json\n    });\n    return new UserDataReader(serializer, preConverter);\n  }\n\n  private static databaseIdFromApp(app: FirebaseApp): DatabaseId {\n    if (!contains(app.options, 'projectId')) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        '\"projectId\" not provided in firebase.initializeApp.'\n      );\n    }\n\n    const projectId = app.options.projectId;\n    if (!projectId || typeof projectId !== 'string') {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        'projectId must be a string in FirebaseApp.options'\n      );\n    }\n    return new DatabaseId(projectId);\n  }\n\n  get app(): FirebaseApp {\n    if (!this._firebaseApp) {\n      throw new FirestoreError(\n        Code.FAILED_PRECONDITION,\n        \"Firestore was not initialized using the Firebase SDK. 'app' is \" +\n          'not available'\n      );\n    }\n    return this._firebaseApp;\n  }\n\n  INTERNAL = {\n    delete: async (): Promise<void> => {\n      // The client must be initalized to ensure that all subsequent API usage\n      // throws an exception.\n      this.ensureClientConfigured();\n      await this._firestoreClient!.terminate();\n    }\n  };\n\n  collection(pathString: string): firestore.CollectionReference {\n    validateExactNumberOfArgs('Firestore.collection', arguments, 1);\n    validateArgType('Firestore.collection', 'non-empty string', 1, pathString);\n    this.ensureClientConfigured();\n    return new CollectionReference(ResourcePath.fromString(pathString), this);\n  }\n\n  doc(pathString: string): firestore.DocumentReference {\n    validateExactNumberOfArgs('Firestore.doc', arguments, 1);\n    validateArgType('Firestore.doc', 'non-empty string', 1, pathString);\n    this.ensureClientConfigured();\n    return DocumentReference.forPath(ResourcePath.fromString(pathString), this);\n  }\n\n  collectionGroup(collectionId: string): firestore.Query {\n    validateExactNumberOfArgs('Firestore.collectionGroup', arguments, 1);\n    validateArgType(\n      'Firestore.collectionGroup',\n      'non-empty string',\n      1,\n      collectionId\n    );\n    if (collectionId.indexOf('/') >= 0) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        `Invalid collection ID '${collectionId}' passed to function ` +\n          `Firestore.collectionGroup(). Collection IDs must not contain '/'.`\n      );\n    }\n    this.ensureClientConfigured();\n    return new Query(\n      new InternalQuery(ResourcePath.EMPTY_PATH, collectionId),\n      this\n    );\n  }\n\n  runTransaction<T>(\n    updateFunction: (transaction: firestore.Transaction) => Promise<T>\n  ): Promise<T> {\n    validateExactNumberOfArgs('Firestore.runTransaction', arguments, 1);\n    validateArgType('Firestore.runTransaction', 'function', 1, updateFunction);\n    return this.ensureClientConfigured().transaction(\n      (transaction: InternalTransaction) => {\n        return updateFunction(new Transaction(this, transaction));\n      }\n    );\n  }\n\n  batch(): firestore.WriteBatch {\n    this.ensureClientConfigured();\n\n    return new WriteBatch(this);\n  }\n\n  static get logLevel(): firestore.LogLevel {\n    switch (getLogLevel()) {\n      case LogLevel.DEBUG:\n        return 'debug';\n      case LogLevel.SILENT:\n        return 'silent';\n      default:\n        // The default log level is error\n        return 'error';\n    }\n  }\n\n  static setLogLevel(level: firestore.LogLevel): void {\n    validateExactNumberOfArgs('Firestore.setLogLevel', arguments, 1);\n    validateArgType('Firestore.setLogLevel', 'non-empty string', 1, level);\n    switch (level) {\n      case 'debug':\n        setLogLevel(LogLevel.DEBUG);\n        break;\n      case 'error':\n        setLogLevel(LogLevel.ERROR);\n        break;\n      case 'silent':\n        setLogLevel(LogLevel.SILENT);\n        break;\n      default:\n        throw new FirestoreError(\n          Code.INVALID_ARGUMENT,\n          'Invalid log level: ' + level\n        );\n    }\n  }\n\n  // Note: this is not a property because the minifier can't work correctly with\n  // the way TypeScript compiler outputs properties.\n  _areTimestampsInSnapshotsEnabled(): boolean {\n    return this._settings.timestampsInSnapshots;\n  }\n}\n\n/**\n * A reference to a transaction.\n */\nexport class Transaction implements firestore.Transaction {\n  constructor(\n    private _firestore: Firestore,\n    private _transaction: InternalTransaction\n  ) {}\n\n  get<T>(\n    documentRef: firestore.DocumentReference<T>\n  ): Promise<firestore.DocumentSnapshot<T>> {\n    validateExactNumberOfArgs('Transaction.get', arguments, 1);\n    const ref = validateReference(\n      'Transaction.get',\n      documentRef,\n      this._firestore\n    );\n    return this._transaction\n      .lookup([ref._key])\n      .then((docs: MaybeDocument[]) => {\n        if (!docs || docs.length !== 1) {\n          return fail('Mismatch in docs returned from document lookup.');\n        }\n        const doc = docs[0];\n        if (doc instanceof NoDocument) {\n          return new DocumentSnapshot<T>(\n            this._firestore,\n            ref._key,\n            null,\n            /* fromCache= */ false,\n            /* hasPendingWrites= */ false,\n            ref._converter\n          );\n        } else if (doc instanceof Document) {\n          return new DocumentSnapshot<T>(\n            this._firestore,\n            ref._key,\n            doc,\n            /* fromCache= */ false,\n            /* hasPendingWrites= */ false,\n            ref._converter\n          );\n        } else {\n          throw fail(\n            `BatchGetDocumentsRequest returned unexpected document type: ${doc.constructor.name}`\n          );\n        }\n      });\n  }\n\n  set<T>(\n    documentRef: firestore.DocumentReference<T>,\n    value: T,\n    options?: firestore.SetOptions\n  ): Transaction {\n    validateBetweenNumberOfArgs('Transaction.set', arguments, 2, 3);\n    const ref = validateReference(\n      'Transaction.set',\n      documentRef,\n      this._firestore\n    );\n    options = validateSetOptions('Transaction.set', options);\n    const [convertedValue, functionName] = applyFirestoreDataConverter(\n      ref._converter,\n      value,\n      'Transaction.set'\n    );\n    const parsed =\n      options.merge || options.mergeFields\n        ? this._firestore._dataReader.parseMergeData(\n            functionName,\n            convertedValue,\n            options.mergeFields\n          )\n        : this._firestore._dataReader.parseSetData(\n            functionName,\n            convertedValue\n          );\n    this._transaction.set(ref._key, parsed);\n    return this;\n  }\n\n  update(\n    documentRef: firestore.DocumentReference<unknown>,\n    value: firestore.UpdateData\n  ): Transaction;\n  update(\n    documentRef: firestore.DocumentReference<unknown>,\n    field: string | ExternalFieldPath,\n    value: unknown,\n    ...moreFieldsAndValues: unknown[]\n  ): Transaction;\n  update(\n    documentRef: firestore.DocumentReference<unknown>,\n    fieldOrUpdateData: string | ExternalFieldPath | firestore.UpdateData,\n    value?: unknown,\n    ...moreFieldsAndValues: unknown[]\n  ): Transaction {\n    let ref;\n    let parsed;\n\n    if (\n      typeof fieldOrUpdateData === 'string' ||\n      fieldOrUpdateData instanceof ExternalFieldPath\n    ) {\n      validateAtLeastNumberOfArgs('Transaction.update', arguments, 3);\n      ref = validateReference(\n        'Transaction.update',\n        documentRef,\n        this._firestore\n      );\n      parsed = this._firestore._dataReader.parseUpdateVarargs(\n        'Transaction.update',\n        fieldOrUpdateData,\n        value,\n        moreFieldsAndValues\n      );\n    } else {\n      validateExactNumberOfArgs('Transaction.update', arguments, 2);\n      ref = validateReference(\n        'Transaction.update',\n        documentRef,\n        this._firestore\n      );\n      parsed = this._firestore._dataReader.parseUpdateData(\n        'Transaction.update',\n        fieldOrUpdateData\n      );\n    }\n\n    this._transaction.update(ref._key, parsed);\n    return this;\n  }\n\n  delete(documentRef: firestore.DocumentReference<unknown>): Transaction {\n    validateExactNumberOfArgs('Transaction.delete', arguments, 1);\n    const ref = validateReference(\n      'Transaction.delete',\n      documentRef,\n      this._firestore\n    );\n    this._transaction.delete(ref._key);\n    return this;\n  }\n}\n\nexport class WriteBatch implements firestore.WriteBatch {\n  private _mutations = [] as Mutation[];\n  private _committed = false;\n\n  constructor(private _firestore: Firestore) {}\n\n  set<T>(\n    documentRef: firestore.DocumentReference<T>,\n    value: T,\n    options?: firestore.SetOptions\n  ): WriteBatch {\n    validateBetweenNumberOfArgs('WriteBatch.set', arguments, 2, 3);\n    this.verifyNotCommitted();\n    const ref = validateReference(\n      'WriteBatch.set',\n      documentRef,\n      this._firestore\n    );\n    options = validateSetOptions('WriteBatch.set', options);\n    const [convertedValue, functionName] = applyFirestoreDataConverter(\n      ref._converter,\n      value,\n      'WriteBatch.set'\n    );\n    const parsed =\n      options.merge || options.mergeFields\n        ? this._firestore._dataReader.parseMergeData(\n            functionName,\n            convertedValue,\n            options.mergeFields\n          )\n        : this._firestore._dataReader.parseSetData(\n            functionName,\n            convertedValue\n          );\n    this._mutations = this._mutations.concat(\n      parsed.toMutations(ref._key, Precondition.NONE)\n    );\n    return this;\n  }\n\n  update(\n    documentRef: firestore.DocumentReference<unknown>,\n    value: firestore.UpdateData\n  ): WriteBatch;\n  update(\n    documentRef: firestore.DocumentReference<unknown>,\n    field: string | ExternalFieldPath,\n    value: unknown,\n    ...moreFieldsAndValues: unknown[]\n  ): WriteBatch;\n  update(\n    documentRef: firestore.DocumentReference<unknown>,\n    fieldOrUpdateData: string | ExternalFieldPath | firestore.UpdateData,\n    value?: unknown,\n    ...moreFieldsAndValues: unknown[]\n  ): WriteBatch {\n    this.verifyNotCommitted();\n\n    let ref;\n    let parsed;\n\n    if (\n      typeof fieldOrUpdateData === 'string' ||\n      fieldOrUpdateData instanceof ExternalFieldPath\n    ) {\n      validateAtLeastNumberOfArgs('WriteBatch.update', arguments, 3);\n      ref = validateReference(\n        'WriteBatch.update',\n        documentRef,\n        this._firestore\n      );\n      parsed = this._firestore._dataReader.parseUpdateVarargs(\n        'WriteBatch.update',\n        fieldOrUpdateData,\n        value,\n        moreFieldsAndValues\n      );\n    } else {\n      validateExactNumberOfArgs('WriteBatch.update', arguments, 2);\n      ref = validateReference(\n        'WriteBatch.update',\n        documentRef,\n        this._firestore\n      );\n      parsed = this._firestore._dataReader.parseUpdateData(\n        'WriteBatch.update',\n        fieldOrUpdateData\n      );\n    }\n\n    this._mutations = this._mutations.concat(\n      parsed.toMutations(ref._key, Precondition.exists(true))\n    );\n    return this;\n  }\n\n  delete(documentRef: firestore.DocumentReference<unknown>): WriteBatch {\n    validateExactNumberOfArgs('WriteBatch.delete', arguments, 1);\n    this.verifyNotCommitted();\n    const ref = validateReference(\n      'WriteBatch.delete',\n      documentRef,\n      this._firestore\n    );\n    this._mutations = this._mutations.concat(\n      new DeleteMutation(ref._key, Precondition.NONE)\n    );\n    return this;\n  }\n\n  commit(): Promise<void> {\n    this.verifyNotCommitted();\n    this._committed = true;\n    if (this._mutations.length > 0) {\n      return this._firestore.ensureClientConfigured().write(this._mutations);\n    }\n\n    return Promise.resolve();\n  }\n\n  private verifyNotCommitted(): void {\n    if (this._committed) {\n      throw new FirestoreError(\n        Code.FAILED_PRECONDITION,\n        'A write batch can no longer be used after commit() ' +\n          'has been called.'\n      );\n    }\n  }\n}\n\n/**\n * A reference to a particular document in a collection in the database.\n */\nexport class DocumentReference<T = firestore.DocumentData>\n  implements firestore.DocumentReference<T> {\n  private _firestoreClient: FirestoreClient;\n\n  constructor(\n    public _key: DocumentKey,\n    readonly firestore: Firestore,\n    readonly _converter?: firestore.FirestoreDataConverter<T>\n  ) {\n    this._firestoreClient = this.firestore.ensureClientConfigured();\n  }\n\n  static forPath<U>(\n    path: ResourcePath,\n    firestore: Firestore,\n    converter?: firestore.FirestoreDataConverter<U>\n  ): DocumentReference<U> {\n    if (path.length % 2 !== 0) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        'Invalid document reference. Document ' +\n          'references must have an even number of segments, but ' +\n          `${path.canonicalString()} has ${path.length}`\n      );\n    }\n    return new DocumentReference(new DocumentKey(path), firestore, converter);\n  }\n\n  get id(): string {\n    return this._key.path.lastSegment();\n  }\n\n  get parent(): firestore.CollectionReference<T> {\n    return new CollectionReference(\n      this._key.path.popLast(),\n      this.firestore,\n      this._converter\n    );\n  }\n\n  get path(): string {\n    return this._key.path.canonicalString();\n  }\n\n  collection(\n    pathString: string\n  ): firestore.CollectionReference<firestore.DocumentData> {\n    validateExactNumberOfArgs('DocumentReference.collection', arguments, 1);\n    validateArgType(\n      'DocumentReference.collection',\n      'non-empty string',\n      1,\n      pathString\n    );\n    if (!pathString) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        'Must provide a non-empty collection name to collection()'\n      );\n    }\n    const path = ResourcePath.fromString(pathString);\n    return new CollectionReference(this._key.path.child(path), this.firestore);\n  }\n\n  isEqual(other: firestore.DocumentReference<T>): boolean {\n    if (!(other instanceof DocumentReference)) {\n      throw invalidClassError('isEqual', 'DocumentReference', 1, other);\n    }\n    return (\n      this.firestore === other.firestore &&\n      this._key.isEqual(other._key) &&\n      this._converter === other._converter\n    );\n  }\n\n  set(\n    value: firestore.DocumentData,\n    options?: firestore.SetOptions\n  ): Promise<void>;\n  set(value: T, options?: firestore.SetOptions): Promise<void> {\n    validateBetweenNumberOfArgs('DocumentReference.set', arguments, 1, 2);\n    options = validateSetOptions('DocumentReference.set', options);\n    const [convertedValue, functionName] = applyFirestoreDataConverter(\n      this._converter,\n      value,\n      'DocumentReference.set'\n    );\n    const parsed =\n      options.merge || options.mergeFields\n        ? this.firestore._dataReader.parseMergeData(\n            functionName,\n            convertedValue,\n            options.mergeFields\n          )\n        : this.firestore._dataReader.parseSetData(functionName, convertedValue);\n    return this._firestoreClient.write(\n      parsed.toMutations(this._key, Precondition.NONE)\n    );\n  }\n\n  update(value: firestore.UpdateData): Promise<void>;\n  update(\n    field: string | ExternalFieldPath,\n    value: unknown,\n    ...moreFieldsAndValues: unknown[]\n  ): Promise<void>;\n  update(\n    fieldOrUpdateData: string | ExternalFieldPath | firestore.UpdateData,\n    value?: unknown,\n    ...moreFieldsAndValues: unknown[]\n  ): Promise<void> {\n    let parsed;\n\n    if (\n      typeof fieldOrUpdateData === 'string' ||\n      fieldOrUpdateData instanceof ExternalFieldPath\n    ) {\n      validateAtLeastNumberOfArgs('DocumentReference.update', arguments, 2);\n      parsed = this.firestore._dataReader.parseUpdateVarargs(\n        'DocumentReference.update',\n        fieldOrUpdateData,\n        value,\n        moreFieldsAndValues\n      );\n    } else {\n      validateExactNumberOfArgs('DocumentReference.update', arguments, 1);\n      parsed = this.firestore._dataReader.parseUpdateData(\n        'DocumentReference.update',\n        fieldOrUpdateData\n      );\n    }\n\n    return this._firestoreClient.write(\n      parsed.toMutations(this._key, Precondition.exists(true))\n    );\n  }\n\n  delete(): Promise<void> {\n    validateExactNumberOfArgs('DocumentReference.delete', arguments, 0);\n    return this._firestoreClient.write([\n      new DeleteMutation(this._key, Precondition.NONE)\n    ]);\n  }\n\n  onSnapshot(\n    observer: PartialObserver<firestore.DocumentSnapshot<T>>\n  ): Unsubscribe;\n  onSnapshot(\n    options: firestore.SnapshotListenOptions,\n    observer: PartialObserver<firestore.DocumentSnapshot<T>>\n  ): Unsubscribe;\n  onSnapshot(\n    onNext: NextFn<firestore.DocumentSnapshot<T>>,\n    onError?: ErrorFn,\n    onCompletion?: CompleteFn\n  ): Unsubscribe;\n  onSnapshot(\n    options: firestore.SnapshotListenOptions,\n    onNext: NextFn<firestore.DocumentSnapshot<T>>,\n    onError?: ErrorFn,\n    onCompletion?: CompleteFn\n  ): Unsubscribe;\n\n  onSnapshot(...args: unknown[]): Unsubscribe {\n    validateBetweenNumberOfArgs(\n      'DocumentReference.onSnapshot',\n      arguments,\n      1,\n      4\n    );\n    let options: firestore.SnapshotListenOptions = {\n      includeMetadataChanges: false\n    };\n    let observer: PartialObserver<firestore.DocumentSnapshot<T>>;\n    let currArg = 0;\n    if (\n      typeof args[currArg] === 'object' &&\n      !isPartialObserver(args[currArg])\n    ) {\n      options = args[currArg] as firestore.SnapshotListenOptions;\n      validateOptionNames('DocumentReference.onSnapshot', options, [\n        'includeMetadataChanges'\n      ]);\n      validateNamedOptionalType(\n        'DocumentReference.onSnapshot',\n        'boolean',\n        'includeMetadataChanges',\n        options.includeMetadataChanges\n      );\n      currArg++;\n    }\n\n    const internalOptions = {\n      includeMetadataChanges: options.includeMetadataChanges\n    };\n\n    if (isPartialObserver(args[currArg])) {\n      observer = args[currArg] as PartialObserver<\n        firestore.DocumentSnapshot<T>\n      >;\n    } else {\n      validateArgType(\n        'DocumentReference.onSnapshot',\n        'function',\n        currArg,\n        args[currArg]\n      );\n      validateOptionalArgType(\n        'DocumentReference.onSnapshot',\n        'function',\n        currArg + 1,\n        args[currArg + 1]\n      );\n      validateOptionalArgType(\n        'DocumentReference.onSnapshot',\n        'function',\n        currArg + 2,\n        args[currArg + 2]\n      );\n      observer = {\n        next: args[currArg] as NextFn<firestore.DocumentSnapshot<T>>,\n        error: args[currArg + 1] as ErrorFn,\n        complete: args[currArg + 2] as CompleteFn\n      };\n    }\n    return this.onSnapshotInternal(internalOptions, observer);\n  }\n\n  private onSnapshotInternal(\n    options: ListenOptions,\n    observer: PartialObserver<firestore.DocumentSnapshot<T>>\n  ): Unsubscribe {\n    let errHandler = (err: Error): void => {\n      console.error('Uncaught Error in onSnapshot:', err);\n    };\n    if (observer.error) {\n      errHandler = observer.error.bind(observer);\n    }\n\n    const asyncObserver = new AsyncObserver<ViewSnapshot>({\n      next: snapshot => {\n        if (observer.next) {\n          debugAssert(\n            snapshot.docs.size <= 1,\n            'Too many documents returned on a document query'\n          );\n          const doc = snapshot.docs.get(this._key);\n\n          observer.next(\n            new DocumentSnapshot(\n              this.firestore,\n              this._key,\n              doc,\n              snapshot.fromCache,\n              snapshot.hasPendingWrites,\n              this._converter\n            )\n          );\n        }\n      },\n      error: errHandler\n    });\n    const internalListener = this._firestoreClient.listen(\n      InternalQuery.atPath(this._key.path),\n      asyncObserver,\n      options\n    );\n\n    return () => {\n      asyncObserver.mute();\n      this._firestoreClient.unlisten(internalListener);\n    };\n  }\n\n  get(options?: firestore.GetOptions): Promise<firestore.DocumentSnapshot<T>> {\n    validateBetweenNumberOfArgs('DocumentReference.get', arguments, 0, 1);\n    validateGetOptions('DocumentReference.get', options);\n    return new Promise(\n      (resolve: Resolver<firestore.DocumentSnapshot<T>>, reject: Rejecter) => {\n        if (options && options.source === 'cache') {\n          this.firestore\n            .ensureClientConfigured()\n            .getDocumentFromLocalCache(this._key)\n            .then(doc => {\n              resolve(\n                new DocumentSnapshot(\n                  this.firestore,\n                  this._key,\n                  doc,\n                  /*fromCache=*/ true,\n                  doc instanceof Document ? doc.hasLocalMutations : false,\n                  this._converter\n                )\n              );\n            }, reject);\n        } else {\n          this.getViaSnapshotListener(resolve, reject, options);\n        }\n      }\n    );\n  }\n\n  private getViaSnapshotListener(\n    resolve: Resolver<firestore.DocumentSnapshot<T>>,\n    reject: Rejecter,\n    options?: firestore.GetOptions\n  ): void {\n    const unlisten = this.onSnapshotInternal(\n      {\n        includeMetadataChanges: true,\n        waitForSyncWhenOnline: true\n      },\n      {\n        next: (snap: firestore.DocumentSnapshot<T>) => {\n          // Remove query first before passing event to user to avoid\n          // user actions affecting the now stale query.\n          unlisten();\n\n          if (!snap.exists && snap.metadata.fromCache) {\n            // TODO(dimond): If we're online and the document doesn't\n            // exist then we resolve with a doc.exists set to false. If\n            // we're offline however, we reject the Promise in this\n            // case. Two options: 1) Cache the negative response from\n            // the server so we can deliver that even when you're\n            // offline 2) Actually reject the Promise in the online case\n            // if the document doesn't exist.\n            reject(\n              new FirestoreError(\n                Code.UNAVAILABLE,\n                'Failed to get document because the client is ' + 'offline.'\n              )\n            );\n          } else if (\n            snap.exists &&\n            snap.metadata.fromCache &&\n            options &&\n            options.source === 'server'\n          ) {\n            reject(\n              new FirestoreError(\n                Code.UNAVAILABLE,\n                'Failed to get document from server. (However, this ' +\n                  'document does exist in the local cache. Run again ' +\n                  'without setting source to \"server\" to ' +\n                  'retrieve the cached document.)'\n              )\n            );\n          } else {\n            resolve(snap);\n          }\n        },\n        error: reject\n      }\n    );\n  }\n\n  withConverter<U>(\n    converter: firestore.FirestoreDataConverter<U>\n  ): firestore.DocumentReference<U> {\n    return new DocumentReference<U>(this._key, this.firestore, converter);\n  }\n}\n\nclass SnapshotMetadata implements firestore.SnapshotMetadata {\n  constructor(\n    readonly hasPendingWrites: boolean,\n    readonly fromCache: boolean\n  ) {}\n\n  isEqual(other: firestore.SnapshotMetadata): boolean {\n    return (\n      this.hasPendingWrites === other.hasPendingWrites &&\n      this.fromCache === other.fromCache\n    );\n  }\n}\n\n/**\n * Options interface that can be provided to configure the deserialization of\n * DocumentSnapshots.\n */\nexport interface SnapshotOptions extends firestore.SnapshotOptions {}\n\nexport class DocumentSnapshot<T = firestore.DocumentData>\n  implements firestore.DocumentSnapshot<T> {\n  constructor(\n    private _firestore: Firestore,\n    private _key: DocumentKey,\n    public _document: Document | null,\n    private _fromCache: boolean,\n    private _hasPendingWrites: boolean,\n    private readonly _converter?: firestore.FirestoreDataConverter<T>\n  ) {}\n\n  data(options?: firestore.SnapshotOptions): T | undefined {\n    validateBetweenNumberOfArgs('DocumentSnapshot.data', arguments, 0, 1);\n    options = validateSnapshotOptions('DocumentSnapshot.data', options);\n    if (!this._document) {\n      return undefined;\n    } else {\n      // We only want to use the converter and create a new DocumentSnapshot\n      // if a converter has been provided.\n      if (this._converter) {\n        const snapshot = new QueryDocumentSnapshot(\n          this._firestore,\n          this._key,\n          this._document,\n          this._fromCache,\n          this._hasPendingWrites\n        );\n        return this._converter.fromFirestore(snapshot, options);\n      } else {\n        const userDataWriter = new UserDataWriter(\n          this._firestore,\n          this._firestore._areTimestampsInSnapshotsEnabled(),\n          options.serverTimestamps,\n          /* converter= */ undefined\n        );\n        return userDataWriter.convertValue(this._document.toProto()) as T;\n      }\n    }\n  }\n\n  get(\n    fieldPath: string | ExternalFieldPath,\n    options?: firestore.SnapshotOptions\n  ): unknown {\n    validateBetweenNumberOfArgs('DocumentSnapshot.get', arguments, 1, 2);\n    options = validateSnapshotOptions('DocumentSnapshot.get', options);\n    if (this._document) {\n      const value = this._document\n        .data()\n        .field(fieldPathFromArgument('DocumentSnapshot.get', fieldPath));\n      if (value !== null) {\n        const userDataWriter = new UserDataWriter(\n          this._firestore,\n          this._firestore._areTimestampsInSnapshotsEnabled(),\n          options.serverTimestamps,\n          this._converter\n        );\n        return userDataWriter.convertValue(value);\n      }\n    }\n    return undefined;\n  }\n\n  get id(): string {\n    return this._key.path.lastSegment();\n  }\n\n  get ref(): firestore.DocumentReference<T> {\n    return new DocumentReference<T>(\n      this._key,\n      this._firestore,\n      this._converter\n    );\n  }\n\n  get exists(): boolean {\n    return this._document !== null;\n  }\n\n  get metadata(): firestore.SnapshotMetadata {\n    return new SnapshotMetadata(this._hasPendingWrites, this._fromCache);\n  }\n\n  isEqual(other: firestore.DocumentSnapshot<T>): boolean {\n    if (!(other instanceof DocumentSnapshot)) {\n      throw invalidClassError('isEqual', 'DocumentSnapshot', 1, other);\n    }\n    return (\n      this._firestore === other._firestore &&\n      this._fromCache === other._fromCache &&\n      this._key.isEqual(other._key) &&\n      (this._document === null\n        ? other._document === null\n        : this._document.isEqual(other._document)) &&\n      this._converter === other._converter\n    );\n  }\n}\n\nexport class QueryDocumentSnapshot<T = firestore.DocumentData>\n  extends DocumentSnapshot<T>\n  implements firestore.QueryDocumentSnapshot<T> {\n  data(options?: SnapshotOptions): T {\n    const data = super.data(options);\n    debugAssert(\n      data !== undefined,\n      'Document in a QueryDocumentSnapshot should exist'\n    );\n    return data;\n  }\n}\n\nexport class Query<T = firestore.DocumentData> implements firestore.Query<T> {\n  constructor(\n    public _query: InternalQuery,\n    readonly firestore: Firestore,\n    protected readonly _converter?: firestore.FirestoreDataConverter<T>\n  ) {}\n\n  where(\n    field: string | ExternalFieldPath,\n    opStr: firestore.WhereFilterOp,\n    value: unknown\n  ): firestore.Query<T> {\n    validateExactNumberOfArgs('Query.where', arguments, 3);\n    validateDefined('Query.where', 3, value);\n\n    // Enumerated from the WhereFilterOp type in index.d.ts.\n    const whereFilterOpEnums = [\n      '<',\n      '<=',\n      '==',\n      '>=',\n      '>',\n      'array-contains',\n      'in',\n      'array-contains-any'\n    ];\n    validateStringEnum('Query.where', whereFilterOpEnums, 2, opStr);\n\n    let fieldValue: api.Value;\n    const fieldPath = fieldPathFromArgument('Query.where', field);\n    const operator = Operator.fromString(opStr);\n    if (fieldPath.isKeyField()) {\n      if (\n        operator === Operator.ARRAY_CONTAINS ||\n        operator === Operator.ARRAY_CONTAINS_ANY\n      ) {\n        throw new FirestoreError(\n          Code.INVALID_ARGUMENT,\n          `Invalid Query. You can't perform '${operator.toString()}' ` +\n            'queries on FieldPath.documentId().'\n        );\n      } else if (operator === Operator.IN) {\n        this.validateDisjunctiveFilterElements(value, operator);\n        const referenceList: api.Value[] = [];\n        for (const arrayValue of value as api.Value[]) {\n          referenceList.push(this.parseDocumentIdValue(arrayValue));\n        }\n        fieldValue = { arrayValue: { values: referenceList } };\n      } else {\n        fieldValue = this.parseDocumentIdValue(value);\n      }\n    } else {\n      if (\n        operator === Operator.IN ||\n        operator === Operator.ARRAY_CONTAINS_ANY\n      ) {\n        this.validateDisjunctiveFilterElements(value, operator);\n      }\n      fieldValue = this.firestore._dataReader.parseQueryValue(\n        'Query.where',\n        value,\n        // We only allow nested arrays for IN queries.\n        /** allowArrays = */ operator === Operator.IN ? true : false\n      );\n    }\n    const filter = FieldFilter.create(fieldPath, operator, fieldValue);\n    this.validateNewFilter(filter);\n    return new Query(\n      this._query.addFilter(filter),\n      this.firestore,\n      this._converter\n    );\n  }\n\n  orderBy(\n    field: string | ExternalFieldPath,\n    directionStr?: firestore.OrderByDirection\n  ): firestore.Query<T> {\n    validateBetweenNumberOfArgs('Query.orderBy', arguments, 1, 2);\n    validateOptionalArgType(\n      'Query.orderBy',\n      'non-empty string',\n      2,\n      directionStr\n    );\n    let direction: Direction;\n    if (directionStr === undefined || directionStr === 'asc') {\n      direction = Direction.ASCENDING;\n    } else if (directionStr === 'desc') {\n      direction = Direction.DESCENDING;\n    } else {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        `Function Query.orderBy() has unknown direction '${directionStr}', ` +\n          `expected 'asc' or 'desc'.`\n      );\n    }\n    if (this._query.startAt !== null) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        'Invalid query. You must not call Query.startAt() or ' +\n          'Query.startAfter() before calling Query.orderBy().'\n      );\n    }\n    if (this._query.endAt !== null) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        'Invalid query. You must not call Query.endAt() or ' +\n          'Query.endBefore() before calling Query.orderBy().'\n      );\n    }\n    const fieldPath = fieldPathFromArgument('Query.orderBy', field);\n    const orderBy = new OrderBy(fieldPath, direction);\n    this.validateNewOrderBy(orderBy);\n    return new Query(\n      this._query.addOrderBy(orderBy),\n      this.firestore,\n      this._converter\n    );\n  }\n\n  limit(n: number): firestore.Query<T> {\n    validateExactNumberOfArgs('Query.limit', arguments, 1);\n    validateArgType('Query.limit', 'number', 1, n);\n    validatePositiveNumber('Query.limit', 1, n);\n    return new Query(\n      this._query.withLimitToFirst(n),\n      this.firestore,\n      this._converter\n    );\n  }\n\n  limitToLast(n: number): firestore.Query<T> {\n    validateExactNumberOfArgs('Query.limitToLast', arguments, 1);\n    validateArgType('Query.limitToLast', 'number', 1, n);\n    validatePositiveNumber('Query.limitToLast', 1, n);\n    return new Query(\n      this._query.withLimitToLast(n),\n      this.firestore,\n      this._converter\n    );\n  }\n\n  startAt(\n    docOrField: unknown | firestore.DocumentSnapshot<unknown>,\n    ...fields: unknown[]\n  ): firestore.Query<T> {\n    validateAtLeastNumberOfArgs('Query.startAt', arguments, 1);\n    const bound = this.boundFromDocOrFields(\n      'Query.startAt',\n      docOrField,\n      fields,\n      /*before=*/ true\n    );\n    return new Query(\n      this._query.withStartAt(bound),\n      this.firestore,\n      this._converter\n    );\n  }\n\n  startAfter(\n    docOrField: unknown | firestore.DocumentSnapshot<unknown>,\n    ...fields: unknown[]\n  ): firestore.Query<T> {\n    validateAtLeastNumberOfArgs('Query.startAfter', arguments, 1);\n    const bound = this.boundFromDocOrFields(\n      'Query.startAfter',\n      docOrField,\n      fields,\n      /*before=*/ false\n    );\n    return new Query(\n      this._query.withStartAt(bound),\n      this.firestore,\n      this._converter\n    );\n  }\n\n  endBefore(\n    docOrField: unknown | firestore.DocumentSnapshot<unknown>,\n    ...fields: unknown[]\n  ): firestore.Query<T> {\n    validateAtLeastNumberOfArgs('Query.endBefore', arguments, 1);\n    const bound = this.boundFromDocOrFields(\n      'Query.endBefore',\n      docOrField,\n      fields,\n      /*before=*/ true\n    );\n    return new Query(\n      this._query.withEndAt(bound),\n      this.firestore,\n      this._converter\n    );\n  }\n\n  endAt(\n    docOrField: unknown | firestore.DocumentSnapshot<unknown>,\n    ...fields: unknown[]\n  ): firestore.Query<T> {\n    validateAtLeastNumberOfArgs('Query.endAt', arguments, 1);\n    const bound = this.boundFromDocOrFields(\n      'Query.endAt',\n      docOrField,\n      fields,\n      /*before=*/ false\n    );\n    return new Query(\n      this._query.withEndAt(bound),\n      this.firestore,\n      this._converter\n    );\n  }\n\n  isEqual(other: firestore.Query<T>): boolean {\n    if (!(other instanceof Query)) {\n      throw invalidClassError('isEqual', 'Query', 1, other);\n    }\n    return (\n      this.firestore === other.firestore && this._query.isEqual(other._query)\n    );\n  }\n\n  withConverter<U>(\n    converter: firestore.FirestoreDataConverter<U>\n  ): firestore.Query<U> {\n    return new Query<U>(this._query, this.firestore, converter);\n  }\n\n  /** Helper function to create a bound from a document or fields */\n  private boundFromDocOrFields(\n    methodName: string,\n    docOrField: unknown | firestore.DocumentSnapshot<T>,\n    fields: unknown[],\n    before: boolean\n  ): Bound {\n    validateDefined(methodName, 1, docOrField);\n    if (docOrField instanceof DocumentSnapshot) {\n      if (fields.length > 0) {\n        throw new FirestoreError(\n          Code.INVALID_ARGUMENT,\n          `Too many arguments provided to ${methodName}().`\n        );\n      }\n      const snap = docOrField;\n      if (!snap.exists) {\n        throw new FirestoreError(\n          Code.NOT_FOUND,\n          `Can't use a DocumentSnapshot that doesn't exist for ` +\n            `${methodName}().`\n        );\n      }\n      return this.boundFromDocument(snap._document!, before);\n    } else {\n      const allFields = [docOrField].concat(fields);\n      return this.boundFromFields(methodName, allFields, before);\n    }\n  }\n\n  /**\n   * Create a Bound from a query and a document.\n   *\n   * Note that the Bound will always include the key of the document\n   * and so only the provided document will compare equal to the returned\n   * position.\n   *\n   * Will throw if the document does not contain all fields of the order by\n   * of the query or if any of the fields in the order by are an uncommitted\n   * server timestamp.\n   */\n  private boundFromDocument(doc: Document, before: boolean): Bound {\n    const components: api.Value[] = [];\n\n    // Because people expect to continue/end a query at the exact document\n    // provided, we need to use the implicit sort order rather than the explicit\n    // sort order, because it's guaranteed to contain the document key. That way\n    // the position becomes unambiguous and the query continues/ends exactly at\n    // the provided document. Without the key (by using the explicit sort\n    // orders), multiple documents could match the position, yielding duplicate\n    // results.\n    for (const orderBy of this._query.orderBy) {\n      if (orderBy.field.isKeyField()) {\n        components.push(refValue(this.firestore._databaseId, doc.key));\n      } else {\n        const value = doc.field(orderBy.field);\n        if (isServerTimestamp(value)) {\n          throw new FirestoreError(\n            Code.INVALID_ARGUMENT,\n            'Invalid query. You are trying to start or end a query using a ' +\n              'document for which the field \"' +\n              orderBy.field +\n              '\" is an uncommitted server timestamp. (Since the value of ' +\n              'this field is unknown, you cannot start/end a query with it.)'\n          );\n        } else if (value !== null) {\n          components.push(value);\n        } else {\n          const field = orderBy.field.canonicalString();\n          throw new FirestoreError(\n            Code.INVALID_ARGUMENT,\n            `Invalid query. You are trying to start or end a query using a ` +\n              `document for which the field '${field}' (used as the ` +\n              `orderBy) does not exist.`\n          );\n        }\n      }\n    }\n    return new Bound(components, before);\n  }\n\n  /**\n   * Converts a list of field values to a Bound for the given query.\n   */\n  private boundFromFields(\n    methodName: string,\n    values: unknown[],\n    before: boolean\n  ): Bound {\n    // Use explicit order by's because it has to match the query the user made\n    const orderBy = this._query.explicitOrderBy;\n    if (values.length > orderBy.length) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        `Too many arguments provided to ${methodName}(). ` +\n          `The number of arguments must be less than or equal to the ` +\n          `number of Query.orderBy() clauses`\n      );\n    }\n\n    const components: api.Value[] = [];\n    for (let i = 0; i < values.length; i++) {\n      const rawValue = values[i];\n      const orderByComponent = orderBy[i];\n      if (orderByComponent.field.isKeyField()) {\n        if (typeof rawValue !== 'string') {\n          throw new FirestoreError(\n            Code.INVALID_ARGUMENT,\n            `Invalid query. Expected a string for document ID in ` +\n              `${methodName}(), but got a ${typeof rawValue}`\n          );\n        }\n        if (\n          !this._query.isCollectionGroupQuery() &&\n          rawValue.indexOf('/') !== -1\n        ) {\n          throw new FirestoreError(\n            Code.INVALID_ARGUMENT,\n            `Invalid query. When querying a collection and ordering by FieldPath.documentId(), ` +\n              `the value passed to ${methodName}() must be a plain document ID, but ` +\n              `'${rawValue}' contains a slash.`\n          );\n        }\n        const path = this._query.path.child(ResourcePath.fromString(rawValue));\n        if (!DocumentKey.isDocumentKey(path)) {\n          throw new FirestoreError(\n            Code.INVALID_ARGUMENT,\n            `Invalid query. When querying a collection group and ordering by ` +\n              `FieldPath.documentId(), the value passed to ${methodName}() must result in a ` +\n              `valid document path, but '${path}' is not because it contains an odd number ` +\n              `of segments.`\n          );\n        }\n        const key = new DocumentKey(path);\n        components.push(refValue(this.firestore._databaseId, key));\n      } else {\n        const wrapped = this.firestore._dataReader.parseQueryValue(\n          methodName,\n          rawValue\n        );\n        components.push(wrapped);\n      }\n    }\n\n    return new Bound(components, before);\n  }\n\n  onSnapshot(\n    observer: PartialObserver<firestore.QuerySnapshot<T>>\n  ): Unsubscribe;\n  onSnapshot(\n    options: firestore.SnapshotListenOptions,\n    observer: PartialObserver<firestore.QuerySnapshot<T>>\n  ): Unsubscribe;\n  onSnapshot(\n    onNext: NextFn<firestore.QuerySnapshot<T>>,\n    onError?: ErrorFn,\n    onCompletion?: CompleteFn\n  ): Unsubscribe;\n  onSnapshot(\n    options: firestore.SnapshotListenOptions,\n    onNext: NextFn<firestore.QuerySnapshot<T>>,\n    onError?: ErrorFn,\n    onCompletion?: CompleteFn\n  ): Unsubscribe;\n\n  onSnapshot(...args: unknown[]): Unsubscribe {\n    validateBetweenNumberOfArgs('Query.onSnapshot', arguments, 1, 4);\n    let options: firestore.SnapshotListenOptions = {};\n    let observer: PartialObserver<firestore.QuerySnapshot<T>>;\n    let currArg = 0;\n    if (\n      typeof args[currArg] === 'object' &&\n      !isPartialObserver(args[currArg])\n    ) {\n      options = args[currArg] as firestore.SnapshotListenOptions;\n      validateOptionNames('Query.onSnapshot', options, [\n        'includeMetadataChanges'\n      ]);\n      validateNamedOptionalType(\n        'Query.onSnapshot',\n        'boolean',\n        'includeMetadataChanges',\n        options.includeMetadataChanges\n      );\n      currArg++;\n    }\n\n    if (isPartialObserver(args[currArg])) {\n      observer = args[currArg] as PartialObserver<firestore.QuerySnapshot<T>>;\n    } else {\n      validateArgType('Query.onSnapshot', 'function', currArg, args[currArg]);\n      validateOptionalArgType(\n        'Query.onSnapshot',\n        'function',\n        currArg + 1,\n        args[currArg + 1]\n      );\n      validateOptionalArgType(\n        'Query.onSnapshot',\n        'function',\n        currArg + 2,\n        args[currArg + 2]\n      );\n      observer = {\n        next: args[currArg] as NextFn<firestore.QuerySnapshot<T>>,\n        error: args[currArg + 1] as ErrorFn,\n        complete: args[currArg + 2] as CompleteFn\n      };\n    }\n    this.validateHasExplicitOrderByForLimitToLast(this._query);\n    return this.onSnapshotInternal(options, observer);\n  }\n\n  private onSnapshotInternal(\n    options: ListenOptions,\n    observer: PartialObserver<firestore.QuerySnapshot<T>>\n  ): Unsubscribe {\n    let errHandler = (err: Error): void => {\n      console.error('Uncaught Error in onSnapshot:', err);\n    };\n    if (observer.error) {\n      errHandler = observer.error.bind(observer);\n    }\n\n    const asyncObserver = new AsyncObserver<ViewSnapshot>({\n      next: (result: ViewSnapshot): void => {\n        if (observer.next) {\n          observer.next(\n            new QuerySnapshot(\n              this.firestore,\n              this._query,\n              result,\n              this._converter\n            )\n          );\n        }\n      },\n      error: errHandler\n    });\n\n    const firestoreClient = this.firestore.ensureClientConfigured();\n    const internalListener = firestoreClient.listen(\n      this._query,\n      asyncObserver,\n      options\n    );\n    return (): void => {\n      asyncObserver.mute();\n      firestoreClient.unlisten(internalListener);\n    };\n  }\n\n  private validateHasExplicitOrderByForLimitToLast(query: InternalQuery): void {\n    if (query.hasLimitToLast() && query.explicitOrderBy.length === 0) {\n      throw new FirestoreError(\n        Code.UNIMPLEMENTED,\n        'limitToLast() queries require specifying at least one orderBy() clause'\n      );\n    }\n  }\n\n  get(options?: firestore.GetOptions): Promise<firestore.QuerySnapshot<T>> {\n    validateBetweenNumberOfArgs('Query.get', arguments, 0, 1);\n    validateGetOptions('Query.get', options);\n    this.validateHasExplicitOrderByForLimitToLast(this._query);\n    return new Promise(\n      (resolve: Resolver<firestore.QuerySnapshot<T>>, reject: Rejecter) => {\n        if (options && options.source === 'cache') {\n          this.firestore\n            .ensureClientConfigured()\n            .getDocumentsFromLocalCache(this._query)\n            .then((viewSnap: ViewSnapshot) => {\n              resolve(\n                new QuerySnapshot(\n                  this.firestore,\n                  this._query,\n                  viewSnap,\n                  this._converter\n                )\n              );\n            }, reject);\n        } else {\n          this.getViaSnapshotListener(resolve, reject, options);\n        }\n      }\n    );\n  }\n\n  private getViaSnapshotListener(\n    resolve: Resolver<firestore.QuerySnapshot<T>>,\n    reject: Rejecter,\n    options?: firestore.GetOptions\n  ): void {\n    const unlisten = this.onSnapshotInternal(\n      {\n        includeMetadataChanges: true,\n        waitForSyncWhenOnline: true\n      },\n      {\n        next: (result: firestore.QuerySnapshot<T>) => {\n          // Remove query first before passing event to user to avoid\n          // user actions affecting the now stale query.\n          unlisten();\n\n          if (\n            result.metadata.fromCache &&\n            options &&\n            options.source === 'server'\n          ) {\n            reject(\n              new FirestoreError(\n                Code.UNAVAILABLE,\n                'Failed to get documents from server. (However, these ' +\n                  'documents may exist in the local cache. Run again ' +\n                  'without setting source to \"server\" to ' +\n                  'retrieve the cached documents.)'\n              )\n            );\n          } else {\n            resolve(result);\n          }\n        },\n        error: reject\n      }\n    );\n  }\n\n  /**\n   * Parses the given documentIdValue into a ReferenceValue, throwing\n   * appropriate errors if the value is anything other than a DocumentReference\n   * or String, or if the string is malformed.\n   */\n  private parseDocumentIdValue(documentIdValue: unknown): api.Value {\n    if (typeof documentIdValue === 'string') {\n      if (documentIdValue === '') {\n        throw new FirestoreError(\n          Code.INVALID_ARGUMENT,\n          'Invalid query. When querying with FieldPath.documentId(), you ' +\n            'must provide a valid document ID, but it was an empty string.'\n        );\n      }\n      if (\n        !this._query.isCollectionGroupQuery() &&\n        documentIdValue.indexOf('/') !== -1\n      ) {\n        throw new FirestoreError(\n          Code.INVALID_ARGUMENT,\n          `Invalid query. When querying a collection by ` +\n            `FieldPath.documentId(), you must provide a plain document ID, but ` +\n            `'${documentIdValue}' contains a '/' character.`\n        );\n      }\n      const path = this._query.path.child(\n        ResourcePath.fromString(documentIdValue)\n      );\n      if (!DocumentKey.isDocumentKey(path)) {\n        throw new FirestoreError(\n          Code.INVALID_ARGUMENT,\n          `Invalid query. When querying a collection group by ` +\n            `FieldPath.documentId(), the value provided must result in a valid document path, ` +\n            `but '${path}' is not because it has an odd number of segments (${path.length}).`\n        );\n      }\n      return refValue(this.firestore._databaseId, new DocumentKey(path));\n    } else if (documentIdValue instanceof DocumentReference) {\n      const ref = documentIdValue as DocumentReference<T>;\n      return refValue(this.firestore._databaseId, ref._key);\n    } else {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        `Invalid query. When querying with FieldPath.documentId(), you must provide a valid ` +\n          `string or a DocumentReference, but it was: ` +\n          `${valueDescription(documentIdValue)}.`\n      );\n    }\n  }\n\n  /**\n   * Validates that the value passed into a disjunctrive filter satisfies all\n   * array requirements.\n   */\n  private validateDisjunctiveFilterElements(\n    value: unknown,\n    operator: Operator\n  ): void {\n    if (!Array.isArray(value) || value.length === 0) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        'Invalid Query. A non-empty array is required for ' +\n          `'${operator.toString()}' filters.`\n      );\n    }\n    if (value.length > 10) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        `Invalid Query. '${operator.toString()}' filters support a ` +\n          'maximum of 10 elements in the value array.'\n      );\n    }\n    if (value.indexOf(null) >= 0) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        `Invalid Query. '${operator.toString()}' filters cannot contain 'null' ` +\n          'in the value array.'\n      );\n    }\n    if (value.filter(element => Number.isNaN(element)).length > 0) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        `Invalid Query. '${operator.toString()}' filters cannot contain 'NaN' ` +\n          'in the value array.'\n      );\n    }\n  }\n\n  private validateNewFilter(filter: Filter): void {\n    if (filter instanceof FieldFilter) {\n      const arrayOps = [Operator.ARRAY_CONTAINS, Operator.ARRAY_CONTAINS_ANY];\n      const disjunctiveOps = [Operator.IN, Operator.ARRAY_CONTAINS_ANY];\n      const isArrayOp = arrayOps.indexOf(filter.op) >= 0;\n      const isDisjunctiveOp = disjunctiveOps.indexOf(filter.op) >= 0;\n\n      if (filter.isInequality()) {\n        const existingField = this._query.getInequalityFilterField();\n        if (existingField !== null && !existingField.isEqual(filter.field)) {\n          throw new FirestoreError(\n            Code.INVALID_ARGUMENT,\n            'Invalid query. All where filters with an inequality' +\n              ' (<, <=, >, or >=) must be on the same field. But you have' +\n              ` inequality filters on '${existingField.toString()}'` +\n              ` and '${filter.field.toString()}'`\n          );\n        }\n\n        const firstOrderByField = this._query.getFirstOrderByField();\n        if (firstOrderByField !== null) {\n          this.validateOrderByAndInequalityMatch(\n            filter.field,\n            firstOrderByField\n          );\n        }\n      } else if (isDisjunctiveOp || isArrayOp) {\n        // You can have at most 1 disjunctive filter and 1 array filter. Check if\n        // the new filter conflicts with an existing one.\n        let conflictingOp: Operator | null = null;\n        if (isDisjunctiveOp) {\n          conflictingOp = this._query.findFilterOperator(disjunctiveOps);\n        }\n        if (conflictingOp === null && isArrayOp) {\n          conflictingOp = this._query.findFilterOperator(arrayOps);\n        }\n        if (conflictingOp != null) {\n          // We special case when it's a duplicate op to give a slightly clearer error message.\n          if (conflictingOp === filter.op) {\n            throw new FirestoreError(\n              Code.INVALID_ARGUMENT,\n              'Invalid query. You cannot use more than one ' +\n                `'${filter.op.toString()}' filter.`\n            );\n          } else {\n            throw new FirestoreError(\n              Code.INVALID_ARGUMENT,\n              `Invalid query. You cannot use '${filter.op.toString()}' filters ` +\n                `with '${conflictingOp.toString()}' filters.`\n            );\n          }\n        }\n      }\n    }\n  }\n\n  private validateNewOrderBy(orderBy: OrderBy): void {\n    if (this._query.getFirstOrderByField() === null) {\n      // This is the first order by. It must match any inequality.\n      const inequalityField = this._query.getInequalityFilterField();\n      if (inequalityField !== null) {\n        this.validateOrderByAndInequalityMatch(inequalityField, orderBy.field);\n      }\n    }\n  }\n\n  private validateOrderByAndInequalityMatch(\n    inequality: FieldPath,\n    orderBy: FieldPath\n  ): void {\n    if (!orderBy.isEqual(inequality)) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        `Invalid query. You have a where filter with an inequality ` +\n          `(<, <=, >, or >=) on field '${inequality.toString()}' ` +\n          `and so you must also use '${inequality.toString()}' ` +\n          `as your first Query.orderBy(), but your first Query.orderBy() ` +\n          `is on field '${orderBy.toString()}' instead.`\n      );\n    }\n  }\n}\n\nexport class QuerySnapshot<T = firestore.DocumentData>\n  implements firestore.QuerySnapshot<T> {\n  private _cachedChanges: Array<firestore.DocumentChange<T>> | null = null;\n  private _cachedChangesIncludeMetadataChanges: boolean | null = null;\n\n  readonly metadata: firestore.SnapshotMetadata;\n\n  constructor(\n    private readonly _firestore: Firestore,\n    private readonly _originalQuery: InternalQuery,\n    private readonly _snapshot: ViewSnapshot,\n    private readonly _converter?: firestore.FirestoreDataConverter<T>\n  ) {\n    this.metadata = new SnapshotMetadata(\n      _snapshot.hasPendingWrites,\n      _snapshot.fromCache\n    );\n  }\n\n  get docs(): Array<firestore.QueryDocumentSnapshot<T>> {\n    const result: Array<firestore.QueryDocumentSnapshot<T>> = [];\n    this.forEach(doc => result.push(doc));\n    return result;\n  }\n\n  get empty(): boolean {\n    return this._snapshot.docs.isEmpty();\n  }\n\n  get size(): number {\n    return this._snapshot.docs.size;\n  }\n\n  forEach(\n    callback: (result: firestore.QueryDocumentSnapshot<T>) => void,\n    thisArg?: unknown\n  ): void {\n    validateBetweenNumberOfArgs('QuerySnapshot.forEach', arguments, 1, 2);\n    validateArgType('QuerySnapshot.forEach', 'function', 1, callback);\n    this._snapshot.docs.forEach(doc => {\n      callback.call(thisArg, this.convertToDocumentImpl(doc));\n    });\n  }\n\n  get query(): firestore.Query<T> {\n    return new Query(this._originalQuery, this._firestore, this._converter);\n  }\n\n  docChanges(\n    options?: firestore.SnapshotListenOptions\n  ): Array<firestore.DocumentChange<T>> {\n    if (options) {\n      validateOptionNames('QuerySnapshot.docChanges', options, [\n        'includeMetadataChanges'\n      ]);\n      validateNamedOptionalType(\n        'QuerySnapshot.docChanges',\n        'boolean',\n        'includeMetadataChanges',\n        options.includeMetadataChanges\n      );\n    }\n\n    const includeMetadataChanges = !!(\n      options && options.includeMetadataChanges\n    );\n\n    if (includeMetadataChanges && this._snapshot.excludesMetadataChanges) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        'To include metadata changes with your document changes, you must ' +\n          'also pass { includeMetadataChanges:true } to onSnapshot().'\n      );\n    }\n\n    if (\n      !this._cachedChanges ||\n      this._cachedChangesIncludeMetadataChanges !== includeMetadataChanges\n    ) {\n      this._cachedChanges = changesFromSnapshot<T>(\n        this._firestore,\n        includeMetadataChanges,\n        this._snapshot,\n        this._converter\n      );\n      this._cachedChangesIncludeMetadataChanges = includeMetadataChanges;\n    }\n\n    return this._cachedChanges;\n  }\n\n  /** Check the equality. The call can be very expensive. */\n  isEqual(other: firestore.QuerySnapshot<T>): boolean {\n    if (!(other instanceof QuerySnapshot)) {\n      throw invalidClassError('isEqual', 'QuerySnapshot', 1, other);\n    }\n\n    return (\n      this._firestore === other._firestore &&\n      this._originalQuery.isEqual(other._originalQuery) &&\n      this._snapshot.isEqual(other._snapshot) &&\n      this._converter === other._converter\n    );\n  }\n\n  private convertToDocumentImpl(doc: Document): QueryDocumentSnapshot<T> {\n    return new QueryDocumentSnapshot(\n      this._firestore,\n      doc.key,\n      doc,\n      this.metadata.fromCache,\n      this._snapshot.mutatedKeys.has(doc.key),\n      this._converter\n    );\n  }\n}\n\nexport class CollectionReference<T = firestore.DocumentData> extends Query<T>\n  implements firestore.CollectionReference<T> {\n  constructor(\n    readonly _path: ResourcePath,\n    firestore: Firestore,\n    _converter?: firestore.FirestoreDataConverter<T>\n  ) {\n    super(InternalQuery.atPath(_path), firestore, _converter);\n    if (_path.length % 2 !== 1) {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        'Invalid collection reference. Collection ' +\n          'references must have an odd number of segments, but ' +\n          `${_path.canonicalString()} has ${_path.length}`\n      );\n    }\n  }\n\n  get id(): string {\n    return this._query.path.lastSegment();\n  }\n\n  get parent(): firestore.DocumentReference<firestore.DocumentData> | null {\n    const parentPath = this._query.path.popLast();\n    if (parentPath.isEmpty()) {\n      return null;\n    } else {\n      return new DocumentReference<firestore.DocumentData>(\n        new DocumentKey(parentPath),\n        this.firestore\n      );\n    }\n  }\n\n  get path(): string {\n    return this._query.path.canonicalString();\n  }\n\n  doc(pathString?: string): firestore.DocumentReference<T> {\n    validateBetweenNumberOfArgs('CollectionReference.doc', arguments, 0, 1);\n    // We allow omission of 'pathString' but explicitly prohibit passing in both\n    // 'undefined' and 'null'.\n    if (arguments.length === 0) {\n      pathString = AutoId.newId();\n    }\n    validateArgType(\n      'CollectionReference.doc',\n      'non-empty string',\n      1,\n      pathString\n    );\n    if (pathString === '') {\n      throw new FirestoreError(\n        Code.INVALID_ARGUMENT,\n        'Document path must be a non-empty string'\n      );\n    }\n    const path = ResourcePath.fromString(pathString!);\n    return DocumentReference.forPath<T>(\n      this._query.path.child(path),\n      this.firestore,\n      this._converter\n    );\n  }\n\n  add(value: T): Promise<firestore.DocumentReference<T>> {\n    validateExactNumberOfArgs('CollectionReference.add', arguments, 1);\n    const convertedValue = this._converter\n      ? this._converter.toFirestore(value)\n      : value;\n    validateArgType('CollectionReference.add', 'object', 1, convertedValue);\n    const docRef = this.doc();\n    return docRef.set(value).then(() => docRef);\n  }\n\n  withConverter<U>(\n    converter: firestore.FirestoreDataConverter<U>\n  ): firestore.CollectionReference<U> {\n    return new CollectionReference<U>(this._path, this.firestore, converter);\n  }\n}\n\nfunction validateSetOptions(\n  methodName: string,\n  options: firestore.SetOptions | undefined\n): firestore.SetOptions {\n  if (options === undefined) {\n    return {\n      merge: false\n    };\n  }\n\n  validateOptionNames(methodName, options, ['merge', 'mergeFields']);\n  validateNamedOptionalType(methodName, 'boolean', 'merge', options.merge);\n  validateOptionalArrayElements(\n    methodName,\n    'mergeFields',\n    'a string or a FieldPath',\n    options.mergeFields,\n    element =>\n      typeof element === 'string' || element instanceof ExternalFieldPath\n  );\n\n  if (options.mergeFields !== undefined && options.merge !== undefined) {\n    throw new FirestoreError(\n      Code.INVALID_ARGUMENT,\n      `Invalid options passed to function ${methodName}(): You cannot specify both \"merge\" ` +\n        `and \"mergeFields\".`\n    );\n  }\n\n  return options;\n}\n\nfunction validateSnapshotOptions(\n  methodName: string,\n  options: firestore.SnapshotOptions | undefined\n): firestore.SnapshotOptions {\n  if (options === undefined) {\n    return {};\n  }\n\n  validateOptionNames(methodName, options, ['serverTimestamps']);\n  validateNamedOptionalPropertyEquals(\n    methodName,\n    'options',\n    'serverTimestamps',\n    options.serverTimestamps,\n    ['estimate', 'previous', 'none']\n  );\n  return options;\n}\n\nfunction validateGetOptions(\n  methodName: string,\n  options: firestore.GetOptions | undefined\n): void {\n  validateOptionalArgType(methodName, 'object', 1, options);\n  if (options) {\n    validateOptionNames(methodName, options, ['source']);\n    validateNamedOptionalPropertyEquals(\n      methodName,\n      'options',\n      'source',\n      options.source,\n      ['default', 'server', 'cache']\n    );\n  }\n}\n\nfunction validateReference<T>(\n  methodName: string,\n  documentRef: firestore.DocumentReference<T>,\n  firestore: Firestore\n): DocumentReference<T> {\n  if (!(documentRef instanceof DocumentReference)) {\n    throw invalidClassError(methodName, 'DocumentReference', 1, documentRef);\n  } else if (documentRef.firestore !== firestore) {\n    throw new FirestoreError(\n      Code.INVALID_ARGUMENT,\n      'Provided document reference is from a different Firestore instance.'\n    );\n  } else {\n    return documentRef;\n  }\n}\n\n/**\n * Calculates the array of firestore.DocumentChange's for a given ViewSnapshot.\n *\n * Exported for testing.\n */\nexport function changesFromSnapshot<T>(\n  firestore: Firestore,\n  includeMetadataChanges: boolean,\n  snapshot: ViewSnapshot,\n  converter?: firestore.FirestoreDataConverter<T>\n): Array<firestore.DocumentChange<T>> {\n  if (snapshot.oldDocs.isEmpty()) {\n    // Special case the first snapshot because index calculation is easy and\n    // fast\n    let lastDoc: Document;\n    let index = 0;\n    return snapshot.docChanges.map(change => {\n      const doc = new QueryDocumentSnapshot<T>(\n        firestore,\n        change.doc.key,\n        change.doc,\n        snapshot.fromCache,\n        snapshot.mutatedKeys.has(change.doc.key),\n        converter\n      );\n      debugAssert(\n        change.type === ChangeType.Added,\n        'Invalid event type for first snapshot'\n      );\n      debugAssert(\n        !lastDoc || snapshot.query.docComparator(lastDoc, change.doc) < 0,\n        'Got added events in wrong order'\n      );\n      lastDoc = change.doc;\n      return {\n        type: 'added' as firestore.DocumentChangeType,\n        doc,\n        oldIndex: -1,\n        newIndex: index++\n      };\n    });\n  } else {\n    // A DocumentSet that is updated incrementally as changes are applied to use\n    // to lookup the index of a document.\n    let indexTracker = snapshot.oldDocs;\n    return snapshot.docChanges\n      .filter(\n        change => includeMetadataChanges || change.type !== ChangeType.Metadata\n      )\n      .map(change => {\n        const doc = new QueryDocumentSnapshot<T>(\n          firestore,\n          change.doc.key,\n          change.doc,\n          snapshot.fromCache,\n          snapshot.mutatedKeys.has(change.doc.key),\n          converter\n        );\n        let oldIndex = -1;\n        let newIndex = -1;\n        if (change.type !== ChangeType.Added) {\n          oldIndex = indexTracker.indexOf(change.doc.key);\n          debugAssert(oldIndex >= 0, 'Index for document not found');\n          indexTracker = indexTracker.delete(change.doc.key);\n        }\n        if (change.type !== ChangeType.Removed) {\n          indexTracker = indexTracker.add(change.doc);\n          newIndex = indexTracker.indexOf(change.doc.key);\n        }\n        return { type: resultChangeType(change.type), doc, oldIndex, newIndex };\n      });\n  }\n}\n\nfunction resultChangeType(type: ChangeType): firestore.DocumentChangeType {\n  switch (type) {\n    case ChangeType.Added:\n      return 'added';\n    case ChangeType.Modified:\n    case ChangeType.Metadata:\n      return 'modified';\n    case ChangeType.Removed:\n      return 'removed';\n    default:\n      return fail('Unknown change type: ' + type);\n  }\n}\n\n/**\n * Converts custom model object of type T into DocumentData by applying the\n * converter if it exists.\n *\n * This function is used when converting user objects to DocumentData\n * because we want to provide the user with a more specific error message if\n * their set() or fails due to invalid data originating from a toFirestore()\n * call.\n */\nfunction applyFirestoreDataConverter<T>(\n  converter: firestore.FirestoreDataConverter<T> | undefined,\n  value: T,\n  functionName: string\n): [firestore.DocumentData, string] {\n  let convertedValue;\n  if (converter) {\n    convertedValue = converter.toFirestore(value);\n    functionName = 'toFirestore() in ' + functionName;\n  } else {\n    convertedValue = value as firestore.DocumentData;\n  }\n  return [convertedValue, functionName];\n}\n\nfunction contains(obj: object, key: string): obj is { key: unknown } {\n  return Object.prototype.hasOwnProperty.call(obj, key);\n}\n\n// Export the classes with a private constructor (it will fail if invoked\n// at runtime). Note that this still allows instanceof checks.\n\n// We're treating the variables as class names, so disable checking for lower\n// case variable names.\nexport const PublicFirestore = makeConstructorPrivate(\n  Firestore,\n  'Use firebase.firestore() instead.'\n);\nexport const PublicTransaction = makeConstructorPrivate(\n  Transaction,\n  'Use firebase.firestore().runTransaction() instead.'\n);\nexport const PublicWriteBatch = makeConstructorPrivate(\n  WriteBatch,\n  'Use firebase.firestore().batch() instead.'\n);\nexport const PublicDocumentReference = makeConstructorPrivate(\n  DocumentReference,\n  'Use firebase.firestore().doc() instead.'\n);\nexport const PublicDocumentSnapshot = makeConstructorPrivate(DocumentSnapshot);\nexport const PublicQueryDocumentSnapshot = makeConstructorPrivate(\n  QueryDocumentSnapshot\n);\nexport const PublicQuery = makeConstructorPrivate(Query);\nexport const PublicQuerySnapshot = makeConstructorPrivate(QuerySnapshot);\nexport const PublicCollectionReference = makeConstructorPrivate(\n  CollectionReference,\n  'Use firebase.firestore().collection() instead.'\n);\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { FirebaseApp, FirebaseNamespace } from '@firebase/app-types';\nimport { FirebaseAuthInternalName } from '@firebase/auth-interop-types';\nimport { _FirebaseNamespace } from '@firebase/app-types/private';\nimport { Component, ComponentType, Provider } from '@firebase/component';\nimport { PublicBlob } from '../api/blob';\nimport {\n  CACHE_SIZE_UNLIMITED,\n  Firestore,\n  PublicCollectionReference,\n  PublicDocumentReference,\n  PublicDocumentSnapshot,\n  PublicFirestore,\n  PublicQuery,\n  PublicQueryDocumentSnapshot,\n  PublicQuerySnapshot,\n  PublicTransaction,\n  PublicWriteBatch\n} from '../api/database';\nimport { FieldPath } from '../api/field_path';\nimport { PublicFieldValue } from '../api/field_value';\nimport { GeoPoint } from '../api/geo_point';\nimport { Timestamp } from '../api/timestamp';\n\nconst firestoreNamespace = {\n  Firestore: PublicFirestore,\n  GeoPoint,\n  Timestamp,\n  Blob: PublicBlob,\n  Transaction: PublicTransaction,\n  WriteBatch: PublicWriteBatch,\n  DocumentReference: PublicDocumentReference,\n  DocumentSnapshot: PublicDocumentSnapshot,\n  Query: PublicQuery,\n  QueryDocumentSnapshot: PublicQueryDocumentSnapshot,\n  QuerySnapshot: PublicQuerySnapshot,\n  CollectionReference: PublicCollectionReference,\n  FieldPath,\n  FieldValue: PublicFieldValue,\n  setLogLevel: Firestore.setLogLevel,\n  CACHE_SIZE_UNLIMITED\n};\n\n/**\n * Configures Firestore as part of the Firebase SDK by calling registerService.\n *\n * @param firebase The FirebaseNamespace to register Firestore with\n * @param firestoreFactory A factory function that returns a new Firestore\n *    instance.\n */\nexport function configureForFirebase(\n  firebase: FirebaseNamespace,\n  firestoreFactory: (\n    app: FirebaseApp,\n    auth: Provider<FirebaseAuthInternalName>\n  ) => Firestore\n): void {\n  (firebase as _FirebaseNamespace).INTERNAL.registerComponent(\n    new Component(\n      'firestore',\n      container => {\n        const app = container.getProvider('app').getImmediate()!;\n        return firestoreFactory(app, container.getProvider('auth-internal'));\n      },\n      ComponentType.PUBLIC\n    ).setServiceProps({ ...firestoreNamespace })\n  );\n}\n","/**\n * @license\n * Copyright 2019 Google Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { ConnectivityMonitor, NetworkStatus } from './connectivity_monitor';\n\nexport class NoopConnectivityMonitor implements ConnectivityMonitor {\n  addCallback(callback: (status: NetworkStatus) => void): void {\n    // No-op.\n  }\n\n  shutdown(): void {\n    // No-op.\n  }\n}\n","/**\n * @license\n * Copyright 2019 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { logDebug } from '../util/log';\nimport {\n  ConnectivityMonitor,\n  ConnectivityMonitorCallback,\n  NetworkStatus\n} from './../remote/connectivity_monitor';\n\nconst LOG_TAG = 'ConnectivityMonitor';\n\n/**\n * Browser implementation of ConnectivityMonitor.\n */\nexport class BrowserConnectivityMonitor implements ConnectivityMonitor {\n  private readonly networkAvailableListener = (): void =>\n    this.onNetworkAvailable();\n  private readonly networkUnavailableListener = (): void =>\n    this.onNetworkUnavailable();\n  private callbacks: ConnectivityMonitorCallback[] = [];\n\n  constructor() {\n    this.configureNetworkMonitoring();\n  }\n\n  addCallback(callback: (status: NetworkStatus) => void): void {\n    this.callbacks.push(callback);\n  }\n\n  shutdown(): void {\n    window.removeEventListener('online', this.networkAvailableListener);\n    window.removeEventListener('offline', this.networkUnavailableListener);\n  }\n\n  private configureNetworkMonitoring(): void {\n    window.addEventListener('online', this.networkAvailableListener);\n    window.addEventListener('offline', this.networkUnavailableListener);\n  }\n\n  private onNetworkAvailable(): void {\n    logDebug(LOG_TAG, 'Network connectivity changed: AVAILABLE');\n    for (const callback of this.callbacks) {\n      callback(NetworkStatus.AVAILABLE);\n    }\n  }\n\n  private onNetworkUnavailable(): void {\n    logDebug(LOG_TAG, 'Network connectivity changed: UNAVAILABLE');\n    for (const callback of this.callbacks) {\n      callback(NetworkStatus.UNAVAILABLE);\n    }\n  }\n\n  // TODO(chenbrian): Consider passing in window either into this component or\n  // here for testing via FakeWindow.\n  /** Checks that all used attributes of window are available. */\n  static isAvailable(): boolean {\n    return (\n      typeof window !== 'undefined' &&\n      window.addEventListener !== undefined &&\n      window.removeEventListener !== undefined\n    );\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { debugAssert } from '../util/assert';\nimport { FirestoreError } from '../util/error';\n\nimport { Stream } from './connection';\n\n/**\n * Provides a simple helper class that implements the Stream interface to\n * bridge to other implementations that are streams but do not implement the\n * interface. The stream callbacks are invoked with the callOn... methods.\n */\nexport class StreamBridge<I, O> implements Stream<I, O> {\n  private wrappedOnOpen: (() => void) | undefined;\n  private wrappedOnClose: ((err?: FirestoreError) => void) | undefined;\n  private wrappedOnMessage: ((msg: O) => void) | undefined;\n\n  private sendFn: (msg: I) => void;\n  private closeFn: () => void;\n\n  constructor(args: { sendFn: (msg: I) => void; closeFn: () => void }) {\n    this.sendFn = args.sendFn;\n    this.closeFn = args.closeFn;\n  }\n\n  onOpen(callback: () => void): void {\n    debugAssert(!this.wrappedOnOpen, 'Called onOpen on stream twice!');\n    this.wrappedOnOpen = callback;\n  }\n\n  onClose(callback: (err?: FirestoreError) => void): void {\n    debugAssert(!this.wrappedOnClose, 'Called onClose on stream twice!');\n    this.wrappedOnClose = callback;\n  }\n\n  onMessage(callback: (msg: O) => void): void {\n    debugAssert(!this.wrappedOnMessage, 'Called onMessage on stream twice!');\n    this.wrappedOnMessage = callback;\n  }\n\n  close(): void {\n    this.closeFn();\n  }\n\n  send(msg: I): void {\n    this.sendFn(msg);\n  }\n\n  callOnOpen(): void {\n    debugAssert(\n      this.wrappedOnOpen !== undefined,\n      'Cannot call onOpen because no callback was set'\n    );\n    this.wrappedOnOpen();\n  }\n\n  callOnClose(err?: FirestoreError): void {\n    debugAssert(\n      this.wrappedOnClose !== undefined,\n      'Cannot call onClose because no callback was set'\n    );\n    this.wrappedOnClose(err);\n  }\n\n  callOnMessage(msg: O): void {\n    debugAssert(\n      this.wrappedOnMessage !== undefined,\n      'Cannot call onMessage because no callback was set'\n    );\n    this.wrappedOnMessage(msg);\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  createWebChannelTransport,\n  ErrorCode,\n  EventType,\n  WebChannel,\n  WebChannelError,\n  WebChannelOptions,\n  XhrIo\n} from '@firebase/webchannel-wrapper';\n\nimport {\n  isBrowserExtension,\n  isElectron,\n  isIE,\n  isMobileCordova,\n  isReactNative,\n  isUWP\n} from '@firebase/util';\n\nimport { Token } from '../api/credentials';\nimport { DatabaseId, DatabaseInfo } from '../core/database_info';\nimport { SDK_VERSION } from '../core/version';\nimport { Connection, Stream } from '../remote/connection';\nimport {\n  mapCodeFromRpcStatus,\n  mapCodeFromHttpResponseErrorStatus\n} from '../remote/rpc_error';\nimport { StreamBridge } from '../remote/stream_bridge';\nimport { debugAssert, fail, hardAssert } from '../util/assert';\nimport { Code, FirestoreError } from '../util/error';\nimport { logDebug } from '../util/log';\nimport { Indexable } from '../util/misc';\nimport { Rejecter, Resolver } from '../util/promise';\nimport { StringMap } from '../util/types';\n\nconst LOG_TAG = 'Connection';\n\nconst RPC_STREAM_SERVICE = 'google.firestore.v1.Firestore';\nconst RPC_URL_VERSION = 'v1';\n\n/**\n * Maps RPC names to the corresponding REST endpoint name.\n * Uses Object Literal notation to avoid renaming.\n */\nconst RPC_NAME_REST_MAPPING: { [key: string]: string } = {};\nRPC_NAME_REST_MAPPING['BatchGetDocuments'] = 'batchGet';\nRPC_NAME_REST_MAPPING['Commit'] = 'commit';\n\n// TODO(b/38203344): The SDK_VERSION is set independently from Firebase because\n// we are doing out-of-band releases. Once we release as part of Firebase, we\n// should use the Firebase version instead.\nconst X_GOOG_API_CLIENT_VALUE = 'gl-js/ fire/' + SDK_VERSION;\n\nconst XHR_TIMEOUT_SECS = 15;\n\nexport class WebChannelConnection implements Connection {\n  private readonly databaseId: DatabaseId;\n  private readonly baseUrl: string;\n  private readonly forceLongPolling: boolean;\n\n  constructor(info: DatabaseInfo) {\n    this.databaseId = info.databaseId;\n    const proto = info.ssl ? 'https' : 'http';\n    this.baseUrl = proto + '://' + info.host;\n    this.forceLongPolling = info.forceLongPolling;\n  }\n\n  /**\n   * Modifies the headers for a request, adding any authorization token if\n   * present and any additional headers for the request.\n   */\n  private modifyHeadersForRequest(\n    headers: StringMap,\n    token: Token | null\n  ): void {\n    if (token) {\n      for (const header in token.authHeaders) {\n        if (token.authHeaders.hasOwnProperty(header)) {\n          headers[header] = token.authHeaders[header];\n        }\n      }\n    }\n    headers['X-Goog-Api-Client'] = X_GOOG_API_CLIENT_VALUE;\n  }\n\n  invokeRPC<Req, Resp>(\n    rpcName: string,\n    request: Req,\n    token: Token | null\n  ): Promise<Resp> {\n    const url = this.makeUrl(rpcName);\n\n    return new Promise((resolve: Resolver<Resp>, reject: Rejecter) => {\n      const xhr = new XhrIo();\n      xhr.listenOnce(EventType.COMPLETE, () => {\n        try {\n          switch (xhr.getLastErrorCode()) {\n            case ErrorCode.NO_ERROR:\n              const json = xhr.getResponseJson() as Resp;\n              logDebug(LOG_TAG, 'XHR received:', JSON.stringify(json));\n              resolve(json);\n              break;\n            case ErrorCode.TIMEOUT:\n              logDebug(LOG_TAG, 'RPC \"' + rpcName + '\" timed out');\n              reject(\n                new FirestoreError(Code.DEADLINE_EXCEEDED, 'Request time out')\n              );\n              break;\n            case ErrorCode.HTTP_ERROR:\n              const status = xhr.getStatus();\n              logDebug(\n                LOG_TAG,\n                'RPC \"' + rpcName + '\" failed with status:',\n                status,\n                'response text:',\n                xhr.getResponseText()\n              );\n              if (status > 0) {\n                const responseError = (xhr.getResponseJson() as WebChannelError)\n                  .error;\n                if (\n                  !!responseError &&\n                  !!responseError.status &&\n                  !!responseError.message\n                ) {\n                  const firestoreErrorCode = mapCodeFromHttpResponseErrorStatus(\n                    responseError.status\n                  );\n                  reject(\n                    new FirestoreError(\n                      firestoreErrorCode,\n                      responseError.message\n                    )\n                  );\n                } else {\n                  reject(\n                    new FirestoreError(\n                      Code.UNKNOWN,\n                      'Server responded with status ' + xhr.getStatus()\n                    )\n                  );\n                }\n              } else {\n                // If we received an HTTP_ERROR but there's no status code,\n                // it's most probably a connection issue\n                logDebug(LOG_TAG, 'RPC \"' + rpcName + '\" failed');\n                reject(\n                  new FirestoreError(Code.UNAVAILABLE, 'Connection failed.')\n                );\n              }\n              break;\n            default:\n              fail(\n                'RPC \"' +\n                  rpcName +\n                  '\" failed with unanticipated ' +\n                  'webchannel error ' +\n                  xhr.getLastErrorCode() +\n                  ': ' +\n                  xhr.getLastError() +\n                  ', giving up.'\n              );\n          }\n        } finally {\n          logDebug(LOG_TAG, 'RPC \"' + rpcName + '\" completed.');\n        }\n      });\n\n      // The database field is already encoded in URL. Specifying it again in\n      // the body is not necessary in production, and will cause duplicate field\n      // errors in the Firestore Emulator. Let's remove it.\n      const jsonObj = ({ ...request } as unknown) as Indexable;\n      delete jsonObj.database;\n\n      const requestString = JSON.stringify(jsonObj);\n      logDebug(LOG_TAG, 'XHR sending: ', url + ' ' + requestString);\n      // Content-Type: text/plain will avoid preflight requests which might\n      // mess with CORS and redirects by proxies. If we add custom headers\n      // we will need to change this code to potentially use the\n      // $httpOverwrite parameter supported by ESF to avoid\n      // triggering preflight requests.\n      const headers: StringMap = { 'Content-Type': 'text/plain' };\n\n      this.modifyHeadersForRequest(headers, token);\n\n      xhr.send(url, 'POST', requestString, headers, XHR_TIMEOUT_SECS);\n    });\n  }\n\n  invokeStreamingRPC<Req, Resp>(\n    rpcName: string,\n    request: Req,\n    token: Token | null\n  ): Promise<Resp[]> {\n    // The REST API automatically aggregates all of the streamed results, so we\n    // can just use the normal invoke() method.\n    return this.invokeRPC<Req, Resp[]>(rpcName, request, token);\n  }\n\n  openStream<Req, Resp>(\n    rpcName: string,\n    token: Token | null\n  ): Stream<Req, Resp> {\n    const urlParts = [\n      this.baseUrl,\n      '/',\n      RPC_STREAM_SERVICE,\n      '/',\n      rpcName,\n      '/channel'\n    ];\n    const webchannelTransport = createWebChannelTransport();\n    const request: WebChannelOptions = {\n      // Required for backend stickiness, routing behavior is based on this\n      // parameter.\n      httpSessionIdParam: 'gsessionid',\n      initMessageHeaders: {},\n      messageUrlParams: {\n        // This param is used to improve routing and project isolation by the\n        // backend and must be included in every request.\n        database: `projects/${this.databaseId.projectId}/databases/${this.databaseId.database}`\n      },\n      sendRawJson: true,\n      supportsCrossDomainXhr: true,\n      internalChannelParams: {\n        // Override the default timeout (randomized between 10-20 seconds) since\n        // a large write batch on a slow internet connection may take a long\n        // time to send to the backend. Rather than have WebChannel impose a\n        // tight timeout which could lead to infinite timeouts and retries, we\n        // set it very large (5-10 minutes) and rely on the browser's builtin\n        // timeouts to kick in if the request isn't working.\n        forwardChannelRequestTimeoutMs: 10 * 60 * 1000\n      },\n      forceLongPolling: this.forceLongPolling\n    };\n\n    this.modifyHeadersForRequest(request.initMessageHeaders!, token);\n\n    // Sending the custom headers we just added to request.initMessageHeaders\n    // (Authorization, etc.) will trigger the browser to make a CORS preflight\n    // request because the XHR will no longer meet the criteria for a \"simple\"\n    // CORS request:\n    // https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS#Simple_requests\n    //\n    // Therefore to avoid the CORS preflight request (an extra network\n    // roundtrip), we use the httpHeadersOverwriteParam option to specify that\n    // the headers should instead be encoded into a special \"$httpHeaders\" query\n    // parameter, which is recognized by the webchannel backend. This is\n    // formally defined here:\n    // https://github.com/google/closure-library/blob/b0e1815b13fb92a46d7c9b3c30de5d6a396a3245/closure/goog/net/rpc/httpcors.js#L32\n    //\n    // TODO(b/145624756): There is a backend bug where $httpHeaders isn't respected if the request\n    // doesn't have an Origin header. So we have to exclude a few browser environments that are\n    // known to (sometimes) not include an Origin. See\n    // https://github.com/firebase/firebase-js-sdk/issues/1491.\n    if (\n      !isMobileCordova() &&\n      !isReactNative() &&\n      !isElectron() &&\n      !isIE() &&\n      !isUWP() &&\n      !isBrowserExtension()\n    ) {\n      request.httpHeadersOverwriteParam = '$httpHeaders';\n    }\n\n    const url = urlParts.join('');\n    logDebug(LOG_TAG, 'Creating WebChannel: ' + url + ' ' + request);\n    const channel = webchannelTransport.createWebChannel(url, request);\n\n    // WebChannel supports sending the first message with the handshake - saving\n    // a network round trip. However, it will have to call send in the same\n    // JS event loop as open. In order to enforce this, we delay actually\n    // opening the WebChannel until send is called. Whether we have called\n    // open is tracked with this variable.\n    let opened = false;\n\n    // A flag to determine whether the stream was closed (by us or through an\n    // error/close event) to avoid delivering multiple close events or sending\n    // on a closed stream\n    let closed = false;\n\n    const streamBridge = new StreamBridge<Req, Resp>({\n      sendFn: (msg: Req) => {\n        if (!closed) {\n          if (!opened) {\n            logDebug(LOG_TAG, 'Opening WebChannel transport.');\n            channel.open();\n            opened = true;\n          }\n          logDebug(LOG_TAG, 'WebChannel sending:', msg);\n          channel.send(msg);\n        } else {\n          logDebug(LOG_TAG, 'Not sending because WebChannel is closed:', msg);\n        }\n      },\n      closeFn: () => channel.close()\n    });\n\n    // Closure events are guarded and exceptions are swallowed, so catch any\n    // exception and rethrow using a setTimeout so they become visible again.\n    // Note that eventually this function could go away if we are confident\n    // enough the code is exception free.\n    const unguardedEventListen = <T>(\n      type: string,\n      fn: (param?: T) => void\n    ): void => {\n      // TODO(dimond): closure typing seems broken because WebChannel does\n      // not implement goog.events.Listenable\n      channel.listen(type, (param: unknown) => {\n        try {\n          fn(param as T);\n        } catch (e) {\n          setTimeout(() => {\n            throw e;\n          }, 0);\n        }\n      });\n    };\n\n    unguardedEventListen(WebChannel.EventType.OPEN, () => {\n      if (!closed) {\n        logDebug(LOG_TAG, 'WebChannel transport opened.');\n      }\n    });\n\n    unguardedEventListen(WebChannel.EventType.CLOSE, () => {\n      if (!closed) {\n        closed = true;\n        logDebug(LOG_TAG, 'WebChannel transport closed');\n        streamBridge.callOnClose();\n      }\n    });\n\n    unguardedEventListen<Error>(WebChannel.EventType.ERROR, err => {\n      if (!closed) {\n        closed = true;\n        logDebug(LOG_TAG, 'WebChannel transport errored:', err);\n        streamBridge.callOnClose(\n          new FirestoreError(\n            Code.UNAVAILABLE,\n            'The operation could not be completed'\n          )\n        );\n      }\n    });\n\n    // WebChannel delivers message events as array. If batching is not enabled\n    // (it's off by default) each message will be delivered alone, resulting in\n    // a single element array.\n    interface WebChannelResponse {\n      data: Resp[];\n    }\n\n    unguardedEventListen<WebChannelResponse>(\n      WebChannel.EventType.MESSAGE,\n      msg => {\n        if (!closed) {\n          const msgData = msg!.data[0];\n          hardAssert(!!msgData, 'Got a webchannel message without data.');\n          // TODO(b/35143891): There is a bug in One Platform that caused errors\n          // (and only errors) to be wrapped in an extra array. To be forward\n          // compatible with the bug we need to check either condition. The latter\n          // can be removed once the fix has been rolled out.\n          // Use any because msgData.error is not typed.\n          const msgDataOrError: WebChannelError | object = msgData;\n          const error =\n            msgDataOrError.error ||\n            (msgDataOrError as WebChannelError[])[0]?.error;\n          if (error) {\n            logDebug(LOG_TAG, 'WebChannel received error:', error);\n            // error.status will be a string like 'OK' or 'NOT_FOUND'.\n            const status: string = error.status;\n            let code = mapCodeFromRpcStatus(status);\n            let message = error.message;\n            if (code === undefined) {\n              code = Code.INTERNAL;\n              message =\n                'Unknown error status: ' +\n                status +\n                ' with message ' +\n                error.message;\n            }\n            // Mark closed so no further events are propagated\n            closed = true;\n            streamBridge.callOnClose(new FirestoreError(code, message));\n            channel.close();\n          } else {\n            logDebug(LOG_TAG, 'WebChannel received:', msgData);\n            streamBridge.callOnMessage(msgData);\n          }\n        }\n      }\n    );\n\n    setTimeout(() => {\n      // Technically we could/should wait for the WebChannel opened event,\n      // but because we want to send the first message with the WebChannel\n      // handshake we pretend the channel opened here (asynchronously), and\n      // then delay the actual open until the first message is sent.\n      streamBridge.callOnOpen();\n    }, 0);\n    return streamBridge;\n  }\n\n  // visible for testing\n  makeUrl(rpcName: string): string {\n    const urlRpcName = RPC_NAME_REST_MAPPING[rpcName];\n    debugAssert(\n      urlRpcName !== undefined,\n      'Unknown REST mapping for: ' + rpcName\n    );\n    return (\n      this.baseUrl +\n      '/' +\n      RPC_URL_VERSION +\n      '/projects/' +\n      this.databaseId.projectId +\n      '/databases/' +\n      this.databaseId.database +\n      '/documents:' +\n      urlRpcName\n    );\n  }\n}\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport firebase from '@firebase/app';\nimport { FirebaseNamespace } from '@firebase/app-types';\n\nimport { Firestore } from './src/api/database';\nimport { IndexedDbComponentProvider } from './src/core/component_provider';\nimport { configureForFirebase } from './src/platform/config';\nimport { name, version } from './package.json';\n\nimport './register-module';\nimport './src/platform_browser/browser_init';\n\n/**\n * Registers the main Firestore build with the components framework.\n * Persistence can be enabled via `firebase.firestore().enablePersistence()`.\n */\nexport function registerFirestore(instance: FirebaseNamespace): void {\n  configureForFirebase(\n    instance,\n    (app, auth) => new Firestore(app, auth, new IndexedDbComponentProvider())\n  );\n  instance.registerVersion(name, version);\n}\n\nregisterFirestore(firebase);\n","/**\n * @license\n * Copyright 2017 Google Inc.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { PlatformSupport } from '../platform/platform';\nimport { BrowserPlatform } from './browser_platform';\n\n/**\n * This code needs to run before Firestore is used. This can be achieved in\n * several ways:\n *   1) Through the JSCompiler compiling this code and then (automatically)\n *      executing it before exporting the Firestore symbols.\n *   2) Through importing this module first in a Firestore main module\n */\nPlatformSupport.setPlatform(new BrowserPlatform());\n","/**\n * @license\n * Copyright 2017 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *   http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { DatabaseId, DatabaseInfo } from '../core/database_info';\nimport { Platform } from '../platform/platform';\nimport { Connection } from '../remote/connection';\nimport { JsonProtoSerializer } from '../remote/serializer';\nimport { ConnectivityMonitor } from './../remote/connectivity_monitor';\n\nimport { NoopConnectivityMonitor } from '../remote/connectivity_monitor_noop';\nimport { BrowserConnectivityMonitor } from './browser_connectivity_monitor';\nimport { WebChannelConnection } from './webchannel_connection';\n\nexport class BrowserPlatform implements Platform {\n  readonly useProto3Json = true;\n  readonly base64Available: boolean;\n\n  constructor() {\n    this.base64Available = typeof atob !== 'undefined';\n  }\n\n  get document(): Document | null {\n    return typeof document !== 'undefined' ? document : null;\n  }\n\n  get window(): Window | null {\n    return typeof window !== 'undefined' ? window : null;\n  }\n\n  loadConnection(databaseInfo: DatabaseInfo): Promise<Connection> {\n    return Promise.resolve(new WebChannelConnection(databaseInfo));\n  }\n\n  newConnectivityMonitor(): ConnectivityMonitor {\n    if (BrowserConnectivityMonitor.isAvailable()) {\n      return new BrowserConnectivityMonitor();\n    } else {\n      return new NoopConnectivityMonitor();\n    }\n  }\n\n  newSerializer(databaseId: DatabaseId): JsonProtoSerializer {\n    return new JsonProtoSerializer(databaseId, { useProto3Json: true });\n  }\n\n  formatJSON(value: unknown): string {\n    return JSON.stringify(value);\n  }\n\n  atob(encoded: string): string {\n    return atob(encoded);\n  }\n\n  btoa(raw: string): string {\n    return btoa(raw);\n  }\n}\n"],"names":["SDK_VERSION","firebase","User","[object Object]","uid","this","__PRIVATE_otherUser","Code","OK","CANCELLED","UNKNOWN","INVALID_ARGUMENT","DEADLINE_EXCEEDED","NOT_FOUND","ALREADY_EXISTS","PERMISSION_DENIED","UNAUTHENTICATED","RESOURCE_EXHAUSTED","FAILED_PRECONDITION","ABORTED","OUT_OF_RANGE","UNIMPLEMENTED","INTERNAL","UNAVAILABLE","DATA_LOSS","FirestoreError","Error","code","message","super","toString","name","value","user","Promise","resolve","__PRIVATE_changeListener","__PRIVATE_authProvider","currentUser","auth","getImmediate","optional","addAuthTokenListener","get","then","__PRIVATE_initialTokenCounter","forceRefresh","getToken","__PRIVATE_tokenData","__PRIVATE_hardAssert","accessToken","removeAuthTokenListener","__PRIVATE_currentUid","getUid","__PRIVATE_gapi","__PRIVATE_sessionIndex","h","headers","X-Goog-AuthUser","__PRIVATE_authHeader","Timestamp","seconds","nanoseconds","fromMillis","Date","now","date","getTime","milliseconds","Math","floor","toMillis","other","__PRIVATE_primitiveComparator","__PRIVATE_adjustedSeconds","String","padStart","timestamp","__PRIVATE_SnapshotVersion","MIN","isEqual","segments","offset","length","undefined","fail","__PRIVATE_BasePath","__PRIVATE_nameOrPath","slice","limit","forEach","__PRIVATE_segment","push","size","index","__PRIVATE_i","__PRIVATE_potentialChild","fn","end","p1","p2","__PRIVATE_len","min","left","right","ResourcePath","join","path","indexOf","split","filter","__PRIVATE_identifierRegExp","FieldPath","test","map","str","replace","__PRIVATE_current","__PRIVATE_addCurrentSegment","__PRIVATE_inBackticks","c","next","collectionId","k1","k2","__PRIVATE_DocumentKey","__PRIVATE_comparator","root","__PRIVATE_LLRBNode","EMPTY","key","remove","node","cmp","__PRIVATE_prunedNodes","action","k","v","__PRIVATE_descriptions","__PRIVATE_startKey","__PRIVATE_isReverse","pop","result","color","RED","n","__PRIVATE_smallest","__PRIVATE_nl","__PRIVATE_nr","__PRIVATE_blackDepth","pow","data","__PRIVATE_elem","cb","range","__PRIVATE_iter","start","has","add","__PRIVATE_thisIt","__PRIVATE_otherIt","__PRIVATE_thisElem","__PRIVATE_otherElem","__PRIVATE_res","targetId","obj","count","Object","prototype","hasOwnProperty","call","__PRIVATE_binaryString","base64","__PRIVATE_PlatformSupport","atob","array","fromCharCode","__PRIVATE_binaryStringFromUint8Array","btoa","buffer","Uint8Array","charCodeAt","__PRIVATE_uint8ArrayFromBinaryString","isSafeInteger","Number","isInteger","__PRIVATE_isNegativeZero","MAX_SAFE_INTEGER","MIN_SAFE_INTEGER","__PRIVATE_ByteString","mapValue","fields","stringValue","__PRIVATE_localWriteTime","__PRIVATE_normalizeTimestamp","nanos","__PRIVATE_ISO_TIMESTAMP_REG_EXP","RegExp","__PRIVATE_isServerTimestamp","JSON","stringify","__PRIVATE_leftType","__PRIVATE_typeOrder","booleanValue","__PRIVATE_getLocalWriteTime","timestampValue","__PRIVATE_leftTimestamp","__PRIVATE_rightTimestamp","__PRIVATE_timestampEquals","__PRIVATE_normalizeByteString","__PRIVATE_blobEquals","referenceValue","__PRIVATE_normalizeNumber","geoPointValue","latitude","longitude","__PRIVATE_geoPointEquals","integerValue","__PRIVATE_n1","__PRIVATE_n2","isNaN","__PRIVATE_numberEquals","__PRIVATE_arrayEquals","arrayValue","values","__PRIVATE_leftMap","__PRIVATE_rightMap","__PRIVATE_objectSize","__PRIVATE_valueEquals","__PRIVATE_objectEquals","__PRIVATE_haystack","__PRIVATE_needle","find","__PRIVATE_rightType","__PRIVATE_leftNumber","doubleValue","__PRIVATE_rightNumber","__PRIVATE_compareNumbers","__PRIVATE_compareTimestamps","__PRIVATE_leftBytes","__PRIVATE_rightBytes","__PRIVATE_compareBlobs","__PRIVATE_leftPath","__PRIVATE_rightPath","__PRIVATE_leftSegments","__PRIVATE_rightSegments","__PRIVATE_comparison","__PRIVATE_compareReferences","__PRIVATE_compareGeoPoints","__PRIVATE_leftArray","__PRIVATE_rightArray","compare","__PRIVATE_valueCompare","__PRIVATE_compareArrays","__PRIVATE_leftKeys","keys","__PRIVATE_rightKeys","sort","__PRIVATE_keyCompare","__PRIVATE_compareMaps","canonicalId","__PRIVATE_canonifyValue","__PRIVATE_normalizedTimestamp","__PRIVATE_canonifyTimestamp","toBase64","__PRIVATE_geoPoint","first","__PRIVATE_canonifyArray","__PRIVATE_sortedKeys","__PRIVATE_canonifyMap","__PRIVATE_fraction","exec","__PRIVATE_nanoStr","substr","__PRIVATE_parsedDate","blob","fromBase64String","fromUint8Array","__PRIVATE_databaseId","projectId","database","isArray","previousValue","__type__","__local_write_time__","serverTimestamp","__PRIVATE_transformResult","__PRIVATE_ServerTimestampTransform","elements","apply","__PRIVATE_coercedFieldValuesArray","__PRIVATE_toUnion","some","element","__PRIVATE_toRemove","serializer","__PRIVATE_operand","__PRIVATE_baseValue","__PRIVATE_sum","asNumber","__PRIVATE_isDouble","__PRIVATE_fieldsAsSet","fieldPath","found","__PRIVATE_fieldMaskPath","FieldTransform","field","transform","version","transformResults","Precondition","updateTime","exists","Ht","__PRIVATE_maybeDoc","Document","__PRIVATE_Mutation","__PRIVATE_precondition","__PRIVATE_mutationResult","hasCommittedMutations","__PRIVATE_baseDoc","te","__PRIVATE_fieldMask","__PRIVATE_newData","__PRIVATE_ObjectValue","__PRIVATE_builder","newValue","set","delete","fieldTransforms","doc","__PRIVATE_baseObject","__PRIVATE_fieldTransform","__PRIVATE_existingValue","__PRIVATE_coercedValue","__PRIVATE_l","r","__PRIVATE_serverTransformResults","proto","__PRIVATE_isMapValue","__PRIVATE_currentPath","__PRIVATE_nestedFields","__PRIVATE_nestedPath","child","__PRIVATE_FieldMask","Map","__PRIVATE_currentLevel","__PRIVATE_currentSegment","currentValue","entries","__PRIVATE_mergedResult","__PRIVATE_currentOverlays","__PRIVATE_modified","__PRIVATE_resultAtPath","__PRIVATE_pathSegment","__PRIVATE_nested","__PRIVATE_d1","__PRIVATE_d2","__PRIVATE_MaybeDocument","__PRIVATE_objectValue","options","hasPendingWrites","v1","v2","Target","collectionGroup","orderBy","filters","startAt","endAt","f","o","__PRIVATE_isNullOrUndefined","Query","__PRIVATE_explicitOrderBy","__PRIVATE_limitType","__PRIVATE_inequalityField","__PRIVATE_firstOrderByField","__PRIVATE_foundKeyOrdering","__PRIVATE_lastDirection","dir","__PRIVATE_Direction","ASCENDING","__PRIVATE_newFilters","concat","__PRIVATE_newOrderBy","bound","__PRIVATE_comparedOnKeyField","__PRIVATE_comp","FieldFilter","__PRIVATE_operators","op","__PRIVATE_orderBys","DESCENDING","position","before","__PRIVATE_docPath","matches","__PRIVATE_Operator","LESS_THAN","LESS_THAN_OR_EQUAL","EQUAL","GREATER_THAN_OR_EQUAL","GREATER_THAN","ARRAY_CONTAINS","IN","ARRAY_CONTAINS_ANY","__PRIVATE_isNullValue","__PRIVATE_isNanValue","__PRIVATE_arrayValueContains","val","p","__PRIVATE_orderByComponent","component","__PRIVATE_KEY_ORDERING_ASC","__PRIVATE_KEY_ORDERING_DESC","target","__PRIVATE_purpose","sequenceNumber","__PRIVATE_snapshotVersion","lastLimboFreeSnapshotVersion","resumeToken","ExistenceFilter","__PRIVATE_logError","__PRIVATE_RpcCode","RpcCode","__PRIVATE_EMPTY_MAYBE_DOCUMENT_MAP","__PRIVATE_maybeDocumentMap","__PRIVATE_EMPTY_DOCUMENT_MAP","__PRIVATE_EMPTY_DOCUMENT_VERSION_MAP","__PRIVATE_EMPTY_DOCUMENT_KEY_SET","__PRIVATE_EMPTY_TARGET_ID_SET","__PRIVATE_documentMap","__PRIVATE_oldSet","__PRIVATE_thisDoc","__PRIVATE_otherDoc","__PRIVATE_docStrings","__PRIVATE_keyedMap","__PRIVATE_sortedSet","__PRIVATE_newSet","__PRIVATE_change","__PRIVATE_oldChange","type","__PRIVATE_changes","query","docs","__PRIVATE_oldDocs","docChanges","__PRIVATE_mutatedKeys","fromCache","__PRIVATE_syncStateChanged","__PRIVATE_excludesMetadataChanges","documents","__PRIVATE_DocumentSet","__PRIVATE_otherChanges","__PRIVATE_targetChanges","__PRIVATE_targetMismatches","__PRIVATE_documentUpdates","__PRIVATE_resolvedLimboDocuments","TargetChange","__PRIVATE_targetIdSet","__PRIVATE_documentKeySet","__PRIVATE_addedDocuments","__PRIVATE_modifiedDocuments","__PRIVATE_removedDocuments","__PRIVATE_updatedTargetIds","removedTargetIds","__PRIVATE_newDoc","__PRIVATE_existenceFilter","state","targetIds","cause","__PRIVATE_snapshotChangesMap","As","Ns","Fs","__PRIVATE_changeType","__PRIVATE_metadataProvider","__PRIVATE_documentTargetMap","__PRIVATE_docChange","targetChange","__PRIVATE_targetState","removeTarget","__PRIVATE__","__PRIVATE_watchChange","__PRIVATE_expectedCount","__PRIVATE_targetData","__PRIVATE_targets","__PRIVATE_isOnlyLimboTarget","__PRIVATE_remoteEvent","document","__PRIVATE_updatedDocument","__PRIVATE_targetMapping","__PRIVATE_targetActive","__PRIVATE_logDebug","__PRIVATE_DIRECTIONS","__PRIVATE_dirs","__PRIVATE_OPERATORS","__PRIVATE_ops","status","__PRIVATE_mapCodeFromRpcCode","Infinity","toISOString","bytes","toUint8Array","__PRIVATE_resource","__PRIVATE_isValidResourceName","__PRIVATE_resourceName","pn","fromVersion","missing","readTime","targetChangeType","__PRIVATE_causeProto","documentChange","__PRIVATE_entityChange","documentDelete","__PRIVATE_docDelete","documentRemove","__PRIVATE_docRemove","__PRIVATE_mutation","update","updateMask","verify","currentDocument","NONE","toVersion","commitTime","__PRIVATE_protos","setToServerValue","appendMissingElements","removeAllFromArray","increment","instance","__PRIVATE_documentsTarget","structuredQuery","parent","from","allDescendants","where","__PRIVATE_fromCount","__PRIVATE_filterBy","goog-listen-tags","compositeFilter","unaryFilter","fieldFilter","reduce","__PRIVATE_accum","order","cursor","__PRIVATE_fieldReference","direction","create","__PRIVATE_nanField","NaN","__PRIVATE_nullField","nullValue","__PRIVATE_canonicalFields","fieldPaths","platform","__PRIVATE_logClient","Logger","logLevel","setLogLevel","__PRIVATE_newLevel","msg","LogLevel","DEBUG","args","debug","ERROR","error","e","__PRIVATE_failure","assertion","__PRIVATE_chars","__PRIVATE_autoId","charAt","random","every","s","persistenceKey","host","ssl","forceLongPolling","wi","__PRIVATE_mapKeyFn","id","__PRIVATE_otherKey","splice","__PRIVATE_isEmpty","batchId","baseMutations","mutations","__PRIVATE_docKey","__PRIVATE_batchResult","__PRIVATE_mutationResults","__PRIVATE_maybeDocs","__PRIVATE_mutatedDocuments","__PRIVATE_m","__PRIVATE_mutatedDocument","batch","__PRIVATE_commitVersion","streamToken","__PRIVATE_docVersions","results","__PRIVATE_versionMap","__PRIVATE_documentVersionMap","__PRIVATE_DocReference","ref","__PRIVATE_emptyKey","__PRIVATE_startRef","__PRIVATE_endRef","__PRIVATE_firstRef","__PRIVATE_targetOrBatchId","PersistencePromise","callback","__PRIVATE_nextFn","__PRIVATE_catchFn","reject","all","__PRIVATE_resolvedCount","done","__PRIVATE_err","__PRIVATE_predicates","predicate","__PRIVATE_isTrue","collection","__PRIVATE_promises","__PRIVATE_maybeDocument","transaction","__PRIVATE_documentKey","__PRIVATE_bufferedEntry","__PRIVATE_documentKeys","__PRIVATE_PRIMARY_LEASE_LOST_ERROR_MSG","listener","__PRIVATE_remoteDocumentCache","__PRIVATE_mutationQueue","__PRIVATE_indexManager","__PRIVATE_batches","__PRIVATE_inBatches","__PRIVATE_nullableMaybeDocumentMap","__PRIVATE_localView","getEntries","__PRIVATE_baseDocs","__PRIVATE_sinceReadTime","__PRIVATE_parents","__PRIVATE_collectionQuery","__PRIVATE_mutationBatches","__PRIVATE_queryResults","__PRIVATE_matchingMutationBatches","__PRIVATE_mergedDocuments","__PRIVATE_mutatedDoc","__PRIVATE_existingDocuments","__PRIVATE_missingBaseDocEntriesForPatching","__PRIVATE_missingBaseDocs","__PRIVATE_addedKeys","__PRIVATE_removedKeys","__PRIVATE_viewSnapshot","__PRIVATE_sequenceNumberSyncer","__PRIVATE_externalPreviousValue","max","__PRIVATE_nextValue","__PRIVATE_ListenSequence","promise","__PRIVATE_asyncQueue","__PRIVATE_timerId","__PRIVATE_targetTimeMs","__PRIVATE_removalCallback","bind","catch","__PRIVATE_delayMs","__PRIVATE_targetTime","__PRIVATE_delayedOp","setTimeout","reason","clearTimeout","Hr","enqueue","__PRIVATE_newTail","stack","__PRIVATE_DelayedOperation","__PRIVATE_removedOp","__PRIVATE_currentTail","__PRIVATE_lastTimerId","a","b","__PRIVATE_aSequence","__PRIVATE_aIndex","__PRIVATE_bSequence","__PRIVATE_bIndex","__PRIVATE_seqCmp","__PRIVATE_maxElements","__PRIVATE_entry","__PRIVATE_highestValue","last","__PRIVATE_bufferEntryComparator","maxValue","__PRIVATE_GC_DID_NOT_RUN","lo","do","fo","To","__PRIVATE_cacheSizeCollectionThreshold","__PRIVATE_percentileToCollect","__PRIVATE_maximumSequenceNumbersToCollect","__PRIVATE_cacheSize","__PRIVATE_LruParams","__PRIVATE_garbageCollector","__PRIVATE_localStore","cancel","ko","delay","__PRIVATE_delegate","__PRIVATE_params","txn","__PRIVATE_percentile","targetCount","upperBound","activeTargetIds","__PRIVATE_upperBoundSequenceNumber","__PRIVATE_sequenceNumbersToCollect","__PRIVATE_targetsRemoved","__PRIVATE_countedTargetsTs","__PRIVATE_foundUpperBoundTs","__PRIVATE_removedTargetsTs","__PRIVATE_removedDocumentsTs","__PRIVATE_startTs","__PRIVATE_sequenceNumbers","__PRIVATE_numTargetsRemoved","__PRIVATE_documentsRemoved","__PRIVATE_getLogLevel","persistence","__PRIVATE_queryEngine","__PRIVATE_initialUser","t","__PRIVATE_newMutationQueue","__PRIVATE_newLocalDocuments","runTransaction","__PRIVATE_oldBatches","__PRIVATE_promisedOldBatches","__PRIVATE_newBatches","__PRIVATE_removedBatchIds","__PRIVATE_addedBatchIds","__PRIVATE_changedKeys","__PRIVATE_affectedDocuments","ah","uh","_h","__PRIVATE_existingDocs","zi","__PRIVATE_affected","__PRIVATE_documentBuffer","Eh","__PRIVATE_affectedKeys","__PRIVATE_remoteVersion","__PRIVATE_newTargetDataByTargetMap","__PRIVATE_oldTargetData","__PRIVATE_newTargetData","__PRIVATE_LocalStore","__PRIVATE_changedDocs","__PRIVATE_updatedKeys","__PRIVATE_existingDoc","__PRIVATE_updateRemoteVersion","lastRemoteSnapshotVersion","__PRIVATE_viewChanges","__PRIVATE_viewChange","__PRIVATE_updatedTargetData","__PRIVATE_afterBatchId","__PRIVATE_cached","__PRIVATE_keepPersistedTargetData","mode","__PRIVATE_removed","__PRIVATE_usePreviousResults","__PRIVATE_remoteKeys","zh","networkEnabled","__PRIVATE_docKeys","__PRIVATE_promiseChain","__PRIVATE_remoteDoc","__PRIVATE_ackVersion","__PRIVATE_cachedTargetData","sa","async","functionName","__PRIVATE_formatPlural","__PRIVATE_numberOfArgs","__PRIVATE_minNumberOfArgs","__PRIVATE_maxNumberOfArgs","__PRIVATE_argument","__PRIVATE_validateType","__PRIVATE_ordinal","__PRIVATE_validateArgType","__PRIVATE_optionName","__PRIVATE_validateNamedType","__PRIVATE_typeDescription","__PRIVATE_validator","Array","__PRIVATE_valueDescription","__PRIVATE_validateArrayElements","__PRIVATE_inputName","input","__PRIVATE_expected","__PRIVATE_expectedDescription","__PRIVATE_actualDescription","__PRIVATE_validateNamedPropertyEquals","valid","__PRIVATE_isPlainObject","description","getPrototypeOf","substring","__PRIVATE_customObjectName","constructor","__PRIVATE_tryGetCustomObjectType","__PRIVATE_optionNames","num","__PRIVATE_cls","__PRIVATE_optionalMessage","__PRIVATE_PublicConstructor","assign","Blob","__PRIVATE_byteString","__PRIVATE_assertBase64Available","__PRIVATE_validateExactNumberOfArgs","arguments","__PRIVATE_assertUint8ArrayAvailable","__PRIVATE_invalidClassError","__PRIVATE_PublicBlob","__PRIVATE_makeConstructorPrivate","fieldNames","__PRIVATE_minNumberOfElements","__PRIVATE_validateNamedArrayAtLeastNumberOfElements","__PRIVATE_InternalFieldPath","__PRIVATE_RESERVED","__PRIVATE__methodName","__PRIVATE_validateNoArgs","__PRIVATE_DeleteFieldValueImpl","__PRIVATE_ServerTimestampFieldValueImpl","__PRIVATE_validateAtLeastNumberOfArgs","__PRIVATE_FieldValueImpl","__PRIVATE__elements","__PRIVATE__operand","__PRIVATE_PublicFieldValue","GeoPoint","isFinite","__PRIVATE_RESERVED_FIELD_REGEX","__PRIVATE_dataSource","methodName","__PRIVATE_arrayElement","__PRIVATE_childPath","context","__PRIVATE_fieldDescription","__PRIVATE_isWrite","__PRIVATE_preConverter","__PRIVATE_validatePlainObject","__PRIVATE_updateData","__PRIVATE_validatedFieldPaths","__PRIVATE_stringOrFieldPath","__PRIVATE_fieldPathFromDotSeparatedString","contains","__PRIVATE_fieldMaskPaths","__PRIVATE_childContext","__PRIVATE_parsedValue","mask","moreFieldsAndValues","__PRIVATE_fieldPathFromArgument","__PRIVATE_allowArrays","__PRIVATE_errorMessage","__PRIVATE_looksLikeJsonObject","__PRIVATE_entryIndex","__PRIVATE_parsedEntry","__PRIVATE_parsedElements","arrayUnion","arrayRemove","__PRIVATE_numericIncrement","fromDate","bytesValue","search","__PRIVATE_fromDotSeparatedString","__PRIVATE_queue","__PRIVATE_initialDelayMs","__PRIVATE_backoffFactor","__PRIVATE_maxDelayMs","reset","__PRIVATE_desiredDelayWithJitterMs","__PRIVATE_delaySoFarMs","__PRIVATE_remainingDelayMs","__PRIVATE_connectionTimerId","__PRIVATE_idleTimerId","__PRIVATE_connection","__PRIVATE_credentialsProvider","close","stream","send","__PRIVATE_finalState","__PRIVATE_dispatchIfNotClosed","__PRIVATE_closeCount","token","__PRIVATE_rpcError","onMessage","__PRIVATE_startCloseCount","__PRIVATE_PersistentStream","credentials","__PRIVATE_watchChangeProto","snapshot","request","addTarget","labels","wu","__PRIVATE_responseProto","lastStreamToken","writeResults","writes","response","__PRIVATE_rpcName","Transaction","__PRIVATE_datastore","Set","write","__PRIVATE_unwritten","__PRIVATE__version","commit","__PRIVATE_docVersion","__PRIVATE_existingVersion","__PRIVATE_onlineStateHandler","__PRIVATE_newState","details","__PRIVATE_connectivityMonitor","_u","ou","du","Ru","Iu","enableNetwork","stop","isPrimary","__PRIVATE_requestTargetData","__PRIVATE_lastBatchIdRetrieved","shift","__PRIVATE_success","__PRIVATE_MutationBatchResult","__PRIVATE_errorHandling","__PRIVATE_isPermanentError","createWebStorageClientStateKey","clientId","createWebStorageMutationBatchKey","__PRIVATE_mutationKey","createWebStorageQueryTargetMetadataKey","__PRIVATE_mutationBatch","parse","__PRIVATE_validData","__PRIVATE_firestoreError","__PRIVATE_batchMetadata","updateTimeMs","__PRIVATE_clientState","__PRIVATE_activeTargetIdsSet","onlineState","__PRIVATE_localClientId","__PRIVATE_WebStorageSharedClientState","__PRIVATE_escapedPersistenceKey","storage","window","localStorage","createWebStorageSequenceNumberKey","createWebStorageOnlineStateKey","addEventListener","__PRIVATE_existingClients","__PRIVATE_storageItem","getItem","__PRIVATE_RemoteClientState","__PRIVATE_onlineStateJSON","event","setItem","__PRIVATE_activeTargets","__PRIVATE_queryState","metadata","__PRIVATE_QueryTargetMetadata","removeItem","removeEventListener","storageArea","__PRIVATE_mutationMetadata","__PRIVATE_queryTargetMetadata","__PRIVATE_seqString","__PRIVATE_parsed","__PRIVATE_fromWebStorageSequenceNumber","i_","__PRIVATE_mutationState","__PRIVATE_targetKey","__PRIVATE_targetMetadata","match","userId","__PRIVATE_MutationMetadata","__PRIVATE_SharedOnlineState","__PRIVATE_existingTargets","__PRIVATE_newTargets","__PRIVATE_addedTargets","__PRIVATE_removedTargets","__PRIVATE_lastId","__PRIVATE__syncedDocuments","C_","__PRIVATE_previousChanges","__PRIVATE_changeSet","__PRIVATE_oldDocumentSet","__PRIVATE_newMutatedKeys","__PRIVATE_newDocumentSet","__PRIVATE_needsRefill","__PRIVATE_lastDocInLimit","__PRIVATE_firstDocInLimit","__PRIVATE_newMaybeDoc","__PRIVATE_oldDoc","__PRIVATE_oldDocHadPendingMutations","__PRIVATE_newDocHasPendingMutations","__PRIVATE_changeApplied","track","D_","N_","M_","_s","__PRIVATE_updateLimboDocuments","__PRIVATE_c1","__PRIVATE_c2","__PRIVATE_compareChangeType","__PRIVATE_limboChanges","__PRIVATE_newSyncState","x_","__PRIVATE_oldLimboDocuments","__PRIVATE_queryResult","__PRIVATE_ViewSnapshot","__PRIVATE_remoteStore","updateFunction","__PRIVATE_deferred","__PRIVATE_userPromise","__PRIVATE_commitError","__PRIVATE_userPromiseError","view","__PRIVATE_sharedClientState","__PRIVATE_maxConcurrentLimboResolutions","q","__PRIVATE_TargetIdGenerator","cl","__PRIVATE_syncEngineListener","__PRIVATE_queryView","listen","__PRIVATE_viewDocChanges","__PRIVATE_synthesizedTargetChange","__PRIVATE_queries","__PRIVATE_userCallback","__PRIVATE_limboResolution","__PRIVATE_ignoreIfPrimaryLeaseLoss","source","__PRIVATE_newViewSnapshots","__PRIVATE_limboKey","__PRIVATE_batchState","__PRIVATE_mutationBatchResult","__PRIVATE_highestBatchId","__PRIVATE_callbacks","clear","__PRIVATE_newCallbacks","__PRIVATE_limboKeys","__PRIVATE_limboTargetId","__PRIVATE_limboChange","__PRIVATE_newSnaps","__PRIVATE_docChangesInAllViews","__PRIVATE_queriesProcessed","__PRIVATE_LocalViewChanges","__PRIVATE_fnName","__PRIVATE_userChanged","__PRIVATE_activeQueries","__PRIVATE_synthesizedRemoteEvent","__PRIVATE_RemoteEvent","__PRIVATE_added","disableNetwork","__PRIVATE_keySet","__PRIVATE_syncEngine","subscribe","__PRIVATE_firstListen","__PRIVATE_queryInfo","__PRIVATE_lastListen","__PRIVATE_viewSnaps","__PRIVATE_raisedEvent","__PRIVATE_viewSnap","onError","observer","__PRIVATE_queryObserver","__PRIVATE_snap","includeMetadataChanges","__PRIVATE_maybeOnline","__PRIVATE_hasPendingWritesChanged","__PRIVATE_localDocuments","__PRIVATE_previousResults","__PRIVATE_updatedResults","__PRIVATE_sortedPreviousResults","__PRIVATE_limboFreeSnapshotVersion","__PRIVATE_docAtLimitEdge","__PRIVATE_encodeSeparator","__PRIVATE_encodeSegment","__PRIVATE_resultBuf","__PRIVATE_escapeChar","__PRIVATE_lastReasonableEscapeIndex","__PRIVATE_segmentBuilder","__PRIVATE_currentPiece","db","__PRIVATE_SimpleDb","getUA","__PRIVATE_schemaConverter","indexedDB","open","onsuccess","onblocked","onerror","onupgradeneeded","oldVersion","createOrUpgrade","SCHEMA_VERSION","__PRIVATE_wrapRequest","deleteDatabase","navigator","__PRIVATE_ua","__PRIVATE_iOSVersion","__PRIVATE_isUnsupportedIOS","__PRIVATE_androidVersion","__PRIVATE_isUnsupportedAndroid","__PRIVATE_process","store","__PRIVATE_iOSVersionRegex","__PRIVATE_androidVersionRegex","__PRIVATE_versionChangeListener","onversionchange","__PRIVATE_objectStores","__PRIVATE_transactionFn","__PRIVATE_readonly","__PRIVATE_attemptNumber","__PRIVATE_SimpleDbTransaction","__PRIVATE_transactionFnResult","abort","__PRIVATE_retryable","__PRIVATE_dbCursor","Bi","ad","oncomplete","onabort","__PRIVATE_checkForAndReportiOSError","objectStoreNames","nd","aborted","__PRIVATE_storeName","objectStore","__PRIVATE_keyOrValue","put","__PRIVATE_indexOrRange","control","__PRIVATE_optionsOrCallback","__PRIVATE_cursorRequest","primaryKey","__PRIVATE_shouldContinue","continue","controller","__PRIVATE_userResult","__PRIVATE_indexName","reverse","openKeyCursor","openCursor","__PRIVATE_reportedIOSError","__PRIVATE_IOS_ERROR","__PRIVATE_newError","__PRIVATE_referenceDelegate","empty","IDBKeyRange","NEGATIVE_INFINITY","POSITIVE_INFINITY","__PRIVATE_mutationsStore","DbMutationBatch","userMutationsIndex","__PRIVATE_mutationQueuesStore","__PRIVATE_documentStore","__PRIVATE_documentMutationsStore","__PRIVATE_mutationStore","__PRIVATE_dbBatch","__PRIVATE_collectionParents","__PRIVATE_indexKey","DbDocumentMutation","PLACEHOLDER","__PRIVATE_nextBatchId","lowerBound","__PRIVATE_foundBatch","__PRIVATE_dbBatches","__PRIVATE_indexPrefix","prefixForPath","__PRIVATE_indexStart","__PRIVATE_userID","__PRIVATE_encodedPath","__PRIVATE_decodeResourcePath","__PRIVATE_uniqueBatchIDs","__PRIVATE_batchID","__PRIVATE_queryPath","__PRIVATE_immediateChildrenLength","__PRIVATE_batchIDs","__PRIVATE_removeMutationBatch","__PRIVATE_startRange","prefixForUser","__PRIVATE_danglingMutationReferences","__PRIVATE_mutationQueueContainsKey","DbMutationQueue","__PRIVATE_containsKey","Td","keyPath","__PRIVATE_indexTxn","only","__PRIVATE_numDeleted","__PRIVATE_removePromise","__PRIVATE_IndexedDbPersistence","__PRIVATE_targetIdGenerator","highestTargetId","__PRIVATE_getHighestListenSequenceNumber","highestListenSequenceNumber","__PRIVATE_targetsStore","__PRIVATE_retrieveMetadata","DbTargetGlobal","updated","DbTarget","queryTargetsIndexName","__PRIVATE_documentTargetStore","__PRIVATE_encodeResourcePath","DbTargetDocument","__PRIVATE_immediateSuccessor","documentTargetsIndex","__PRIVATE_targetGlobal","__PRIVATE_remoteDocumentsStore","__PRIVATE_dbKey","__PRIVATE_sizeDelta","getMetadata","byteSize","__PRIVATE_dbRemoteDoc","Ud","__PRIVATE_dbDocumentSize","__PRIVATE_sizeMap","Wd","jd","__PRIVATE_keyIter","__PRIVATE_nextKey","__PRIVATE_potentialKeyRaw","__PRIVATE_potentialKey","__PRIVATE_immediateChildrenPathLength","__PRIVATE_iterationOptions","__PRIVATE_collectionKey","__PRIVATE_readTimeKey","DbRemoteDocument","collectionReadTimeIndex","__PRIVATE_lastReadTime","__PRIVATE_documentsStore","readTimeIndex","__PRIVATE_IndexedDbRemoteDocumentCache","__PRIVATE_documentGlobalStore","DbRemoteDocumentGlobal","unknownDocument","noDocument","__PRIVATE_RemoteDocumentChangeBuffer","__PRIVATE_documentCache","__PRIVATE_trackRemovals","__PRIVATE_previousSize","__PRIVATE_deletedDoc","updateMetadata","__PRIVATE_getResult","__PRIVATE_maybeDocuments","collectionPath","parentPath","__PRIVATE_existingParents","SchemaConverter","__PRIVATE_simpleDbTransaction","createObjectStore","DbPrimaryClient","__PRIVATE_createPrimaryClientStore","autoIncrement","createIndex","userMutationsKeyPath","unique","__PRIVATE_createMutationQueue","__PRIVATE_createQueryCache","__PRIVATE_createRemoteDocumentCache","deleteObjectStore","__PRIVATE_dropQueryCache","__PRIVATE_globalStore","__PRIVATE_writeEmptyTargetGlobalEntry","__PRIVATE_existingMutations","__PRIVATE_v3MutationsStore","__PRIVATE_writeAll","__PRIVATE_upgradeMutationBatchSchemaAndMigrateData","DbClientMetadata","__PRIVATE_createClientMetadataStore","removeAcknowledgedMutations","__PRIVATE_createDocumentGlobalStore","addDocumentGlobal","ensureSequenceNumbers","createCollectionParentIndex","__PRIVATE_dropRemoteDocumentChangesStore","__PRIVATE_remoteDocumentStore","readTimeIndexPath","collectionReadTimeIndexPath","__PRIVATE_createRemoteDocumentReadTimeIndex","rewriteCanonicalIds","__PRIVATE_byteCount","__PRIVATE_queuesStore","__PRIVATE_queues","lastAcknowledgedBatchId","__PRIVATE_currentSequenceNumber","__PRIVATE_docSentinelKey","__PRIVATE_sentinelKey","__PRIVATE_maybeSentinel","__PRIVATE_writeSentinelKey","DbCollectionParent","__PRIVATE_collectionParentsStore","cache","__PRIVATE_addEntry","__PRIVATE_pathSegments","__PRIVATE_targetStore","__PRIVATE_originalDbTarget","__PRIVATE_originalTargetData","__PRIVATE_updatedDbTarget","DbTimestamp","ownerId","allowTabSynchronization","leaseTimestampMs","localWriteTimeMs","DbNoDocument","DbUnknownDocument","lastListenSequenceNumber","documentTargetsKeyPath","queryTargetsKeyPath","inForeground","ALL_STORES","__PRIVATE_collectionParent","__PRIVATE_parentPaths","LocalSerializer","__PRIVATE_remoteSerializer","__PRIVATE_dbReadTime","__PRIVATE_dbTimestampKey","__PRIVATE_dbTimestamp","__PRIVATE_serializedBaseMutations","__PRIVATE_serializedMutations","__PRIVATE_dbTarget","__PRIVATE_dbLastLimboFreeTimestamp","__PRIVATE_queryProto","__PRIVATE_PRIMARY_LEASE_EXCLUSIVE_ERROR_MSG","__PRIVATE_PersistenceTransaction","__PRIVATE_lruParams","__PRIVATE_primaryStateListener","__PRIVATE_primaryState","__PRIVATE_databaseDeletedListener","newVersion","__PRIVATE_clientMetadataStore","__PRIVATE_canActAsPrimary","__PRIVATE_primaryClientStore","__PRIVATE_primaryClient","__PRIVATE_metadataStore","active","__PRIVATE_inactive","__PRIVATE_client","__PRIVATE_inactiveClient","__PRIVATE_currentPrimary","__PRIVATE_otherClient","__PRIVATE_otherClientHasBetterNetworkState","__PRIVATE_otherClientHasBetterVisibility","__PRIVATE_otherClientHasSameNetworkState","__PRIVATE_clients","__PRIVATE_activityThresholdMs","__PRIVATE_clientMetadata","__PRIVATE_dbName","__PRIVATE_IndexedDbMutationQueue","__PRIVATE_transactionOperation","__PRIVATE_simpleDbMode","__PRIVATE_persistenceTransaction","__PRIVATE_simpleDbTxn","__PRIVATE_holdsPrimaryLease","__PRIVATE_newPrimary","__PRIVATE_databaseInfo","__PRIVATE_maxAgeMs","visibilityState","__PRIVATE_isZombied","__PRIVATE_docCountPromise","__PRIVATE_docCount","__PRIVATE_orphanedCount","__PRIVATE_inMemoryPins","__PRIVATE_mutationQueuesContainKey","__PRIVATE_changeBuffer","__PRIVATE_documentCount","__PRIVATE_isPinned","__PRIVATE_nextPath","__PRIVATE_nextToReport","__PRIVATE_sentinelRow","__PRIVATE_batchIndex","__PRIVATE_rawIndex","prefix","__PRIVATE_startPath","__PRIVATE_rowKeyPath","__PRIVATE_references","__PRIVATE_sizer","__PRIVATE_currentSize","iterator","__PRIVATE_MemoryRemoteDocumentCache","__PRIVATE_removals","__PRIVATE_matchingKeys","__PRIVATE_referenceDelegateFactory","lT","__PRIVATE_isReferenced","__PRIVATE_persistenceSettings","synchronizeTabs","$a","wf","cacheSizeBytes","rf","clearPersistence","__PRIVATE_MEMORY_ONLY_PERSISTENCE_ERROR_MESSAGE","__PRIVATE_MemoryEagerDelegate","__PRIVATE_AutoId","__PRIVATE_componentProvider","__PRIVATE_initializationDone","__PRIVATE_persistenceResult","__PRIVATE_initialized","initialize","terminate","console","warn","IT","DOMException","yT","muted","eventHandler","__PRIVATE_methods","object","method","__PRIVATE_implementsAnyMethods","firestore","timestampsInSnapshots","__PRIVATE_serverTimestampBehavior","converter","__PRIVATE_getPreviousValue","__PRIVATE_normalizedValue","toDate","__PRIVATE_resourcePath","DocumentReference","CACHE_SIZE_UNLIMITED","settings","__PRIVATE_validateNamedOptionalType","__PRIVATE_validateOptionNames","experimentalForceLongPolling","Firestore","__PRIVATE_databaseIdOrApp","__PRIVATE_persistenceProvider","app","external","__PRIVATE_settingsLiteral","__PRIVATE_newSettings","__PRIVATE_makeCredentialsProvider","experimentalTabSynchronization","_removeServiceInstance","ZT","waitForPendingWrites","arg","__PRIVATE_isPartialObserver","__PRIVATE_asyncObserver","dn","__PRIVATE_thisDb","__PRIVATE_otherDb","__PRIVATE_pathString","CollectionReference","WriteBatch","SILENT","level","__PRIVATE__firestore","__PRIVATE__transaction","documentRef","__PRIVATE_validateReference","DocumentSnapshot","__PRIVATE_validateBetweenNumberOfArgs","__PRIVATE_validateSetOptions","__PRIVATE_convertedValue","__PRIVATE_applyFirestoreDataConverter","merge","mergeFields","__PRIVATE_fieldOrUpdateData","__PRIVATE__key","__PRIVATE__converter","__PRIVATE_currArg","__PRIVATE_internalOptions","__PRIVATE_validateOptionalArgType","complete","__PRIVATE_errHandler","__PRIVATE_internalListener","__PRIVATE_InternalQuery","__PRIVATE_validateGetOptions","__PRIVATE_unlisten","Kl","SnapshotMetadata","__PRIVATE__document","__PRIVATE__fromCache","__PRIVATE__hasPendingWrites","__PRIVATE_validateSnapshotOptions","QueryDocumentSnapshot","fromFirestore","serverTimestamps","__PRIVATE__query","opStr","__PRIVATE_validateDefined","__PRIVATE_fieldValue","__PRIVATE_enums","__PRIVATE_validateStringEnum","operator","__PRIVATE_referenceList","directionStr","__PRIVATE_validatePositiveNumber","__PRIVATE_docOrField","__PRIVATE_allFields","components","__PRIVATE_refValue","__PRIVATE_rawValue","__PRIVATE_wrapped","QuerySnapshot","__PRIVATE_firestoreClient","__PRIVATE_documentIdValue","__PRIVATE_arrayOps","__PRIVATE_disjunctiveOps","__PRIVATE_isArrayOp","__PRIVATE_isDisjunctiveOp","__PRIVATE_existingField","__PRIVATE_conflictingOp","__PRIVATE_inequality","__PRIVATE__originalQuery","__PRIVATE__snapshot","thisArg","__PRIVATE_lastDoc","oldIndex","newIndex","__PRIVATE_indexTracker","__PRIVATE_resultChangeType","__PRIVATE_changesFromSnapshot","__PRIVATE__path","toFirestore","__PRIVATE_docRef","__PRIVATE_validateOptionalArrayElements","__PRIVATE_validateNamedOptionalPropertyEquals","__PRIVATE_PublicFirestore","__PRIVATE_PublicTransaction","__PRIVATE_PublicWriteBatch","__PRIVATE_PublicDocumentReference","__PRIVATE_PublicDocumentSnapshot","__PRIVATE_PublicQueryDocumentSnapshot","__PRIVATE_PublicQuery","__PRIVATE_PublicQuerySnapshot","__PRIVATE_PublicCollectionReference","__PRIVATE_firestoreNamespace","FieldValue","__PRIVATE_RPC_NAME_REST_MAPPING","BatchGetDocuments","Commit","__PRIVATE_X_GOOG_API_CLIENT_VALUE","info","__PRIVATE_header","url","__PRIVATE_xhr","XhrIo","listenOnce","EventType","COMPLETE","getLastErrorCode","ErrorCode","NO_ERROR","json","getResponseJson","TIMEOUT","HTTP_ERROR","getStatus","getResponseText","__PRIVATE_responseError","__PRIVATE_firestoreErrorCode","__PRIVATE_serverError","toLowerCase","__PRIVATE_mapCodeFromHttpResponseErrorStatus","getLastError","__PRIVATE_jsonObj","__PRIVATE_requestString","Content-Type","__PRIVATE_urlParts","__PRIVATE_webchannelTransport","createWebChannelTransport","httpSessionIdParam","initMessageHeaders","messageUrlParams","sendRawJson","supportsCrossDomainXhr","internalChannelParams","forwardChannelRequestTimeoutMs","isMobileCordova","isReactNative","isElectron","isIE","isUWP","isBrowserExtension","httpHeadersOverwriteParam","channel","createWebChannel","__PRIVATE_opened","closed","__PRIVATE_streamBridge","Lm","Om","__PRIVATE_unguardedEventListen","param","WebChannel","OPEN","CLOSE","MESSAGE","__PRIVATE_msgData","__PRIVATE_msgDataOrError","__PRIVATE_mapCodeFromRpcStatus","__PRIVATE_urlRpcName","__PRIVATE_firestoreFactory","registerComponent","Component","container","getProvider","setServiceProps","__PRIVATE_configureForFirebase","registerVersion","__PRIVATE_BrowserConnectivityMonitor","__PRIVATE_encoded","raw","__PRIVATE_registerFirestore"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;sDAoBO,OAAMA,IAAcC,EAASD;;;;;;;;;;;;;;;;;;;;;UCCvBE;IASXC,YAAqBC;QAAAC,WAAAD;;IAErBD;QACE,OAAmB,QAAZE,KAAKD;;;;;WAOdD;QACE,OAAIE,WACK,SAASA,KAAKD,MAEd;;IAIXD,QAAQG;QACN,OAAOA,EAAUF,QAAQC,KAAKD;;;;8BA1BhBF,qBAAkB,IAAIA,EAAK;;;AAI3CA,MAAqC,IAAIA,EAAK,2BAC9CA,MAA8B,IAAIA,EAAK;;;;;;;;;;;;;;;;;;ACHlC,MAAMK,IAAO;;;;IAIlBC,IAAI;;IAGJC,WAAW;;IAGXC,SAAS;;;;;;;IAQTC,kBAAkB;;;;;;;;IASlBC,mBAAmB;;IAGnBC,WAAW;;;;;IAMXC,gBAAgB;;;;;;;;IAShBC,mBAAmB;;;;;IAMnBC,iBAAiB;;;;;IAMjBC,oBAAoB;;;;;;;;;;;;;;;;;;;;;IAsBpBC,qBAAqB;;;;;;;;IASrBC,SAAS;;;;;;;;;;;;;;;;IAiBTC,cAAc;;IAGdC,eAAe;;;;;IAMfC,UAAU;;;;;;;;IASVC,aAAa;;IAGbC,WAAW;;;;;;;;UASAC,UAAuBC;IAIlCvB,YAAqBwB,GAAqBC;QACxCC,MAAMD,IADavB,YAAAsB,GAAqBtB,eAAAuB,GAH1CvB,YAAO;;;;QASLA,KAAKyB,WAAW,MAAM,GAAGzB,KAAK0B,eAAe1B,KAAKsB,UAAUtB,KAAKuB;;;;;;;;;;;;;;;;;;;;IC3GnEzB,YAAY6B,GAAsBC;QAAA5B,YAAA4B,GAFlC5B,YAAO,SAGLA,SAAmB;;QAEnBA,OAAgC,gBAAI,UAAU2B;;;;;IAqClD7B;;;;;;QAMEE,SAA0D;;IAE1DF;QACE,OAAO+B,QAAQC,QAAsB;;IAGvChC;IAEAA,EAAkBiC;QAKhB/B;;QAEA+B,EAAelC,EAAKc;;IAGtBb;QAKEE,SAAsB;;;;;IA4BxBF,YAAYkC;;;;;QAnBZhC,SAAiE;;QAGzDA,mBAAoBH,EAAKc,iBACjCX,UAAuC;;;;;QAMvCA,SAAuB;;QAGvBA,SAA0D,MAElDA,qBAAe,GAKrBA,SAAqB;YACnBA,UACAA,KAAKiC,cAAcjC,UACnBA,UAA2B,GACvBA,UACFA,OAAoBA,KAAKiC;WAI7BjC,SAAoB,GAEpBA,KAAKkC,OAAOF,EAAaG,aAAa;YAAEC,WAAU;YAE9CpC,KAAKkC,OACPlC,KAAKkC,KAAKG,qBAAqBrC,KAAmB;;QAGlDA,OAAmB,OACnBgC,EAAaM,MAAMC,KACjBL;YACElC,KAAKkC,OAAOA,GACRlC;;YAEFA,KAAKkC,KAAKG,qBAAqBrC;WAGnC;;IAONF;;;;QASE,MAAM0C,IAAsBxC,QACtByC,IAAezC,KAAKyC;QAG1B,OAFAzC,KAAKyC,gBAAe,GAEfzC,KAAKkC,OAIHlC,KAAKkC,KAAKQ,SAASD,GAAcF,KAAKI;;;;YAI3C,IAAI3C,cACF,MAAM,IAAIoB,EACRlB,EAAKY,SACL;YAGF,YACE8B,GACmC,mBAA1BD,EAAUE,aACjB;YAEK,MAAeF,EAAUE,aAAa7C,KAAKiC,gBAE3C;aApBJJ,QAAQC,QAAQ;;IA0B3BhC;QACEE,KAAKyC,gBAAe;;IAGtB3C,EAAkBiC;QAKhB/B;;QAGIA,UACF+B,EAAe/B,KAAKiC;;IAIxBnC;QAUME,KAAKkC,QACPlC,KAAKkC,KAAKY,wBAAwB9C,KAAmB,IAEvDA,SAAqB,MACrBA,SAAsB;;;;;;IAOxBF;QACE,MAAMiD,IAAa/C,KAAKkC,QAAQlC,KAAKkC,KAAKc;QAK1C,OAJAJ,GACiB,SAAfG,KAA6C,sBAC7C,+BAEK,IAAIlD;;;;;;;;;;;IAwBbC,YAAoBmD,GAAoBC;gCAHxClD,YAAO,cACPA,YAAOH;;IAIPsD;QACE,MAAMC,IAAwC;YAC5CC,mBAAmBrD;WAEfsD,IAAatD,OAAUkC,OAAqC;QAIlE,aAFEkB,EAAuB,oBAElBA;;;;;;;;;IAUTtD,YAAoBmD,GAAoBC;;;IAExCpD;QACE,OAAO+B,QAAQC,QAAQ,MAAoB9B,QAAWA;;IAGxDF,EAAkBiC;;QAEhBA,EAAelC;;IAGjBC;IAEAA;;;;;;UCxTWyD;IAeXzD,YAAqB0D,GAA0BC;QAC7C,IADmBzD,eAAAwD,GAA0BxD,mBAAAyD,GACzCA,IAAc,GAChB,MAAM,IAAIrC,EACRlB,EAAKI,kBACL,yCAAyCmD;QAG7C,IAAIA,KAAe,KACjB,MAAM,IAAIrC,EACRlB,EAAKI,kBACL,yCAAyCmD;QAG7C,IAAID,KA9BY,aA+Bd,MAAM,IAAIpC,EACRlB,EAAKI,kBACL,qCAAqCkD;;gBAIzC,IAAIA,KAAW,cACb,MAAM,IAAIpC,EACRlB,EAAKI,kBACL,qCAAqCkD;;IArC3C1D;QACE,OAAOyD,EAAUG,WAAWC,KAAKC;;IAGnC9D,gBAAgB+D;QACd,OAAON,EAAUG,WAAWG,EAAKC;;IAGnChE,kBAAkBiE;QAChB,MAAMP,IAAUQ,KAAKC,MAAMF,IAAe;QAE1C,OAAO,IAAIR,EAAUC,GAD2B,OAAjCO,IAAyB,MAAVP;;IAgChC1D;QACE,OAAO,IAAI6D,KAAK3D,KAAKkE;;IAGvBpE;QACE,OAAsB,MAAfE,KAAKwD,UAAiBxD,KAAKyD,cAAc;;IAGlD3D,EAAWqE;QACT,OAAInE,KAAKwD,YAAYW,EAAMX,UAClBY,GAAoBpE,KAAKyD,aAAaU,EAAMV,eAE9CW,GAAoBpE,KAAKwD,SAASW,EAAMX;;IAGjD1D,QAAQqE;QACN,OACEA,EAAMX,YAAYxD,KAAKwD,WAAWW,EAAMV,gBAAgBzD,KAAKyD;;IAIjE3D;QACE,OACE,uBACAE,KAAKwD,UACL,mBACAxD,KAAKyD,cACL;;IAIJ3D;;;;;;;QAOE,MAAMuE,IAAkBrE,KAAKwD,WAnFb;;gBAuFhB,OAFyBc,UAAwBC,SAAS,IAAI,OAEpC,MADGD,OAAOtE,KAAKyD,aAAac,SAAS,GAAG;;;;;;;;;;;;;;;;;;;;;;;;ICzEpEzE,YAA4B0E;QAAAxE,iBAAAwE;;IAR5B1E,SAAqB6B;QACnB,OAAO,MAAoBA;;IAG7B7B;QACE,OAAO2E,EAAgBC;;IAKzB5E,EAAUqE;QACR,OAAOnE,KAAKwE,YAAqBL,EAAMK;;IAGzC1E,QAAQqE;QACN,OAAOnE,KAAKwE,UAAUG,QAAQR,EAAMK;;oFAItC1E;;QAEE,OAAgC,MAAzBE,KAAKwE,UAAUhB,UAAgBxD,KAAKwE,UAAUf,cAAc;;IAGrE3D;QACE,OAAO,qBAAqBE,KAAKwE,UAAU/C,aAAa;;IAG1D3B;QACE,OAAOE,KAAKwE;;;;AA/BEC,QAAM,MAAoB,IAAIlB,EAAU,GAAG;;;;;ACC7D;IAKEzD,YAAY8E,GAAoBC,GAAiBC;aAChCC,MAAXF,IACFA,IAAS,IACAA,IAASD,EAASE,UAC3BE,GAAK,YAAYH,IAAS,mBAAmBD,EAASE;aAGzCC,MAAXD,IACFA,IAASF,EAASE,SAASD,IAClBC,IAASF,EAASE,SAASD,KACpCG,GAAK,YAAYF,IAAS,oBAAoBF,EAASE,SAASD;QAElE7E,KAAK4E,WAAWA,GAChB5E,KAAK6E,SAASA,GACd7E,SAAW8E;;IAqBbA;QACE,OAAO9E;;IAGTF,QAAQqE;QACN,OAA4C,MAArCc,IAAoBjF,MAAMmE;;IAGnCrE,MAAMoF;QACJ,MAAMN,IAAW5E,KAAK4E,SAASO,MAAMnF,KAAK6E,QAAQ7E,KAAKoF;QAQvD,OAPIF,iBACFA,EAAWG,QAAQC;YACjBV,EAASW;aAGXX,EAASW,SAEJvF,OAAe4E;;kEAIhB9E;QACN,OAAOE,KAAK6E,SAAS7E,KAAK8E;;IAG5BhF,EAAS0F;QAMP,OALAA,SAAgBT,MAATS,IAAqB,IAAIA,GAKzBxF,OACLA,KAAK4E,UACL5E,KAAK6E,SAASW,GACdxF,KAAK8E,SAASU;;IAIlB1F;QAEE,OAAOE,OAAeA,KAAK4E,UAAU5E,KAAK6E,QAAQ7E,KAAK8E,SAAS;;IAGlEhF;QAEE,OAAOE,KAAK4E,SAAS5E,KAAK6E;;IAG5B/E;QACE,OAAOE,KAAKsC,IAAItC,KAAK8E,SAAS;;IAGhChF,IAAI2F;QAEF,OAAOzF,KAAK4E,SAAS5E,KAAK6E,SAASY;;IAGrC3F;QACE,OAAuB,MAAhBE,KAAK8E;;IAGdhF,EAAWqE;QACT,IAAIA,EAAMW,SAAS9E,KAAK8E,QACtB,QAAO;QAGT,KAAK,IAAIY,IAAI,GAAGA,IAAI1F,KAAK8E,QAAQY,KAC/B,IAAI1F,KAAKsC,WAAW6B,EAAM7B,QACxB,QAAO;QAIX,QAAO;;IAGTxC,EAAoB6F;QAClB,IAAI3F,KAAK8E,SAAS,MAAMa,EAAeb,QACrC,QAAO;QAGT,KAAK,IAAIY,IAAI,GAAGA,IAAI1F,KAAK8E,QAAQY,KAC/B,IAAI1F,KAAKsC,WAAWqD,EAAerD,QACjC,QAAO;QAIX,QAAO;;IAGTxC,QAAQ8F;QACN,KAAK,IAAIF,IAAI1F,KAAK6E,QAAQgB,IAAM7F,KAAKoF,SAASM,IAAIG,GAAKH,KACrDE,EAAG5F,KAAK4E;;IAIZ9E;QACE,OAAOE,KAAK4E,SAASO,MAAMnF,KAAK6E,QAAQ7E,KAAKoF;;IAG/CtF,SACEgG,GACAC;QAEA,MAAMC,IAAMhC,KAAKiC,IAAIH,EAAGhB,QAAQiB,EAAGjB;QACnC,KAAK,IAAIY,IAAI,GAAGA,OAASA,KAAK;YAC5B,MAAMQ,IAAOJ,EAAGxD,QACV6D,IAAQJ,EAAGzD;YACjB,IAAI4D,IAAOC,GACT,QAAQ;YAEV,IAAID,IAAOC,GACT,OAAO;;QAGX,OAAIL,EAAGhB,SAASiB,EAAGjB,UACT,IAENgB,EAAGhB,SAASiB,EAAGjB,SACV,IAEF;;;;;;;UAQEsB,UAAqBnB;IAChCnF,EACE8E,GACAC,GACAC;QAEA,OAAO,IAAIsB,EAAaxB,GAAUC,GAAQC;;IAG5ChF;;;;QAKE,OAAOE,SAAeqG,KAAK;;IAG7BvG;QACE,OAAOE;;;;WAMTF,SAAkBwG;;;;QAKhB,IAAIA,EAAKC,QAAQ,SAAS,GACxB,MAAM,IAAInF,EACRlB,EAAKI,kBACL,iBAAiBgG;;;gBAMrB,MAAM1B,IAAW0B,EAAKE,MAAM,KAAKC,OAAOnB,KAAWA,EAAQR,SAAS;QAEpE,OAAO,IAAIsB,EAAaxB;;;;AAGnBwB,MAAa,IAAIA,EAAa;;AAGvC,MAAMM,IAAmB;;gFAGZC,UAAkB1B;IAC7BnF,EACE8E,GACAC,GACAC;QAEA,OAAO,IAAI6B,EAAU/B,GAAUC,GAAQC;;;;;WAOjChF,SAAyBwF;QAC/B,OAAOoB,EAAiBE;;IAG1B9G;QACE,OAAOE,SACJ6G,IAAIC,MACHA,IAAMA,EAAIC,QAAQ,MAAM,QAAQA,QAAQ,KAAK,QACxCJ,IAA4BG,OAC/BA,IAAM,MAAMA,IAAM;QAEbA,IAERT,KAAK;;IAGVvG;QACE,OAAOE;;;;WAMTF;QACE,OAAuB,MAAhBE,KAAK8E,UAnQiB,eAmQD9E,KAAKsC,IAAI;;;;WAMvCxC;QACE,OAAO,IAAI6G,EAAU,EA1QQ;;;;;;;;;;;WAuR/B7G,SAAwBwG;QACtB,MAAM1B,IAAqB;QAC3B,IAAIoC,IAAU,IACVtB,IAAI;QAER,MAAMuB,IAAoB;YACxB,IAAuB,MAAnBD,EAAQlC,QACV,MAAM,IAAI1D,EACRlB,EAAKI,kBACL,uBAAuBgG,wCACrB;YAGN1B,EAASW,SACTyB,IAAU;;QAGZ,IAAIE,KAAc;QAElB,MAAOxB,IAAIY,EAAKxB,UAAQ;YACtB,MAAMqC,IAAIb;YACV,IAAU,SAANa,GAAY;gBACd,IAAIzB,IAAI,MAAMY,EAAKxB,QACjB,MAAM,IAAI1D,EACRlB,EAAKI,kBACL,yCAAyCgG;gBAG7C,MAAMc,IAAOd,EAAKZ,IAAI;gBACtB,IAAe,SAAT0B,KAA0B,QAATA,KAAyB,QAATA,GACrC,MAAM,IAAIhG,EACRlB,EAAKI,kBACL,uCAAuCgG;gBAG3CU,KAAWI,GACX1B,KAAK;mBACU,QAANyB,KACTD,QACAxB,OACe,QAANyB,UAITH,KAAWG,GACXzB,QAJAuB,KACAvB;;QAQJ,IAFAuB,QAGE,MAAM,IAAI7F,EACRlB,EAAKI,kBACL,6BAA6BgG;QAIjC,OAAO,IAAIK,EAAU/B;;;;AAGhB+B,MAAa,IAAIA,EAAU;;;;;;;;;;;;;;;;;;;ICjVlC7G,YAAqBwG;QAAAtG,YAAAsG;;IAQrBxG,UAAgB4B;QACd,OAAO,MAAgB0E,IAAwB1E,KAAe;;6EAIhE5B,GAAgBuH;QACd,OACErH,KAAKsG,KAAKxB,UAAU,KACpB9E,KAAKsG,KAAKhE,IAAItC,KAAKsG,KAAKxB,SAAS,OAAOuC;;IAI5CvH,QAAQqE;QACN,OACY,SAAVA,KAAqE,MAAnDiC,IAAwBpG,KAAKsG,MAAMnC,EAAMmC;;IAI/DxG;QACE,OAAOE,KAAKsG,KAAK7E;;IAKnB3B,SAAkBwH,GAAiBC;QACjC,OAAOnB,IAAwBkB,EAAGhB,MAAMiB,EAAGjB;;IAG7CxG,UAAqBwG;QACnB,OAAOA,EAAKxB,SAAS,KAAM;;;;;;;WAS7BhF,UAAoB8E;QAClB,OAAO,MAAgB,IAAIwB,EAAaxB,EAASO;;;;AAjB5CqC,UAAQ,MAAgB,IAAIpB,EAAa;;;;;;;;;;;;;;;;;;;;;ICNhDtG,YACS2H,GACPC;oBAEA1H,KAAK0H,OAAOA,KAAcC,EAASC;;;IAIrC9H,GAAO+H,GAAQlG;QACb,OAAO,MACL3B,QACAA,KAAK0H,QACKG,GAAKlG,GAAO3B,WACd,MAAM,MAAM2H,MAAgB,MAAM;;;IAK9C7H,OAAO+H;QACL,OAAO,MACL7H,QACAA,KAAK0H,KACFI,OAAOD,GAAK7H,WACP,MAAM,MAAM2H,MAAgB,MAAM;;;IAK9C7H,IAAI+H;QACF,IAAIE,IAAO/H,KAAK0H;QAChB,OAAQK,SAAgB;YACtB,MAAMC,IAAMhI,OAAgB6H,GAAKE,EAAKF;YACtC,IAAY,MAARG,GACF,OAAOD,EAAKpG;YACHqG,IAAM,IACfD,IAAOA,EAAK7B,OACH8B,IAAM,MACfD,IAAOA,EAAK5B;;QAGhB,OAAO;;;;IAKTrG,QAAQ+H;;QAEN,IAAII,IAAc,GACdF,IAAO/H,KAAK0H;QAChB,OAAQK,SAAgB;YACtB,MAAMC,IAAMhI,OAAgB6H,GAAKE,EAAKF;YACtC,IAAY,MAARG,GACF,OAAOC,IAAcF,EAAK7B,KAAKV;YACtBwC,IAAM,IACfD,IAAOA,EAAK7B;;YAGZ+B,KAAeF,EAAK7B,KAAKV,OAAO,GAChCuC,IAAOA,EAAK5B;;;gBAIhB,QAAQ;;IAGVrG;QACE,OAAOE,KAAK0H;;;IAIdlC;QACE,OAAOxF,KAAK0H,KAAKlC;;;IAInB1F;QACE,OAAOE,KAAK0H;;;IAId5H;QACE,OAAOE,KAAK0H;;;;;;IAOd5H,GAAoBoI;QAClB,OAAQlI,KAAK0H,QAAyCQ;;IAGxDpI,QAAQ8F;QACN5F,QAAsB,CAACmI,GAAGC,OACxBxC,EAAGuC,GAAGC,KACC;;IAIXtI;QACE,MAAMuI,IAAyB;QAK/B,OAJArI,QAAsB,CAACmI,GAAGC,OACxBC,EAAa9C,KAAK,GAAG4C,KAAKC,OACnB,KAEF,IAAIC,EAAahC,KAAK;;;;;;;IAQ/BvG,GAAoBoI;QAClB,OAAQlI,KAAK0H,QAAyCQ;;;IAIxDpI;QACE,OAAO,MAA4BE,KAAK0H,MAAM,MAAM1H,SAAiB;;IAGvEF,GAAgB+H;QACd,OAAO,MAA4B7H,KAAK0H,MAAMG,GAAK7H,SAAiB;;IAGtEF;QACE,OAAO,MAA4BE,KAAK0H,MAAM,MAAM1H,SAAiB;;IAGvEF,GAAuB+H;QACrB,OAAO,MAA4B7H,KAAK0H,MAAMG,GAAK7H,SAAiB;;;;;;;IAStEF,YACEiI,GACAO,GACAb,GACAc;QAEAvI,aACAA,UAAiB;QAEjB,IAAIgI,IAAM;QACV,OAAQD,SAON,IANAC,IAAMM,IAAWb,EAAWM,EAAKF,UAAiB;;cAGhDG,MAAQ,IAGNA,IAAM;;QAGND,IADE/H,UACK+H,EAAK7B,OAEL6B,EAAK5B,YAET;YAAA,IAAY,MAAR6B,GAAW;;;gBAGpBhI,QAAeuF,KAAKwC;gBACpB;;;;YAIA/H,QAAeuF,KAAKwC,IAElBA,IADE/H,UACK+H,EAAK5B,QAEL4B,EAAK7B;;;IAMpBpG;QAME,IAAIiI,IAAO/H,QAAewI;QAC1B,MAAMC,IAAS;YAAEZ,KAAKE,EAAKF;YAAKlG,OAAOoG,EAAKpG;;QAE5C,IAAI3B,SAEF,KADA+H,IAAOA,EAAK7B,OACJ6B,SACN/H,QAAeuF,KAAKwC,IACpBA,IAAOA,EAAK5B,YAId,KADA4B,IAAOA,EAAK5B,QACJ4B,SACN/H,QAAeuF,KAAKwC;QACpBA,IAAOA,EAAK7B;QAIhB,OAAOuC;;IAGT3I;QACE,OAAOE,QAAe8E,SAAS;;IAGjChF;QACE,IAA8B,MAA1BE,QAAe8E,QACjB,OAAO;QAGT,MAAMiD,IAAO/H,QAAeA,QAAe8E,SAAS;QACpD,OAAO;YAAE+C,KAAKE,EAAKF;YAAKlG,OAAOoG,EAAKpG;;;;;;;;IAkBtC7B,YACS+H,GACAlG,GACP+G,GACAxC,GACAC;QAJOnG,WAAA6H,GACA7H,aAAA2B,GAKP3B,KAAK0I,QAAiB,QAATA,IAAgBA,IAAQf,EAASgB,KAC9C3I,KAAKkG,OAAe,QAARA,IAAeA,IAAOyB,EAASC;QAC3C5H,KAAKmG,QAAiB,QAATA,IAAgBA,IAAQwB,EAASC,OAC9C5H,KAAKwF,OAAOxF,KAAKkG,KAAKV,OAAO,IAAIxF,KAAKmG,MAAMX;;;IAI9C1F,GACE+H,GACAlG,GACA+G,GACAxC,GACAC;QAEA,OAAO,MACE,QAAP0B,IAAcA,IAAM7H,KAAK6H,KAChB,QAATlG,IAAgBA,IAAQ3B,KAAK2B,OACpB,QAAT+G,IAAgBA,IAAQ1I,KAAK0I,OACrB,QAARxC,IAAeA,IAAOlG,KAAKkG,MAClB,QAATC,IAAgBA,IAAQnG,KAAKmG;;IAIjCrG;QACE,QAAO;;;;;;IAOTA,GAAoBoI;QAClB,OACGlI,KAAKkG,QAAyCgC,MAC/CA,EAAOlI,KAAK6H,KAAK7H,KAAK2B,UACrB3B,KAAKmG,SAA0C+B;;;;;;IAQpDpI,GAAoBoI;QAClB,OACGlI,KAAKmG,SAA0C+B,MAChDA,EAAOlI,KAAK6H,KAAK7H,KAAK2B,UACrB3B,KAAKkG,QAAyCgC;;;IAK3CpI;QACN,OAAIE,KAAKkG,WACAlG,OAECA,KAAKkG,KAAwBD;;;IAKzCnG;QACE,OAAOE,KAAKiG,MAAM4B;;;IAIpB/H;QACE,OAAIE,KAAKmG,YACAnG,KAAK6H,MAEL7H,KAAKmG;;;IAKhBrG,GAAO+H,GAAQlG,GAAU8F;QACvB,IAAImB,IAAoB5I;QACxB,MAAMgI,IAAMP,EAAWI,GAAKe,EAAEf;QAc9B,OAZEe,IADEZ,IAAM,IACJY,KAAO,MAAM,MAAM,MAAMA,EAAE1C,QAAY2B,GAAKlG,OAAoB,QACnD,MAARqG,IACLY,KAAO,MAAMjH,GAAO,MAAM,MAAM,QAEhCiH,KACF,MACA,MACA,MACA,MACAA,EAAEzC,SAAa0B,GAAKlG;QAGjBiH;;IAGT9I;QACE,IAAIE,KAAKkG,UACP,OAAOyB,EAASC;QAElB,IAAIgB,IAAoB5I;QAKxB,OAJK4I,EAAE1C,aAAiB0C,EAAE1C,KAAKA,cAC7B0C,IAAIA,SAENA,IAAIA,KAAO,MAAM,MAAM,MAAOA,EAAE1C,WAAqC;QAC9D0C;;;IAIT9I,OACE+H,GACAJ;QAEA,IAAIoB,GACAD,IAAoB5I;QACxB,IAAIyH,EAAWI,GAAKe,EAAEf,OAAO,GACtBe,EAAE1C,YAAmB0C,EAAE1C,aAAiB0C,EAAE1C,KAAKA,cAClD0C,IAAIA;QAENA,IAAIA,KAAO,MAAM,MAAM,MAAMA,EAAE1C,KAAK4B,OAAOD,OAAkB,YACxD;YAOL,IANIe,EAAE1C,cACJ0C,IAAIA,SAEDA,EAAEzC,aAAoByC,EAAEzC,cAAkByC,EAAEzC,MAAMD,cACrD0C,IAAIA;YAEyB,MAA3BnB,EAAWI,GAAKe,EAAEf,MAAY;gBAChC,IAAIe,EAAEzC,WACJ,OAAOwB,EAASC;gBAEhBiB,IAAYD,EAAEzC,MAAyBF,OACvC2C,IAAIA,KACFC,EAAShB,KACTgB,EAASlH,OACT,MACA,MACCiH,EAAEzC;;YAITyC,IAAIA,KAAO,MAAM,MAAM,MAAM,MAAMA,EAAEzC,MAAM2B,OAAOD;;QAEpD,OAAOe;;IAGT9I;QACE,OAAOE,KAAK0I;;;IAId5I;QACE,IAAI8I,IAAoB5I;QAUxB,OATI4I,EAAEzC,eAAkByC,EAAE1C,cACxB0C,IAAIA,SAEFA,EAAE1C,aAAgB0C,EAAE1C,KAAKA,cAC3B0C,IAAIA;QAEFA,EAAE1C,aAAgB0C,EAAEzC,eACtByC,IAAIA,SAECA;;IAGT9I;QACE,IAAI8I,IAAI5I;QAYR,OAXI4I,EAAEzC,MAAMD,cACV0C,IAAIA,KACF,MACA,MACA,MACA,MACCA,EAAEzC,aAELyC,IAAIA;QACJA,IAAIA,SAECA;;IAGT9I;QACE,IAAI8I,IAAI5I;QAKR,OAJI4I,EAAE1C,KAAKA,cACT0C,IAAIA,QACJA,IAAIA,SAECA;;IAGT9I;QACE,MAAMgJ,IAAK9I,QAAU,MAAM,MAAM2H,EAASgB,KAAK,MAAM3I,KAAKmG,MAAMD;QAChE,OAAQlG,KAAKmG,SACX,MACA,MACAnG,KAAK0I,UAEL;;IAIJ5I;QACE,MAAMiJ,IAAK/I,QAAU,MAAM,MAAM2H,EAASgB,KAAK3I,KAAKkG,KAAKC,OAAO;QAChE,OAAQnG,KAAKkG,QAA6B,MAAM,MAAMlG,KAAK0I,OAAO;;IAGpE5I;QACE,MAAMoG,IAAOlG,KAAKkG,QAAU,MAAM,OAAOlG,KAAKkG,KAAKwC,OAAO,MAAM,OAC1DvC,IAAQnG,KAAKmG,SAAW,MAAM,OAAOnG,KAAKmG,MAAMuC,OAAO,MAAM;QACnE,OAAO1I,QAAU,MAAM,OAAOA,KAAK0I,OAAOxC,GAAMC;;;IAIlDrG;QACE,MAAMkJ,IAAahJ;QACnB,OAAIgE,KAAKiF,IAAI,SAAoBjJ,KAAKwF,OAAO;;;;IAS/C1F;QACE,IAAIE,aAAgBA,KAAKkG,WACvB,MAAMlB,GAAK,4BAA4BhF,KAAK6H,MAAM,MAAM7H,KAAK2B,QAAQ;QAEvE,IAAI3B,KAAKmG,YACP,MAAMnB,GAAK,qBAAqBhF,KAAK6H,MAAM,MAAM7H,KAAK2B,QAAQ;QAEhE,MAAMqH,IAAchJ,KAAKkG;QACzB,IAAI8C,MAAgBhJ,KAAKmG,YACvB,MAAMnB,GAAK;QAEX,OAAOgE,KAAchJ,YAAe,IAAI;;;;;;8DArPrC2H;UAAiC,MAEjCA,SAAM,GACNA,QAAQ;;;AAiUjBA,EAASC,QAAQ;;;IAzEjB9H;QAgBEE,YAAO;;IAfP6H;QACE,MAAM7C,GAAK;;IAEbrD;QACE,MAAMqD,GAAK;;IAEb0D;QACE,MAAM1D,GAAK;;IAEbkB;QACE,MAAMlB,GAAK;;IAEbmB;QACE,MAAMnB,GAAK;;;IAKblF,GACE+H,GACAlG,GACA+G,GACAxC,GACAC;QAEA,OAAOnG;;;IAITF,GAAO+H,GAAQlG,GAAU8F;QACvB,OAAO,MAAmBI,GAAKlG;;;IAIjC7B,OAAO+H,GAAQJ;QACb,OAAOzH;;IAGTF;QACE,QAAO;;IAGTA,GAAiBoI;QACf,QAAO;;IAGTpI,GAAiBoI;QACf,QAAO;;IAGTpI;QACE,OAAO;;IAGTA;QACE,OAAO;;IAGTA;QACE,QAAO;;;IAITA;QACE,QAAO;;IAGTA;QACE,OAAO;;;;;;;;;;;;;;;;;;;;;;;;;;;;ICxjBTA,YAAoB2H;oBAClBzH,KAAKkJ,OAAO,MAA0BlJ;;IAGxCF,IAAIqJ;QACF,OAA+B,SAAxBnJ,KAAKkJ,KAAK5G;;IAGnBxC;QACE,OAAOE,KAAKkJ;;IAGdpJ;QACE,OAAOE,KAAKkJ;;IAGd1D;QACE,OAAOxF,KAAKkJ,KAAK1D;;IAGnB1F,QAAQqJ;QACN,OAAOnJ,KAAKkJ,KAAK3C;;iEAInBzG,QAAQsJ;QACNpJ,KAAKkJ,QAAsB,CAACf,GAAMC,OAChCgB,EAAGjB,KACI;;4EAKXrI,GAAeuJ,GAAeD;QAC5B,MAAME,IAAOtJ,KAAKkJ,QAAqBG,EAAM;QAC7C,MAAOC,UAAgB;YACrB,MAAMH,IAAOG;YACb,IAAItJ,OAAgBmJ,EAAKtB,KAAKwB,EAAM,OAAO,GACzC;YAEFD,EAAGD,EAAKtB;;;;;WAOZ/H,GAAasJ,GAA0BG;QACrC,IAAID;QAMJ,KAJEA,SADYvE,MAAVwE,IACKvJ,KAAKkJ,QAAqBK,KAE1BvJ,KAAKkJ,WAEPI,UAAgB;YAGrB,KADeF,EADFE,OACUzB,MAErB;;;uEAMN/H,GAAkBqJ;QAChB,MAAMG,IAAOtJ,KAAKkJ;QAClB,OAAOI,SAAiBA,OAAezB,MAAM;;IAG/C/H;QACE,OAAO,MAAyBE,KAAKkJ;;IAGvCpJ,GAAgB+H;QACd,OAAO,MAAyB7H,KAAKkJ,QAAqBrB;;4CAI5D/H,IAAIqJ;QACF,OAAOnJ,QAAUA,KAAKkJ,KAAKpB,iBAA0B;;iCAIvDhI,OAAOqJ;QACL,OAAKnJ,KAAKwJ,SAGHxJ,QAAUA,KAAKkJ,KAAKpB,aAFlB9H;;IAKXF;QACE,OAAOE,KAAKkJ;;IAGdpJ,GAAUqE;QACR,IAAIsE,IAAuBzI;;gBAW3B,OARIyI,EAAOjD,OAAOrB,EAAMqB,SACtBiD,IAAStE,GACTA,IAAQnE,OAGVmE,EAAMkB,QAAQ8D;YACZV,IAASA,EAAOgB;YAEXhB;;IAGT3I,QAAQqE;QACN,MAAMA,iBACJ,QAAO;QAET,IAAInE,KAAKwF,SAASrB,EAAMqB,MACtB,QAAO;QAGT,MAAMkE,IAAS1J,KAAKkJ,WACdS,IAAUxF,EAAM+E;QACtB,MAAOQ,UAAkB;YACvB,MAAME,IAAWF,OAAiB7B,KAC5BgC,IAAYF,OAAkB9B;YACpC,IAA6C,MAAzC7H,cACF,QAAO;;QAGX,QAAO;;IAGTF;QACE,MAAMgK,IAAW;QAIjB,OAHA9J,KAAKqF,QAAQ0E;YACXD,EAAIvE,KAAKwE;;;IAKbjK;QACE,MAAM2I,IAAc;QAEpB,OADAzI,KAAKqF,QAAQ8D,KAAQV,EAAOlD,UACrB,eAAekD,EAAOhH,aAAa;;IAG5C3B,GAAaoJ;QACX,MAAMT,IAAS,MAAczI;QAE7B,OADAyI,EAAOS,OAAOA,GACPT;;;;;IAKT3I,YAAoBwJ;;;IAEpBxJ;QACE,OAAOE,aAAoB6H;;IAG7B/H;QACE,OAAOE;;;;;;;;;;;;;;;;;;;eCpKmBgK;IAC5B,IAAIC,IAAQ;IACZ,KAAK,MAAMpC,KAAOmC,GACZE,OAAOC,UAAUC,eAAeC,KAAKL,GAAKnC,MAC5CoC;IAGJ,OAAOA;;;SAGO5E,EACd2E,GACApE;IAEA,KAAK,MAAMiC,KAAOmC,GACZE,OAAOC,UAAUC,eAAeC,KAAKL,GAAKnC,MAC5CjC,EAAGiC,GAAKmC,EAAInC;;;WAKSmC;IAKzB,KAAK,MAAMnC,KAAOmC,GAChB,IAAIE,OAAOC,UAAUC,eAAeC,KAAKL,GAAKnC,IAC5C,QAAO;IAGX,QAAO;;;;;;;;;;;;;;;;;;;;;;;;;;;ICvBP/H,YAAqCwK;;;IAErCxK,wBAAwByK;QACtB,MAAMD,IAAeE,QAA8BC,KAAKF;QACxD,OAAO;;IAGTzK,sBAAsB4K;QACpB,MAAMJ;;;;iBA4BiCI;YACzC,IAAIJ,IAAe;YACnB,KAAK,IAAI5E,IAAI,GAAGA,IAAIgF,EAAM5F,aACxBwF,KAAgBhG,OAAOqG,aAAaD;YAEtC;;;;GAjCuBE,EAA2BF;QAChD,OAAO;;IAGT5K;QACE,OAAO0K,QAA8BK,KAAK7K;;IAG5CF;QACE,gBA8BuCwK;YACzC,MAAMQ,IAAS,IAAIC,WAAWT,EAAaxF;YAC3C,KAAK,IAAIY,IAAI,GAAGA,IAAI4E,EAAaxF,QAAQY,KACvCoF,OAAYR,EAAaU;YAE3B,OAAOF;;;;;;;;;;;;;;;;;;;;GAnCEG,EAA2BjL;;IAGpCF;QACE,OAAkC,IAA3BE,QAAkB8E;;IAG3BhF,EAAUqE;QACR,OAAOC,GAAoBpE,SAAmBmE;;IAGhDrE,QAAQqE;QACN,OAAOnE,YAAsBmE;;;;WCnCCxC;IAChC,OAAOA,QAAAA;;;2DAIsBA;;;IAG7B,QAAkB,MAAXA,KAAgB,IAAIA,MAAU,IAAA;;;;;;aAOvBuJ,EAAcvJ;IAC5B,OACmB,mBAAVA,KACPwJ,OAAOC,UAAUzJ,OAChB0J,EAAe1J,MAChBA,KAASwJ,OAAOG,oBAChB3J,KAASwJ,OAAOI;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;GDjBlBC,QAAoC,MAAe;;WEiBnB7J;;IAEhC,OAPgC,sDAMlBA,QAAAA,aAAAA,EAAO8J,uCAAUC,WAAU,2CAAeC;;;;;;;;;WAkDxBhK;IAChC,MAAMiK,IAAiBC,GACrBlK,EAAM8J,SAAUC,4BAA6C;IAE/D,OAAO,IAAInI,EAAUqI,EAAepI,SAASoI,EAAeE;;;;;;;;;;;;;;;;;;;oECnE9D;MAAMC,IAAwB,IAAIC,OAChC;;4EAIwBrK;IACxB,OAAI,eAAeA,wBAER,kBAAkBA,2BAElB,kBAAkBA,KAAS,iBAAiBA,0BAE5C,oBAAoBA,6BAEpB,iBAAiBA,0BAEjB,gBAAgBA,wBAEhB,oBAAoBA,uBAEpB,mBAAmBA,4BAEnB,gBAAgBA,yBAEhB,cAAcA,IACnBsK,EAAkBtK,2DAKfqD,GAAK,yBAAyBkH,KAAKC,UAAUxK;;;wFAK5BuE,GAAiBC;IAC3C,MAAMiG,IAAWC,EAAUnG;IAE3B,IAAIkG,MADcC,EAAUlG,IAE1B,QAAO;IAGT;MACE;QACE,QAAO;;MACT;QACE,OAAOD,EAAKoG,iBAAiBnG,EAAMmG;;MACrC;QACE,OAAOC,EAAkBrG,GAAMvB,QAAQ4H,EAAkBpG;;MAC3D;QACE,OAwBN,SAAyBD,GAAiBC;YACxC,IACiC,mBAAxBD,EAAKsG,kBACoB,mBAAzBrG,EAAMqG,kBACbtG,EAAKsG,eAAe1H,WAAWqB,EAAMqG,eAAe1H;;YAGpD,OAAOoB,EAAKsG,mBAAmBrG,EAAMqG;YAGvC,MAAMC,IAAgBZ,GAAmB3F,EAAoB,iBACvDwG,IAAiBb,GAAmB1F,EAAqB;YAC/D,OACEsG,EAAcjJ,YAAYkJ,EAAelJ,WACzCiJ,EAAcX,UAAUY,EAAeZ;SAtC9Ba,CAAgBzG,GAAMC;;MAC/B;QACE,OAAOD,EAAKyF,gBAAgBxF,EAAMwF;;MACpC;QACE,OA+CN,SAAoBzF,GAAiBC;YACnC,OAAOyG,GAAoB1G,EAAgB,YAAEvB,QAC3CiI,GAAoBzG,EAAiB;SAjD5B0G,CAAW3G,GAAMC;;MAC1B;QACE,OAAOD,EAAK4G,mBAAmB3G,EAAM2G;;MACvC;QACE,OAkCN,SAAwB5G,GAAiBC;YACvC,OACE4G,GAAgB7G,EAAK8G,cAAeC,cAClCF,GAAgB5G,EAAM6G,cAAeC,aACvCF,GAAgB7G,EAAK8G,cAAeE,eAClCH,GAAgB5G,EAAM6G,cAAeE;SAvC9BC,CAAejH,GAAMC;;MAC9B;QACE,gBA+CuBD,GAAiBC;YAC5C,IAAI,kBAAkBD,KAAQ,kBAAkBC,GAC9C,OACE4G,GAAgB7G,EAAKkH,kBAAkBL,GAAgB5G,EAAMiH;YAE1D,IAAI,iBAAiBlH,KAAQ,iBAAiBC,GAAO;gBAC1D,MAAMkH,IAAKN,GAAgB7G,EAAiB,cACtCoH,IAAKP,GAAgB5G,EAAkB;gBAE7C,OAAIkH,UACKhC,SAAuBA,OAEvBkC,YAAaA;;YAIxB,QAAO;SA/DIC,CAAatH,GAAMC;;MAC5B;QACE,OAAOsH,GACLvH,EAAKwH,WAAYC,UAAU,IAC3BxH,EAAMuH,WAAYC,UAAU;;MAGhC;QACE,OA0DN,SAAsBzH,GAAiBC;YACrC,MAAMyH,IAAU1H,EAAKuF,SAAUC,UAAU,IACnCmC,IAAW1H,EAAMsF,SAAUC,UAAU;YAE3C,IAAIoC,SAAwBA,MAC1B,QAAO;YAGT,KAAK,MAAMjG,QACT,IAAI+F,EAAQxD,eAAevC,YAEL9C,MAAlB8I,EAAShG,OACRkG,EAAYH,EAAQ/F,IAAMgG,EAAShG,MAEpC,QAAO;YAIb,QAAO;;6EA5EImG,EAAa9H,GAAMC;;MAC5B;QACE,OAAOnB,GAAK,4BAA4BkH,KAAKC,UAAUjG;;;;WA+E3D+H,GACAC;IAEA,YACgEnJ,OAA7DkJ,EAASN,UAAU,IAAIQ,KAAK/F,KAAK2F,EAAY3F;;;WAIrBlC,GAAiBC;IAC5C,MAAMiG,IAAWC,EAAUnG,IACrBkI,IAAY/B,EAAUlG;IAE5B,IAAIiG,SACF,OAAOhI;IAGT;MACE;QACE,OAAO;;MACT;QACE,OAAOA,GAAoB8B,EAAkB,cAAEC,EAAmB;;MACpE;QACE,OAyBN,SAAwBD,GAAiBC;YACvC,MAAMkI,IAAatB,GAAgB7G,EAAKkH,gBAAgBlH,EAAKoI,cACvDC,IAAcxB,GAAgB5G,EAAMiH,gBAAgBjH,EAAMmI;YAEhE,OAAID,SACM,IACCA,QACF,IACEA,UACF;;YAGHd,WACKA,WAAqB,KAAK,IAE1B;SAxCAiB,CAAetI,GAAMC;;MAC9B;QACE,OAAOsI,EAAkBvI,EAAoB,gBAAEC,EAAqB;;MACtE;QACE,OAAOsI,EACLlC,EAAkBrG,IAClBqG,EAAkBpG;;MAEtB;QACE,OAAO/B,GAAoB8B,EAAiB,aAAEC,EAAkB;;MAClE;QACE,OAkFN,SACED,GACAC;YAEA,MAAMuI,IAAY9B,GAAoB1G,IAChCyI,IAAa/B,GAAoBzG;YACvC,OAAOuI;SAxFIE,CAAa1I,EAAgB,YAAEC,EAAiB;;MACzD;QACE,OAsDN,SAA2B0I,GAAkBC;YAC3C,MAAMC,IAAeF,EAASrI,MAAM,MAC9BwI,IAAgBF,EAAUtI,MAAM;YACtC,KAAK,IAAId,IAAI,GAAGA,IAAIqJ,EAAajK,UAAUY,IAAIsJ,EAAclK,QAAQY,KAAK;gBACxE,MAAMuJ,IAAa7K,GAAoB2K,MAAiBC;gBACxD,IAAmB,MAAfC,GACF;;YAGJ,OAAO7K,GAAoB2K,EAAajK,QAAQkK,EAAclK;SA/DnDoK,CAAkBhJ,EAAoB,gBAAEC,EAAqB;;MACtE;QACE,OAgEN,SAA0BD,GAAkBC;YAC1C,MAAM8I,IAAa7K,GACjB2I,GAAgB7G,EAAK+G,WACrBF,GAAgB5G,EAAM8G;YAExB,IAAmB,MAAfgC,GACF;YAEF,OAAO7K,GACL2I,GAAgB7G,EAAKgH,YACrBH,GAAgB5G,EAAM+G;SA1EbiC,CAAiBjJ,EAAmB,eAAEC,EAAoB;;MACnE;QACE,OAqFN,SAAuBD,GAAsBC;YAC3C,MAAMiJ,IAAYlJ,EAAKyH,UAAU,IAC3B0B,IAAalJ,EAAMwH,UAAU;YAEnC,KAAK,IAAIjI,IAAI,GAAGA,IAAI0J,EAAUtK,UAAUY,IAAI2J,EAAWvK,aAAa;gBAClE,MAAMwK,IAAUC,EAAaH,MAAcC;gBAC3C,IAAIC,GACF,OAAOA;;YAGX,OAAOlL,GAAoBgL,EAAUtK,QAAQuK,EAAWvK;SA/F7C0K,CAActJ,EAAgB,YAAEC,EAAiB;;MAC1D;QACE,OAgGN,SAAqBD,GAAoBC;YACvC,MAAMyH,IAAU1H,EAAKwF,UAAU,IACzB+D,IAAWvF,OAAOwF,SAClB7B,IAAW1H,EAAMuF,UAAU,IAC3BiE,IAAYzF,OAAOwF;;;;;YAMzBD,EAASG,QACTD,EAAUC;YAEV,KAAK,IAAIlK,IAAI,GAAGA,IAAI+J,EAAS3K,UAAUY,IAAIiK,EAAU7K,aAAa;gBAChE,MAAM+K,IAAazL,GAAoBqL,MAAaE;gBACpD,IAAmB,MAAfE,GACF;gBAEF,MAAMP,IAAUC,EAAa3B,EAAQ6B,OAAc5B,EAAS8B;gBAC5D,IAAgB,MAAZL,GACF,OAAOA;;YAIX,OAAOlL,GAAoBqL,EAAS3K,QAAQ6K,EAAU7K;;;;;GAxH3CgL,EAAY5J,EAAc,UAAEC,EAAe;;MACpD;QACE,MAAMnB,GAAK;;;;AAwBjB,WAA2BkB,GAAqBC;IAC9C,IACkB,mBAATD,KACU,mBAAVC,KACPD,EAAKpB,WAAWqB,EAAMrB,QAEtB,OAAOV,GAAoB8B,GAAMC;IAGnC,MAAMsG,IAAgBZ,GAAmB3F,IACnCwG,IAAiBb,GAAmB1F,IAEpC8I,IAAa7K,GACjBqI,EAAcjJ,SACdkJ,EAAelJ;IAEjB,OAAmB,MAAfyL,QAGG7K,GAAoBqI,EAAcX,OAAOY,EAAeZ;;;SAkFjDiE,EAAYpO;IAC1B,OAAOqO,EAAcrO;;;AAGvB,WAAuBA;IACrB,OAAI,eAAeA,IACV,SACE,kBAAkBA,IACpB,KAAKA,EAAM2K,eACT,kBAAkB3K,IACpB,KAAKA,EAAMyL,eACT,iBAAiBzL,IACnB,KAAKA,EAAM2M,cACT,oBAAoB3M,IAuBjC,SAA2B6C;QACzB,MAAMyL,IAAsBpE,GAAmBrH;QAC/C,OAAO,QAAQyL,EAAoBzM,WAAWyM,EAAoBnE;KAxBzDoE,CAAkBvO,EAAqB,kBACrC,iBAAiBA,IACnBA,EAAMgK,cACJ,gBAAgBhK,IAgBpBiL,GAfqBjL,EAAiB,YAeNwO,aAd5B,oBAAoBxO,KA0BNmL,IAzBEnL,EAAqB;IA0BzC6F,KAAqBsF,GAAgBrL,cAzBjC,mBAAmBE,IAqBvB,QADiByO,IAnBEzO,EAAoB,eAoBvBsL,YAAYmD,EAASlD,eAnBjC,gBAAgBvL,IA4C7B,SAAuB+L;QACrB,IAAIjF,IAAS,KACT4H,KAAQ;QACZ,KAAK,MAAM1O,KAAS+L,EAAWC,UAAU,IAClC0C,IAGHA,KAAQ,IAFR5H,KAAU,KAIZA,KAAUuH,EAAcrO;QAE1B,OAAO8G,IAAS;;;;;GAtDP6H,EAAc3O,EAAiB,cAC7B,cAAcA,IAwB3B,SAAqB8J;;;QAGnB,MAAM8E,IAAarG,OAAOwF,KAAKjE,EAASC,UAAU,IAAIkE;QAEtD,IAAInH,IAAS,KACT4H,KAAQ;QACZ,KAAK,MAAMxI,QACJwI,IAGHA,KAAQ,IAFR5H,KAAU,KAIZA,KAAU,GAAGZ,KAAOmI,EAAcvE,EAASC,OAAQ7D;QAErD,OAAOY,IAAS;KAtCP+H,CAAY7O,EAAe,YAE3BqD,GAAK,yBAAyBkH,KAAKC,UAAUxK;IAaxD,IAA0ByO,GAICtD;;;YAkGzBjJ;;;;IAOA,IALAjB,KAAaiB,GAAM,kDAKC,mBAATA,GAAmB;;;;QAK5B,IAAIiI,IAAQ;QACZ,MAAM2E,IAAW1E,EAAsB2E,KAAK7M;QAE5C,IADAjB,QAAuB,wBAAwBiB,IAC3C4M,EAAS,IAAI;;YAEf,IAAIE,IAAUF,EAAS;YACvBE,KAAWA,IAAU,aAAaC,OAAO,GAAG,IAC5C9E,IAAQX;;;gBAIV,MAAM0F,IAAa,IAAIlN,KAAKE;QAG5B,OAAO;YAAEL,SAFOQ,KAAKC,MAAM4M,EAAW/M,YAAY;YAEhCgI,OAAAA;;;IAOlB,OAAO;QAAEtI,SAFOuJ,GAAgBlJ,EAAKL;QAEnBsI,OADJiB,GAAgBlJ,EAAKiI;;;;;;;gBASPnK;;IAE9B,OAAqB,mBAAVA,IACFA,IACmB,mBAAVA,IACTwJ,OAAOxJ,KAEP;;;kFAKyBmP;IAClC,OAAoB,mBAATA,IACFtF,EAAWuF,iBAAiBD,KAE5BtF,EAAWwF,eAAeF;;;gFAKZG,GAAwBpJ;IAC/C,OAAO;QACLiF,gBAAgB,YAAYmE,EAAWC,uBACrCD,EAAWE,sBACCtJ,EAAIvB;;;;6DAKN8E,GACdzJ;IAEA,SAASA,KAAS,kBAAkBA;;;;;SAgBtByP,GACdzP;IAEA,SAASA,KAAS,gBAAgBA;;;2DAYlCA;IAEA,SAASA,KAAS,eAAeA;;;mDAKjCA;IAEA,SAASA,KAAS,iBAAiBA,KAAS4L,MAAMpC,OAAOxJ,EAAM2M;;;0DAK/D3M;IAEA,SAASA,KAAS,cAAcA;;;;;;;;;;;;;;;;;;;;IC7hBhC7B;IAGAA,GACEuR,GACAzF;QAEA,gBF1BFA,GACAyF;YAEA,MAAM5F,IAAyB;gBAC7BC,QAAQ;oBACN4F,UAAY;wBACV3F,aApB0B;;oBAsB5B4F,sBAAwB;wBACtB/E,gBAAgB;4BACdhJ,SAASoI,EAAepI;4BACxBsI,OAAOF,EAAenI;;;;;YAU9B,OAJI4N,MACF5F,EAASC,4BAA8B2F,IAGlC;gBAAE5F,UAAAA;;;;;;;;GEKA+F,KAAiCH;;IAG1CvR,GACEuR,GACAI;QAEA,OAAOA;;IAGT3R,GAAiBuR;QACf,OAAO;;;IAGTvR,QAAQqE;QACN,OAAOA;;;;AArBFuN,cAAW;;;;IA2BlB5R,YAAqB6R;QAAA3R,gBAAA2R;;IAErB7R,GACEuR,GACAzF;QAEA,OAAO5L,KAAK4R,MAAMP;;IAGpBvR,GACEuR,GACAI;;;;QAKA,OAAOzR,KAAK4R,MAAMP;;IAGZvR,MAAMuR;QACZ,MAAM1D,IAASkE,GAAwBR;QACvC,KAAK,MAAMS,KAAW9R,KAAK2R,UACpBhE,EAAOoE,KAAKC,KAAWjE,EAAYiE,UACtCrE,EAAOpI;QAGX,OAAO;YAAEmI,YAAY;gBAAEC,QAAAA;;;;IAGzB7N,GAAiBuR;QACf,OAAO;;;IAGTvR,QAAQqE;QACN,OACEA,mBACAsJ,GAAYzN,KAAK2R,UAAUxN,EAAMwN;;;;;IAOrC7R,YAAqB6R;QAAA3R,gBAAA2R;;IAErB7R,GACEuR,GACAzF;QAEA,OAAO5L,KAAK4R,MAAMP;;IAGpBvR,GACEuR,GACAI;;;;QAKA,OAAOzR,KAAK4R,MAAMP;;IAGZvR,MAAMuR;QACZ,IAAI1D,IAASkE,GAAwBR;QACrC,KAAK,MAAMY,KAAYjS,KAAK2R,UAC1BhE,IAASA,EAAOlH,OAAOuL,MAAYjE,EAAYiE;QAEjD,OAAO;YAAEtE,YAAY;gBAAEC,QAAAA;;;;IAGzB7N,GAAiBuR;QACf,OAAO;;;IAGTvR,QAAQqE;QACN,OACEA,mBACAsJ,GAAYzN,KAAK2R,UAAUxN,EAAMwN;;;;;;;;;;IAYrC7R,YACmBoS,GACRC;QADQnS,kBAAAkS;;IASnBpS,GACEuR,GACAzF;;;;QAKA,MAAMwG,IAAYpS,QAAsBqR,IAClCgB,IAAMrS,KAAKsS,cAAsBtS,KAAKsS,SAAStS;QACrD,OAAIoL,SAAwBA,GAAUpL,WAC7BA,KAAKkS,mBAELlS,KAAKkS;;IAIhBpS,GACEuR,GACAI;QAMA;;;;;WAOF3R,GAAiBuR;QACf,OD2VKjG,GADgBzJ,IC1VL0P,eDoVlB1P;YAEA,SAASA,KAAS,iBAAiBA;;kFAKR4Q,EAAS5Q,KC3VD0P,IAAiB;YAAEjE,cAAc;;YD0V7CzL;;ICvVvB7B,QAAQqE;QACN,OACEA,mBACA4J,EAAY/N,SAAcmE;;IAItBrE,SAAS6B;QACf,OAAOoL,GAAgBpL,EAAMyL,gBAAgBzL,EAAM2M;;;;AAIvD,YAAiC3M;IAC/B,OAAOyP,GAAQzP,MAAUA,EAAM+L,WAAWC,SACtChM,EAAM+L,WAAWC,OAAOxI,UACxB;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IC5MJrF,YAAqB4L;QAAA1L,cAAA0L;;;IAIrB5L,UAAe4L;QACb,OAAO,OAAcA;;IAGvB5L,UAAiB4L;QACf,IAAI8G,IAAc,MAAyB7L;QAE3C,OADA+E,EAAOrG,QAAQoN,KAAcD,IAAcA,EAAY/I,IAAIgJ,KACpD;;;;;;;WAST3S,GAAO2S;QACL,IAAIC,KAAQ;QAMZ,OALA1S,KAAK0L,OAAOrG,QAAQsN;YACdA,IAAyBF,OAC3BC,KAAQ;YAGLA;;IAGT5S,QAAQqE;QACN,OAAOnE,KAAK0L,OAAO/G,QAAQR,EAAMuH;;;;yEAKxBkH;IACX9S,YACW+S,GACAC;QADA9S,aAAA6S,GACA7S,iBAAA8S;;IAGXhT,QAAQqE;QACN,OACEnE,KAAK6S,MAAMlO,QAAQR,EAAM0O,UAAU7S,KAAK8S,UAAUnO,QAAQR,EAAM2O;;;;;IAOpEhT;;;;;;;;;;;IAWWiT;;;;;;;;IAQAC;QARAhT,eAAA+S,GAQA/S,wBAAAgT;;;;;;;;UAiBAC;IAGXnT,YACWoT,GACAC;QADAnT,kBAAAkT,GACAlT,cAAAmT;;8DASXrT,cAAcqT;QACZ,OAAO,IAAIF,QAAalO,GAAWoO;;kFAIrCrT,kBAAkBiT;QAChB,OAAO,IAAIE,GAAaF;;0DAI1BK;QACE,YAA2BrO,MAApB/E,KAAKkT,mBAA4CnO,MAAhB/E,KAAKmT;;;;;WAO/CrT,GAAWuT;QACT,YAAwBtO,MAApB/E,KAAKkT,aAELG,aAAoBC,MACpBD,EAASN,QAAQpO,QAAQ3E,KAAKkT,mBAEPnO,MAAhB/E,KAAKmT,UACPnT,KAAKmT,WAAWE,aAAoBC;;IAO/CxT,QAAQqE;QACN,OACEnE,KAAKmT,WAAWhP,EAAMgP,WACrBnT,KAAKkT,eACA/O,EAAM+O,cAAclT,KAAKkT,WAAWvO,QAAQR,EAAM+O,eACnD/O,EAAM+O;;;;AAlDCD,UAAO,IAAIA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IAwK3BnT,GAA2BuT;;;;;;WAejBvT,UACRuT;QAEA,OAAIA,aAAoBC,KACfD,EAASN,UAETtO,EAAgBC;;;;;;;qBASI6O;IAC/BzT,YACW+H,GACAlG,GACA6R;QAEThS,SAJSxB,WAAA6H,GACA7H,aAAA2B,gBAMF3B;;IAETF,GACEuT,GACAI;QAEAzT;;;;QAWA,MAAM+S,IAAUU,EAAeV;QAC/B,OAAO,IAAIO,GAAStT,KAAK6H,KAAKkL,GAAS/S,KAAK2B,OAAO;YACjD+R,wBAAuB;;;IAI3B5T,GACEuT,GACAM,GACA/H;QAIA,IAFA5L,aAEKA,eACH;QAGF,MAAM+S,IAAUQ;QAChB,OAAO,IAAID,GAAStT,KAAK6H,KAAKkL,GAAS/S,KAAK2B,OAAO;YACjDiS,KAAmB;;;IAIvB9T,GAAiBuT;QACf,OAAO;;IAGTvT,QAAQqE;QACN,OACEA,mBACAnE,KAAK6H,IAAIlD,QAAQR,EAAM0D,QACvB7H,KAAK2B,MAAMgD,QAAQR,EAAMxC,UACzB3B,QAAkB2E,QAAQR;;;;;;;;;;;;;;;;qBAkBGoP;IACjCzT,YACW+H,GACAqB,GACA2K,GACAL;QAEThS,SALSxB,WAAA6H,GACA7H,YAAAkJ,6BAOFlJ;;IAETF,GACEuT,GACAI;QASA,IAPAzT,aAOKA;;;;;QAKH,OAAO,OAAoBA,KAAK6H,KAAK4L,EAAeV;QAGtD,MAAMe,IAAU9T;QAChB,OAAO,IAAIsT,GAAStT,KAAK6H,KAAK4L,EAAeV,YAAkB;YAC7DW,wBAAuB;;;IAI3B5T,GACEuT,GACAM,GACA/H;QAIA,IAFA5L,aAEKA,eACH;QAGF,MAAM+S,IAAUQ,UACVO,IAAU9T;QAChB,OAAO,IAAIsT,GAAStT,KAAK6H,KAAKkL,MAAkB;YAC9Ca,KAAmB;;;IAIvB9T,GAAiBuT;QACf,OAAO;;IAGTvT,QAAQqE;QACN,OACEA,mBACAnE,KAAK6H,IAAIlD,QAAQR,EAAM0D,QACvB7H,QAAe2E,QAAQR,SACvBnE,QAAkB2E,QAAQR;;;;;;WAS9BrE,GAAsBuT;QACpB,IAAInK;QAMJ,OAJEA,IADEmK,aAAoBC,KACfD,EAASnK,SAET6K,GAAYnM,OAEd5H,QAAiBkJ;;IAG1BpJ,GAAoBoJ;QAClB,MAAM8K,IAAU9K;QAWhB,OAVAlJ,QAAe0L,OAAOrG,QAAQoN;YAC5B,KAAKA,OAAqB;gBACxB,MAAMwB,IAAWjU,KAAKkJ,KAAK2J,MAAMJ;gBAChB,SAAbwB,IACFD,EAAQE,IAAIzB,GAAWwB,KAEvBD,EAAQG,OAAO1B;;YAIduB;;;;;;;;;;;;qBAa4BT;IAQrCzT,YACW+H,GACAuM;QAET5S,SAHSxB,WAAA6H,GACA7H,uBAAAoU,GATFpU;;;;QAKTA,UAAwBiT,GAAaE,QAAO;;IAS5CrT,GACEuT,GACAI;QASA,IAPAzT,YAEA4C,GACqC,QAAnC6Q,EAAeT,kBACf;SAGGhT;;;;;QAKH,OAAO,OAAoBA,KAAK6H,KAAK4L,EAAeV;QAGtD,MAAMsB,IAAMrU,YACNgT,IAAmBhT,WAEvByT,EAAgC,mBAG5BV,IAAUU,EAAeV,SACzBe,IAAU9T,QAAqBqU,EAAInL,QAAQ8J;QACjD,OAAO,IAAIM,GAAStT,KAAK6H,KAAKkL,MAAkB;YAC9CW,wBAAuB;;;IAI3B5T,GACEuT,GACAM,GACA/H;QAIA,IAFA5L,aAEKA,eACH;QAGF,MAAMqU,IAAMrU,YACNgT,IAAmBhT,kBAKnB8T,IAAU9T,QAAqBqU,EAAInL,QAAQ8J;QACjD,OAAO,IAAIM,GAAStT,KAAK6H,KAAKwM,EAAItB,YAAkB;YAClDa,KAAmB;;;IAIvB9T,GAAiBuT;QACf,IAAIiB,IAAwC;QAC5C,KAAK,MAAMC,KAAkBvU,KAAKoU,iBAAiB;YACjD,MAAMI,IACJnB,aAAoBC,KAChBD,EAASR,MAAM0B,EAAe1B,cAC9B9N,GACA0P,IAAeF,EAAezB,aAClC0B,KAAiB;YAGC,QAAhBC,MAEAH,IADgB,QAAdA,IACWP,QAAyBG,IACpCK,EAAe1B,YAIJyB,EAAWJ,IAAIK,EAAe1B;;QAIjD,OAAOyB,IAAaA,SAAqB;;IAG3CxU,QAAQqE;QACN,OACEA,mBACAnE,KAAK6H,IAAIlD,QAAQR,EAAM0D,QACvB4F,GAAYzN,KAAKoU,iBAAiBjQ,EAAMiQ,iBAAiB,CAACM,GAAGC,MAC3DD,EAAE/P,QAAQgQ,OAEZ3U,QAAkB2E,QAAQR;;;;;;;WAU9BrE,GAAwBuT;QAStB;;;;;;;;;;WAYFvT,GACE6T,GACAiB;QAEA,MAAM5B,IAAgC;QACtCpQ,GACE5C,KAAKoU,gBAAgBtP,WAAW8P,EAAuB9P,QACvD,kCAAkC8P,EAAuB9P,aACvD,uCAAuC9E,KAAKoU,gBAAgBtP;QAGhE,KAAK,IAAIY,IAAI,GAAGA,IAAIkP,EAAuB9P,QAAQY,KAAK;YACtD,MAAM6O,IAAiBvU,KAAKoU,oBACtBtB,IAAYyB,EAAezB;YACjC,IAAIzB,IAAkC;YAClCsC,aAAmBL,OACrBjC,IAAgBsC,EAAQd,MAAM0B,EAAe1B,SAE/CG,EAAiBzN,KACfuN,KACEzB,GACAuD;;QAIN,OAAO5B;;;;;;;;;;;;;WAeTlT,GACE8L,GACAyH,GACAM;QAEA,MAAMX,IAAgC;QACtC,KAAK,MAAMuB,KAAkBvU,KAAKoU,iBAAiB;YACjD,MAAMtB,IAAYyB,EAAezB;YAEjC,IAAIzB,IAAkC;YAClCgC,aAAoBC,OACtBjC,IAAgBgC,EAASR,MAAM0B,EAAe1B,SAG1B,SAAlBxB,KAA0BsC,aAAmBL;;;;;YAK/CjC,IAAgBsC,EAAQd,MAAM0B,EAAe1B,SAG/CG,EAAiBzN,KACfuN,KAA2BzB;;QAG/B,OAAO2B;;IAGTlT,GACEoJ,GACA8J;QAOA,MAAMgB,IAAU9K;QAChB,KAAK,IAAIxD,IAAI,GAAGA,IAAI1F,KAAKoU,gBAAgBtP,QAAQY,KAAK;YACpD,MACM+M,IADiBzS,KAAKoU,mBACKvB;YACjCmB,EAAQE,IAAIzB,GAAWO;;QAEzB,OAAOgB;;;;+EAKyBT;IAClCzT,YAAqB+H,GAA2B2L;QAC9ChS,SADmBxB,WAAA6H,gBAIZ7H;;IAETF,GACEuT,GACAI;;;;QAaA,OAXAzT,YAWO,OAAeA,KAAK6H,KAAK4L,EAAeV,SAAS;YACtDW,wBAAuB;;;IAI3B5T,GACEuT,GACAM,GACA/H;QAIA,OAFA5L,YAEKA,gBAUE,OAAeA,KAAK6H,KAAKpD;;IAGlC3E,GAAiBuT;QACf,OAAO;;IAGTvT,QAAQqE;QACN,OACEA,mBACAnE,KAAK6H,IAAIlD,QAAQR,EAAM0D,QACvB7H,QAAkB2E,QAAQR;;;;;;;;;;qBAYIoP;IAClCzT,YAAqB+H,GAA2B2L;QAC9ChS,SADmBxB,WAAA6H,gBAIZ7H;;IAETF,GACEuT,GACAI;QAEAzO,GAAK;;IAGPlF,GACEuT,GACAM,GACA/H;QAEA5G,GAAK;;IAGPlF,GAAiBuT;QACfrO,GAAK;;IAGPlF,QAAQqE;QACN,OACEA,mBACAnE,KAAK6H,IAAIlD,QAAQR,EAAM0D,QACvB7H,QAAkB2E,QAAQR;;;;;;;;;;;;;;;;;;;;;;;;IC9wB9BrE,YAA4B+U;QAAA7U,aAAA6U;;+EAQ5B/U;QACE,OAAOiU,GAAYnM;;;;;;;WASrB9H,MAAMwG;QACJ,IAAIA,OACF,OAAOtG,KAAK6U;QACP;YACL,IAAIlT,IAAmB3B,KAAK6U;YAC5B,KAAK,IAAInP,IAAI,GAAGA,IAAIY,EAAKxB,SAAS,QAAQ;gBACxC,KAAKnD,EAAM8J,SAAUC,QACnB,OAAO;gBAGT,IADA/J,IAAQA,EAAM8J,SAAUC,OAAOpF,EAAKhE,UAC/BwS,GAAWnT,IACd,OAAO;;YAKX,OADAA,KAASA,EAAM8J,SAAUC,UAAU,IAAIpF,QAChC3E,KAAS;;;;;;WAQpB7B;QACE,OAAOE,QAAsBA,KAAK6U,MAAe;;IAGnD/U,GAAyB6B;QACvB,IAAI+J,IAAS,MAAyB/E;QAsBtC,OArBAtB,EAAQ1D,EAAM+J,UAAU,IAAI,CAAC7D,GAAKlG;YAChC,MAAMoT,IAAc,IAAIpO,EAAU,EAACkB;YACnC,6BAAIwE,EAAU1K,IAAkC;gBAC9C,MACMqT,IADahV,QAAsB2B,EAAe,UACxB+J;gBAC5BsJ;;gBAEFtJ,IAASA,EAAOjC;;;gBAIhBuL,EAAa3P,QAAQ4P;oBACnBvJ,IAASA,EAAOjC,IAAIsL,EAAYG;;;;;YAMpCxJ,IAASA,EAAOjC;YAGb0L,MAAkBzJ;;IAG3B5L,QAAQqE;QACN,OAAO4J,EAAY/N,KAAK6U,OAAO1Q,EAAM0Q;;wFAIvC/U;QACE,OAAO,OAAuBE;;;;AAhFzB+T,WAAQ,OAAgB;IAAEtI,UAAU;;;;;;;;;;;IAsG3C3L,YAA6BwU;;;QAL7BtU,UAAqB,IAAIoV;;;;;;;;WAczBtV,IAAIwG,GAAiB3E;QAMnB,OADA3B,QAAgBsG,GAAM3E,IACf3B;;;;;;;;WAUTF,OAAOwG;QAML,OADAtG,QAAgBsG,GAAM,OACftG;;;;;WAOTF,GAAmBwG,GAAiB3E;QAClC,IAAI0T,IAAerV;QAEnB,KAAK,IAAI0F,IAAI,GAAGA,IAAIY,EAAKxB,SAAS,QAAQ;YACxC,MAAMwQ,IAAiBhP,EAAKhE;YAC5B,IAAIiT,IAAeF,EAAa/S;YAE5BiT,aAAwBH;;YAE1BC,IAAeE,IAEfA,8BACAlJ,EAAUkJ;;YAGVA,IAAe,IAAIH,IACjBlL,OAAOsL,QAAQD,EAAa9J,SAAUC,UAAU,MAElD2J,EAAanB,OAAoBqB,IACjCF,IAAeE;;YAGfA,IAAe,IAAIH,KACnBC,EAAanB,OAAoBqB,IACjCF,IAAeE;;QAInBF,EAAanB,IAAI5N,OAAoB3E;;iEAIvC7B;QACE,MAAM2V,IAAezV,QACnB2G,KACA3G;QAEF,OAAoB,QAAhByV,IACK,YAEAzV;;;;;;;;;;;;;WAgBXF,GACEiV,GACAW;QAEA,IAAIC,KAAW;QAEf,MAAMnB,IAAgBxU,QAAgB6S,UAChC+C,IAAed;0BAGZN,EAAc/I,SAASC,UAC5B;QAkBJ,OAhBAgK,EAAgBrQ,QAAQ,CAAC1D,GAAOkU;YAC9B,IAAIlU,aAAiByT,KAAK;gBACxB,MAAMU,IAAS9V,QAAkB+U,EAAYG,UAAoBvT;gBACnD,QAAVmU,MACFF,UACAD,KAAW;mBAEM,SAAVhU,KACTiU,OAA4BjU,GAC5BgU,KAAW,KACFC,EAAaxL,6BACfwL,MACPD,KAAW;YAIRA,IAAW;YAAElK,UAAU;gBAAEC;;YAA2B;;;;;;;;;;;;;;;;;;;;;;;;IChP7D5L,YAAqB+H,GAA2BkL;QAA3B/S,WAAA6H,GAA2B7H,eAAA+S;;IAEhDjT,UAAoBiW,GAAmBC;QACrC,OAAOxO,IAAuBuO,EAAGlO,KAAKmO,EAAGnO;;;;;;;UAkBhCyL,WAAiB2C;IAI5BnW,YACE+H,GACAkL,GACiBmD,GACjBC;QAEA3U,MAAMqG,GAAKkL,iBACX/S,YAA2BmW,MAC3BnW,KAAK0T,0BAA0ByC,EAAQzC;;IAGzC5T,MAAMwG;QACJ,OAAOtG,QAAiB6S,MAAMvM;;IAGhCxG;QACE,OAAOE;;IAGTF;QACE,OAAOE,QAAiB6U;;IAG1B/U,QAAQqE;QACN,OACEA,aAAiBmP,MACjBtT,KAAK6H,IAAIlD,QAAQR,EAAM0D,QACvB7H,KAAK+S,QAAQpO,QAAQR,EAAM4O,YAC3B/S,YAA2BmE,QAC3BnE,KAAK0T,0BAA0BvP,EAAMuP,yBACrC1T,QAAiB2E,QAAQR;;IAI7BrE;QACE,OACE,YAAYE,KAAK6H,QACf7H,KAAK+S,YACF/S,QAAiByB,iBACtB,uBAAuBzB,gBACvB,2BAA2BA,KAAK0T;;IAIpC0C;QACE,OAAOpW,WAA0BA,KAAK0T;;IAGxC5T,UAAsB+S,GAAkBkD,GAAcC;QACpD,MAAMK,IAAKN,EAAGlD,MAAMA,IACdyD,IAAKN,EAAGnD,MAAMA;QACpB,OAAW,SAAPwD,KAAsB,SAAPC,IACV/G,EAAa8G,GAAIC,KAEjBtR,GAAK;;;;;;;;qBAUciR;IAG9BnW,YACE+H,GACAkL,GACAoD;QAEA3U,MAAMqG,GAAKkL,IACX/S,KAAK0T,2BAA2ByC,MAAWA,EAAQzC;;IAGrD5T;QACE,OAAO,cAAcE,KAAK6H,QAAQ7H,KAAK+S;;IAGzCqD;QACE,OAAOpW,KAAK0T;;IAGd5T,QAAQqE;QACN,OACEA,mBACAA,EAAMuP,0BAA0B1T,KAAK0T,yBACrCvP,EAAM4O,QAAQpO,QAAQ3E,KAAK+S,YAC3B5O,EAAM0D,IAAIlD,QAAQ3E,KAAK6H;;;;;;;qBASQoO;IACnCnW;QACE,OAAO,mBAAmBE,KAAK6H,QAAQ7H,KAAK+S;;IAG9CqD;QACE,QAAO;;IAGTtW,QAAQqE;QACN,OACEA,mBACAA,EAAM4O,QAAQpO,QAAQ3E,KAAK+S,YAC3B5O,EAAM0D,IAAIlD,QAAQ3E,KAAK6H;;;;;;;;;;;;;;;;;;;;;;;;;;UChJhB0O;;;;;;;;;IAWXzW,YACWwG,GACAkQ,IAAiC,MACjCC,IAAqB,IACrBC,IAAoB,IACpBtR,IAAuB,MACvBuR,IAAwB,MACxBC,IAAsB;QANtB5W,YAAAsG,GACAtG,uBAAAwW,GACAxW,eAAAyW,GACAzW,eAAA0W,GACA1W,aAAAoF;QACApF,eAAA2W,GACA3W,aAAA4W,GAjBX5W,UAA6C;;IAoB7CF;QACE,IAAiC,SAA7BE,SAAmC;YACrC,IAAI+P,IAAc/P,KAAKsG;YACM,SAAzBtG,KAAKwW,oBACPzG,KAAe,SAAS/P,KAAKwW,kBAE/BzG,KAAe;YACfA,KAAe/P,KAAK0W,QAAQ7P,IAAIgQ,KAAKA,EAAE9G,eAAe1J,KAAK,MAC3D0J,KAAe,QACfA,KAAe/P,KAAKyW,QAAQ5P,IAAIiQ,KAAKA,EAAE/G,eAAe1J,KAAK;YAEtD0Q,EAAkB/W,KAAKoF,WAC1B2K,KAAe,OACfA,KAAe/P,KAAKoF,QAElBpF,KAAK2W,YACP5G,KAAe,QACfA,KAAe/P,KAAK2W,QAAQ5G;YAE1B/P,KAAK4W,UACP7G,KAAe,QACfA,KAAe/P,KAAK4W,MAAM7G,gBAE5B/P,UAA2B+P;;QAE7B,OAAO/P;;IAGTF;QACE,IAAIgH,IAAM9G,KAAKsG;QAmBf,OAlB6B,SAAzBtG,KAAKwW,oBACP1P,KAAO,sBAAsB9G,KAAKwW;QAEhCxW,KAAK0W,QAAQ5R,SAAS,MACxBgC,KAAO,eAAe9G,KAAK0W,QAAQrQ,KAAK,WAErC0Q,EAAkB/W,KAAKoF,WAC1B0B,KAAO,cAAc9G,KAAKoF;QAExBpF,KAAKyW,QAAQ3R,SAAS,MACxBgC,KAAO,eAAe9G,KAAKyW,QAAQpQ,KAAK,WAEtCrG,KAAK2W,YACP7P,KAAO,gBAAgB9G,KAAK2W,QAAQ5G;QAElC/P,KAAK4W,UACP9P,KAAO,cAAc9G,KAAK4W,MAAM7G,gBAE3B,UAAUjJ;;IAGnBhH,QAAQqE;QACN,IAAInE,KAAKoF,UAAUjB,EAAMiB,OACvB,QAAO;QAGT,IAAIpF,KAAKyW,QAAQ3R,WAAWX,EAAMsS,QAAQ3R,QACxC,QAAO;QAGT,KAAK,IAAIY,IAAI,GAAGA,IAAI1F,KAAKyW,QAAQ3R,QAAQY,KACvC,KAAK1F,KAAKyW,WAAW9R,QAAQR,EAAMsS,aACjC,QAAO;QAIX,IAAIzW,KAAK0W,QAAQ5R,WAAWX,EAAMuS,QAAQ5R,QACxC,QAAO;QAGT,KAAK,IAAIY,IAAI,GAAGA,IAAI1F,KAAK0W,QAAQ5R,QAAQY,KACvC,KAAK1F,KAAK0W,WAAW/R,QAAQR,EAAMuS,aACjC,QAAO;QAIX,OAAI1W,KAAKwW,oBAAoBrS,EAAMqS,sBAI9BxW,KAAKsG,KAAK3B,QAAQR,EAAMmC,aAKV,SAAjBtG,KAAK2W,UACA3W,KAAK2W,QAAQhS,QAAQR,EAAMwS,WACV,SAAlBxS,EAAMwS,aAKU,SAAf3W,KAAK4W,QACR5W,KAAK4W,MAAMjS,QAAQR,EAAMyS,SACT,SAAhBzS,EAAMyS;;IAGZ9W;QACE,OACE0H,KAA0BxH,KAAKsG,SACN,SAAzBtG,KAAKwW,mBACmB,MAAxBxW,KAAK0W,QAAQ5R;;;;;;;;;;;;;;;;;;;;;;;;UCvGNkS;;;;;IAcXlX,YACWwG,GACAkQ,IAAiC,MACjCS,IAA6B,IAC7BP,IAAoB,IACpBtR,IAAuB,MACvB8R,sBACAP,IAAwB,MACxBC,IAAsB;QAPtB5W,YAAAsG,GACAtG,uBAAAwW,gBAEAxW,eAAA0W,GACA1W,aAAAoF;qBAEApF,eAAA2W,GACA3W,aAAA4W,GAjBX5W,UAA4C;;QAG5CA,UAAwC,MAgBlCA,KAAK2W,WACP3W,QAAsBA,KAAK2W,UAEzB3W,KAAK4W,SACP5W,QAAsBA,KAAK4W;;IA3B/B9W,UAAcwG;QACZ,OAAO,IAAI0Q,GAAM1Q;;IA8BnBmQ;QACE,IAA6B,SAAzBzW,SAA+B;YACjC,MAAMmX,IAAkBnX,WAClBoX,IAAoBpX;YAC1B,IAAwB,SAApBmX,KAAkD,SAAtBC;;;;YAI1BD,QACFnX,UAAuB,SAEvBA,UAAuB,EACrB,sBAIC;gBAOLA,UAAuB;gBACvB,IAAIqX,KAAmB;gBACvB,KAAK,MAAMZ,KAAWzW,SACpBA,QAAqBuF,KAAKkR,IACtBA,EAAQ5D,cACVwE,KAAmB;gBAGvB,QAAuB;;;oBAGrB,MAAMC,IACJtX,QAAqB8E,SAAS,IAC1B9E,QAAqBA,QAAqB8E,SAAS,GAAGyS,MACtDC,GAAUC;oBAChBzX,QAAqBuF,KACnB+R,MAAkBE,GAAUC;;;;QAOpC,OAAOzX;;IAGTF,GAAU2G;QAcR,MAAMiR,IAAa1X,KAAK0W,QAAQiB,OAAO,EAAClR;QACxC,OAAO,IAAIuQ,GACThX,KAAKsG,MACLtG,KAAKwW,iBACLxW,QAAqBmF,YAErBnF,KAAKoF,OACLpF,SACAA,KAAK2W,SACL3W,KAAK4W;;IAIT9W,GAAW2W;;QAMT,MAAMmB,IAAa5X,QAAqB2X,OAAO,EAAClB;QAChD,OAAO,IAAIO,GACThX,KAAKsG,MACLtG,KAAKwW,oBAELxW,KAAK0W,QAAQvR,SACbnF,KAAKoF,OACLpF,SACAA,KAAK2W,SACL3W,KAAK4W;;IAIT9W,GAAiBsF;QACf,OAAO,IAAI4R,GACThX,KAAKsG,MACLtG,KAAKwW,iBACLxW,QAAqBmF,SACrBnF,KAAK0W,QAAQvR,SACbC,qBAEApF,KAAK2W,SACL3W,KAAK4W;;IAIT9W,GAAgBsF;QACd,OAAO,IAAI4R,GACThX,KAAKsG,MACLtG,KAAKwW,iBACLxW,QAAqBmF,SACrBnF,KAAK0W,QAAQvR,SACbC,oBAEApF,KAAK2W,SACL3W,KAAK4W;;IAIT9W,GAAY+X;QACV,OAAO,IAAIb,GACThX,KAAKsG,MACLtG,KAAKwW,iBACLxW,QAAqBmF,SACrBnF,KAAK0W,QAAQvR,SACbnF,KAAKoF,OACLpF,SACA6X,GACA7X,KAAK4W;;IAIT9W,GAAU+X;QACR,OAAO,IAAIb,GACThX,KAAKsG,MACLtG,KAAKwW,iBACLxW,QAAqBmF,SACrBnF,KAAK0W,QAAQvR,SACbnF,KAAKoF,OACLpF,SACAA,KAAK2W,SACLkB;;;;;;;WAUJ/X,GAAwBwG;QACtB,OAAO,IAAI0Q,GACT1Q;6BACqB,MACrBtG,QAAqBmF,SACrBnF,KAAK0W,QAAQvR,SACbnF,KAAKoF,OACLpF,SACAA,KAAK2W,SACL3W,KAAK4W;;;;;WAQT9W;QACE,OAC0B,MAAxBE,KAAK0W,QAAQ5R,UACE,SAAf9E,KAAKoF,SACW,QAAhBpF,KAAK2W,WACS,QAAd3W,KAAK4W,UAC4B,MAAhC5W,QAAqB8E,UACa,MAAhC9E,QAAqB8E,UACpB9E,QAAqB,GAAG6S;;;;;IAOhC/S;QACE,OAAO,GAAGE,UAAgB+P,oBAAoB/P;;IAGhDF;QACE,OAAO,gBAAgBE,UAAgByB,yBACrCzB;;IAIJF,QAAQqE;QACN,OACEnE,UAAgB2E,QAAQR,WACxBnE,YAAmBmE;;IAIvBrE,GAAciW,GAAcC;QAC1B,IAAI8B,KAAqB;QACzB,KAAK,MAAMrB,KAAWzW,KAAKyW,SAAS;YAClC,MAAMsB,IAAOtB,EAAQnH;YACrB,IAAa,MAATyI,GACF;YAEFD,IAAqBA,KAAsBrB,EAAQ5D;;QAOrD,OAAO;;IAGT/S,QAAQuU;QACN,OACErU,QAAmCqU,MACnCrU,QAAoBqU,MACpBrU,QAAoBqU,MACpBrU,QAAmBqU;;IAIvBvU;QACE,QAAQiX,EAAkB/W,KAAKoF,8BAAUpF;;IAG3CF;QACE,QAAQiX,EAAkB/W,KAAKoF,6BAAUpF;;IAG3CF;QACE,OAAOE,QAAqB8E,SAAS,IACjC9E,QAAqB,GAAG6S,QACxB;;IAGN/S;QACE,KAAK,MAAM2G,KAAUzG,KAAK0W,SACxB,IAAIjQ,aAAkBuR,MAAevR,QACnC,OAAOA,EAAOoM;QAGlB,OAAO;;;;IAKT/S,GAAmBmY;QACjB,KAAK,MAAMxR,KAAUzG,KAAK0W,SACxB,IAAIjQ,aAAkBuR,MAChBC,EAAU1R,QAAQE,EAAOyR,OAAO,GAClC,OAAOzR,EAAOyR;QAIpB,OAAO;;IAGTpY;QACE,OAAOE;;IAGTF;QACE,OAAgC,SAAzBE,KAAKwW;;;;;WAOd1W;QACE,KAAKE,SACH,wBAAIA,SACFA,UAAsB,IAAIuW,GACxBvW,KAAKsG,MACLtG,KAAKwW,iBACLxW,KAAKyW,SACLzW,KAAK0W,SACL1W,KAAKoF,OACLpF,KAAK2W,SACL3W,KAAK4W,aAEF;;YAEL,MAAMuB,IAAW;YACjB,KAAK,MAAM1B,KAAWzW,KAAKyW,SAAS;gBAClC,MAAMc,IACJd,EAAQc,QAAQC,GAAUY,aACtBZ,GAAUC,YACVD,GAAUY;gBAChBD,EAAS5S,KAAK,OAAYkR,EAAQ5D,OAAO0E;;;wBAI3C,MAAMZ,IAAU3W,KAAK4W,QACjB,OAAU5W,KAAK4W,MAAMyB,WAAWrY,KAAK4W,MAAM0B,UAC3C,MACE1B,IAAQ5W,KAAK2W,UACf,OAAU3W,KAAK2W,QAAQ0B,WAAWrY,KAAK2W,QAAQ2B,UAC/C;;YAGJtY,UAAsB,IAAIuW,GACxBvW,KAAKsG,MACLtG,KAAKwW,oBAELxW,KAAK0W,SACL1W,KAAKoF,OACLuR,GACAC;;QAIN,OAAO5W;;IAGTF,GAAsCuU;QACpC,MAAMkE,IAAUlE,EAAIxM,IAAIvB;QACxB,OAA6B,SAAzBtG,KAAKwW,kBAILnC,EAAIxM,OAAoB7H,KAAKwW,oBAC7BxW,KAAKsG,YAEEkB,KAA0BxH,KAAKsG,QAEjCtG,KAAKsG,KAAK3B,aAGV3E,KAAKsG;;;;;WAQhBxG,GAAuBuU;QACrB,KAAK,MAAMoC,KAAWzW;;QAEpB,KAAKyW,EAAQ5D,aAAmD,SAA7BwB,EAAIxB,MAAM4D,EAAQ5D,QACnD,QAAO;QAGX,QAAO;;IAGT/S,GAAuBuU;QACrB,KAAK,MAAM5N,KAAUzG,KAAK0W,SACxB,KAAKjQ,EAAO+R,QAAQnE,IAClB,QAAO;QAGX,QAAO;;;;WAMTvU,GAAsBuU;QACpB,SAAIrU,KAAK2W,YAAY3W,KAAK2W,WAA4B3W,KAAKyW,SAASpC,SAGhErU,KAAK4W,UAAS5W,KAAK4W,SAA0B5W,KAAKyW,SAASpC;;IAMjEvU,GAAyB+X;;;;IA+CzB/X,YAAmB4B;QAAA1B,YAAA0B;;IAvBnB5B,SAAkBoY;QAChB,QAAQA;UACN,KAAK;YACH,OAAOO,GAASC;;UAClB,KAAK;YACH,OAAOD,GAASE;;UAClB,KAAK;YACH,OAAOF,GAASG;;UAClB,KAAK;YACH,OAAOH,GAASI;;UAClB,KAAK;YACH,OAAOJ,GAASK;;UAClB,KAAK;YACH,OAAOL,GAASM;;UAClB,KAAK;YACH,OAAON,GAASO;;UAClB,KAAK;YACH,OAAOP,GAASQ;;UAClB;YACE,OAAOjU,GAAK,mCAAmCkT;;;IAMrDpY;QACE,OAAOE,KAAK0B;;IAGd5B,QAAQqE;QACN,OAAOnE,KAAK0B,SAASyC,EAAMzC;;;;AAvCtB+W,eAAY,OAAa,MACzBA,wBAAqB,OAAa,OAClCA,WAAQ,OAAa;AACrBA,kBAAe,OAAa,MAC5BA,2BAAwB,OAAa,OACrCA,oBAAiB,OAAa;AAC9BA,QAAK,OAAa,OAClBA,wBAAqB,OAAa;;MAoC9BT;IACXlY,YACS+S,GACAqF,GACAvW;QAEPH,SAJOxB,aAAA6S,GACA7S,UAAAkY,GACAlY,aAAA2B;;;;WAQT7B,cAAc+S,GAAkBqF,GAAcvW;QAC5C,IAAIkR,OACF,OAAIqF,MAAOO,GAASO,KASX,OAAqBnG,GAAOlR,KAU5B,OAAmBkR,GAAOqF,GAAIvW;QAElC,IAAIuX,GAAYvX,IAAQ;YAC7B,IAAIuW,MAAOO,GAASG,OAClB,MAAM,IAAIxX,EACRlB,EAAKI,kBACL;YAGJ,OAAO,IAAI0X,GAAYnF,GAAOqF,GAAIvW;;QAC7B,IAAIwX,GAAWxX,IAAQ;YAC5B,IAAIuW,MAAOO,GAASG,OAClB,MAAM,IAAIxX,EACRlB,EAAKI,kBACL;YAGJ,OAAO,IAAI0X,GAAYnF,GAAOqF,GAAIvW;;QAC7B,OAAIuW,MAAOO,GAASM,iBAClB,OAAwBlG,GAAOlR,KAC7BuW,MAAOO,GAASO,KAKlB,OAAanG,GAAOlR,KAClBuW,MAAOO,GAASQ,qBAKlB,OAA2BpG,GAAOlR,KAElC,IAAIqW,GAAYnF,GAAOqF,GAAIvW;;IAItC7B,QAAQuU;QACN,MAAMlQ,IAAQkQ,EAAIxB,MAAM7S,KAAK6S;;gBAG7B,OACY,SAAV1O,KACAkI,EAAUrM,KAAK2B,WAAW0K,EAAUlI,MACpCnE,QAAuBuP,EAAapL,GAAOnE,KAAK2B;;IAIpD7B,GAA4BmP;QAC1B,QAAQjP,KAAKkY;UACX,KAAKO,GAASC;YACZ,OAAOzJ,IAAa;;UACtB,KAAKwJ,GAASE;YACZ,OAAO1J,KAAc;;UACvB,KAAKwJ,GAASG;YACZ,OAAsB,MAAf3J;;UACT,KAAKwJ,GAASK;YACZ,OAAO7J,IAAa;;UACtB,KAAKwJ,GAASI;YACZ,OAAO5J,KAAc;;UACvB;YACE,OAAOjK,GAAK,mCAAmChF,KAAKkY;;;IAI1DpY;QACE,OACE,EACE2Y,GAASC,WACTD,GAASE,oBACTF,GAASK,cACTL,GAASI,wBACTtS,QAAQvG,KAAKkY,OAAO;;IAI1BpY;;;;QAIE,OACEE,KAAK6S,YACL7S,KAAKkY,GAAGzW,aACRsO,EAAY/P,KAAK2B;;IAIrB7B,QAAQqE;QACN,OAAIA,aAAiB6T,OAEjBhY,KAAKkY,GAAGvT,QAAQR,EAAM+T,OACtBlY,KAAK6S,MAAMlO,QAAQR,EAAM0O,UACzB9E,EAAY/N,KAAK2B,OAAOwC,EAAMxC;;IAOpC7B;QACE,OAAO,GAAGE,KAAK6S,aAA2B7S,KAAKkY,MAAMnI,EACnD/P,KAAK2B;;;;6EAMyBqW;IAGlClY,YAAY+S,GAAkBqF,GAAcvW;QAC1CH,MAAMqR,GAAOqF,GAAIvW,IAKjB3B,KAAK6H,MAAML,KAAqB7F,EAAMmL;;IAGxChN,QAAQuU;QACN,MAAMpF,IAAazH,IAAuB6M,EAAIxM,KAAK7H,KAAK6H;QACxD,OAAO7H;;;;2EAK2BgY;IAGpClY,YAAY+S,GAAkBlR;QAC5BH,MAAMqR,GAAO4F,GAASO,IAAIrX,IAE1B3B,KAAK0P,QAAQ/N,EAAM+L,WAAWC,UAAU,IAAI9G,IAAIuB,KAKvCZ,KAAqBY,EAAE0E;;IAIlChN,QAAQuU;QACN,OAAOrU,KAAK0P,KAAKqC,KAAKlK,KAAOA,EAAIlD,QAAQ0P,EAAIxM;;;;8EAKRmQ;IACvClY,YAAY+S,GAAkBlR;QAC5BH,MAAMqR,GAAO4F,GAASM,gBAAgBpX;;IAGxC7B,QAAQuU;QACN,MAAMlQ,IAAQkQ,EAAIxB,MAAM7S,KAAK6S;QAC7B,OAAOzB,GAAQjN,MAAUiV,EAAmBjV,EAAMuJ,YAAY1N,KAAK2B;;;;kEAKzCqW;IAC5BlY,YAAY+S,GAAkBlR;QAC5BH,MAAMqR,GAAO4F,GAASO,IAAIrX;;IAI5B7B,QAAQuU;QACN,MAAMlQ,IAAQkQ,EAAIxB,MAAM7S,KAAK6S;QAC7B,OAAiB,SAAV1O,KAAkBiV,EAAmBpZ,KAAK2B,MAAiB,YAAEwC;;;;kFAK5B6T;IAC1ClY,YAAY+S,GAAkBlR;QAC5BH,MAAMqR,GAAO4F,GAASQ,oBAAoBtX;;IAI5C7B,QAAQuU;QACN,MAAMlQ,IAAQkQ,EAAIxB,MAAM7S,KAAK6S;QAC7B,UAAKzB,GAAQjN,OAAWA,EAAMuJ,WAAWC,WAGlCxJ,EAAMuJ,WAAWC,OAAOoE,KAAKsH,KAClCD,EAAmBpZ,KAAK2B,MAAiB,YAAE0X;;;;;;;IAY/CvZ,YAA2B4B;QAAA1B,YAAA0B;;IAE3B5B;QACE,OAAOE,KAAK0B;;;;AANP8V,eAAY,OAAc,QAC1BA,gBAAa,OAAc;;;;;;;;;;;;;;;;;IAwBlC1X,YAAqBuY,GAAgCC;QAAhCtY,gBAAAqY,GAAgCrY,cAAAsY;;IAErDxY;;QAEE,OAAO,GAAGE,KAAKsY,SAAS,MAAM,OAAOtY,KAAKqY,SACvCxR,IAAIyS,KAAKvJ,EAAYuJ,IACrBjT,KAAK;;;;;WAOVvG,GAAoB2W,GAAoBpC;QAKtC,IAAIpF,IAAa;QACjB,KAAK,IAAIvJ,IAAI,GAAGA,IAAI1F,KAAKqY,SAASvT,QAAQY,KAAK;YAC7C,MAAM6T,IAAmB9C,MACnB+C,IAAYxZ,KAAKqY;YACvB,IAAIkB,EAAiB1G,WAKnB5D,IAAazH,IACXA,KAAqBgS,EAAU1M,iBAC/BuH,EAAIxM,WAED;gBAMLoH,IAAaM,EAAaiK,GALTnF,EAAIxB,MAAM0G,EAAiB1G;;YAU9C,IAHI0G,EAAiBhC,QAAQC,GAAUY,eACrCnJ,MAA2B,IAEV,MAAfA,GACF;;QAGJ,OAAOjP,KAAKsY,SAASrJ,KAAc,IAAIA,IAAa;;IAGtDnP,QAAQqE;QACN,IAAc,SAAVA,GACF,QAAO;QAET,IACEnE,KAAKsY,WAAWnU,EAAMmU,UACtBtY,KAAKqY,SAASvT,WAAWX,EAAMkU,SAASvT,QAExC,QAAO;QAET,KAAK,IAAIY,IAAI,GAAGA,IAAI1F,KAAKqY,SAASvT,QAAQY,KAAK;YAG7C,KAAKqI,EAFgB/N,KAAKqY,aACJlU,EAAMkU,cAE1B,QAAO;;QAGX,QAAO;;;;;;;IAWTvY,YAAqB+S,GAAkB0E;QAAlBvX,aAAA6S,QACP9N,MAARwS,MACFA,IAAMC,GAAUC,YAElBzX,KAAKuX,MAAMA,GACXvX,UAAoB6S;;IAGtB/S,QAAQiW,GAAcC;QACpB,MAAM/G,IAAajP,UACfsT,cACAA,MAAwBtT,KAAK6S;QACjC,QAAQ7S,KAAKuX;UACX,KAAKC,GAAUC;YACb;;UACF,KAAKD,GAAUY;YACb,QAAQ;;UACV;YACE,OAAOpT,GAAK,wBAAwBhF,KAAKuX;;;IAI/CzX;;QAEE,OAAOE,KAAK6S,YAA0B7S,KAAKuX,IAAI9V;;IAGjD3B;QACE,OAAO,GAAGE,KAAK6S,cAA4B7S,KAAKuX;;IAGlDzX,QAAQqE;QACN,OAAOnE,KAAKuX,QAAQpT,EAAMoT,OAAOvX,KAAK6S,MAAMlO,QAAQR,EAAM0O;;;;AAI9D,MAAM4G,KAAmB,OAAY9S,OAAsB6Q,GAAUC,YAC/DiC,KAAoB,OACxB/S,OACA6Q,GAAUY;;;;;;;;;;;;;;;;;;;;;;ICz0BVtY;;IAEW6Z;;;;;IAKA5P;;IAEA6P;;;;;IAKAC;;IAEAC,IAAmCrV,EAAgBC;;;;UAKnDqV,IAAgDtV,EAAgBC;;;;;;UAOhEsV,IAA0BxO;QA1B1BxL,cAAA2Z,GAKA3Z,gBAAA+J,gBAOA/J,sBAAA6Z;QAOA7Z,oCAAA+Z,GAOA/Z,mBAAAga;;kFAIXla,GAAmB+Z;QACjB,OAAO,OACL7Z,KAAK2Z,QACL3Z,KAAK+J,UACL/J,SACA6Z,GACA7Z,SACAA,KAAK+Z,8BACL/Z,KAAKga;;;;;WAQTla,GACEka,GACAF;QAEA,OAAO,OACL9Z,KAAK2Z,QACL3Z,KAAK+J,UACL/J,SACAA,KAAK6Z,mBAEL7Z,KAAK+Z,8BACLC;;;;;WAQJla,GACEia;QAEA,OAAO,OACL/Z,KAAK2Z,QACL3Z,KAAK+J,UACL/J,SACAA,KAAK6Z,gBACL7Z,SACA+Z,GACA/Z,KAAKga;;;;;;;;;;;;;;;;;;;UCpGEC;;IAEXna,YAAmBmK;QAAAjK,aAAAiK;;;;;;;;;;;;;;;;;;;;;;;;;;;;;GCYrB;;;;;;;;YA0BiC3I;IAC/B,QAAQA;MACN,KAAKpB,EAAKC;QACR,OAAO6E,GAAK;;MACd,KAAK9E,EAAKE;MACV,KAAKF,EAAKG;MACV,KAAKH,EAAKK;MACV,KAAKL,EAAKU;MACV,KAAKV,EAAKe;MACV,KAAKf,EAAKgB;;;cAGV,KAAKhB,EAAKS;QACR,QAAO;;MACT,KAAKT,EAAKI;MACV,KAAKJ,EAAKM;MACV,KAAKN,EAAKO;MACV,KAAKP,EAAKQ;MACV,KAAKR,EAAKW;;;;cAIV,KAAKX,EAAKY;MACV,KAAKZ,EAAKa;MACV,KAAKb,EAAKc;MACV,KAAKd,EAAKiB;QACR,QAAO;;MACT;QACE,OAAO6D,GAAK,0BAA0B1D;;;;;;;;;;;;;;;;;;;;;;;YA4CTA;IACjC,SAAayD,MAATzD;;;IAIF,OADA4Y,GAAS,4BACFha,EAAKG;IAGd,QAAQiB;MACN,KAAK6Y,GAAQha;QACX,OAAOD,EAAKC;;MACd,KAAKga,GAAQ/Z;QACX,OAAOF,EAAKE;;MACd,KAAK+Z,GAAQ9Z;QACX,OAAOH,EAAKG;;MACd,KAAK8Z,GAAQ5Z;QACX,OAAOL,EAAKK;;MACd,KAAK4Z,GAAQvZ;QACX,OAAOV,EAAKU;;MACd,KAAKuZ,GAAQlZ;QACX,OAAOf,EAAKe;;MACd,KAAKkZ,GAAQjZ;QACX,OAAOhB,EAAKgB;;MACd,KAAKiZ,GAAQxZ;QACX,OAAOT,EAAKS;;MACd,KAAKwZ,GAAQ7Z;QACX,OAAOJ,EAAKI;;MACd,KAAK6Z,GAAQ3Z;QACX,OAAON,EAAKM;;MACd,KAAK2Z,GAAQ1Z;QACX,OAAOP,EAAKO;;MACd,KAAK0Z,GAAQzZ;QACX,OAAOR,EAAKQ;;MACd,KAAKyZ,GAAQtZ;QACX,OAAOX,EAAKW;;MACd,KAAKsZ,GAAQrZ;QACX,OAAOZ,EAAKY;;MACd,KAAKqZ,GAAQpZ;QACX,OAAOb,EAAKa;;MACd,KAAKoZ,GAAQnZ;QACX,OAAOd,EAAKc;;MACd,KAAKmZ,GAAQhZ;QACX,OAAOjB,EAAKiB;;MACd;QACE,OAAO6D,GAAK,0BAA0B1D;;;;;;;;;;;8CA5I1C8Y;AACAA,gCACAA;AACAA,oDACAA;AACAA,8CACAA;AACAA,iDACAA;AACAA,wDACAA;AACAA,2CACAA;AACAA,mCACAA,yCACAA;;;;;;;;;;;;;;;;;;ACfF,MAAMC,KAA2B,MAC/B7S;;;IAGA;;;;IASA,OAAO8S;;;AAST,MAAMC,KAAqB,MACzB/S;;;IAGA;;;AAIF,MAAMgT,KAA6B,MACjChT;;;IAGA;;;AAIF,MAAMiT,KAAyB,MAAcjT;;eACXkI;IAChC,IAAIwE;IACJ,KAAK,MAAMrM,KAAO6H,GAChBwE,IAAMA,EAAIzK,IAAI5B;IAEhB,OAAOqM;;;AAIT,MAAMwG,KAAsB;;;IAE1B;;;;;;;;;;;;;;;;;;;;;;;;;;ICtCA5a,YAAYiY;;;QAIR/X,aAAkB,CAAC+V,GAAcC,MAC/B+B,WAAgBvQ,IAAuBuO,EAAGlO,KAAKmO,EAAGnO,OAElC,CAACkO,GAAcC,MAC/BxO,IAAuBuO,EAAGlO,KAAKmO,EAAGnO;QAGtC7H,UAAgB2a,MAChB3a,UAAiB,MAA8BA;;;;;WArBjDF,UAAgB8a;QACd,OAAO,OAAgBA;;IAuBzB9a,IAAI+H;QACF,OAAiC,QAA1B7H,QAAcsC,IAAIuF;;IAG3B/H,IAAI+H;QACF,OAAO7H,QAAcsC,IAAIuF;;IAG3B/H;QACE,OAAOE;;IAGTF;QACE,OAAOE;;IAGTF;QACE,OAAOE;;;;;WAOTF,QAAQ+H;QACN,MAAMwM,IAAMrU,QAAcsC,IAAIuF;QAC9B,OAAOwM,IAAMrU,QAAeuG,QAAQ8N,MAAQ;;IAG9C7O;QACE,OAAOxF,QAAewF;;kEAIxB1F,QAAQsJ;QACNpJ,WAAgC,CAACmI,GAAGC,OAClCgB,EAAGjB,KACI;;8DAKXrI,IAAIuU;;QAEF,MAAMH,IAAMlU,KAAKmU,OAAOE,EAAIxM;QAC5B,OAAOqM,KACLA,QAAoBG,EAAIxM,KAAKwM,IAC7BH,QAAqBG,GAAK;;kDAK9BvU,OAAO+H;QACL,MAAMwM,IAAMrU,KAAKsC,IAAIuF;QACrB,OAAKwM,IAIErU,QAAUA,QAAc8H,OAAOD,IAAM7H,QAAe8H,OAAOuM,MAHzDrU;;IAMXF,QAAQqE;QACN,MAAMA,kBACJ,QAAO;QAET,IAAInE,KAAKwF,SAASrB,EAAMqB,MACtB,QAAO;QAGT,MAAMkE,IAAS1J,cACT2J,IAAUxF;QAChB,MAAOuF,UAAkB;YACvB,MAAMmR,IAAUnR,OAAiB7B,KAC3BiT,IAAWnR,OAAkB9B;YACnC,KAAKgT,EAAQlW,YACX,QAAO;;QAGX,QAAO;;IAGT7E;QACE,MAAMib,IAAuB;QAI7B,OAHA/a,KAAKqF,QAAQgP;YACX0G,EAAWxV,KAAK8O,EAAI5S;YAEI,MAAtBsZ,EAAWjW,SACN,mBAEA,sBAAsBiW,EAAW1U,KAAK,UAAU;;IAI3DvG,GACEkb,GACAC;QAEA,MAAMC,IAAS;QAIf,OAHAA,MAAoBlb,QACpBkb,UACAA;;;;;;;;;;;;;;;;;;;;;;;;ICjHJpb;QACEE,UAAoB,MAClBwH;;IAGF1H,MAAMqb;QACJ,MAAMtT,IAAMsT,EAAO9G,IAAIxM,KACjBuT,IAAYpb,QAAesC,IAAIuF;;;0BAQnCsT,EAAOE,6BACPD,EAAUC,OAEVrb,UAAiBA,WAAsB6H,6BAEvCsT,EAAOE,4BACPD,EAAUC,OAEVrb,UAAiBA,WAAsB6H,GAAK;YAC1CwT,MAAMD,EAAUC;YAChBhH,KAAK8G,EAAO9G;kCAGd8G,EAAOE,6BACPD,EAAUC,OAEVrb,UAAiBA,WAAsB6H,GAAK;YAC1CwT;YACAhH,KAAK8G,EAAO9G;kCAGd8G,EAAOE,0BACPD,EAAUC,OAEVrb,UAAiBA,WAAsB6H,GAAK;YAC1CwT;YACAhH,KAAK8G,EAAO9G;iCAGd8G,EAAOE,0BACPD,EAAUC,OAEVrb,UAAiBA,QAAe8H,OAAOD,yBAEvCsT,EAAOE,6BACPD,EAAUC,OAEVrb,UAAiBA,WAAsB6H,GAAK;YAC1CwT;YACAhH,KAAK+G,EAAU/G;+BAGjB8G,EAAOE,4BACPD,EAAUC,OAEVrb,UAAiBA,WAAsB6H,GAAK;YAC1CwT;YACAhH,KAAK8G,EAAO9G;;;;;;;;;QAUdrP,GACE,yCACEkH,KAAKC,eACL,YACAD,KAAKC,gBAnETnM,UAAiBA,WAAsB6H;;IAwE3C/H;QACE,MAAMwb,IAAgC;QAMtC,OALAtb,WACE,CAAC6H,GAAkBsT;YACjBG,EAAQ/V;;;;;;IAQdzF,YACWyb,GACAC,GACAC,GACAC,GACAC,GACAC,GACAC,GACAC;QAPA9b,aAAAub,GACAvb,YAAAwb,gBAEAxb,kBAAA0b,gBAEA1b,iBAAA4b;;;sFAMX9b,UACEyb,GACAQ,GACAJ,GACAC;QAEA,MAAMN,IAAgC;QAKtC,OAJAS,EAAU1W,QAAQgP;YAChBiH,EAAQ/V,KAAK;gBAAE8V;gBAAwBhH,KAAAA;;YAGlC,OACLkH,GACAQ,GACAC,MAAqBD,UAGrBH;iCACwB;wCACO;;IAInCxF;QACE,QAAQpW;;IAGVF,QAAQqE;QACN,MACEnE,KAAK4b,cAAczX,EAAMyX,aACzB5b,YAA0BmE,QACzBnE,QAAiB2E,QAAQR,SACzBnE,KAAKub,MAAM5W,QAAQR,EAAMoX,UACzBvb,KAAKwb,KAAK7W,QAAQR,EAAMqX,SACxBxb,QAAa2E,QAAQR,QAEtB,QAAO;QAET,MAAMmX,IAAgCtb,KAAK0b,YACrCO,IAAqC9X,EAAMuX;QACjD,IAAIJ,EAAQxW,WAAWmX,EAAanX,QAClC,QAAO;QAET,KAAK,IAAIY,IAAI,GAAGA,IAAI4V,EAAQxW,QAAQY,KAClC,IACE4V,KAAWD,SAASY,KAAgBZ,SACnCC,KAAWjH,IAAI1P,QAAQsX,KAAgB5H,MAExC,QAAO;QAGX,QAAO;;;;;;;;;;;;;;;;;;;;;;;;;ICxKTvU;;;;IAIWga;;;;IAIAoC;;;;;IAKAC;;;;;IAKAC;;;;IAIAC;;;;;;;;;;IAUXvc,UACEiK,GACA/C;QAEA,MAAMkV,IAAgB,IAAI9G;QAQ1B,OAPA8G,EAAchI,IACZnK,GACAuS,MACEvS,QAIG,OACLtF,EAAgBC,QAEhB6X,MACAjC,MACAkC;;;;;;;;;;;UAaOF;IACXxc;;;;;;;IAOWka;;;;;;IAMAhT;;;;;IAKAyV;;;;;IAKAC;;;;;IAKAC;QArBA3c,mBAAAga;;;;;;WA6BXla,UACEiK,GACA/C;QAEA,OAAO,IAAIsV,GACT9Q,SAEAgR,MACAA,MACAA;;;;;;;;;;;;;;;;;;;;;;;;;;IC1FJ1c;;IAES8c;;IAEAC;;IAEAhV;;;;;IAKAiV;qBAPA9c,wBAAA6c,GAEA7c,WAAA6H;;;;;IAUT/H,YACSiK,GACAgT;QADA/c,gBAAA+J;;;;;IAcTjK;;IAESkd;;IAEAC;;;;;;;IAOAjD,IAA0BxO;2DAE1B0R,IAA+B;QAX/Bld,aAAAgd,GAEAhd,iBAAAid,GAOAjd,mBAAAga,GAEAha,aAAAkd;;;;mDAKX;IAAApd;;;;;QAKEE,UAA2B;;;;;;;QAQ3BA,UAGImd;;QAGJnd,UAAmCwL,MACnCxL,WAAmB;;;;;;QAOnBA,WAA6B;;;;;;;;;WAU7Bod;QACE,OAAOpd;;gEAITga;QACE,OAAOha;;6EAITqd;QACE,OAAiC,MAA1Brd;;iFAITsd;QACE,OAAOtd;;;;;WAOTF,GAAkBka;QACZA,SAAoC,MACtCha,WAA0B,GAC1BA,UAAoBga;;;;;;;WAUxBla;QACE,IAAI2c,IAAiBD,MACjBE,IAAoBF,MACpBG,IAAmBH;QAkBvB,OAhBAxc,QAAqBqF,QAAQ,CAACwC,GAAK0V;YACjC;cACE;gBACEd,IAAiBA,EAAehT,IAAI5B;gBACpC;;cACF;gBACE6U,IAAoBA,EAAkBjT,IAAI5B;gBAC1C;;cACF;gBACE8U,IAAmBA,EAAiBlT,IAAI5B;gBACxC;;cACF;gBACE7C,GAAK;;YAIJ,IAAIsX,GACTtc,SACAA;;;;WAUJF;QACEE,WAA0B,GAC1BA,UAAuBmd;;IAGzBrd,GAAkB+H,GAAkB0V;QAClCvd,WAA0B,GAC1BA,UAAuBA,WAA4B6H;;IAGrD/H,GAAqB+H;QACnB7H,WAA0B,GAC1BA,UAAuBA,QAAqB8H,OAAOD;;IAGrD/H;QACEE,WAAyB;;IAG3BF;QACEE,WAAyB;;IAG3BF;QACEE,WAA0B,GAC1BA,WAAgB;;;;;;;;IA4BlBF,YAAoB0d;;;QAGpBxd,UAAuB,IAAIoV;;QAG3BpV,UAAiCsa;;QAGjCta,UAAuCyd;;;;;;QAOvCzd,UAA8B;;;;WAK9BF,GAAqB4d;QACnB,KAAK,MAAM3T,KAAY2T,MACjBA,gBAA4BpK,KAC9BtT,QAAyB+J,GAAU2T,QAC1BA,sBACT1d,QACE+J,GACA2T,EAAU7V,KACV6V;QAKN,KAAK,MAAM3T,KAAY2T,EAAUb,kBAC/B7c,QAA8B+J,GAAU2T,EAAU7V,KAAK6V;;sFAK3D5d,GAAmB6d;QACjB3d,QAAmB2d,GAAc5T;YAC/B,MAAM6T,IAAc5d,QAAuB+J;YAC3C,QAAQ4T,EAAaX;cACnB;gBACMhd,QAAoB+J,MACtB6T,KAA8BD,EAAa3D;gBAE7C;;cACF;;;gBAGE4D,QACKA;;;;gBAIHA,QAEFA,KAA8BD,EAAa3D;gBAC3C;;cACF;;;;;gBAKE4D,QACKA,QACH5d,KAAK6d,aAAa9T;gBAMpB;;cACF;gBACM/J,QAAoB+J,OACtB6T,QACAA,KAA8BD,EAAa3D;gBAE7C;;cACF;gBACMha,QAAoB+J;;;;gBAItB/J,QAAiB+J,IACjB6T,KAA8BD,EAAa3D;gBAE7C;;cACF;gBACEhV,GAAK,wCAAwC2Y,EAAaX;;;;;;;;WAUlEld,GACE6d,GACA/X;QAEI+X,EAAaV,UAAUnY,SAAS,IAClC6Y,EAAaV,UAAU5X,QAAQO,KAE/B5F,QAAkBqF,QAAQ,CAACyY,GAAG/T;YACxB/J,QAAoB+J,MACtBnE,EAAGmE;;;;;;;WAWXjK,GAAsBie;QACpB,MAAMhU,IAAWgU,EAAYhU,UACvBiU,IAAgBD,KAA4B9T,OAE5CgU,IAAaje,QAA+B+J;QAClD,OAAgB;YACd,MAAM4P,IAASsE,EAAWtE;YAC1B,IAAIA,QACF,IAAsB,MAAlBqE,GAAqB;;;;;;;gBAOvB,MAAMnW,IAAM,MAAgB8R,EAAOrT;gBACnCtG,QACE+J,GACAlC,GACA,OAAeA,GAAKpD;mBAGtB7B,GACoB,MAAlBob,GACA,2DAGC;gBACehe,QAAsC+J;;;gBAIxD/J,QAAiB+J,IACjB/J,UAA2BA,QAAyByJ,IAAIM;;;;;;;WAUhEjK,GAAkBga;QAChB,MAAMoC,IAAgB,IAAI9G;QAE1BpV,QAAkBqF,QAAQ,CAACuY,GAAa7T;YACtC,MAAMkU,IAAaje,QAA+B+J;YAClD,OAAgB;gBACd,IAAI6T,QAAuBK,EAAWtE,aAA0B;;;;;;;;;oBAU9D,MAAM9R,IAAM,MAAgBoW,EAAWtE,OAAOrT;oBAEH,SAAzCtG,QAA4BsC,IAAIuF,MAC/B7H,QAA4B+J,GAAUlC,MAEvC7H,QACE+J,GACAlC,GACA,OAAeA;;gBAKjB+V,SACF1B,EAAchI,IAAInK,GAAU6T,SAC5BA;;;QAKN,IAAIvB,IAAyBG;;;;;;gBAO7Bxc,QAAkCqF,QAAQ,CAACwC,GAAKqW;YAC9C,IAAIC,KAAoB;YAExBD,KAAqBnU;gBACnB,MAAMkU,IAAaje,QAA+B+J;gBAClD,QACEkU,iCACAA,SAEAE,KAAoB,IACb;sBAOT9B,IAAyBA,EAAuB5S,IAAI5B;;QAIxD,MAAMuW,IAAc,aAGlBpe,SACAA;QAQF,OAJAA,UAA8Bsa,MAC9Bta,UAAoCyd,MACpCzd,UAA2B;;;;;;;IAU7BF,GAAoBiK,GAAoBsU;QACtC,KAAKre,QAAoB+J,IACvB;QAGF,MAAMwT,IAAavd,QAA4B+J,GAAUsU,EAASxW;QAI9C7H,QAAuB+J,MACbsU,EAASxW,SAEvC7H,UAA8BA,WAC5Bqe,EAASxW,KACTwW,IAGFre,UAAoCA,WAClCqe,EAASxW,KACT7H,QAAiCqe,EAASxW,KAAK4B,IAAIM;;;;;;;;;;IAYvDjK,GACEiK,GACAlC,GACAyW;QAEA,KAAKte,QAAoB+J,IACvB;QAGF,MAAM6T,IAAc5d,QAAuB+J;QACvC/J,QAA4B+J,GAAUlC,KACxC+V,KAA8B/V;;;QAI9B+V,KAAiC/V,IAGnC7H,UAAoCA,WAClC6H,GACA7H,QAAiC6H,GAAKsM,OAAOpK,WAI7C/J,UAA8BA,WAC5B6H;;IAMN/H,aAAaiK;QACX/J,QAAkBmU,OAAOpK;;;;;;WAQ3BjK,GAAyCiK;QACvC,MACM4T,IADc3d,QAAuB+J;QAE3C,OACE/J,WAA6C+J,GAAUvE,OACvDmY,KAA4BnY,OAC5BmY,KAA8BnY;;;;;WAQlC1F,GAA2BiK;QAEL/J,QAAuB+J;;IAI7CjK,GAA0BiK;QACxB,IAAItB,IAASzI,QAAkBsC,IAAIyH;QAKnC,OAJKtB,MACHA,IAAS,QACTzI,QAAkBkU,IAAInK,GAAUtB,KAE3BA;;IAGT3I,GAAoC+H;QAClC,IAAI0W,IAAgBve,QAAkCsC,IAAIuF;QAU1D,aAPE0W,IAAgB,WAChBve,UAAoCA,WAClC6H;;;;;;WAaN/H,GAAyBiK;QACvB,MAAMyU,IAA4D,SAA7Cxe,QAA+B+J;QAIpD,YAFE0U,GAxXU,yBAwXQ,4BAA4B1U;;;;;WASlDjK,GAAoCiK;QAClC,MAAM6T,IAAc5d,QAAkBsC,IAAIyH;QAC1C,OAAO6T,KAAeA,OAClB,OACA5d,WAA6C+J;;;;;;WAQnDjK,GAAoBiK;QAKlB/J,QAAkBkU,IAAInK,GAAU,SAKX/J,WAA6C+J,GACrD1E,QAAQwC;YACnB7H,QAA8B+J,GAAUlC,wBAA0B;;;;;;WAOtE/H,GACEiK,GACAlC;QAGA,OADqB7H,WAA6C+J,GAC9CP,IAAI3B;;;;AAI5B;IACE,OAAO,MACLL;;;AAIJ;IACE,OAAO,MAAuCA;;;;;;;;;;;;;;;;;;GClmBhD,OAAMkX,KAAa;IACjB,MAAMC,IAA8C;IAGpD,OAFAA,EAAKnH,GAAUC,UAAU/V,QAAQ,aACjCid,EAAKnH,GAAUY,WAAW1W,QAAQ;;EAHjB,IAObkd,KAAY;IAChB,MAAMC,IAA2C;IASjD,OARAA,EAAIpG,GAASC,UAAUhX,QAAQ,aAC/Bmd,EAAIpG,GAASE,mBAAmBjX,QAAQ;IACxCmd,EAAIpG,GAASK,aAAapX,QAAQ,gBAClCmd,EAAIpG,GAASI,sBAAsBnX,QAAQ;IAC3Cmd,EAAIpG,GAASG,MAAMlX,QAAQ,SAC3Bmd,EAAIpG,GAASM,eAAerX,QAAQ,kBACpCmd,EAAIpG,GAASO,GAAGtX,QAAQ;IACxBmd,EAAIpG,GAASQ,mBAAmBvX,QAAQ;EATxB;;;;;;;;;IAmChB5B,YACUmR,GACAkF;qBAAAnW,eAAAmW;;IAGVrW,GAAcgf;QACZ,MAAMxd,SACYyD,MAAhB+Z,EAAOxd,OACHpB,EAAKG,UACL0e,GAAmBD,EAAOxd;QAChC,OAAO,IAAIF,EAAeE,GAAMwd,EAAOvd,WAAW;;;;;;;;;WAWpDzB,GAAqBuZ;QACnB,OAAIrZ,KAAKmW,cAAyBY,EAAkBsC,KAC3CA,IAEA;YAAE1X,OAAO0X;;;;;WAOpBvZ,GACEuZ;QAEA,IAAI5Q;QAMJ,OAJEA,IADiB,mBAAR4Q,IACAA,EAAI1X,QAEJ0X,GAEJtC,EAAkBtO,KAAU,OAAOA;;;;WAM5C3I,GAAU6B;QACR,OAAO;YAAEyL,cAAc,KAAKzL;;;;;;WAO9B7B,GAAS6B;QACP,IAAI3B,KAAKmW,YAAuB;YAC9B,IAAI5I,MAAM5L,IACR,OAAO;gBAAE2M,aAAa;;YACjB,IAAI3M,MAAUqd,IAAAA,GACnB,OAAO;gBAAE1Q,aAAa;;YACjB,IAAI3M,OAAWqd,IAAAA,GACpB,OAAO;gBAAE1Q,aAAa;;;QAG1B,OAAO;YAAEA,aAAajD,EAAe1J,KAAS,OAAOA;;;;;;;WAQvD7B,GAAS6B;QACP,OAAOuJ,EAAcvJ,KAAS3B,QAAe2B,KAAS3B,QAAc2B;;;;WAMtE7B,EAAY0E;QACV,IAAIxE,KAAKmW,YAAuB;YAU9B,OAAO,GANW,IAAIxS,KAAyB,MAApBa,EAAUhB,SAAgByb,cAEnBlY,QAAQ,SAAS,IAAIA,QAAQ,KAAK,QAEnD,cAAcvC,EAAUf,aAAa0B,OAAO;;QAI7D,OAAO;YACL3B,SAAS,KAAKgB,EAAUhB;YACxBsI,OAAOtH,EAAUf;;;IAMvB3D,EAAsB+D;QACpB,MAAMW,IAAYqH,GAAmBhI;QACrC,OAAO,IAAIN,EAAUiB,EAAUhB,SAASgB,EAAUsH;;;;;;WAQpDhM,GAAQof;QACN,OAAIlf,KAAKmW,aACA+I,EAAM/O,aAEN+O,EAAMC;;;;WAOjBrf,GAAU6B;QACR,OAAI3B,KAAKmW,cACPvT,QACYmC,MAAVpD,KAAwC,mBAAVA,GAC9B;QAEK6J,EAAWuF,iBAAiBpP,KAAgB,QAEnDiB,QACYmC,MAAVpD,KAAuBA,aAAiBoJ,YACxC;QAEKS,EAAWwF,eAAerP,KAAgB,IAAIoJ;;IAIzDjL,UAAUiT;QACR,OAAO/S,OAAiB+S;;IAG1BjT,YAAYiT;QAEV,OADAnQ,KAAamQ,GAAS,iDACftO,IAA8BzE,OAAmB+S;;IAG1DjT,GAAewG,GAAoB2K;QACjC,OAAOjR,QAA8BiR,KAAcjR,SAChDkV,MAAM,aACNA,MAAM5O;;IAIXxG,GAAiB4B;QACf,MAAM0d,IAAWhZ,IAAwB1E;QAKzC,OAJAkB,GACEyc,OACA,sCAAsCD,EAAS3d;;IAKnD3B,GAAO+H;QACL,OAAO7H,QAAoB6H,EAAIvB;;IAGjCxG,GAAS4B;QACP,MAAM0d,IAAWpf,QAAsB0B;QAgBvC,OAfAkB,GACEwc,EAAS9c,IAAI,OAAOtC,QAAgBkR,WACpC,sDACEkO,EAAS9c,IAAI,KACb,SACAtC,QAAgBkR;QAEpBtO,IACIwc,EAAS9c,IAAI,OAAOtC,QAAgBmR,YACpCiO,EAAS9c,IAAI,OAAOtC,QAAgBmR,UACtC,uDACEiO,EAAS9c,IAAI,KACb,SACAtC,QAAgBmR;QAEb,MAAgBnR;;IAGzBF,GAAYwG;QACV,OAAOtG,QAAoBsG;;IAG7BxG,GAAc4B;QACZ,MAAM4d,IAAetf,QAAsB0B;;;;;gBAK3C,OAA4B,MAAxB4d,EAAaxa,SACRsB,MAEFpG;;IAGTuf;QAOE,OANa,IAAInZ,EAAa,EAC5B,YACApG,QAAgBkR,WAChB,aACAlR,QAAgBmR;;IAKpBrR,GAAiCmR;QAC/B,OAAO,IAAI7K,EAAa,EACtB,YACA6K,EAAWC,WACX,aACAD,EAAWE;;IAIfrR,GACEwf;QAMA,OAJA1c,GACE0c,EAAaxa,SAAS,KAA6B,gBAAxBwa,EAAahd,IAAI,IAC5C,sCAAsCgd,EAAa7d;QAE9C6d,IAAsB;;sFAI/Bxf,GAAmB+H,GAAkB6D;QACnC,OAAO;YACLhK,MAAM1B,QAAY6H;YAClB6D,QAAQA,EAAOmJ,MAAMpJ,SAASC;;;IAIlC5L,GAAWue;QAKT,OAAO;YACL3c,MAAM1B,QAAYqe,EAASxW;YAC3B6D,QAAQ2S,OAAmB5S,SAASC;YACpCwH,YAAYlT,OAAiBqe,EAAStL;;;IAI1CjT,GACEue,GACA3K;QAEA,MAAM7L,IAAM7H,QAAcqe,EAAc,OAClCtL,IAAU/S,KAAKwf,YAAYnB,EAASnL,aACpChK,IAAO,OAAgB;YAAEuC,UAAU;gBAAEC,QAAQ2S,EAAS3S;;;QAC5D,OAAO,IAAI4H,GAASzL,GAAKkL,GAAS7J,GAAM;YACtCwK,yBAAyBA;;;IAI7B5T,GAAkBuU;QAChBzR,KACIyR,EAAI3B,OACN;QAEY2B,EAAI3B,MAAMhR,MACV2S,EAAI3B,MAAMQ;QACxB,MAAMrL,IAAM7H,QAAcqU,EAAI3B,MAAMhR,OAC9BqR,IAAU/S,KAAKwf,YAAYnL,EAAI3B,MAAMQ,aACrChK,IAAO,OAAgB;YAAEuC,UAAU;gBAAEC,QAAQ2I,EAAI3B,MAAMhH;;;QAC7D,OAAO,IAAI4H,GAASzL,GAAKkL,GAAS7J,GAAM;;IAG1CpJ,GAAoB2I;QAClB7F,KACI6F,EAAOgX,SACT;QAEF7c,KACI6F,EAAOiX,UACT;QAEF,MAAM7X,IAAM7H,QAAcyI,EAAOgX,UAC3B1M,IAAU/S,KAAKwf,YAAY/W,EAAOiX;QACxC,OAAO,OAAe7X,GAAKkL;;IAG7BjT,GAAkB2I;QAChB,OAAI,WAAWA,IACNzI,QAAeyI,KACb,aAAaA,IACfzI,QAAiByI,KAEnBzD,GAAK,iCAAiCkH,KAAKC,UAAU1D;;IAG9D3I,GAAgBqb;QACd,IAAI4C;QACJ,IAAI,qBAA0B;YACd5C,EAAOwC;;;YAGrB,MAAMX,IAAQhd,QACZmb,EAAOwC,aAAagC,oBAAoB,cAEpC1C,IAAwB9B,EAAOwC,aAAaV,aAAa,IAEzDjD,IAAcha,QAAemb,EAAOwC,aAAa3D,cACjD4F,IAAazE,EAAOwC,aAAcT,OAClCA,IAAQ0C,KAAc5f;YAC5B+d,IAAc,OACZf,GACAC,GACAjD,GACAkD,KAAS;eAEN,IAAI,uBAA4B;YACvB/B,EAAO0E;YACrB,MAAMC,IAAe3E,EAAO0E;YACdC,EAAazB,UACbyB,EAAazB,SAAS3c,MAElCoe,EAAazB,SAASnL;YAGxB,MAAMrL,IAAM7H,QAAc8f,EAAazB,SAAS3c,OAC1CqR,IAAU/S,KAAKwf,YAAYM,EAAazB,SAASnL,aACjDhK,IAAO,OAAgB;gBAC3BuC,UAAU;oBAAEC,QAAQoU,EAAazB,SAAS3S;;gBAEtC2I,IAAM,IAAIf,GAASzL,GAAKkL,GAAS7J,GAAM,KACvC0T,IAAmBkD,EAAa7C,aAAa,IAC7CJ,IAAmBiD,EAAajD,oBAAoB;YAC1DkB,IAAc,UAEZlB,GACAxI,EAAIxM,KACJwM;eAEG,IAAI,uBAA4B;YACvB8G,EAAO4E;YACrB,MAAMC,IAAY7E,EAAO4E;YACXC,EAAU3B;YACxB,MAAMxW,IAAM7H,QAAcggB,EAAU3B,WAC9BtL,IAAUiN,EAAUN,WACtB1f,KAAKwf,YAAYQ,EAAUN,YAC3Bjb,OACE4P,IAAM,OAAexM,GAAKkL,IAC1B8J,IAAmBmD,EAAUnD,oBAAoB;YACvDkB,IAAc,OAAwB,IAAIlB,GAAkBxI,EAAIxM,KAAKwM;eAChE,IAAI,uBAA4B;YACvB8G,EAAO8E;YACrB,MAAMC,IAAY/E,EAAO8E;YACXC,EAAU7B;YACxB,MAAMxW,IAAM7H,QAAckgB,EAAU7B,WAC9BxB,IAAmBqD,EAAUrD,oBAAoB;YACvDkB,IAAc,OAAwB,IAAIlB,GAAkBhV,GAAK;eAC5D;YAAA,MAAI,gBAUT,OAAO7C,GAAK,yBAAyBkH,KAAKC;YAVb;gBAEfgP,EAAO1U;gBACrB,MAAMA,IAAS0U,EAAO1U;gBACRA,EAAOsD;gBACrB,MAAME,IAAQxD,EAAOwD,SAAS,GACxB8S,IAAkB,IAAI9C,GAAgBhQ,IACtCF,IAAWtD,EAAOsD;gBACxBgU,IAAc,OAA0BhU;;;QAI1C;;IAGFjK,GACEkd;QAEA,OAAc,gBAAVA,uBAEiB,UAAVA,oBAEU,aAAVA,sBAEU,cAAVA,sBAEU,YAAVA,oBAGFhY,GAAK,wCAAwCgY;;IAIxDld,GAA0Bqb;;;;QAIxB,MAAM,sBACJ,OAAO1W,EAAgBC;QAEzB,MAAMiZ,IAAexC,EAAoB;QACzC,OAAIwC,EAAaV,aAAaU,EAAaV,UAAUnY,SAC5CL,EAAgBC,MAEpBiZ,EAAa+B,WAGX1f,KAAKwf,YAAY7B,EAAa+B,YAF5Bjb,EAAgBC;;IAK3B5E,GAAWqgB;QACT,IAAI1X;QACJ,IAAI0X,iBACF1X,IAAS;YACP2X,QAAQpgB,QAAwBmgB,EAAStY,KAAKsY,EAASxe;gBAEpD,IAAIwe,iBACT1X,IAAS;YAAE0L,QAAQnU,QAAYmgB,EAAStY;gBACnC,IAAIsY,iBACT1X,IAAS;YACP2X,QAAQpgB,QAAwBmgB,EAAStY,KAAKsY,EAASjX;YACvDmX,YAAYrgB,QAAoBmgB;gBAE7B,IAAIA,iBACT1X,IAAS;YACPqK,WAAW;gBACTuL,UAAUre,QAAYmgB,EAAStY;gBAC/BuM,iBAAiB+L,EAAS/L,gBAAgBvN,IAAIiM,KAC5C9S,QAAsB8S;;gBAIvB;YAAA,MAAIqN,kBAKT,OAAOnb,GAAK,2BAA2Bmb,EAAS9E;YAJhD5S,IAAS;gBACP6X,QAAQtgB,QAAYmgB,EAAStY;;;QAUjC,OAJKsY,YACH1X,EAAO8X,kBAAkBvgB,QAAoBmgB,QAGxC1X;;IAGT3I,GAAa+U;QACX,MAAMrB,IAAeqB,EAAM0L,kBACvBvgB,QAAsB6U,EAAM0L,mBAC5BtN,GAAauN;QAEjB,IAAI3L,EAAMuL,QAAQ;YACFvL,EAAMuL,OAAO1e;YAC3B,MAAMmG,IAAM7H,QAAc6U,EAAMuL,OAAO1e,OACjCC,IAAQ,OAAgB;gBAC5B8J,UAAU;oBAAEC,QAAQmJ,EAAMuL,OAAO1U;;;YAEnC,IAAImJ,EAAMwL,YAAY;gBACpB,MAAMxM,IAAY7T,QAAsB6U,EAAMwL;gBAC9C,OAAO,OAAkBxY,GAAKlG;;YAE9B,OAAO,OAAgBkG,GAAKlG;;QAEzB,IAAIkT,EAAMV,QAAQ;YACvB,MAAMtM,IAAM7H,QAAc6U,EAAMV;YAChC,OAAO,OAAmBtM;;QACrB,IAAIgN,EAAM/B,WAAW;YAC1B,MAAMjL,IAAM7H,QAAc6U,EAAM/B,UAAmB,WAC7CsB,IAAkBS,EAAM/B,UAAUsB,gBAAiBvN,IAAIiM,KAC3D9S,QAAwB8S;YAM1B,OAJAlQ,IAC0B,MAAxB4Q,EAAaL,QACb;YAEK,OAAsBtL,GAAKuM;;QAC7B,IAAIS,EAAMyL,QAAQ;YACvB,MAAMzY,IAAM7H,QAAc6U,EAAMyL;YAChC,OAAO,OAAmBzY;;QAE1B,OAAO7C,GAAK,6BAA6BkH,KAAKC,UAAU0I;;IAI5D/U,GAAuB0T;QAErB,YAAgCzO,MAA5ByO,EAAaN,aACR;YACLA,YAAYlT,KAAKygB,UAAUjN,EAAaN;iBAETnO,MAAxByO,EAAaL,SACf;YAAEA,QAAQK,EAAaL;YAEvBnO,GAAK;;IAIhBlF,GAAyB0T;QACvB,YAAgCzO,MAA5ByO,EAAaN,aACRD,GAAaC,WAAWlT,KAAKwf,YAAYhM,EAAaN,oBAC5BnO,MAAxByO,EAAaL,SACfF,GAAaE,OAAOK,EAAaL,UAEjCF,GAAauN;;IAIxB1gB,GACE+U,GACA6L;;QAGA,IAAI3N,IAAU8B,EAAM3B,aAChBlT,KAAKwf,YAAY3K,EAAM3B,cACvBlT,KAAKwf,YAAYkB;QAEjB3N,EAAQpO,QAAQF,EAAgBC;;;;;;QAMlCqO,IAAU/S,KAAKwf,YAAYkB;QAG7B,IAAI1N,IAAuC;QAI3C,OAHI6B,EAAM7B,oBAAoB6B,EAAM7B,iBAAiBlO,SAAS,MAC5DkO,IAAmB6B,EAAM7B;QAEpB,OAAmBD,GAASC;;IAGrClT,GACE6gB,GACAD;QAEA,OAAIC,KAAUA,EAAO7b,SAAS,KAC5BlC,QACiBmC,MAAf2b,GACA;QAEKC,EAAO9Z,IAAIgO,KAAS7U,QAAqB6U,GAAO6L,OAEhD;;IAIX5gB,GAAyByU;QACvB,MAAMzB,IAAYyB,EAAezB;QACjC,IAAIA,iBACF,OAAO;YACLL,WAAW8B,EAAe1B;YAC1B+N,kBAAkB;;QAEf,IAAI9N,iBACT,OAAO;YACLL,WAAW8B,EAAe1B;YAC1BgO,uBAAuB;gBACrBlT,QAAQmF,EAAUnB;;;QAGjB,IAAImB,iBACT,OAAO;YACLL,WAAW8B,EAAe1B;YAC1BiO,oBAAoB;gBAClBnT,QAAQmF,EAAUnB;;;QAGjB,IAAImB,iBACT,OAAO;YACLL,WAAW8B,EAAe1B;YAC1BkO,WAAWjO;;QAGb,MAAM9N,GAAK,wBAAwBuP,EAAezB;;IAItDhT,GAA2B+U;QACzB,IAAI/B,IAAuC;QAC3C,IAAI,sBAAsB+B,GACxBjS,GAC6B,mBAA3BiS,EAAM+L,kBACN,2CAA2C1U,KAAKC,UAAU0I;QAE5D/B,IAAYpB,GAAyBsP,eAChC,IAAI,2BAA2BnM,GAAO;YAC3C,MAAMlH,IAASkH,EAAMgM,sBAAuBlT,UAAU;YACtDmF,IAAY,OAAiCnF;eACxC,IAAI,wBAAwBkH,GAAO;YACxC,MAAMlH,IAASkH,EAAMiM,mBAAoBnT,UAAU;YACnDmF,IAAY,OAAkCnF;eACrC,eAAekH,IACxB/B,IAAY,OACV9S,MACA6U,EAAgB,aAGlB7P,GAAK,8BAA8BkH,KAAKC,UAAU0I;QAEpD,MAAMpC,IAAY9L,IAA2BkO,EAAgB;QAC7D,OAAO,IAAIjC,GAAeH,GAAWK;;IAGvChT,GAAkB6Z;QAChB,OAAO;YAAEoC,WAAW,EAAC/b,QAAiB2Z,EAAOrT;;;IAG/CxG,GAAoBmhB;QAClB,MAAMhX,IAAQgX,EAAgBlF,UAAWjX;QACzClC,GACY,MAAVqH,GACA,sDAAsDA;QAExD,MAAMvI,IAAOuf,EAAgBlF,UAAW;QACxC,OAAO/E,MAAahX,QAAmB0B;;IAGzC5B,GAAc6Z;;QAEZ,MAAMlR,IAA0B;YAAEyY,iBAAiB;WAC7C5a,IAAOqT,EAAOrT;QACW,SAA3BqT,EAAOnD,mBAKT/N,EAAO0Y,SAASnhB,QAAiBsG,IACjCmC,EAAOyY,gBAAiBE,OAAO,EAC7B;YACE/Z,cAAcsS,EAAOnD;YACrB6K,iBAAgB;gBAQpB5Y,EAAO0Y,SAASnhB,QAAiBsG,QACjCmC,EAAOyY,gBAAiBE,OAAO,EAAC;YAAE/Z,cAAcf;;QAGlD,MAAMgb,IAAQthB,QAAc2Z,EAAOjD;QAC/B4K,MACF7Y,EAAOyY,gBAAiBI,QAAQA;QAGlC,MAAM7K,IAAUzW,QAAa2Z,EAAOlD;QAChCA,MACFhO,EAAOyY,gBAAiBzK,UAAUA;QAGpC,MAAMrR,IAAQpF,QAAkB2Z,EAAOvU;QAYvC,OAXc,SAAVA,MACFqD,EAAOyY,gBAAiB9b,QAAQA,IAG9BuU,EAAOhD,YACTlO,EAAOyY,gBAAiBvK,UAAU3W,QAAc2Z,EAAOhD;QAErDgD,EAAO/C,UACTnO,EAAOyY,gBAAiBtK,QAAQ5W,QAAc2Z,EAAO/C,SAGhDnO;;IAGT3I,GAAgB6Z;QACd,IAAIrT,IAAOtG,QAAmB2Z,EAAc;QAE5C,MAAM4B,IAAQ5B,EAAOuH,iBACfK,IAAYhG,EAAM6F,OAAO7F,EAAM6F,KAAKtc,SAAS;QACnD,IAAI0R,IAAiC;QACrC,IAAI+K,IAAY,GAAG;YACjB3e,GACgB,MAAd2e,GACA;YAEF,MAAMH,IAAO7F,EAAM6F,KAAM;YACrBA,EAAKC,iBACP7K,IAAkB4K,EAAK/Z,eAEvBf,IAAOA,EAAK4O,MAAMkM,EAAK/Z;;QAI3B,IAAIma,IAAqB;QACrBjG,EAAM+F,UACRE,IAAWxhB,QAAgBub,EAAM+F;QAGnC,IAAI7K,IAAqB;QACrB8E,EAAM9E,YACRA,IAAUzW,QAAeub,EAAM9E;QAGjC,IAAIrR,IAAuB;QACvBmW,EAAMnW,UACRA,IAAQpF,QAAoBub,EAAMnW;QAGpC,IAAIuR,IAAwB;QACxB4E,EAAM5E,YACRA,IAAU3W,QAAgBub,EAAM5E;QAGlC,IAAIC,IAAsB;QAK1B,OAJI2E,EAAM3E,UACRA,IAAQ5W,QAAgBub,EAAM3E,SAGzB,IAAII,GACT1Q,GACAkQ,GACAC,MAEArR,qBAEAuR,GACAC;;IAIJ9W,GACEme;QAEA,MAAMtc,IAAQ3B,QAAaie;QAC3B,OAAa,QAATtc,IACK,OAEA;YACL8f,oBAAoB9f;;;IAK1B7B,GAAgB8Z;QACd;UACE;YACE,OAAO;;UACT;YACE,OAAO;;UACT;YACE,OAAO;;UACT;YACE,OAAO5U,GAAK;;;IAIlBlF,GAASme;QACP,IAAIxV;QACJ,MAAMkR,IAASsE,EAAWtE;QAc1B,OAXElR,IADEkR,SACO;YAAEoC,WAAW/b,QAAuB2Z;YAEpC;YAAE4B,OAAOvb,QAAmB2Z;WAGvClR,EAAOsB,WAAWkU,EAAWlU,UAEzBkU,EAAWjE,mBAAoC,MACjDvR,EAAOuR,cAAcha,QAAaie,EAAWjE;QAGxCvR;;IAGT3I,GAAiB4W;QACf,IAAuB,MAAnBA,EAAQ5R,QACV;QAEF,MAAM6b,IAASjK,EAAQ7P,IAAIJ,KACrBA,aAAkBuR,KACbhY,QAA0ByG,KAE1BzB,GAAK,0BAA0BkH,KAAKC,UAAU1F;QAGzD,OAAsB,MAAlBka,EAAO7b,SACF6b,EAAO,KAET;YAAEe,iBAAiB;gBAAExJ,IAAI;gBAAOxB;;;;IAGzC5W,GAAmB2G;QACjB,OAAKA,SAE6B1B,MAAvB0B,EAAOkb,cACT,EAAC3hB,QAAqByG,YACG1B,MAAvB0B,EAAOmb,cACT,EAAC5hB,QAAqByG,YACO1B,MAA3B0B,EAAOib,kBACTjb,EAAOib,gBACXhL,QAAS7P,IAAIgQ,KAAK7W,QAAgB6W,IAClCgL,OAAO,CAACC,GAAO9a,MAAY8a,EAAMnK,aAE7B3S,GAAK,qBAAqBkH,KAAKC,UAAU1F,MAVzC;;IAcX3G,GAAgBqY;QACd,IAAwB,MAApBA,EAASrT,QAGb,OAAOqT,EAAStR,IAAIkb,KAAS/hB,QAAqB+hB;;IAGpDjiB,GAAkBqY;QAChB,OAAOA,EAAStR,IAAIkb,KAAS/hB,QAAuB+hB;;IAGtDjiB,GAAiBkiB;QACf,OAAO;YACL1J,QAAQ0J,EAAO1J;YACf3K,QAAQqU,EAAO3J;;;IAInBvY,GAAmBkiB;QACjB,MAAM1J,MAAW0J,EAAO1J,QAClBD,IAAW2J,EAAOrU,UAAU;QAClC,OAAO,OAAU0K,GAAUC;;;IAI7BxY,GAAYyX;QACV,OAAOmH,GAAWnH,EAAI7V;;;IAIxB5B,GAAcyX;QACZ,QAAQA;UACN,KAAK;YACH,OAAOC,GAAUC;;UACnB,KAAK;YACH,OAAOD,GAAUY;;UACnB;YACE;;;;IAKNtY,GAAeoY;QACb,OAAO0G,GAAU1G,EAAGxW;;IAGtB5B,GAAiBoY;QACf,QAAQA;UACN,KAAK;YACH,OAAOO,GAASG;;UAClB,KAAK;YACH,OAAOH,GAASK;;UAClB,KAAK;YACH,OAAOL,GAASI;;UAClB,KAAK;YACH,OAAOJ,GAASC;;UAClB,KAAK;YACH,OAAOD,GAASE;;UAClB,KAAK;YACH,OAAOF,GAASM;;UAClB,KAAK;YACH,OAAON,GAASO;;UAClB,KAAK;YACH,OAAOP,GAASQ;;UAClB,KAAK;YACH,OAAOjU,GAAK;;UACd;YACE,OAAOA,GAAK;;;IAIlBlF,GAAqBwG;QACnB,OAAO;YAAEmM,WAAWnM;;;IAGtBxG,GAAuBmiB;QACrB,OAAOtb,IAA2Bsb,EAAyB;;;IAI7DniB,GAAgB2W;QACd,OAAO;YACL5D,OAAO7S,QAA0ByW,EAAQ5D;YACzCqP,WAAWliB,QAAiByW,EAAQc;;;IAIxCzX,GAAkB2W;QAChB,OAAO,OACLzW,QAA4ByW,EAAc,QAC1CzW,QAAmByW,EAAQyL;;IAI/BpiB,GAAgB2G;QACd,OAAOuR,GAAYmK,OACjBniB,QAA4ByG,EAAOmb,YAAmB,QACtD5hB,QAAsByG,EAAOmb,YAAgB,KAC7Cnb,EAAOmb,YAAmB;;;IAK9B9hB,GAAqB2G;QACnB,IAAIA,EAAOyR,OAAOO,GAASG,OAAO;YAChC,IAAIO,GAAW1S,EAAO9E,QACpB,OAAO;gBACLggB,aAAa;oBACX9O,OAAO7S,QAA0ByG,EAAOoM;oBACxCqF,IAAI;;;YAGH,IAAIgB,GAAYzS,EAAO9E,QAC5B,OAAO;gBACLggB,aAAa;oBACX9O,OAAO7S,QAA0ByG,EAAOoM;oBACxCqF,IAAI;;;;QAKZ,OAAO;YACL0J,aAAa;gBACX/O,OAAO7S,QAA0ByG,EAAOoM;gBACxCqF,IAAIlY,QAAoByG,EAAOyR;gBAC/BvW,OAAO8E,EAAO9E;;;;IAKpB7B,GAAgB2G;QACd,QAAQA,EAAOkb,YAAgB;UAC7B,KAAK;YACH,MAAMS,IAAWpiB,QACfyG,EAAOkb,YAAmB;YAE5B,OAAO3J,GAAYmK,UAAiB1J,GAASG,OAAO;gBAClDtK,aAAa+T;;;UAEjB,KAAK;YACH,MAAMC,IAAYtiB,QAChByG,EAAOkb,YAAmB;YAE5B,OAAO3J,GAAYmK,UAAkB1J,GAASG,OAAO;gBACnD2J,WAAW;;;UAEf,KAAK;YACH,OAAOvd,GAAK;;UACd;YACE,OAAOA,GAAK;;;IAIlBlF,GAAe+T;QACb,MAAM2O,IAA4B;QAIlC,OAHA3O,EAAUnI,OAAOrG,QAAQwN,KACvB2P,EAAgBjd,KAAKsN,SAEhB;YACL4P;;;IAIJ3iB,GAAiB+U;QACf,MACMnJ,KADQmJ,EAAM4N,cAAc,IACb5b,IAAIP,KAAQK,IAA2BL;QAC5D,OAAO6O,MAAoBzJ;;;;YAIKpF;;IAElC,OACEA,EAAKxB,UAAU,KACC,eAAhBwB,EAAKhE,IAAI,MACO,gBAAhBgE,EAAKhE,IAAI;;;;;;;;;;;;;;;;;;;;;;;;ICtgCXxC,UAAmB4iB;QACblY,GAAgBkY,YAClB1d,GAAK,6BAEPwF,GAAgBkY,WAAWA;;IAG7B5iB;QAIE,OAHK0K,GAAgBkY,YACnB1d,GAAK,qBAEAwF,GAAgBkY;;;;;;;;;;;;;;;;;;;GCxD3B,OAAMC,KAAY,IAAIC,EAAO;;;;IAI3B,OAAOD,GAAUE;;;SAGHC,GAAYC;IAC1BJ,GAAUE;;;YAGaG,MAAgBhZ;IACvC,IAAI2Y,GAAUE,YAAYI,EAASC,OAAO;QACxC,MAAMC,IAAOnZ,EAAInD;QACjB8b,GAAUS,MAAM,cAAczjB,OAAiBqjB,QAAUG;;;;YAIpCH,MAAgBhZ;IACvC,IAAI2Y,GAAUE,YAAYI,EAASI,OAAO;QACxC,MAAMF,IAAOnZ,EAAInD;QACjB8b,GAAUW,MAAM,cAAc3jB,OAAiBqjB,QAAUG;;;;;;GAO7D,aAAqBnZ;IACnB,IAAmB,mBAARA,GACT,OAAOA;IACF;QACL,MAAM0Y,IAAWlY;QACjB;YACE,OAAOkY,KAAoB1Y;UAC3B,OAAOuZ;;YAEP,OAAOvZ;;;;;;;;;;;;;;;;;;;;;;;;;;;aCjCGhF,GAAKwe;;;IAGnB,MAAMjiB,IACJ,cAAc5B;;;;IAMhB,MALAua,GAAS3Y,IAKH,IAAIF,MAAME;;;;;;gBAQhBkiB,GACAliB;IAEKkiB,KACHze,GAAKzD;;;;;;;;;;;;;;;;;;;ICxBPzB;;QAEE,MAAM4jB,IACJ;QACF,IAAIC,IAAS;QACb,KAAK,IAAIje,IAAI,GAAGA,IAAI,IAAIA,KACtBie,KAAUD,EAAME,OAAO5f,KAAKC,MAAMD,KAAK6f,WAAWH,EAAM5e;QAG1D;;;;YAImCoB,GAASC;IAC9C,OAAID,IAAOC,KACD,IAEND,IAAOC,IACF,IAEF;;;6DASPD,GACAC,GACAsB;IAEA,OAAIvB,EAAKpB,WAAWqB,EAAMrB,UAGnBoB,EAAK4d,MAAM,CAACniB,GAAO8D,MAAUgC,EAAW9F,GAAOwE,EAAMV;;;;;;gBAM3Bse;;IAEjC,OAAOA,IAAI;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ICrCXjkB,YACWmR,GACA+S,GACAC,GACAC,GACAC;qBAHAnkB,sBAAAgkB,GACAhkB,YAAAikB,GACAjkB,WAAAkkB,GACAlkB,wBAAAmkB;;;;;;;IAUXrkB,YAAqBoR,GAAmBC;QAAnBnR,iBAAAkR,GACnBlR,KAAKmR,WAAWA,KANU;;IAS5BiT;QACE,OAV0B,gBAUnBpkB,KAAKmR;;IAGdrR,QAAQqE;QACN,OACEA,mBACAA,EAAM+M,cAAclR,KAAKkR,aACzB/M,EAAMgN,aAAanR,KAAKmR;;IAI5BrR,EAAUqE;QACR,OACEC,GAAoBpE,KAAKkR,WAAW/M,EAAM+M,cAC1C9M,GAAoBpE,KAAKmR,UAAUhN,EAAMgN;;;;;;;;;;;;;;;;;;;;;;;;;;IC3B7CrR,YAAoBukB;;;;;;;;QAJpBrkB,UAEI;;2EAKJF,IAAI+H;QACF,MAAMyc,IAAKtkB,QAAc6H,IACnB2Q,IAAUxY,QAAWskB;QAC3B,SAAgBvf,MAAZyT,GAGJ,KAAK,OAAO+L,GAAU5iB,MAAU6W,GAC9B,IAAI+L,EAAS5f,QAAQkD,IACnB,OAAOlG;;IAMb7B,IAAI+H;QACF,YAAyB9C,MAAlB/E,KAAKsC,IAAIuF;;iDAIlB/H,IAAI+H,GAAclG;QAChB,MAAM2iB,IAAKtkB,QAAc6H,IACnB2Q,IAAUxY,QAAWskB;QAC3B,SAAgBvf,MAAZyT,GAAJ;YAIA,KAAK,IAAI9S,IAAI,GAAGA,IAAI8S,EAAQ1T,QAAQY,KAClC,IAAI8S,KAAW,GAAG7T,QAAQkD,IAExB,aADA2Q,OAAa,EAAC3Q,GAAKlG;YAIvB6W,EAAQjT,KAAK,EAACsC,GAAKlG;eATjB3B,QAAWskB,KAAM,EAAC,EAACzc,GAAKlG;;;;WAe5B7B,OAAO+H;QACL,MAAMyc,IAAKtkB,QAAc6H,IACnB2Q,IAAUxY,QAAWskB;QAC3B,SAAgBvf,MAAZyT,GACF,QAAO;QAET,KAAK,IAAI9S,IAAI,GAAGA,IAAI8S,EAAQ1T,QAAQY,KAClC,IAAI8S,KAAW,GAAG7T,QAAQkD,IAMxB,OALuB,MAAnB2Q,EAAQ1T,gBACH9E,QAAWskB,KAElB9L,EAAQgM,UAAU;SAEb;QAGX,QAAO;;IAGT1kB,QAAQ8F;QACNP,EAAQrF,SAAY,CAAC8d,GAAGtI;YACtB,KAAK,OAAOrN,GAAGC,MAAMoN,GACnB5P,EAAGuC,GAAGC;;;IAKZtI;QACE,OAAO2kB,EAAQzkB;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ICzDjBF,YACS4kB,GACA9Y,GACA+Y,GACAC;QAHA5kB,eAAA0kB,gBAEA1kB,qBAAA2kB,GACA3kB,iBAAA4kB;;;;;;;;;;WAcT9kB,GACE+kB,GACAxR,GACAyR;QAUA,MAAMC,IAAkBD;QAQxB,KAAK,IAAIpf,IAAI,GAAGA,IAAI1F,KAAK4kB,UAAU9f,QAAQY,KAAK;YAC9C,MAAMya,IAAWngB,KAAK4kB;YACtB,IAAIzE,EAAStY,IAAIlD,YAAiB;gBAChC,MAAM8O,IAAiBsR;gBACvB1R,IAAW8M;;;QAGf;;;;;;;;WAUFrgB,GACE+kB,GACAxR;;;QAYA,KAAK,MAAM8M,KAAYngB,KAAK2kB,eACtBxE,EAAStY,IAAIlD,eACf0O,IAAW8M,WAGTngB;QAKN,MAAM2T;;gBAGN,KAAK,MAAMwM,KAAYngB,KAAK4kB,WACtBzE,EAAStY,IAAIlD,eACf0O,IAAW8M,WAGTngB;QAIN;;;;;WAOFF,GAAwBklB;;;;QAItB,IAAIC;QAUJ,OATAjlB,KAAK4kB,UAAUvf,QAAQ6f;YACrB,MAAMC,IAAkBnlB,QACtBklB,EAAErd,KACFmd,EAAU1iB,IAAI4iB,EAAErd;kBAGhBod,IAAmBA,KAAwBC,EAAErd;;;IAMnD/H;QACE,OAAOE,KAAK4kB,UAAU/C,OACpB,CAACnS,GAAMwV,MAAMxV,EAAKjG,IAAIyb,EAAErd,MACxB2U;;IAIJ1c,QAAQqE;QACN,OACEnE,KAAK0kB,YAAYvgB,EAAMugB,WACvBjX,GAAYzN,KAAK4kB,WAAWzgB,EAAMygB,WAAW,CAAClQ,GAAGC,MAAMD,EAAE/P,QAAQgQ,OACjElH,GAAYzN,KAAK2kB,eAAexgB,EAAMwgB,eAAe,CAACjQ,GAAGC,MACvDD,EAAE/P,QAAQgQ;;;;;IAQhB7U,YACWslB,GACAC,GACAN,GACAO;;;;;IAKAC;QARAvlB,aAAAolB,6BAGAplB,mBAAAslB;;;;;;WAaXxlB,YACEslB,GACAC,GACAG,GACAF;QAEA1iB,GACEwiB,EAAMR,UAAU9f,WAAW0gB,EAAQ1gB,QACnC,oBACEsgB,EAAMR,UAAU9f,SAChB,kCACA0gB,EAAQ1gB;QAGZ,IAAI2gB,IAAaC;QACjB,MAAMd,IAAYQ,EAAMR;QACxB,KAAK,IAAIlf,IAAI,GAAGA,IAAIkf,EAAU9f,QAAQY,KACpC+f,IAAaA,KAAkBb,KAAa/c,KAAK2d,KAAWzS;QAG9D,OAAO,OACLqS,MAEAI,GACAF;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IC9LNxlB;;QAEEE,UAAoB,MAAc2lB;;QAGlC3lB,UAAuB,MAAc2lB;;wEAGrC7lB;QACE,OAAOE;;2EAITF,GAAa+H,GAAkByc;QAC7B,MAAMsB,IAAM,OAAiB/d,GAAKyc;QAClCtkB,UAAiBA,QAAeyJ,IAAImc,IACpC5lB,UAAoBA,QAAkByJ,IAAImc;;0EAI5C9lB,GAAc4P,GAAsB4U;QAClC5U,EAAKrK,QAAQwC,KAAO7H,QAAkB6H,GAAKyc;;;;;WAO7CxkB,GAAgB+H,GAAkByc;QAChCtkB,QAAe,OAAiB6H,GAAKyc;;IAGvCxkB,GAAiB4P,GAAsB4U;QACrC5U,EAAKrK,QAAQwC,KAAO7H,QAAqB6H,GAAKyc;;;;;WAOhDxkB,GAAsBwkB;QACpB,MAAMuB,IAAWre,EAAYI,OACvBke,IAAW,UAA2BxB,IACtCyB,IAAS,UAA2BzB,IAAK,IACzC5U,IAAsB;QAK5B,OAJA1P,WAAiC,UAAoB4lB;YACnD5lB,QAAe4lB,IACflW,EAAKnK,KAAKqgB,EAAI/d;YAET6H;;IAGT5P;QACEE,QAAeqF,QAAQugB,KAAO5lB,QAAe4lB;;IAG/C9lB,GAAkB8lB;QAChB5lB,UAAiBA,QAAemU,OAAOyR,IACvC5lB,UAAoBA,QAAkBmU,OAAOyR;;IAG/C9lB,GAAgBwkB;QACd,MAAMuB,IAAWre,EAAYI,OACvBke,IAAW,UAA2BxB,IACtCyB,IAAS,UAA2BzB,IAAK;QAC/C,IAAI5U,IAAO8M;QAIX,OAHAxc,WAAiC,UAAoB4lB;YACnDlW,IAAOA,EAAKjG,IAAImc,EAAI/d;YAEf6H;;IAGT5P,GAAY+H;QACV,MAAM+d,IAAM,OAAiB/d,GAAK,IAC5Bme,IAAWhmB,WAAiC4lB;QAClD,OAAoB,SAAbI,KAAqBne,EAAIlD,QAAQqhB,EAASne;;;;;IAKnD/H,YACS+H,GACAoe;QADAjmB,WAAA6H;;wCAKT/H,UAAoBoG,GAAoBC;QACtC,OACEqB,IAAuBtB,EAAK2B,KAAK1B,EAAM0B,QACvCzD,GAAoB8B,MAAsBC;;wCAK9CrG,UAAyBoG,GAAoBC;QAC3C,OACE/B,GAAoB8B,MAAsBC,SAC1CqB,IAAuBtB,EAAK2B,KAAK1B,EAAM0B;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;UC9FhCqe;IAeXpmB,YAAYqmB;;;QAZZnmB,UAAqD,MACrDA,UAAkD;;QAG1CA,mBAAwB+E,GACxB/E,kBAA2B+E,GACnC/E,WAAiB;;;QAIjBA,WAA2B,GAGzBmmB,EACExkB;YACE3B,WAAc,GACdA,KAAKyI,SAAS9G,GACV3B;;;YAGFA;WAGJsjB;YACEtjB,WAAc,GACdA,KAAKsjB,QAAQA,GACTtjB,WACFA,QAAmBsjB;;;IAM3BxjB,MACE8F;QAEA,OAAO5F,KAAKoH,UAAKrC,GAAWa;;IAG9B9F,KACEsmB,GACAC;QAMA,OAJIrmB,WACFgF,GAAK,0DAEPhF,WAAwB;QACpBA,UACGA,KAAKsjB,QAGDtjB,WAA0BA,KAAKsjB,SAF/BtjB,WAAyBA,KAAY,UAKvC,IAAIkmB,GAAsB,CAACpkB,GAASwkB;YACzCtmB,UAAqB2B;gBACnB3B,WAAyB2B,GAAOyF,KAAKtF,GAASwkB;eAEhDtmB,UAAsBsjB;gBACpBtjB,WAA0BsjB,GAAOlc,KAAKtF,GAASwkB;;;;IAMvDxmB;QACE,OAAO,IAAI+B,QAAQ,CAACC,GAASwkB;YAC3BtmB,KAAKoH,KAAKtF,GAASwkB;;;IAIvBxmB,GACE8F;QAEA;YACE,MAAM6C,IAAS7C;YACf,OAAI6C,aAAkByd,KACbzd,IAEAyd,GAAmBpkB,QAAQ2G;UAEpC,OAAO8a;YACP,OAAO2C,GAAmBI,OAAU/C;;;IAIxCzjB,GACEsmB,GACAzkB;QAEA,WACS3B,QAAsB,MAAMomB,EAAOzkB,MAGnCukB,GAAmBpkB,QAAYH;;IAI1C7B,GACEumB,GACA/C;QAEA,WACStjB,QAAsB,MAAMqmB,EAAQ/C,MAEpC4C,GAAmBI,OAAUhD;;IAMxCxjB,eAAkB2I;QAChB,OAAO,IAAIyd,GAA6B,CAACpkB,GAASwkB;YAChDxkB,EAAQ2G;;;IAIZ3I,cAAiBwjB;QACf,OAAO,IAAI4C,GAAsB,CAACpkB,GAASwkB;YACzCA,EAAOhD;;;IAIXxjB;;;IAGEymB;QAEA,OAAO,IAAIL,GAAyB,CAACpkB,GAASwkB;YAC5C,IAAItI,IAAgB,GAChBwI,IAAgB,GAChBC,KAAO;YAEXF,EAAIlhB,QAAQ2M;qBAEVA,EAAQ5K,KACN;yBAEMqf,KAAQD,WACV1kB;mBAGJ4kB,KAAOJ;gBAIXG,KAAO,GACHD,WACF1kB;;;;;;;;WAWNhC,UACE6mB;QAEA,IAAIrN,IAAiC4M,GAAmBpkB,SACtD;QAEF,KAAK,MAAM8kB,QACTtN,IAAIA,EAAElS,KAAKyf,SAEAX,GAAmBpkB,aAEnB8kB;QAIb,OAAOtN;;IAkBTxZ,eACEgnB,GACAjQ;QAEA,MAAMkQ,IAA4C;QAIlD,OAHAD,EAAWzhB,QAAQ,CAACsP,GAAGoP;YACrBgD,EAASxhB,KAAKsR,EAAExM,KAAKrK,MAAM2U,GAAGoP;YAEzB/jB;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IC3MXF;;;QAGEE,UAGI,OAAc6H,KAAOA,EAAIpG,aAK7BzB,WAAyB;;IAgBzB0f,aAAuB/d;QAQrB3B,UAAiB2B;;IAGnB+d;QAKE,OAAO1f;;;;;;;WASTF,GAASknB,GAA8BtH;QACrC1f,WACAA,KAAK0f,WAAWA,GAChB1f,QAAakU,IAAI8S,EAAcnf;;;;;;;WASjC/H,GAAY+H,GAAkB6X;QAC5B1f,WACI0f,MACF1f,KAAK0f,WAAWA,IAElB1f,QAAakU,IAAIrM,GAAK;;;;;;;;;;;;WAcxB/H,GACEmnB,GACAC;QAEAlnB;QACA,MAAMmnB,IAAgBnnB,QAAasC;QACnC,YAAsByC,MAAlBoiB,IACKjB,GAAmBpkB,aAEnB9B,QAAkBinB;;;;;;;;;;;;WAe7BnnB,WACEmnB,GACAG;QAEA,OAAOpnB,QAAqBinB;;;;;WAO9BnnB,MAAMmnB;QAGJ,OAFAjnB,WACAA,WAAsB,GACfA,QAAkBinB;;yDAI3BnnB;;;;;;;;;;;;;;;;;;GCxIK,OAAMunB,KACX;;;;;;;;;;IAWFvnB;QACEE,UAA2D;;IAI3DF,GAAuBwnB;QACrBtnB,QAA0BuF,KAAK+hB;;IAGjCxnB;QACEE,QAA0BqF,QAAQiiB,KAAYA;;;;;;;;;;;;;;;;;;;;;;;;;;ICHhDxnB,YACWynB,GACAC,GACAC;;;;;;;;WASX3nB,GACEmnB,GACApf;QAEA,OAAO7H,WACsCinB,GAAapf,GACvDT,KAAKsgB,KAAW1nB,QAAyBinB,GAAapf;;6EAI3D/H,GACEmnB,GACApf,GACA8f;QAEA,OAAO3nB,WAAkCinB,GAAapf,GAAKT,KAAKiN;YAC9D,KAAK,MAAM+Q,QACT/Q,IAAM+Q,KAAuBvd,GAAKwM;YAEpC,OAAOA;;;;;IAMXvU,GACEmnB,GACAzL,GACAkM;QAEA,IAAIlC,IAAUoC;QAOd,OANApM,EAAKnW,QAAQ,CAACwC,GAAKggB;YACjB,KAAK,MAAMzC,QACTyC,IAAYzC,KAAuBvd;YAErC2d,IAAUA,KAAe3d;YAEpB2d;;;;;;;WAST1lB,GACEmnB,GACAvX;QAEA,OAAO1P,QACJ8nB,WAAWb,GAAavX,GACxBtI,KAAKoU,KAAQxb,QAA6BinB,GAAazL;;;;;WAO5D1b,GACEmnB,GACAc;QAEA,OAAO/nB,WACuCinB,MAC3C7f,KAAKsgB;YACJ,MAAMlM,IAAOxb,QACXinB;YAIF,IAAIzB,IAAUlL;YASd,OARAkB,EAAKnW,QAAQ,CAACwC,GAAKwL;;sBAGfA,IAAW,OAAexL,GAAKpD,SAEjC+gB,IAAUA,KAAe3d;gBAGpB2d;;;;;;;;;;WAYb1lB,GACEmnB,GACA1L,GACAyM;QAEA,OAAIzM,SACKvb,QAAuCinB,GAAa1L,EAAMjV,QACxDiV,SACFvb,QACLinB,GACA1L,QAIKvb,QACLinB,GACA1L;;IAMNzb,GACEmnB,GACA1O;;QAGA,OAAOvY,QAAiBinB,GAAa,UAA0B7f,KAC7DiM;YACE,IAAI5K,IAASkS;YAIb,OAHItH,aAAoBC,OACtB7K,IAASA,KAAc4K,EAASxL,UAE3BY;;;IAKb3I,GACEmnB,GACA1L,GACAyM;QAMA,MAAM3gB,IAAekU,EAAM/E;QAC3B,IAAIgP,IAAU7K;QACd,OAAO3a,WACiBinB,GAAa5f,GAClCD,KAAK6gB,KAGG/B,GAAmB7gB,WAAkB8b;YAC1C,MAAM+G,IAAkB3M,KACtB4F,EAAOjM,MAAM7N;YAEf,OAAOrH,QACLinB,SAGA7f,KAAKuN;gBACLA,EAAEtP,QAAQ,CAACwC,GAAKwM;oBACdmR,IAAUA,KAAe3d,GAAKwM;;;WAGjCjN,KAAK,MAAMoe;;IAIpB1lB,GACEmnB,GACA1L,GACAyM;;QAGA,IAAIxC,GACA2C;QACJ,OAAOnoB,WACsBinB,GAAa1L,MACvCnU,KAAKghB,MACJ5C,OACOxlB,WACLinB,GACA1L,KAGHnU,KAAKihB,MACJF;QAOOnoB,QACLinB,MAEAzB,GACApe,KAAKkhB;YACL9C;YAEA,KAAK,MAAMJ,QACT,KAAK,MAAMjF,KAAYiF,EAAMR,WAAW;gBACtC,MAAM/c,IAAMsY,EAAStY,KACf8L,IAAU6R,EAAQljB,IAAIuF,IACtB0gB,IAAapI,WAGjBiF;gBAGAI,IADE+C,aAAsBjV,KACdkS,KAAe3d,QAEf2d,EAAQ1d,OAAOD;;aAMlCT,KAAK;;;QAGJoe,EAAQngB,QAAQ,CAACwC,GAAKwM;YACfkH,EAAM/C,QAAQnE,OACjBmR,IAAUA,EAAQ1d,OAAOD;YAItB2d;;IAIb1lB,GACEmnB,GACAoB,GACAG;QAEA,IAAIC,IAAmCjM;QACvC,KAAK,MAAM4I,QACT,KAAK,MAAMjF,KAAYiF,EAAMR,WAEzBzE,mBACwC,SAAxCqI,EAAkBlmB,IAAI6d,EAAStY,SAE/B4gB,IAAmCA,EAAiChf,IAClE0W,EAAStY;QAMjB,IAAIygB;QACJ,OAAOtoB,QACJ8nB,WAAWb,MACX7f,KAAKshB,MACJA,EAAgBrjB,QAAQ,CAACwC,GAAKwM;YAChB,SAARA,KAAgBA,aAAef,OACjCgV,IAAkBA,KAAuBzgB,GAAKwM;;;;;;;;;;;;;;;;;;;;;;;;;;IC7RxDvU,YACWiK,GACA6R,GACA+M,GACAC;QAHA5oB,gBAAA+J,GACA/J,iBAAA4b;;IAKX9b,UACEiK,GACA8e;QAEA,IAAIF,IAAYnM,MACZoM,IAAcpM;QAElB,KAAK,MAAMkB,KAAamL,EAAanN,YACnC,QAAQgC,EAAUrC;UAChB;YACEsN,IAAYA,EAAUlf,IAAIiU,EAAUrJ,IAAIxM;YACxC;;UACF;YACE+gB,IAAcA,EAAYnf,IAAIiU,EAAUrJ,IAAIxM;;;QAOlD,OAAO,OACLkC,GACA8e,EAAajN;;;;;;;;;;;;;;;;;;;;;;;;;;ICVjB9b,YACUuR,GACRyX;QADQ9oB,qBAAAqR,SAINyX,OAA6CjP,KAC3C7Z,QAAsB6Z,IACxB7Z,UAA8B6Z,KAC5BiP,KAAyCjP;;IAI/C/Z,GACEipB;QAGA,OADA/oB,KAAKqR,gBAAgBrN,KAAKglB,OAA2BhpB,KAAKqR,gBACnDrR,KAAKqR;;IAGdvR;QACE,MAAMmpB,MAAcjpB,KAAKqR;QAIzB,OAHIrR,WACFA;;;;AA5BJkpB,SAAiD;;;;;;;;;;;;;;;;;;;ICSjDppB;QACEE,KAAKmpB,UAAU,IAAItnB,QAAQ,CAACC,GAAsBwkB;YAChDtmB,KAAK8B,UAAUA,GACf9B,KAAKsmB,SAASA;;;;;;;;;;;;;;;;;;;;;;;;;;;GC0BpB;IAOExmB,YACmBspB,GACRC,GACAC,GACQpR,GACAqR;+CADAvpB,UAAAkY,gBANnBlY,UAA4B;QAqF5BA,YAAOA,QAAcmpB,QAAQ5mB,KAAKinB,KAAKxpB,QAAcmpB,UACrDnpB,aAAQA,QAAcmpB,QAAQM,MAAMD,KAAKxpB,QAAcmpB;;;;QA1ErDnpB,QAAcmpB,QAAQM,MAAM/C;;;;;;;;;;;;;;;WAiB9B5mB,UACEspB,GACAC,GACAK,GACAxR,GACAqR;QAEA,MAAMI,IAAahmB,KAAKC,WAClBgmB,IAAY,gBAIhB1R;QAIF,OADA0R,EAAUrgB;;;;;WAQJzJ,MAAM4pB;QACZ1pB,UAAmB6pB,WAAW,MAAM7pB;;;;;WAOtCF;QACE,OAAOE;;;;;;;;WAUTF,OAAOgqB;QACoB,SAArB9pB,YACFA,KAAK+pB,gBACL/pB,QAAcsmB,OACZ,IAAIllB,EACFlB,EAAKE,WACL,yBAAyB0pB,IAAS,OAAOA,IAAS;;IAW1DhqB;QACEE,WAAiC,MACN,SAArBA,WACFA,KAAK+pB,gBACE/pB,KAAKkY,KAAK3V,KAAKkG,KACbzI,QAAc8B,QAAQ2G,OAGxB5G,QAAQC;;IAKbhC;QACmB,SAArBE,YACFA,QAAqBA,OACrB+pB,aAAa/pB,UACbA,UAAmB;;;;;IAKzBF;;QAEEE,UAAiC6B,QAAQC;;;QAIzC9B,WAAmC;;;QAInCA,UAA8D;;QAG9DA,UAAwB;;;QAIxBA,WAA8B;;QAG9BA,UAAoC;;;;IAIpCgqB;QACE,OAAOhqB;;;;;WAOTF,GAAoCoY;;QAElClY,KAAKiqB,QAAQ/R;;;;;WAOfpY,GACEoY;QAEAlY;;QAEAA,QAAqBkY;;;;;WAOvBpY,GACEoY;QAGA,OADAlY,WACOA,QAAqBkY;;;;;;;;WAU9BpY,SAAiCoY;QAC/BlY,WACKA,YACHA,WAAuB,SACjBA,QAA8BkY;;;;;WAQxCpY,QAA2BoY;QAEzB,OADAlY,WACIA,UAEK,IAAI6B,QAAWC,WAEjB9B,QAAqBkY;;IAG9BpY,GAA2CoY;QACzC,MAAMgS,IAAUlqB,QAAUuC,KAAK,OAC7BvC,WAA2B,GACpBkY,IACJuR,MAAOnG;;;;YASN,MARAtjB,UAAesjB,GACftjB,WAA2B,GAE3Bka,GAAS,8BADOoJ,EAAM6G,SAAS7G,EAAM/hB,WAAW;YAM1C+hB;WAEP/gB,KAAKkG,MACJzI,WAA2B,GACpByI;QAIb,OADAzI;;;;;;WASFF,GACEupB,GACAK,GACAxR;QAEAlY;;QAQIA,QAAoBuG,cAAoB,MAC1CmjB,IAAU;QAGZ,MAAME,IAAYQ,MAChBpqB,YAGAkY,GACAmS,KACErqB,QAA4BqqB;QAGhC,OADArqB,QAAuBuF,KAAKqkB;;IAI9B9pB;QACME,WACFgF,GACE,oCACGhF,QAAamqB,SAASnqB,QAAauB;;;;;;;WAW5CzB;;;;WAWAA;;;;;QAKE,IAAIwqB;QACJ;YACEA,IAActqB;iBAEPsqB,MAAgBtqB;;;;;WAO3BF,GAAyBupB;QACvB,KAAK,MAAMnR,KAAMlY,SACf,IAAIkY,YACF,QAAO;QAGX,QAAO;;;;;;;;;WAWTpY,GAA0ByqB;;QAExB,OAAOvqB,UAAauC,KAAK;;YAQvBvC,QAAuB4P,KAAK,CAAC4a,GAAGC,MAAMD,OAAiBC;YAEvD,KAAK,MAAMvS,KAAMlY,SAEf,IADAkY,4BACIqS,KAA+BrS,YACjC;YAIJ,OAAOlY;;;;;WAOXF,GAAqBupB;QACnBrpB,QAAoBuF;;iEAItBzF,GAA+BoY;;QAE7B,MAAMzS,IAAQzF,QAAuBuG,QAAQ2R;QAE7ClY,QAAuBwkB,OAAO/e,GAAO;;;;;;;;;;;;;;;;;;;GCjVzC,cACGilB,GAAWC,KACXC,GAAWC;IAEZ,MAAMC,IAAS1mB;IACf,OAAe,MAAX0mB,IAGK1mB;;;;;;;GAWX;IAOEtE,YAA6BirB;qBANrB/qB,cAAiC,WAIzCA,UAAwB;;IAIxBF;QACE,SAASE;;IAGXF,GAAW+Z;QACT,MAAMmR,IAAqB,EAACnR,GAAgB7Z;QAC5C,IAAIA,KAAK8K,OAAOtF,OAAOxF,SACrBA,KAAK8K,SAAS9K,KAAK8K,OAAOrB,aACrB;YACL,MAAMwhB,IAAejrB,KAAK8K,OAAOogB;YAC7BC,WAA6C,MAC/CnrB,KAAK8K,SAAS9K,KAAK8K,OAAOqJ,UAAqB1K;;;IAKrD2hB;;;;;;;QAOE,OAAOprB,KAAK8K,OAAOogB,OAAQ;;;;AAiB/B,MAAMG,KAA6B;IACjCC,KAAQ;IACRC,IAA0B;IAC1BC,IAAgB;IAChBC,IAAkB;;;;IA8BlB3rB;;;IAGW4rB;;IAEAC;;;IAGAC;;;IA5BX9rB,UAAqB+rB;QACnB,OAAO,UAELC,OACAA;;;;AAVJA,SAAuC,GACvCA,QAA2C,SAC3CA,QAA2C,UAC3CA,QAAwD,IACxDA,QAAkE,KAUlEA,QAAqC,OACnCA,OACAA,OACAA;AAGcA,cAAsB,OACpCA,OACA,GACA;;;;;;;IA4BFhsB,YACmBisB,GACA3C;kCALnBppB,WAA0B,GAOxBA,UAAc;;IAGhBF,MAAMksB;QAMFhsB,kBACA8rB,SAEA9rB;;IAIJF;QACME,YACFA,QAAYisB,UACZjsB,UAAc;;IAIlBksB;QACE,OAAuB,SAAhBlsB;;IAGTF,GAAmBksB;QAKjB,MAAMG,IAAQnsB,UA9CU,MAFA;QAiDxBye,GACE,uBACA,mCAAmC0N,QAErCnsB,UAAcA,iEAEZmsB,GACA,OACEnsB,UAAc;QACdA,WAAc,GACPgsB,KACWhsB,SACfuC,KAAK,MAAMvC,YACXypB;;;;;IAQT3pB,YACmBssB,GACRC;;;iGAIXvsB,GACEwsB,GACAC;QAEA,OAAOvsB,WAAqCssB,GAAKllB,KAAKolB,KAC7CxoB,KAAKC,MAAOsoB,IAAa,MAASC;;oFAK7C1sB,GACEwsB,GACA1jB;QAEA,IAAU,MAANA,GACF,OAAOsd,GAAmBpkB,QAAQonB;QAGpC,MAAMpe,IAAS,OAAgClC;QAC/C,OAAO5I,WACUssB,GAAK3S,KAAU7O,KAAkB6O,EAAOE,iBACtDzS,KAAK,MACGpH,WACLssB,GACAzS,KAAkB/O,KAAkB+O,KAGvCzS,KAAK,MAAM0D,EAAOsgB;;;;;WAOvBtrB,GACEwsB,GACAG,GACAC;QAEA,OAAO1sB,WAA4BssB,GAAKG,GAAYC;;;;;WAOtD5sB,GACEwsB,GACAG;QAEA,OAAOzsB,WAAsCssB,GAAKG;;IAGpD3sB,GACEwsB,GACAI;QAEA,OACE1sB,eAA6C8rB,SAE7CrN,GAAS,uBAAuB;QACzByH,GAAmBpkB,eAGrB9B,QAAkBssB,GAAKllB,KAAKykB,KAC7BA,IAAY7rB,cACdye,GACE,uBACA,0CAA0CoN,OACxC,2BAA2B7rB;cAIxBA,QAA0BssB,GAAKI;;IAK5C5sB,GAAawsB;QACX,OAAOtsB,WAA2BssB;;IAGpCxsB,GACEwsB,GACAI;QAEA,IAAIC,GACAC,GAAkCC,GAElCC,GACFC,GACAC,GACAC;QACF,MAAMC,IAAUvpB,KAAKC;QACrB,OAAO5D,QAA0BssB,GAAKtsB,YACnCoH,KAAK+lB;;QAEAA,IAAkBntB,cACpBye,GACE,uBACA,8CACE,qBAAqBze,gBACrB,QAAQmtB;QAEZP,IAA2B5sB,cAG3B4sB,OAEFE,IAAmBnpB,KAAKC,OAEjB5D,QAAuBssB,QAE/BllB,KAAKqlB,MACJE,IAA2BF,GAC3BM,IAAoBppB,KAAKC;QAElB5D,QACLssB,MAEAI,KAGHtlB,KAAKgmB,MACJP,OACAG,IAAmBrpB,KAAKC,OAEjB5D,QAA6BssB,QAErCllB,KAAKimB;YAGJ,IAFAJ,IAAqBtpB,KAAKC,OAEtB0pB,QAAiBrK,EAASC,OAAO;gBAWnCzE,GAAS,uBATP,6BACA,wBAAwBqO,cACxB,oCAAoCF,UACpC,GAAGG,cACH,aAAaF,kBACb,GAAGG,cACH,aAAaK,oBACb,GAAGJ,cACH,mBAAmBA;;YAIvB,OAAO/G,GAAmBpkB,QAAoB;gBAC5CwpB,KAAQ;gBACRC;gBACAC,IAAAqB;gBACApB,IAAA4B;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ICpPRvtB;;IAEUytB,GACAC,GACRC;QAFQztB,mBAAAutB;;;;QA9BVvtB,UAA8B;;;;;;;QAW9BA,UAA6B;;;QAM7BA,UAA2B,OAAgC0tB,KACzDA,EAAE3d;;;;;;QAQJ/P,UAAqCyE,EAAgBC,KAYnD1E,KAAKutB,kBACHvtB,UAEFA,UAAqButB,SACrBvtB,UAAuButB;QACvBvtB,UAAmButB,QACnBvtB,UAAsB,OACpBA,SACAA,SACAA,KAAKutB,mBAEPvtB,WAAuCA;;qCAIzCF;QACE,OAAOE;;;;;;;;;;IAWTF,SAAuB8B;QACrB,IAAI+rB,IAAmB3tB,SACnB4tB,IAAoB5tB;QAExB,MAAMyI,UAAezI,KAAKutB,YAAYM,eACpC,sBACA,YACAvB;;;YAGE,IAAIwB;YACJ,OAAO9tB,WACkBssB,GACtBllB,KAAK2mB,MACJD,OAEAH,IAAmB3tB,KAAKutB,eAA6B3rB;;;YAIrDgsB,IAAoB,OAClB5tB,YAEAA,KAAKutB,mBAEAI,KAAuCrB,KAE/CllB,KAAK4mB;gBACJ,MAAMC,IAA6B,IAC7BC,IAA2B;;gBAGjC,IAAIC,IAAc3R;gBAElB,KAAK,MAAM4I,QAAqB;oBAC9B6I,EAAgB1oB,KAAK6f,EAAMV;oBAC3B,KAAK,MAAMvE,KAAYiF,EAAMR,WAC3BuJ,IAAcA,EAAY1kB,IAAI0W,EAAStY;;gBAI3C,KAAK,MAAMud,QAAqB;oBAC9B8I,EAAc3oB,KAAK6f,EAAMV;oBACzB,KAAK,MAAMvE,KAAYiF,EAAMR,WAC3BuJ,IAAcA,EAAY1kB,IAAI0W,EAAStY;;;;gCAM3C,OAAO+lB,KACStB,MACbllB,KAAKgnB,MACG;oBACLC,IAAAD;oBACAE,IAAAL;oBACAM,IAAAL;;;;QAWd,OAJAluB,aACAA,aACAA,WAAuCA,UAEhCyI;;4EAIT3I,GAAW8kB;QACT,MAAMhZ,IAAiBrI,EAAUK,OAC3B8L,IAAOkV,EAAU/C,OACrB,CAACnS,GAAMwV,MAAMxV,EAAKjG,IAAIyb,EAAErd,MACxB2U;QAGF,IAAIgS;QAEJ,OAAOxuB,KAAKutB,YACTM,eAAe,2BAA2B,aAAavB,KAI/CtsB,WAAiCssB,GAAK5c,GAAMtI,KAAKoU;YACtDgT,IAAehT;;;;;;YAOf,MAAMmJ,IAA4B;YAElC,KAAK,MAAMxE,KAAYyE,GAAW;gBAChC,MAAMxS,IAAY+N,KAChBqO,EAAalsB,IAAI6d,EAAStY;gBAEX,QAAbuK;;;;gBAIFuS,EAAcpf,KACZ,OACE4a,EAAStY,QAETuK,QACAa,GAAaE,QAAO;;YAM5B,OAAOnT,WACLssB,MAEA3H,GACAC;YAILriB,KAAK6iB;YACJ,MAAM9J,IAAU8J;YAChB,OAAO;gBAAEV,SAASU,EAAMV;gBAAS+J,IAAAnT;;;;;;IAMvCxb,GAAwB4kB;QACtB,OAAO1kB,KAAKutB,YAAYM,eACtB,6BACA,YACAvB,KACStsB,WACessB,GAAK5H,GACxBtd,KAAKsI,KACAA,IACK1P,WACLssB,GACA5c,KAGKwW,GAAmBpkB,QAAiC;;;;;;;;;;;;;;;WAqBvEhC,GACEglB;QAEA,OAAO9kB,KAAKutB,YAAYM,eACtB,qBACA,qBACAvB;YACE,MAAMoC,IAAW5J,EAAYM,MAAM1V,QAC7Bif,IAAiB3uB,WAAqC;gBAC1D4uB,KAAe;;YAEjB,OAAO5uB,WACassB,GAAKxH,EAAYM,OAAON,EAAYQ,aACrDle,KAAK,MACJpH,QAAiCssB,UAElCllB,KAAK,MAAMunB,EAAe/c,MAAM0a,IAChCllB,KAAK,MAAMpH,WAA2CssB,IACtDllB,KAAK,MAAMpH,WAAiCssB;;;;;;;;WAWrDxsB,GAAY4kB;QACV,OAAO1kB,KAAKutB,YAAYM,eACtB,gBACA,qBACAvB;YACE,IAAIuC;YACJ,OAAO7uB,WACgBssB,GAAK5H,GACzBtd,KAAMge,MACLxiB,GAAqB,SAAVwiB,GAAgB;YAC3ByJ,IAAezJ,EAAM1V,QACd1P,WAAuCssB,GAAKlH,KAEpDhe,KAAK,MACGpH,WAA2CssB,IAEnDllB,KAAK,MACGpH,WAAiCssB;;;;;;WAUlDxsB;QACE,OAAOE,KAAKutB,YAAYM,eACtB,uCACA,YACAvB,KACStsB,WAAmDssB;;2EAMhExsB;QACE,OAAOE,KAAKutB,YAAYM,eACtB,yBACA,YACAvB,KACStsB,WAAsCssB;;;;;;WAUnDxsB,GAAmBwlB;QACjB,OAAOtlB,KAAKutB,YAAYM,eACtB,yBACA,qBACAvB,KACStsB,WAAsCssB,GAAKhH;;;;;WASxDxlB;QACE,OAAOE,KAAKutB,YAAYM,eACtB,oCACA,YACAvB,KAAOtsB,WAA8CssB;;;;;;;;;WAYzDxsB,GAAiBse;QACf,MAAM0Q,IAAgB1Q;QACtB,IAAI2Q,IAA2B/uB;QAE/B,OAAOA,KAAKutB,YACTM,eAAe,sBAAsB,qBAAqBvB;YACzD,MAAMqC,IAAiB3uB,WAAqC;gBAC1D4uB,KAAe;;;wBAIjBG,IAA2B/uB;YAE3B,MAAM+mB,IAAW;YACjB3I,KAA0B/Y,QAAQ,CAAC8V,GAAQpR;gBACzC,MAAMilB,IAAgBD,EAAyBzsB,IAAIyH;gBACnD,QACE;;;;gCAMFgd,EAASxhB,KACPvF,WACsBssB,GAAKnR,MAAyBpR,GACjD3C,KAAK,MACGpH,WACLssB,GACAnR,MACApR;gBAKR,MAAMiQ,IAAcmB,EAAOnB;;gCAE3B,IAAIA,SAAoC,GAAG;oBACzC,MAAMiV,IAAgBD,KACHhV,SACGsS;oBACtByC,IAA2BA,KACzBhlB;;;oBAOAmlB,kBAMAnI,EAASxhB,KACPvF,WAAkCssB;;;YAM1C,IAAI6C,IAAc7U,MACd8U,IAAc5S;;;;;YAiElB,IAhEA4B,KAA4B/Y,QAAQ,CAACwC,GAAKwM;gBACxC+a,IAAcA,EAAY3lB,IAAI5B;;;;YAKhCkf,EAASxhB,KACPopB,EAAe7G,WAAWwE,MAAkBllB,KAAKonB;gBAC/CpQ,KAA4B/Y,QAAQ,CAACwC,GAAKwM;oBACxC,MAAMgb,IAAcb,EAAalsB,IAAIuF;;;;;wCAOnCwM,mBACAA,EAAItB,QAAQpO,QAAQF,EAAgBC;;;;oBAKpCiqB,KAA2B9mB,OAC3BsnB,IAAcA,KAAmBtnB,GAAKwM,MAEvB,QAAfgb,KACAhb,EAAItB,UAAkBsc,EAAYtc,WAAW,KACG,MAA/CsB,EAAItB,UAAkBsc,EAAYtc,YACjCsc,EAAYjZ,oBAMduY,KAAwBta;oBACxB8a,IAAcA,KAAmBtnB,GAAKwM,MAEtCoK,GA/hBA,cAiiBE,uCACA5W,GACA,sBACAwnB,EAAYtc,SACZ,mBACAsB,EAAItB;oBAIJqL,KAAmC5U,IAAI3B,MACzCkf,EAASxhB,KACPvF,KAAKutB,kBACHjB,GACAzkB;;kBAYPinB,EAAcnqB,QAAQF,EAAgBC,MAAM;gBAC/C,MAAM4qB,IAAsBtvB,WACIssB,GAC7BllB,KAAKmoB,KAQGvvB,WACLssB,GACAA;gBAINvF,EAASxhB;;YAGX,OAAO2gB,SACJ9e,KAAK,MAAMunB,EAAe/c,MAAM0a,IAChCllB,KAAK,MACGpH,WACLssB;WAKP/pB,KAAK4sB,MACJnvB;;;;;;;;;;;;WAgBEF,UACNkvB,GACAC,GACA9T;;QAQA,IANAvY,GACEqsB,EAAcjV,mBAAoC,GAClD;QAIsD,MAApDgV,EAAchV,kBAChB,QAAO;;;;;;gBAWT,OAFEiV,WACAD,YACehvB,WAUfmb,KAAsB3V,OACtB2V,KAAyB3V,OACzB2V,KAAwB3V,OACT;;;;;;;;;WAMnB1F,GAAuB0vB;QACrB,KAAK,MAAMC,QAA2B;YACpC,MAAM1lB,IAAW0lB,EAAW1lB;YAQ5B,IANA/J,WAAuCyvB,MAAsB1lB,IAC7D/J,WACEyvB,MACA1lB,KAGG0lB,EAAW7T,WAAW;gBACzB,MAAMqC,IAAaje,QAAwBsC,IAAIyH,IAOzCgQ,IAA+BkE,MAC/ByR,IAAoBzR,KACxBlE;;gCAEF/Z,UAA0BA,WACxB+J;;;QAKN,OAAO/J,KAAKutB,YAAYM,eACtB,0BACA,aACAvB,KACSpG,GAAmB7gB,WAEvBoqB,KACQvJ,GAAmB7gB,QACxBoqB,MACC5nB,KACC7H,KAAKutB,kBAA8CjB,GAAKzkB;;;;;;;WActE/H,GAAkB6vB;QAChB,OAAO3vB,KAAKutB,YAAYM,eACtB,2BACA,YACAvB,WACuBvnB,MAAjB4qB,MACFA,KX3uBqB;QW6uBhB3vB,WACLssB;;;;;WAWRxsB,GAAa+H;QACX,OAAO7H,KAAKutB,YAAYM,eAAe,iBAAiB,YAAYvB,KAC3DtsB,WAAgCssB,GAAKzkB;;;;;;;;;WAYhD/H,GAAe6Z;QACb,OAAO3Z,KAAKutB,YACTM,eAAe,mBAAmB,aAAavB;YAC9C,IAAIrO;YACJ,OAAOje,WACUssB,GAAK3S,GACnBvS,KAAMwoB;;;;YAKH3R,OACOiI,GAAmBpkB,cAEnB9B,WAAkCssB,GAAKllB,KAAK2C,MACjDkU,IAAa,OACXtE,GACA5P,oBAEAuiB;YAEKtsB,WACUssB,MACdllB,KAAK;WAKjB7E,KAAK0b,MACqD,SAArDje,QAAwBsC,IAAI2b,EAAWlU,cACzC/J,UAA0BA,WACxBie,EAAWlU;QAGb/J,QAAsBkU,IAAIyF,GAAQsE,EAAWlU;;;;;;;IAWrDjK,GACEmnB,GACAtN;QAEA,MAAM5P,IAAW/J,QAAsBsC,IAAIqX;QAC3C,YAAiB5U,MAAbgF,IACKmc,GAAmBpkB,QACxB9B,QAAwBsC,IAAIyH,MAGvB/J,WAA+BinB,GAAatN;;;;;;;;;;IAYvD7Z,GACEiK,GACA8lB;QAEA,MAAM5R,IAAaje,QAAwBsC,IAAIyH,IAMzC+lB,IAAOD,IAA0B,cAAc;QACrD,OAAO7vB,KAAKutB,YACTM,eAAe,kBAAkBiC,GAAMxD;;;;;;;;;;;YAWtC,MAAMyD,IAAU/vB,WACd+J;YAGF,WAOSmc,GAAmBpkB,YANnBokB,GAAmB7gB,WAAkBwC,KAC1C7H,KAAKutB,kBAA8CjB,GAAKzkB,IACxDT,KAAK;gBACLpH,KAAKutB,eAA8B1P,aAAayO;;WAMrD/pB,KAAK;YACJvC,UAA0BA,QAAwB8H,OAAOiC,IACzD/J,QAAsBmU,OAAO8J,EAAYtE;;;;;;;;;;WAY/C7Z,GACEyb,GACAyU;QAEA,IAAIjW,IAA+BtV,EAAgBC,KAC/CurB,IAAazT;QAEjB,OAAOxc,KAAKutB,YAAYM,eAAe,iBAAiB,YAAYvB,KAC3DtsB,QAAmBssB,GAAK/Q,QAC5BnU,KAAK6W;YACJ,OAGE,OAFAlE,IACEkE,EAAWlE,8BACN/Z,WACuBssB,GAAKrO,EAAWlU,UAC3C3C,KAAKqB;gBACJwnB,IAAaxnB;;WAIpBrB,KAAK,MACJpH,WACEssB,GACA/Q,GACAyU,IACIjW,IACAtV,EAAgBC,KACpBsrB,QAAkCxT,OAGrCpV,KAAK2U,MACG;YAAEA,WAAAA;YAAWmU,IAAAD;;;;;;WAS5BnwB,GAAmBiK;QACjB,OAAO/J,KAAKutB,YAAYM,eACtB,wBACA,YACAvB,KACStsB,WAA4CssB,GAAKviB;;;IAM9DjK;QACE,OAAOE,KAAKutB;;;IAIdztB,GAAkC4kB;QAChC1kB,WAA4C0kB;;;IAI9C5kB,GAAkBqwB;QAChBnwB,KAAKutB,eAA8B4C;;IAGrCrwB,GACEwsB,GACAxH,GACA6J;QAEA,MAAMvJ,IAAQN,EAAYM,OACpBgL,IAAUhL,EAAM1V;QACtB,IAAI2gB,IAAenK,GAAmBpkB;QAiCtC,OAhCAsuB,EAAQ/qB,QAAQwf;YACdwL,IAAeA,EACZjpB,KAAK,MACGunB,KAAwBrC,OAEhCllB,KAAMkpB;gBACL,IAAIjc;gBACJ,MAAMkc,IAAazL,KAAwBxiB;gBAC3CM,GACiB,SAAf2tB,GACA,yDAEGlc,KAAOA,EAAItB,eAAiC,OAC/CsB,IAAM+Q,QAAoC/Q;gBACrCA;;;;gBAaHsa,KAAwBta,GAAKyQ;;YAKhCuL,EAAajpB,KAAK,MACvBpH,WAAuCssB,GAAKlH;;IAIhDtlB,GAAeisB;QACb,OAAO/rB,KAAKutB,YAAYM,eACtB,mBACA,qBACAvB,KAAOP,KAAyBO,GAAKtsB;;;IAKzCF,GAAUiK;QACR,MAAMymB,IAAmBxwB,QAAwBsC,IAAIyH;QAErD,WACSlI,QAAQC,QAAQ0uB,EAAiB7W,UAEjC3Z,KAAKutB,YAAYM,eACtB,mBACA,YACAvB,KACStsB,WACmBssB,GAAKviB,GAC5B3C,KAAK6W,KAAeA,IAAaA,EAAWtE,SAAS;;;;;;;;;IAahE7Z;QACE,OAAOE,KAAKutB,YACTM,eAAe,4BAA4B,YAAYvB,KACtDtsB,WACEssB,GACAtsB,UAGHuC,KAAK,EAAGkuB,IAAAtB,GAAazP,UAAAA,QACpB1f,UAAkC0f;;;;;;;;;IAWxC5f;QACEE,gBAAwCA,KAAKutB,YAAYM,eACvD,8CACA,YACAvB,KAAOtsB,WAAqCssB;;;;;;;;;;;;;;;;;;;;;AAe3CoE,kBACLhK;IAEA,IACEA,EAAIplB,SAASpB,EAAKW,uBAClB6lB,EAAInlB,gBAIJ;IAFAkd,GA5hCY,cA4hCM;;;;;;;;;;;;;;;;;;;;;;;;;gBCxjCSkS,GAAsBxN;IACnD,IAAoB,MAAhBA,EAAKre,QACP,MAAM,IAAI1D,EACRlB,EAAKI,kBACL,YAAYqwB,qCACV,yBACAC,GAAazN,EAAKre,QAAQ,cAC1B;;;;;;;;;gBAaN6rB,GACAxN,GACA0N;IAEA,IAAI1N,EAAKre,cACP,MAAM,IAAI1D,EACRlB,EAAKI,kBACL,YAAYqwB,kBACVC,MAA2B,cAC3B,2BACAA,GAAazN,EAAKre,QAAQ,cAC1B;;;;;;;;;;gBAcN6rB,GACAxN,GACA2N;IAEA,IAAI3N,EAAKre,YACP,MAAM,IAAI1D,EACRlB,EAAKI,kBACL,YAAYqwB,2BACVC,MAA8B,cAC9B,2BACAA,GAAazN,EAAKre,QAAQ,cAC1B;;;;;;;;;;gBAcN6rB,GACAxN,GACA2N,GACAC;IAEA,IAAI5N,EAAKre,cAA4Bqe,EAAKre,YACxC,MAAM,IAAI1D,EACRlB,EAAKI,kBACL,YAAYqwB,wBAAmCG,WAC7C,GAAGC,sCACHH,GAAazN,EAAKre,QAAQ,cAC1B;;;;;;;;;;;YA8BN6rB,GACAtV,GACAhD,GACA2Y;IAEAC,GAAaN,GAActV,GAAM,GAAG6V,GAAQ7Y;;;;;;gBAQ5CsY,GACAtV,GACAhD,GACA2Y;SAEiBjsB,MAAbisB,KACFG,GAAgBR,GAActV,GAAMhD;;;;;;gBAStCsY,GACAtV,GACA+V,GACAJ;IAEAC,GAAaN,GAActV,GAAM,GAAG+V;;;;;;gBAQpCT,GACAtV,GACA+V,GACAJ;SAEiBjsB,MAAbisB,KACFK,GAAkBV,GAActV;;;YAgClCsV,GACAS,GACAE,GACAN,GACAO;SAEiBxsB,MAAbisB,cAjCJL,GACAS,GACAE,GACAN,GACAO;QAEA,MAAMP,aAAoBQ,QACxB,MAAM,IAAIpwB,EACRlB,EAAKI,kBACL,YAAYqwB,oBAA+BS,OACzC,sCAAsCK;QAI5C,KAAK,IAAI/rB,IAAI,GAAGA,IAAIsrB,EAASlsB,aAC3B,KAAKysB,EAAUP,OACb,MAAM,IAAI5vB,EACRlB,EAAKI,kBACL,YAAYqwB,oBAA+BS,OACzC,kBAAkBE,6BAA2C5rB,OAC7D,QAAQ+rB,GAAiBT;KAc/BU,CACEf;;;;;;;;;;YAyCJA,GACAgB,GACAP,GACAQ,GACAC;SAEc9sB,MAAV6sB,cAlCJjB,GACAgB,GACAP,GACAQ,GACAC;QAEA,MAAMC,IAAgC;QAEtC,KAAK,MAAMzY,QAAiB;YAC1B,IAAIA,MAAQuY,GACV;YAEFE,EAAoBvsB,KAAKksB,GAAiBpY;;QAG5C,MAAM0Y,IAAoBN,GAAiBG;QAC3C,MAAM,IAAIxwB,EACRlB,EAAKI,kBACL,iBAAiByxB,0BAA0CpB,oBACzD,IAAIS,0BAAmCU,EAAoBzrB,KAAK;KAgBlE2rB,CACErB,SAGAiB;;;;;;;;;;;;AA+BN,YACEjB,GACAtV,GACAsW,GACAC;IAEA,IAAIK,KAAQ;IASZ,IAPEA,IADW,aAAT5W,IACM6W,GAAcN,KACJ,uBAATvW,IACgB,mBAAVuW,KAAgC,OAAVA,WAEtBA,MAAUvW;KAGtB4W,GAAO;QACV,MAAME,IAAcV,GAAiBG;QACrC,MAAM,IAAIxwB,EACRlB,EAAKI,kBACL,YAAYqwB,oBAA+BgB,OACzC,iBAAiBtW,kBAAqB8W;;;;;;;gBAShBP;IAC5B,OACmB,mBAAVA,KACG,SAAVA,MACC1nB,OAAOkoB,eAAeR,OAAW1nB,OAAOC,aACN,SAAjCD,OAAOkoB,eAAeR;;;uFAKKA;IAC/B,SAAc7sB,MAAV6sB,GACF,OAAO;IACF,IAAc,SAAVA,GACT,OAAO;IACF,IAAqB,mBAAVA,GAIhB,OAHIA,EAAM9sB,SAAS,OACjB8sB,IAAQ,GAAGA,EAAMS,UAAU,GAAG;IAEzBnmB,KAAKC,UAAUylB;IACjB,IAAqB,mBAAVA,KAAuC,oBAAVA,GAC7C,OAAO,KAAKA;IACP,IAAqB,mBAAVA,GAAoB;QACpC,IAAIA,aAAiBJ,OACnB,OAAO;QACF;YACL,MAAMc;;qBAe2BV;gBACrC,IAAIA,EAAMW,aAAa;oBACrB,MACM/M,IADgB,4BACQ9U,KAAKkhB,EAAMW,YAAY9wB;oBACrD,IAAI+jB,KAAWA,EAAQ1gB,SAAS,GAC9B,OAAO0gB,EAAQ;;gBAGnB,OAAO;;8DAvBsBgN;YACzB,WACS,YAAYF,aAEZ;;;IAGN,OAAqB,qBAAVV,IACT,eAEA5sB,GAAK,gCAAgC4sB;;;YAkB9CjB,GACAtY,GACA2Y;IAEA,SAAiBjsB,MAAbisB,GACF,MAAM,IAAI5vB,EACRlB,EAAKI,kBACL,YAAYqwB,wBAAmCO,GAAQ7Y,QACrD;;;;;;gBAUNsY,GACAxa,GACAsc;IAEAptB,EAAQ8Q,GAA0B,CAACtO,GAAKiW;QACtC,IAAI2U,EAAYlsB,QAAQsB,KAAO,GAC7B,MAAM,IAAIzG,EACRlB,EAAKI,kBACL,mBAAmBuH,yBAA2B8oB,UAC5C,wBACA8B,EAAYpsB,KAAK;;;;;;;gBAWzBsqB,GACAtV,GACAhD,GACA2Y;IAEA,MAAMmB,IAAcV;IACpB,OAAO,IAAIrwB,EACTlB,EAAKI,kBACL,YAAYqwB,oBAA+BO,GAAQ7Y,QACjD,oBAAoBgD,kBAAqB8W;;;YAK7CxB,GACAtY,GACAzP;IAEA,IAAIA,KAAK,GACP,MAAM,IAAIxH,EACRlB,EAAKI,kBACL,aAAaqwB,qBAAgCO,GAC3C7Y,oDACiDzP;;;2DAMzD,aAAiB8pB;IACf,QAAQA;MACN,KAAK;QACH,OAAO;;MACT,KAAK;QACH,OAAO;;MACT,KAAK;QACH,OAAO;;MACT;QACE,OAAOA,IAAM;;;;;;GAOnB,aAAsBA,GAAa5rB;IACjC,OAAO,GAAG4rB,KAAO5rB,OAAiB,MAAR4rB,IAAY,KAAK;;;;;;;;;;;;;;;;;;;;;;;;;;;;;gBCvc3CC,GACAC;IAEA;QACE,IAAItP,IAAQ;QAKZ,YAHEA,KAAS,KACTA,SAEI,IAAIliB,EAAelB,EAAKI,kBAAkBgjB;;;;;IAWlD,OANAuP,EAAkB1oB,YAAYwoB,EAAIxoB;;IAGlCD,OAAO4oB,cAGAD;;;;;;;;;;;;;;;;;;;oECvBT;IACE,IAA0B,sBAAf9nB,YACT,MAAM,IAAI3J,EACRlB,EAAKc,eACL;;;2EAMN;IACE,KAAKwJ,YACH,MAAM,IAAIpJ,EACRlB,EAAKc,eACL;;;;;;;;;GHuGJkuB,SAAsD;;MG3F3C6D;IAKXjzB,YAAYkzB;QACVC,MACAjzB;;IAGFF,wBAAwByK;QACtB2oB,GAA0B,yBAAyBC,WAAW,IAC9DhC,GAAgB,yBAAyB,UAAU,GAAG5mB;QACtD0oB;QACA;YACE,OAAO,IAAIF,GAAKvnB,EAAWuF,iBAAiBxG;UAC5C,OAAOgZ;YACP,MAAM,IAAIniB,EACRlB,EAAKI,kBACL,kDAAkDijB;;;IAKxDzjB,sBAAsB4K;QAGpB,IAFAwoB,GAA0B,uBAAuBC,WAAW,IAC5DC,QACM1oB,aAAiBK,aACrB,MAAMsoB,GAAkB,uBAAuB,cAAc,GAAG3oB;QAElE,OAAO,IAAIqoB,GAAKvnB,EAAWwF,eAAetG;;IAG5C5K;QAGE,OAFAozB,GAA0B,iBAAiBC,WAAW,IACtDF,MACOjzB,QAAiBmQ;;IAG1BrQ;QAGE,OAFAozB,GAA0B,qBAAqBC,WAAW,IAC1DC,MACOpzB,QAAiBmf;;IAG1Brf;QACE,OAAO,kBAAkBE,KAAKmQ,aAAa;;IAG7CrQ,QAAQqE;QACN,OAAOnE,QAAiB2E,QAAQR;;;;;;;;;;iDAW7B;MAAMmvB,KAAaC,GACxBR,IACA;;;;;;;;;;;;;;;;;;;;;;;;;UCjFWpsB;;;;;;;IAUX7G,eAAe0zB;kBHkFf7C,GACAhvB,GACAD,GACA+xB;YAEA,MAAM9xB,aAAiB6vB,UAAU7vB,EAAMmD,YACrC,MAAM,IAAI1D,EACRlB,EAAKI,kBACL,YAAYqwB,oBAA+BjvB,yBACzC,yBACA,GAAGkvB,MAAkC;SG3FzC8C,CACE,aACAF,GACA,cACA;QAGF,KAAK,IAAI9tB,IAAI,GAAGA,IAAI8tB,EAAW1uB,aAE7B,IADAqsB,GAAgB,aAAa,aAAaqC,OACb,MAAzBA,KAAc1uB,QAChB,MAAM,IAAI1D,EACRlB,EAAKI,kBACL;QAMNN,UAAqB,MAAsBwzB;;IAa7C1zB;QACE,OAAO6G;;IAGT7G,QAAQqE;QACN,MAAMA,aAAiBwC,KACrB,MAAM0sB,GAAkB,WAAW,aAAa,GAAGlvB;QAErD,OAAOnE,QAAmB2E,QAAQR;;;;;;;;;GAZpCwC,SAAuC,IAAIA,GACzCgtB;;;;;AAkBJ,MAAMC,KAAW,IAAI5nB,OAAO;;;;;;;;;;;;;;;;;;;;;;;;;;IC7D1BlM,YAA+B+zB;;;IAE/B/zB;QAEE,OADAg0B,GAAe,qBAAqBX,YAC7BY,GAAqB/S;;IAG9BlhB;QAEE,OADAg0B,GAAe,8BAA8BX,YACtCa,GAA8BhT;;IAGvClhB,qBAAqB6R;;;QAInB,OAHAsiB,GAA4B,yBAAyBd,WAAW,IAGzD,OAA6BxhB;;IAGtC7R,sBAAsB6R;;;QAIpB,OAHAsiB,GAA4B,0BAA0Bd,WAAW,IAG1D,OAA8BxhB;;IAGvC7R,iBAAiB8I;QAGf,OAFAuoB,GAAgB,wBAAwB,UAAU,GAAGvoB,IACrDsqB,GAA0B,wBAAwBC,WAAW;QACtD,OAAmCvqB;;IAG5C9I,QAAQqE;QACN,OAAOnE,SAASmE;;;;iBAIsB+vB;IACxCp0B;QACE0B,MAAM;;;;0BAGDuyB,eAAW;;iBAG+BG;IACjDp0B;QACE0B,MAAM;;;;0BAGDwyB,eAAW;;iBAG0BE;IAC5Cp0B,YAAqBq0B;QACnB3yB,MAAM;;;;iBAIqC0yB;IAC7Cp0B,YAAqBq0B;QACnB3yB,MAAM;;;;iBAI0C0yB;IAClDp0B,YAAqBs0B;QACnB5yB,MAAM;;;;;;;;;;kEAWH;MAAM6yB,KAAmBd,OAE9B;;;;;;;;;;;;;;;;;;;;;UCpFWe;IAMXx0B,YAAYmN,GAAkBC;QAI5B,IAHAgmB,GAA0B,YAAYC,WAAW,IACjDhC,GAAgB,YAAY,UAAU,GAAGlkB,IACzCkkB,GAAgB,YAAY,UAAU,GAAGjkB;SACpCqnB,SAAStnB,MAAaA,KAAY,MAAMA,IAAW,IACtD,MAAM,IAAI7L,EACRlB,EAAKI,kBACL,4DAA4D2M;QAGhE,KAAKsnB,SAASrnB,MAAcA,KAAa,OAAOA,IAAY,KAC1D,MAAM,IAAI9L,EACRlB,EAAKI,kBACL,+DAA+D4M;QAInElN,UAAYiN,GACZjN,UAAakN;;;;WAMfD;QACE,OAAOjN;;;;WAMTkN;QACE,OAAOlN;;IAGTF,QAAQqE;QACN,OAAOnE,YAAcmE,QAAcnE,YAAemE;;;;;WAOpDrE,EAAWqE;QACT,OACEC,GAAoBpE,SAAWmE,SAC/BC,GAAoBpE,SAAYmE;;;;;;;;;;;;;;;;;;;GClBtC,OAAMqwB,KAAuB;;;IAI3B10B,YACWoJ,GACA2K,GACAO;QAFApU,YAAAkJ,gBAEAlJ,uBAAAoU;;IAGXtU,GAAY+H,GAAkB2L;QAC5B,MAAMoR,IAAY;QAWlB,OAVuB,SAAnB5kB,UACF4kB,EAAUrf,KACR,OAAkBsC,GAAK7H,KAAKkJ,MAAMlJ,eAGpC4kB,EAAUrf,KAAK,OAAgBsC,GAAK7H,KAAKkJ;QAEvClJ,KAAKoU,gBAAgBtP,SAAS,KAChC8f,EAAUrf,KAAK,OAAsBsC,GAAK7H,KAAKoU,mBAE1CwQ;;;;;IAMT9kB,YACWoJ,GACA2K,GACAO;QAFApU,YAAAkJ,gBAEAlJ,uBAAAoU;;IAGXtU,GAAY+H,GAAkB2L;QAC5B,MAAMoR,IAAY,EAChB,OAAkB/c,GAAK7H,KAAKkJ,MAAMlJ;QAKpC,OAHIA,KAAKoU,gBAAgBtP,SAAS,KAChC8f,EAAUrf,KAAK,OAAsBsC,GAAK7H,KAAKoU;QAE1CwQ;;;;AAyBX,YAAiB6P;IACf;MACE;;cACA;;cACA;QACE,QAAO;;MACT;MACA;QACE,QAAO;;MACT;QACE,MAAMzvB,GAAK,uCAAuCyvB;;;;gEAKxD;;;;;;;;;;;;;;;;;;;;;;;IAyBE30B,YACW20B,GACAC,GACApuB,GACAquB,GACTvgB,GACAP;qBAJS7T,kBAAA00B,GACA10B,YAAAsG;;;aAOevB,MAApBqP,KACFpU,WAEFA,eAAqC+E,MAAjB4vB,QACpB30B,KAAKoU,kBAAkBA,KAAmB;QAC1CpU,UAAiB6T,KAAa;;IAGhC/T,GAAqB+S;QACnB,MAAM+hB,IAAyB,QAAb50B,KAAKsG,OAAe,OAAOtG,KAAKsG,KAAK4O,MAAMrC,IACvDgiB,IAAU,OACd70B,SACAA,KAAK00B;2BAEa,GAClB10B,KAAKoU,iBACLpU;QAGF,OADA60B,KAA4BhiB,IACrBgiB;;IAGT/0B,GAAyB+S;QACvB,MAAM+hB,IAAyB,QAAb50B,KAAKsG,OAAe,OAAOtG,KAAKsG,KAAK4O,MAAMrC,IACvDgiB,IAAU,OACd70B,SACAA,KAAK00B;2BAEa,GAClB10B,KAAKoU,iBACLpU;QAGF,OADA60B,QACOA;;IAGT/0B,GAAqB2F;;;QAGnB,OAAO,OACLzF,SACAA,KAAK00B;kBACK;2BACQ,GAClB10B,KAAKoU,iBACLpU;;IAIJF,GAAYgqB;QACV,MAAMgL,IACU,SAAd90B,KAAKsG,QAAiBtG,KAAKsG,WACvB,KACA,oBAAoBtG,KAAKsG,KAAK7E;QACpC,OAAO,IAAIL,EACTlB,EAAKI,kBACL,YAAYN,KAAK00B,4CACf5K;;sFAMNhqB,SAAS2S;QACP,YACgE1N,MAA9D/E,QAAemO,KAAK0E,KAASJ,IAAqBI,YAG5C9N,MAFN/E,KAAKoU,gBAAgBjG,KAAK2E,KACxBL,IAAqBK,EAAUD;;IAKrC/S;;;QAGE,IAAkB,SAAdE,KAAKsG,MAGT,KAAK,IAAIZ,IAAI,GAAGA,IAAI1F,KAAKsG,KAAKxB,QAAQY,KACpC1F,QAAyBA,KAAKsG,KAAKhE;;IAIvCxC,GAA4BwF;QAC1B,IAAuB,MAAnBA,EAAQR,QACV,MAAM9E,QAAiB;QAEzB,IAAI+0B,GAAQ/0B,YAAoBw0B,GAAqB5tB,SACnD,MAAM5G,QAAiB;;;;;;;;;IAyB3BF,YAAmBmR,GAA+BpJ;qBAAA7H,WAAA6H;;;;;;;;IAQlD/H,YACmBoS,GACA8iB;QADAh1B,kBAAAkS;;+DAKnBpS,GAAa40B,GAAoB9C;QAC/B,MAAMiD,IAAU,qBAEdH,GACA/tB;QAEFsuB,GAAoB,uCAAuCJ,GAASjD;QACpE,MAAMsD,IAAal1B,QAAiB4xB,GAAOiD;QAE3C,OAAO,OACL;yBACiB,MACjBA,EAAQzgB;;yEAKZtU,GACE40B,GACA9C,GACAnP;QAEA,MAAMoS,IAAU,0BAEdH,GACA/tB;QAEFsuB,GAAoB,uCAAuCJ,GAASjD;QACpE,MAAMsD,IAAal1B,QAAiB4xB,GAAOiD;QAE3C,IAAIhhB,GACAO;QAEJ,IAAKqO,GAGE;YACL,IAAI0S,IAAsB,MAAyBxuB;YAEnD,KAAK,MAAMyuB,KAAqB3S,GAAY;gBAC1C,IAAIhQ;gBAEJ,IAAI2iB,iBACF3iB,IAAY2iB,WACP;oBAAA,IAAiC,sBAMtC,MAAMpwB,GACJ;oBANFyN,IAAY4iB,GACVX;;gBASJ,KAAKG,EAAQS,SAAS7iB,IACpB,MAAM,IAAIrR,EACRlB,EAAKI,kBACL,UAAUmS;gBAId0iB,IAAsBA,EAAoB1rB,IAAIgJ;;YAGhDoB,IAAYsB,UACZf,IAAkBygB,EAAQzgB,gBAAgB3N,OAAOqM,KAC/Ce,KAAiBf,EAAUD;eAjC7BgB,IAAYsB,MAAoB0f,OAChCzgB,IAAkBygB,EAAQzgB;QAmC5B,OAAO,OACL,cAEAA;;uDAKJtU,GAAgB40B,GAAoB9C;QAClC,MAAMiD,IAAU,wBAEdH,GACA/tB;QAEFsuB,GAAoB,uCAAuCJ,GAASjD;QAEpE,IAAI2D,IAAiB,MAAyB5uB;QAC9C,MAAMuuB,IAAanhB;QACnB1O,EAAQusB,GAAwB,CAAC/pB,GAAKlG;YACpC,MAAM2E,IAAO+uB,GAAgCX,GAAY7sB,IAEnD2tB,IAAeX,KAAiCvuB;YAEtD,KADA3E,IAAQ3B,QAAqB2B;;YAG3B4zB,IAAiBA,EAAe9rB,IAAInD,SAC/B;gBACL,MAAMmvB,IAAcz1B,QAAe2B;gBAChB,QAAf8zB,MACFF,IAAiBA,EAAe9rB,IAAInD,IACpC4uB,EAAWhhB,IAAI5N;;;QAKrB,MAAMovB,IAAOvgB;QACb,OAAO,OACL+f,QACAQ,GACAb,EAAQzgB;;sEAKZtU,GACE40B,GACA7hB,GACAlR,GACAg0B;QAEA,MAAMd,IAAU,wBAEdH,GACA/tB,MAEI+I,IAAO,EAACkmB,GAAsBlB,GAAY7hB,MAC1ClF,IAAS,EAAChM;QAEhB,IAAIg0B,EAAoB7wB,SAAS,KAAM,GACrC,MAAM,IAAI1D,EACRlB,EAAKI,kBACL,YAAYo0B,gDACV;QAIN,KAAK,IAAIhvB,IAAI,GAAGA,IAAIiwB,EAAoB7wB,QAAQY,KAAK,GACnDgK,EAAKnK,KACHqwB,GACElB,GACAiB,QAGJhoB,EAAOpI,KAAKowB,EAAoBjwB,IAAI;QAGtC,IAAI6vB,IAAiB,MAAyB5uB;QAC9C,MAAMuuB,IAAanhB;QAEnB,KAAK,IAAIrO,IAAI,GAAGA,IAAIgK,EAAK5K,aAAa;YACpC,MAAMwB,IAAOoJ,MACP8lB,IAAeX,KAAiCvuB,IAChD3E,IAAQ3B,QAAqB2N;YACnC,IAAIhM;;YAEF4zB,IAAiBA,EAAe9rB,IAAInD,SAC/B;gBACL,MAAMmvB,IAAcz1B,QAAe2B;gBAChB,QAAf8zB,MACFF,IAAiBA,EAAe9rB,IAAInD,IACpC4uB,EAAWhhB,IAAI5N;;;QAKrB,MAAMovB,IAAOvgB;QACb,OAAO,OACL+f,QACAQ,GACAb,EAAQzgB;;;;;;;;WAWZtU,GACE40B,GACA9C,GACAiE,KAAc;QAEd,MAAMhB,IAAU,OACdgB,+CACAnB,GACA/tB;QAQF,OANe3G,QAAe4xB,GAAOiD;;gFAUvC/0B,GAAwB8xB,GAAgBiD;QACtC;YACE,OAAO70B,QAAkB4xB;UACzB,OAAOrO;YACP,MAAMhiB,IAAUu0B,GAAavS;YAC7B,MAAMsR,KAAoBtzB;;;;;;;;;;;WAa9BzB,GAAkB8xB,GAAgBiD;QAEhC,IAAIkB,GADJnE,IAAQ5xB,QAAqB4xB,GAAOiD,KAGlC,OADAI,GAAoB,4BAA4BJ,GAASjD,IAClD5xB,QAAiB4xB,GAAOiD;QAC1B,IAAIjD;;;;;;QAOT,OADA5xB,QAA6B4xB,GAAOiD,IAC7B;QAQP;;;QAJIA,EAAQvuB,QACVuuB,KAAkBtvB,KAAKsvB,EAAQvuB,OAG7BsrB,aAAiBJ,OAAO;;;;;;;YAO1B,IACEqD,kCACAA,MAEA,MAAMA,KAAoB;YAE5B,OAAO70B,QAAgB4xB,GAAoBiD;;QAE3C,OAAO70B,QAAsB4xB,GAAOiD;;IAK1C/0B,GACEkK,GACA6qB;QAEA,MAAMnpB,IAA0B;QAoBhC,OAlBI+Y,EAAQza;;;QAGN6qB,EAAQvuB,QAAQuuB,EAAQvuB,KAAKxB,SAAS,KACxC+vB,KAAkBtvB,KAAKsvB,EAAQvuB,QAGjCjB,EAAQ2E,GAAK,CAACnC,GAAawR;YACzB,MAAMoc,IAAcz1B,QAClBqZ,GACAwb,KAA6BhtB;YAEZ,QAAf4tB,MACF/pB,EAAO7D;YAKN;YAAE4D,UAAU;gBAAEC,QAAAA;;;;IAGvB5L,GAAmB4K,GAAkBmqB;QACnC,MAAMlnB,IAAsB;QAC5B,IAAIqoB,IAAa;QACjB,KAAK,MAAMhL,KAAStgB,GAAO;YACzB,IAAIurB,IAAcj2B,WAEhB60B;YAEiB,QAAfoB;;;YAGFA,IAAc;gBAAE1T,WAAW;gBAE7B5U,EAAOpI,SACPywB;;QAEF,OAAO;YAAEtoB,YAAY;gBAAEC,QAAAA;;;;;;;WAOzB7N,GACE6B,GACAkzB;;QAGA,KAAKE,GAAQF,OACX,MAAMA,KACJ,GAAGlzB;QAGP,IAAqB,SAAjBkzB,EAAQvuB,MACV,MAAMuuB,KACJ,GAAGlzB;QAIP,IAAIA,iBAAuC;YACzC,yBAAIkzB,MAIG,yBAAIA,OAMHA,KACJ,8EAKIA,KACJ;;;YAdFA,KAAkBtvB,KAAKsvB,EAAQvuB;eAkB5B,IAAI3E,iBACTkzB,EAAQzgB,gBAAgB7O,KACtB,IAAIqN,GAAeiiB,EAAQvuB,MAAMoL,GAAyBsP,iBAEvD,IAAIrf,iBAA2C;YACpD,MAAMu0B,IAAiBl2B,QACrB2B,MACAA,OAEIw0B,IAAa;YACnBtB,EAAQzgB,gBAAgB7O,KACtB,IAAIqN,GAAeiiB,EAAQvuB,MAAM6vB;eAE9B,IAAIx0B,iBAA4C;YACrD,MAAMu0B,IAAiBl2B,QACrB2B,MACAA,OAEIy0B,IAAc;YACpBvB,EAAQzgB,gBAAgB7O,KACtB,IAAIqN,GAAeiiB,EAAQvuB,MAAM8vB;eAE9B,IAAIz0B,iBAAiD;YAC1D,MAAMwQ,IAAUnS,QACd,wBACA2B,OAEI00B,IAAmB,OACvBr2B,KAAKkS;YAGP2iB,EAAQzgB,gBAAgB7O,KACtB,IAAIqN,GAAeiiB,EAAQvuB;eAG7BtB,GAAK,8BAA8BrD;;;;;;WASvC7B,GAAyB6B,GAAgBkzB;QACvC,IAAc,SAAVlzB,GACF,OAAO;YAAE4gB,WAAW;;QACf,IAAqB,mBAAV5gB,GAChB,OAAO3B,KAAKkS,cAAoBvQ;QAC3B,IAAqB,oBAAVA,GAChB,OAAO;YAAE2K,cAAc3K;;QAClB,IAAqB,mBAAVA,GAChB,OAAO;YAAEgK,aAAahK;;QACjB,IAAIA,aAAiBgC,MAAM;YAChC,MAAMa,IAAYjB,EAAU+yB,SAAS30B;YACrC,OAAO;gBAAE6K,gBAAgBxM,KAAKkS,aAAuB1N;;;QAChD,IAAI7C,aAAiB4B,GAAW;;;;YAIrC,MAAMiB,IAAY,IAAIjB,EACpB5B,EAAM6B,SACiC,MAAvCQ,KAAKC,MAAMtC,EAAM8B,cAAc;YAEjC,OAAO;gBAAE+I,gBAAgBxM,KAAKkS,aAAuB1N;;;QAChD,IAAI7C,aAAiB2yB,IAC1B,OAAO;YACLtnB,eAAe;gBACbC,UAAUtL,EAAMsL;gBAChBC,WAAWvL,EAAMuL;;;QAGhB,IAAIvL,aAAiBoxB,IAC1B,OAAO;YAAEwD,YAAYv2B,KAAKkS,cAAmBvQ;;QACxC,IAAIA,iBACT,OAAO;YACLmL,gBAAgB9M,KAAKkS,cACnBvQ,EAAMkG,IAAIvB,MACV3E;;QAIJ,MAAMkzB,KACJ,4BAA4BpD,GAAiB9vB;;IAKnD7B,GACE40B,GACA/iB;QAEA,OAAOA,EAAS9K,IAAI,CAACmL,GAAStM;;;;YAI5B,MAAMmvB,IAAU,0BAEdH,GACA/tB;YAEF,OAAO3G,QAAegS,GAAS6iB;;;;;;;;;;;GAYrC,aAA6BjD;IAC3B,SACmB,mBAAVA,KACG,SAAVA,KACEA,aAAiBJ,SACjBI,aAAiBjuB,QACjBiuB,aAAiBruB,KACjBquB,aAAiB0C,MACjB1C,aAAiBmB,MACjBnB,mBACAA;;;AAIN,YACErwB,GACAszB,GACAjD;IAEA,KAAKmE,GAAoBnE,OAAWM,GAAcN,IAAQ;QACxD,MAAMO,IAAcV,GAAiBG;QACrC,MAAoB,gBAAhBO,IAEI0C,KAAoBtzB,IAAU,sBAE9BszB,KAAoBtzB,IAAU,MAAM4wB;;;;;;gBAS9CuC,GACApuB;IAEA,IAAIA,iBACF,OAAOA;IACF,IAAoB,mBAATA,GAChB,OAAO+uB,GAAgCX,GAAYpuB;IAGnD,MAAM,IAAIlF,EACRlB,EAAKI,kBACL,YAAYo0B,iCAHE;;;;;;;;;GAepB,aACEA,GACApuB;IAEA;QACE,gBHxtBmCA;YAErC,IADcA,EAAKkwB,cACN,GACX,MAAM,IAAIp1B,EACRlB,EAAKI,kBACL,uBAAuBgG,gCACrB;YAGN;gBACE,OAAO,IAAIK,MAAaL,EAAKE,MAAM;cACnC,OAAO+c;gBACP,MAAM,IAAIniB,EACRlB,EAAKI,kBACL,uBAAuBgG,kCACrB;;SGysBGmwB,CAAuBnwB;MAC9B,OAAOid;QACP,MAAMhiB,IAAUu0B,GAAavS;QAC7B,MAAM,IAAIniB,EACRlB,EAAKI,kBACL,YAAYo0B,iCAA0CnzB;;;;;;;GAS5D,aAAsB+hB;IACpB,OAAOA,aAAiBjiB,QAAQiiB,EAAM/hB,UAAU+hB,EAAM7hB;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ICzxBtD3B;;;;IAImB42B;;;;IAIArN;;;;;;IAMAsN,IApCoB;;;;UAyCpBC,IAvCU;;;;;UA6CVC,IA1CgB;yEAYnC72B,UAAgC,GAChCA,UAAuD;;QAEvDA,UAA0B2D,KAAKC,OA6B7B5D,KAAK82B;;;;;;;;WAUPh3B;QACEE,UAAqB;;;;;WAOvBF;QACEE,UAAqBA;;;;;;WAQvBF,GAAcoY;;QAEZlY,KAAKisB;;;QAIL,MAAM8K,IAA2B/yB,KAAKC,MACpCjE,UAAqBA,YAIjBg3B,IAAehzB,KAAKglB,IAAI,GAAGrlB,KAAKC,QAAQ5D,UAGxCi3B,IAAmBjzB,KAAKglB,IAC5B,GACA+N;;gBAGE/2B,UAAqB,KACvBye,GAtGU,sBAwGR,mBAAmBwY,UACjB,gBAAgBj3B,iBAChB,sBAAsB+2B,WACtB,iBAAiBC;QAIvBh3B,UAAoBA,WAClBA,YAEA,OACEA,UAAuB2D,KAAKC,OACrBsU;;;QAMXlY,WAAsBA,SAClBA,UAAqBA,YACvBA,UAAqBA,UAEnBA,UAAqBA,YACvBA,UAAqBA;;IAIzBF;QAC4B,SAAtBE,YACFA,QAAkBisB,UAClBjsB,UAAoB;;sFAKxBF;QACE,QAAQkE,KAAK6f,WAAW,MAAO7jB;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ICWjCF,YACU42B,GACRQ,GACQC,GACEC,GACFC,GACE/P;4DAAAtnB,gBAAAsnB,GAnBJtnB;;;;;;QAMRA,UAAqB,GAErBA,UAAoD,MAC5CA,cAA+C,MAYrDA,UAAe;;;;;;;;WAUjBF;QACE,4BACEE,KAAKgd,0BACLhd,KAAKgd,6BACLhd,KAAKgd;;;;;WAQTld;QACE,wBAAOE,KAAKgd;;;;;;;;WAUdld;0BACME,KAAKgd,QASThd,KAAKkC,SARHlC;;;;;;;WAiBJF;QACME,mBACIA,KAAKs3B;;;;;;;;;WAYfx3B;QAMEE,KAAKgd,0BACLhd,QAAa82B;;;;;;;;;;;WAafh3B;;;QAGME,aAAoC,SAAnBA,YACnBA,UAAiBA,WACfA,SAvJgB,KAyJhB,MAAMA;;wDAMZF,GAAsBkjB;QACpBhjB,WACAA,KAAKu3B,OAAQC,KAAKxU;;uFAIZljB;QACN,IAAIE;;;QAGF,OAAOA,KAAKs3B;;gDAKhBx3B;QACME,YACFA,QAAeisB,UACfjsB,UAAiB;;;;;;;;;;;;;;WAiBbF,YACN23B,GACAnU;;QASAtjB,WACAA,QAAaisB;;;QAIbjsB,6BAEIy3B;;QAEFz3B,QAAa82B,UACJxT,KAASA,EAAMhiB,SAASpB,EAAKU;;QAEtCsZ,GAASoJ,EAAM7hB,aACfyY,GACE;QAEFla,gBACSsjB,KAASA,EAAMhiB,SAASpB,EAAKS;;;QAGtCX;;QAIkB,SAAhBA,KAAKu3B,WACPv3B,WACAA,KAAKu3B,OAAOD,SACZt3B,KAAKu3B,SAAS;;;QAKhBv3B,KAAKgd;;cAGChd,KAAKsnB,YAAiBhE;;;;;WAO9BxjB;IAiBQA;QAMNE,KAAKgd;QAEL,MAAM0a,IAAsB13B,QAA+BA,UAGrD23B,IAAa33B;;gBAEnBA,QAAyB0C,WAAWH,KAClCq1B;;;;;YAKM53B;;;;YAIFA,QAAiB43B;WAGpBtU;YACCoU,EAAoB;gBAClB,MAAMG,IAAW,IAAIz2B,EACnBlB,EAAKG,SACL,iCAAiCijB,EAAM/hB;gBAEzC,OAAOvB;;;;IAMfF,GAAoB83B;QAMlB,MAAMF,IAAsB13B,QAA+BA;QAE3DA,KAAKu3B,SAASv3B,QAAc43B,IAC5B53B,KAAKu3B,UAAc;YACjBG,EAAoB,OAKlB13B,KAAKgd,uBACEhd,KAAKsnB;YAGhBtnB,KAAKu3B,UAAgBjU;YACnBoU,EAAoB,MACX13B,QAAuBsjB;YAGlCtjB,KAAKu3B,OAAOO,UAAW9U;YACrB0U,EAAoB,MACX13B,KAAK83B,UAAU9U;;;IAK5BljB;QAKEE,KAAKgd,0BAELhd,WAA2B0wB;YAMzB1wB,KAAKgd,0BACLhd,KAAKuJ;;;;IAMTzJ,GAAkBwjB;;;;;QAahB,OARA7E,GAzbY,oBAybM,qBAAqB6E,MAEvCtjB,KAAKu3B,SAAS,MAMPv3B,KAAKs3B,sBAAmChU;;;;;;;WASjDxjB,GACEi4B;QAEA,OAAQnyB;YACN5F,WAA4B,MACtBA,gBACK4F,OAEP6Y,GAldM,oBAodJ;YAEK5c,QAAQC;;;;;;;;;;;qBA0BmBk2B;IAK1Cl4B,YACE42B,GACAU,GACAa,GACQ/lB,GACRoV;QAEA9lB,mIAKEy2B,GACA3Q;QATMtnB,kBAAAkS;;IAaVpS,GACE83B;QAEA,OAAO53B,WACL,UACA43B;;IAIM93B,UAAUo4B;;QAElBl4B,QAAa82B;QAEb,MAAM/Y,IAAc/d,KAAKkS,kBACnBimB,IAAWn4B,KAAKkS;QAGtB,OAAOlS,KAAKsnB,eAAqC6Q;;;;;;;WASnDr4B,GAAMme;QACJ,MAAMma,IAAyB;QAC/BA,EAAQjnB,WAAWnR,KAAKkS,eACxBkmB,EAAQC,YAAYr4B,KAAKkS;QAEzB,MAAMomB,IAASt4B,KAAKkS;QAChBomB,MACFF,EAAQE,SAASA,IAGnBt4B,QAAiBo4B;;;;;WAOnBt4B,GAAQiK;QACN,MAAMquB,IAAyB;QAC/BA,EAAQjnB,WAAWnR,KAAKkS,eACxBkmB,EAAQva,eAAe9T,GACvB/J,QAAiBo4B;;;;;;;;;;;;;;;;;;;;qBAuCsBJ;IAOzCl4B,YACE42B,GACAU,GACAa,GACQ/lB,GACRoV;QAEA9lB,+HAKEy2B,GACA3Q;QATMtnB,kBAAAkS,GANVlS,WAA6B;;;;;;;;;QA2B7BA,uBAA8BwL;;;;;WAM9B+sB;QACE,OAAOv4B;;;IAITF;QACEE,WAA0B,GAC1BwB,MAAM+H;;IAGRzJ;QACME,WACFA,QAAoB;;IAIxBF,GACE83B;QAEA,OAAO53B,WACL,SACA43B;;IAIM93B,UAAU04B;QAQlB;;QANA51B,KACI41B,EAAclT,aAChB,gDAEFtlB,KAAKy4B,kBAAkBz4B,KAAKkS,cAAqBsmB,EAAclT;QAE1DtlB,SAQE;;;;YAILA,QAAa82B;YAEb,MAAMtR,IAAUxlB,KAAKkS,cACnBsmB,EAAcE,cACdF,EAAc9X,aAEV2E,IAAgBrlB,KAAKkS,WAAWsN,YACpCgZ,EAAyB;YAE3B,OAAOx4B,KAAKsnB,eAA0C9B;;;QAdtD,OALA5iB,IACG41B,EAAcE,gBAAsD,MAAtCF,EAAcE,aAAa5zB,QAC1D;QAEF9E,WAA0B,GACnBA,KAAKsnB;;;;;;WAuBhBxnB;;;QAKE,MAAMs4B,IAAwB;QAC9BA,EAAQjnB,WAAWnR,KAAKkS,eACxBlS,QAAiBo4B;;4EAInBt4B,GAAe8kB;QAWb,MAAMwT,IAAwB;YAC5B9S,aAAatlB,KAAKkS,cAAmBlS,KAAKy4B;YAC1CE,QAAQ/T,EAAU/d,IAAIsZ,KAAYngB,KAAKkS;;QAGzClS,QAAiBo4B;;;;;;;;;;;;;;;;;;;;;;;;;IC5sBnBt4B,YACU42B,GACAU,GACAa,GACA/lB;kCADAlS,mBAAAi4B,GACAj4B,kBAAAkS;;IAGVpS,GACEwnB;QAEA,OAAO,OACLtnB,SACAA,SACAA,KAAKi4B,aACLj4B,KAAKkS,YACLoV;;IAIJxnB,GACEwnB;QAEA,OAAO,OACLtnB,SACAA,SACAA,KAAKi4B,aACLj4B,KAAKkS,YACLoV;;IAIJxnB,OAAO8kB;QACL,MAAMyH,IAAwB;YAC5Blb,UAAUnR,KAAKkS;YACfymB,QAAQ/T,EAAU/d,IAAIqe,KAAKllB,KAAKkS;;QAElC,OAAOlS,QACL,aAEAuC,KAAKq2B,KACE54B,KAAKkS,cACV0mB,EAASF,cACTE,EAASlY;;IAKf5gB,GAAO4P;QACL,MAAM2c,IAAmC;YACvClb,UAAUnR,KAAKkS;YACf6J,WAAWrM,EAAK7I,IAAIsB,KAAKnI,KAAKkS,cAAkB/J;;QAElD,OAAOnI,QAGL,wBAA6BuC,KAAKq2B;YAClC,IAAIpd,IAAOlB;YACXse,EAASvzB,QAAQwP;gBACf,MAAMR,IAAMrU,KAAKkS,cAA6B2C;gBAC9C2G,IAAOA,KAAYnH,EAAIxM,KAAKwM;;YAE9B,MAAM5L,IAA0B;YAMhC,OALAiH,EAAKrK,QAAQwC;gBACX,MAAMwM,IAAMmH,EAAKlZ,IAAIuF;gBACrBjF,KAAayR,GAAK,0CAA0CxM,IAC5DY,EAAOlD,KAAK8O;gBAEP5L;;;+DAKX3I,GAA6B+4B,GAAiBT;QAC5C,OAAOp4B,KAAKi4B,YACTv1B,WACAH,KAAKq1B,KACG53B,cAA8Co4B,GAASR,IAE/DnO,MAAOnG;YAIN,MAHIA,EAAMhiB,SAASpB,EAAKS,mBACtBX,KAAKi4B,iBAED3U;;;qFAKZxjB,GACE+4B,GACAT;QAEA,OAAOp4B,KAAKi4B,YACTv1B,WACAH,KAAKq1B,KACG53B,cAELo4B,GACAR,IAGHnO,MAAOnG;YAIN,MAHIA,EAAMhiB,SAASpB,EAAKS,mBACtBX,KAAKi4B,iBAED3U;;;;;;;;;;;;;;;;;;;;;;;;UCvHDwV;IAoBXh5B,YAAoBi5B;;;QAlBpB/4B,UAAuB0lB,MACf1lB,iBAAwB,IAChCA,WAAoB;;;;;QAMpBA,UAAgD;;;;;;;QAQhDA,UAAwC,IAAIg5B;;IAI5Cl5B,SAAa4P;QAGX,IAFA1P,WAEIA,KAAK4kB,UAAU9f,SAAS,GAC1B,MAAM,IAAI1D,EACRlB,EAAKI,kBACL;QAGJ,MAAMkb,UAAaxb,WAAsB0P;QAQzC,OAPA8L,EAAKnW,QAAQgP;YACPA,mBAA6BA,aAAef,KAC9CtT,QAAmBqU,KAEnBrP,GAAK,qCAAqCqP,EAAIke,YAAY7wB;YAGvD8Z;;IAGT1b,IAAI+H,GAAkBqB;QACpBlJ,KAAKi5B,MAAM/vB,KAAiBrB,GAAK7H,QAAkB6H,MACnD7H,QAAiByJ,IAAI5B;;IAGvB/H,OAAO+H,GAAkBqB;QACvB;YACElJ,KAAKi5B,MAAM/vB,KAAiBrB,GAAK7H,QAA2B6H;UAC5D,OAAO0b;YACPvjB,UAAsBujB;;QAExBvjB,QAAiByJ,IAAI5B;;IAGvB/H,OAAO+H;QACL7H,KAAKi5B,MAAM,EAAC,OAAmBpxB,GAAK7H,QAAkB6H,QACtD7H,QAAiByJ,IAAI5B;;IAGvB/H;QAGE,IAFAE,WAEIA,SACF,MAAMA;QAER,IAAIk5B,IAAYl5B;;gBAEhBA,KAAK4kB,UAAUvf,QAAQ8a;YACrB+Y,IAAYA,EAAUpxB,OAAOqY,EAAStY;;;;QAIxCqxB,EAAU7zB,QAAQ,CAACwC,GAAKsxB;YACtBn5B,KAAK4kB,UAAUrf,KAAK,OAAmBsC,GAAK7H,QAAkB6H;kBAE1D7H,QAAeo5B,OAAOp5B,KAAK4kB,YACjC5kB,WAAiB;;IAGnBF,GAAsBuU;QACpB,IAAIglB;QAEJ,IAAIhlB,aAAef,IACjB+lB,IAAahlB,EAAItB,cACZ;YAAA,MAAIsB,kBAIT,MAAMrP,GAAK,qCAAqCqP,EAAIke,YAAY7wB;;YAFhE23B,IAAa50B;;QAKf,MAAM60B,IAAkBt5B,QAAkBsC,IAAI+R,EAAIxM;QAClD,IAAwB,SAApByxB;YACF,KAAKD,EAAW10B;;YAEd,MAAM,IAAIvD,EACRlB,EAAKY,SACL;eAIJd,UAAoBA,WAAyBqU,EAAIxM;;;;;WAQrD/H,GAAqB+H;QACnB,MAAMkL,IAAU/S,QAAkBsC,IAAIuF;QACtC,QAAK7H,QAAiBwJ,IAAI3B,MAAQkL,IACzBE,GAAaC,WAAWH,KAExBE,GAAauN;;;;WAOxB1gB,GAA8B+H;QAC5B,MAAMkL,IAAU/S,QAAkBsC,IAAIuF;;;gBAGtC,KAAK7H,QAAiBwJ,IAAI3B,MAAQkL,GAAS;YACzC,IAAIA,EAAQpO,QAAQF;;;;;;;;;;YAYlB,MAAM,IAAIrD,EACRlB,EAAKI,kBACL;;wBAIJ,OAAO2S,GAAaC,WAAWH;;;;QAI/B,OAAOE,GAAaE,QAAO;;IAIvBrT,MAAM8kB;QACZ5kB,WACAA,KAAK4kB,YAAY5kB,KAAK4kB,UAAUjN,OAAOiN;;IAGzC9kB;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ICzHAA,YACUspB,GACAmQ;;;QAzBFv5B;;;;;;QAORA,UAA8B;;;;;;QAO9BA,UAA2D;;;;;;QAO3DA,WAAoC;;;;;;;;WAcpCF;QACmC,MAA7BE,YACFA,kCAMAA,UAAwBA,6DA1DE,KA6DxB,OACEA,UAAwB;QAKxBA,QACE,8CAGFA;QAMO6B,QAAQC;;;;;;;WAYvBhC,GAAyBwjB;kCACnBtjB,KAAKgd,QACPhd,oCAaAA;QACIA,WA/GwB,MAgH1BA,WAEAA,QACE,yBACE,6BAA6BsjB,EAAM7hB;QAGvCzB;;;;;;;;WAYNF,IAAI05B;QACFx5B,WACAA,UAA2B,6BAEvBw5B;;;QAGFx5B,WAAiC,IAGnCA;;IAGFF,GAAwB05B;QAClBA,MAAax5B,KAAKgd,UACpBhd,KAAKgd,WACLhd;;IAIJF,GAA2C25B;QACzC,MAAMl4B,IACJ,4CAA4Ck4B,QAC5C;QAGEz5B,WACFka,GAAS3Y,IACTvB,WAAiC,KAEjCye,GAxKU,sBAwKQld;;IAItBzB;QACgC,SAA1BE,YACFA,QAAsBisB,UACtBjsB,UAAwB;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IC5E5BF;;;;IAIUksB;;IAEA+M,GACR3P,GACAmQ,GACAG;;;;;;;;;;;;;;;;;;;QArCF15B,UAAyC;;;;;;;;;;QAWzCA,UAAwB,IAAIoV,KAK5BpV,UAA8D;;;;;QAMtDA,uBAAiB,GAEjBA,kBAAY,GAelBA,aACAA,WAAsC8e;YACpCsK,KAA4BsH;gBACtB1wB,cACFye,GArFM,eAuFJ;sBAEIze;;YAKZA,UAA0B;;QAM1BA,UAAmBA,WAAwC;YACzD25B,IAAQ35B,QAAuBwpB,KAAKxpB;YACpC45B,IAAS55B,QAAwBwpB,KAAKxpB;YACtC65B,IAAe75B,QAAyBwpB,KAAKxpB;YAG/CA,UAAmBA,WAAwC;YACzD25B,IAAQ35B,QAAuBwpB,KAAKxpB;YACpC45B,IAAS55B,QAAwBwpB,KAAKxpB;YACtC85B,IAAqB95B,QAA8BwpB,KAAKxpB;YACxD+5B,IAAkB/5B,QAAsBwpB,KAAKxpB;;;;;;WAcjDF;QACE,OAAOE,KAAKg6B;;kDAIdl6B;QACEE,KAAKmwB,kBAAiB,GAElBnwB,cACFA,QAAiBy4B,wBAAwBz4B;QAErCA,YACFA,YAEAA,QAAwBkU;;cAIpBlU;;;;;WAQVF;QACEE,KAAKmwB,kBAAiB,SAChBnwB;;QAGNA,QAAwBkU;;IAGlBpU;cACAE,QAAiBi6B,cACjBj6B,QAAiBi6B,QAEnBj6B,QAAmB8E,SAAS,MAC9B2Z,GAnKU,eAqKR,8BAA8Bze,QAAmB8E;QAEnD9E,UAAqB,KAGvBA;;IAGFF;QACE2e,GA9KY,eA8KM,+BAClBze,KAAKmwB,kBAAiB,SAChBnwB;QACNA;;;QAIAA,QAAwBkU;;;;;WAO1BpU,OAAOme;QACDje,QAAmBwJ,IAAIyU,EAAWlU;;QAKtC/J,QAAmBkU,IAAI+J,EAAWlU,cAE9B/J;;QAEFA,YACSA,gBACTA;;;;;WAQJF,GAASiK;QAMP/J,QAAmBmU,OAAOpK,IACtB/J,gBACFA,QAAwB+J,IAGM,MAA5B/J,QAAmBwF,SACjBxF,eACFA,eACSA;;;;QAITA,QAAwBkU;;oEAM9BpU,GAAuBiK;QACrB,OAAO/J,QAAmBsC,IAAIyH,MAAa;;oEAI7CjK,GAAuBiK;QACrB,OAAO/J,WAAuC+J;;;;;WAOhDjK,GAAyBme;QACvBje,WAAuDie,EAAWlU,WAClE/J;;;;;;WAQFF,GAA2BiK;QACzB/J,WAAuD+J,IACvD/J,WAAyB+J;;IAG3BjK;QAMEE,UAA6B,OAA0BA,OACvDA,QAAiBuJ,SACjBvJ;;;;;WAOFF;QACE,OACEE,cACCA,gBACDA,QAAmBwF,OAAO;;IAI9B1F;QACE,OAAOE,KAAKk6B,aAAal6B,KAAKmwB;;IAGhCrwB;QACEE,UAA6B;;IAGvBF;QACNE,QAAmBqF,QAAQ,CAAC4Y,GAAYlU;YACtC/J;;;IAIIF,SAAyBwjB;QAU/BtjB;;QAGIA,aACFA,eAEAA;;;;QAKAA,QAAwBkU;;IAIpBpU,SACNie,GACAjE;QAKA;;QAFA9Z,QAAwBkU,4BAGtB6J,uCACAA,EAAYf,SACZe,EAAYb;;;QAIZ,OAAOld;QAeT,IAZI+d,kBACF/d,gBACS+d,kBACT/d,gBAMAA;SAGG8Z,EAAgBnV,QAAQF,EAAgBC,MAAM;YACjD,MAAM6qB,UAAkCvvB;YACpC8Z,IAA0ByV,MAA8B;;;kBAGpDvvB;;;;;;;WAUZF,GAA2Bga;QAKzB,MAAMsE,IAAcpe;;;;QAwDpB,OAlDAoe,KAA0B/Y,QAAQ,CAAC8V,GAAQpR;YACzC,IAAIoR,EAAOnB,mBAAoC,GAAG;gBAChD,MAAMiE,IAAaje,QAAmBsC,IAAIyH;;qCAGxC/J,QAAmBkU,IACjBnK,GACAkU,KAA2B9C,EAAOnB;;;;;QAQ1CoE,KAA6B/Y,QAAQ0E;YACnC,MAAMkU,IAAaje,QAAmBsC,IAAIyH;YAC1C;;YAEE;;;wBAKF/J,QAAmBkU,IACjBnK,GACAkU,KACEzS,MACAyS;;;YAMJje,QAAwB+J;;;;;YAMxB,MAAMowB,IAAoB,OACxBlc,EAAWtE,QACX5P,qCAEAkU,EAAWpE;YAEb7Z;YAIKA;;2CAITF,GAA0Bie;QAExB,MAAMuF,IAAQvF,EAAkB;QAChC,IAAIsS,IAAexuB,QAAQC;QAW3B,OAVAic,EAAYd,UAAU5X,QAAQ0E;YAC5BsmB,IAAeA,EAAa9tB,KAAKmuB;;gBAE/B,IAAI1wB,QAAmBwJ,IAAIO,IAGzB,OAFA/J,QAAmBmU,OAAOpK,IAC1B/J,QAA4B6d,aAAa9T,IAClC/J,WAA6B+J,GAAUuZ;;;;;;;;;;;WAetDxjB;QACE,IAAIE,WAA8B;YAChC,MAAMo6B,IACJp6B,QAAmB8E,SAAS,IACxB9E,QAAmBA,QAAmB8E,SAAS,GAAG4f,WxB/d/B,GwBienBU,UAAcplB;YAIN,SAAVolB,IACgC,MAA9BplB,QAAmB8E,UACrB9E,gBAGFA,QAAwBolB,UAClBplB;;QAINA,aACFA;;;;;WAQJF;QACE,OACEE,aAAwBA,QAAmB8E,SApetB;;;IAyezBhF;QACE,OAAOE,QAAmB8E;;;;;WAO5BhF,GAA2BslB;QAKzBplB,QAAmBuF,KAAK6f,IAEpBplB,gBAA6BA,cAC/BA,WAAgColB,EAAMR;;IAI1C9kB;QACE,OACEE,cACCA,gBACDA,QAAmB8E,SAAS;;IAIhChF;QAKEE,QAAiBuJ;;IAGXzJ;QACNE;;IAGFF;;QAEE,OAAOE,WACeA,QAAiBy4B,iBACpCl2B,KAAK;;YAEJ,KAAK,MAAM6iB,KAASplB,SAClBA,WAAgColB,EAAMR;WAGzC6E;;IAGL3pB,GACEulB,GACAG;QAQA,MAAMJ,IAAQplB,QAAmBq6B,SAC3BC,IAAUC,GAAoBnZ,KAClCgE,MAEAI,GACAxlB,QAAiBy4B;QAEnB,OAAOz4B,cAA8CuC,KAAK,MAGjDvC;;IAIHF,SAAyBwjB;;;QAY/B,IAAIA,KAAStjB,QAAmB8E,SAAS,GAAG;;YAE1C,IAAI01B;;YAWJ,OAREA,IAFEx6B,aAEcA,aAKAA,YAGXw6B,EAAcj4B,KAAK;;;gBAGpBvC,aACFA;;;;;IAOAF,SAA2BwjB;;;;QAIjC,IAAImX,GAAiBnX,EAAMhiB,OAQzB,OAPAmd,GAlmBU,eAomBR,0EACAze,QAAiBy4B;QAEnBz4B,QAAiBy4B,kBAAkBjtB,MAE5BxL,WACewL,MACnBie;;IAOC3pB,SAAuBwjB;;;QAG7B,IrCpkBKmX,GAD6Bn5B,IqCqkBRgiB,EAAMhiB,SrCpkBDA,MAASpB,EAAKY,SqCokBN;;;YAGrC,MAAMskB,IAAQplB,QAAmBq6B;;;;wBAOjC,OAFAr6B,cAEOA,WACcolB,EAAMV,SAASpB,GACjC/gB,KAAK,MAGGvC;;YrCplBqBsB;;;;;;;IqC2lBpCxB;QACE,OAAO,IAAIg5B,GAAY94B;;IAGjBF;QACNE,KAAKmwB,kBAAiB,SAChBnwB,WACNA,QAAwBkU;cAClBlU,KAAKg6B;;IAGbl6B;QACME;;;;QAIFye,GA3pBU,eA2pBQ,4DACZze;;;;WAOVF,SAAwBo6B;QACtBl6B,KAAKk6B,YAAYA,GAEbA,KAAal6B,KAAKmwB,uBACdnwB,KAAKg6B,kBACDE,YACJl6B;QACNA,QAAwBkU;;;;;;;;;;;;;;;;;;;;;;;SCnsBdwmB,GACd1W,GACA2W;IAOA,OAAO,qBAA8B3W,KAAkB2W;;;;;;;;;;;SAuBzCC,GACd5W,GACApiB,GACA8iB;IAEA,IAAImW,IAAc,uBAAgC7W,KAAkBU;IAMpE,OAJI9iB,UACFi5B,KAAe,IAAIj5B,EAAK7B;;;;;;SAsBZ+6B,GACd9W,GACAja;IAEA,OAAO,qBAA8Bia,KAAkBja;;;;;;;;;;;;ICyFvDjK,YACW8B,GACA8iB,GACA1H,GACAsG;QAHAtjB,YAAA4B,GACA5B,eAAA0kB,GACA1kB,aAAAgd,GACAhd,aAAAsjB;;;;;WAYXxjB,UACE8B,GACA8iB,GACA/iB;QAEA,MAAMo5B,IAAgB7uB,KAAK8uB,MAAMr5B;QAEjC,IAAIs5B,IACuB,yBAEtB,MADH,EAAC,WAAW,gBAAgB,aAAY10B,QAAQw0B,EAAc/d,gBAErCjY,MAAxBg2B,EAAczX,SACkB,mBAAxByX,EAAczX,QAErB4X,SAA6Cn2B;QAcjD,OAZIk2B,KAAaF,EAAczX,UAC7B2X,IACyC,mBAAhCF,EAAczX,MAAM/hB,WACS,mBAA7Bw5B,EAAczX,MAAMhiB;cAE3B45B,IAAiB,IAAI95B,EACnB25B,EAAczX,MAAMhiB,MACpBy5B,EAAczX,MAAM/hB,gBAMjB,OACLK,GACA8iB,GACAqW,EAAc/d,aAIhB9C,GArLU,qBAuLR,0CAA0CwK,OAAa/iB;QAElD;;IAIX7B;QACE,MAAMq7B,IAAwC;YAC5Cne,OAAOhd,KAAKgd;YACZoe,cAAcz3B,KAAKC;;QAUrB,OAPI5D,KAAKsjB,UACP6X,EAAc7X,QAAQ;YACpBhiB,MAAMtB,KAAKsjB,MAAMhiB;YACjBC,SAASvB,KAAKsjB,MAAM/hB;YAIjB2K,KAAKC;;;;;;;;;;IAUdrM,YACWiK,GACAiT,GACAsG;QAFAtjB,gBAAA+J,GACA/J,aAAAgd,GACAhd,aAAAsjB;;;;;WAYXxjB,UACEiK,GACApI;QAEA,MAAMic,IAAc1R,KAAK8uB,MAAMr5B;QAE/B,IAAIs5B,IACqB,yBAEpB,MADH,EAAC,eAAe,WAAW,aAAY10B,QAAQqX,EAAYZ,gBAEpCjY,MAAtB6Y,EAAY0F,SACkB,mBAAtB1F,EAAY0F,QAEnB4X,SAA6Cn2B;QAcjD,OAZIk2B,KAAard,EAAY0F,UAC3B2X,IACuC,mBAA9Brd,EAAY0F,MAAM/hB,WACS,mBAA3Bqc,EAAY0F,MAAMhiB;cAEzB45B,IAAiB,IAAI95B,EACnBwc,EAAY0F,MAAMhiB,MAClBsc,EAAY0F,MAAM/hB,gBAMf,OACLwI,GACA6T,EAAYZ,aAId9C,GArQU,qBAuQR,wCAAwCnQ,OAAcpI;QAEjD;;IAIX7B;QACE,MAAM8d,IAAsC;YAC1CZ,OAAOhd,KAAKgd;YACZoe,cAAcz3B,KAAKC;;QAUrB,OAPI5D,KAAKsjB,UACP1F,EAAY0F,QAAQ;YAClBhiB,MAAMtB,KAAKsjB,MAAMhiB;YACjBC,SAASvB,KAAKsjB,MAAM/hB;YAIjB2K,KAAKC;;;;;;;GAiBhB;IACErM,YACW66B,GACAjO;QADA1sB,gBAAA26B,GACA36B,uBAAA0sB;;;;;WAOX5sB,UACE66B,GACAh5B;QAEA,MAAM05B,IAAcnvB,KAAK8uB,MAAMr5B;QAE/B,IAAIs5B,IACqB,wBACvBI,EAAY3O,2BAA2B8E,OAErC8J,IAAqB/e;QAEzB,KAAK,IAAI7W,IAAI,GAAGu1B,KAAav1B,IAAI21B,EAAY3O,gBAAgB5nB,aAC3Dm2B,IAAY/vB,EAAcmwB,EAAY3O;QACtC4O,IAAqBA,EAAmB7xB,IACtC4xB,EAAY3O;QAIhB,WACS,OAAsBiO,SAE7BzgB,GA3UU,qBA6UR,6CAA6CygB,OAAch5B;QAEtD;;;;;;;;;IAWX7B,YAAqB66B,GAA2BY;QAA3Bv7B,gBAAA26B,GAA2B36B,mBAAAu7B;;;;;WAMhDz7B,UAA2B6B;QACzB,MAAM45B,IAAcrvB,KAAK8uB,MAAMr5B;QAQ/B,OALyB,mBAAhB45B,MAEJ,MADH,EAAC,WAAW,UAAU,YAAWh1B,QAAQg1B,EAAYA,gBAErB,mBAAzBA,EAAYZ,WAGZ,OACLY,EAAYZ,UACZY,EAAYA,gBAGdrhB,GA/WU,qBA+WQ,iCAAiCvY;QAC5C;;;;;;;;;;;;;;;;IAgBb7B;QACEE,uBAAkBuc;;IAElBzc,GAAeiK;QACb/J,KAAK0sB,kBAAkB1sB,KAAK0sB,gBAAgBjjB,IAAIM;;IAGlDjK,GAAkBiK;QAChB/J,KAAK0sB,kBAAkB1sB,KAAK0sB,gBAAgBvY,OAAOpK;;;;;WAOrDjK;QACE,MAAMoJ,IAA0B;YAC9BwjB,iBAAiB1sB,KAAK0sB;YACtB0O,cAAcz3B,KAAKC;;QAErB,OAAOsI,KAAKC,UAAUjD;;;;;;;;;IAkCxBpJ,YACmB42B,GACAhU,GACAsB,GACAwX,GACjB/N;QAEA,iBALiBztB,gBAAA0iB,GACA1iB,sBAAAgkB,gBA3BnBhkB,UAA6C;QAC7CA,UAAkE,MAClEA,UAEW,MAKXA,UAAiE,IACjEA,UAAmCA,QAA2BwpB,KAAKxpB,OAKnEA,WAAkB;;;;;QAOlBA,UAAsC,KAS/By7B,MAAwCz7B,KAAK0iB,WAChD,MAAM,IAAIthB,EACRlB,EAAKc,eACL;;;gBAKJ,MAAM06B,IAAwB1X,EAAejd,QAC3C,uBACA;QAGF/G,KAAK27B,UAAU37B,KAAK0iB,SAASkZ,OAAQC,cACrC77B,KAAKiC,iBACLjC,UAA6B06B,GAC3B16B,KAAKgkB,gBACLhkB;QAEFA;;iBD7XFgkB;YAEA,OAAO,6BAAiCA;;;;;;;;;;;;;;;;;GC2Xb8X,EACvB97B,KAAKgkB,iBAEPhkB,QAAmBA,WAAsB,QAEzCA,UAAwB,IAAIgM,OAC1B,sBAA+B0vB;QAEjC17B,UAA0B,IAAIgM,OAC5B,wBAAiC0vB,wBAEnC17B,UAAwB,IAAIgM,OAC1B,sBAA+B0vB;QAGjC17B;;iBDpa2CgkB;YAC7C,OAAO,0BAA8BA;;;uECmab+X;SAA+B/7B,KAAKgkB;;;;;;;QAQ1DhkB,KAAK0iB,SAASkZ,OAAQI,iBAAiB,WAAWh8B;;oFAIpDF,UAAmB4iB;QACjB,UAAUA,EAASkZ,UAA0C,QAAhClZ,EAASkZ,OAAOC;;IAG/C/7B;;;QAaE,MAAMm8B,UAAwBj8B;QAE9B,KAAK,MAAM26B,QAA6B;YACtC,IAAIA,MAAa36B,SACf;YAGF,MAAMk8B,IAAcl8B,KAAKm8B,QACvBzB,GAA+B16B,KAAKgkB,gBAAgB2W;YAEtD,OAAiB;gBACf,MAAMU,IAAce,MAClBzB;sBAIA36B,QAAmBq7B,EAAYV;;;QAKrC36B;;;QAIA,MAAMq8B,IAAkBr8B,KAAK27B,QAAQQ,QAAQn8B;QAC7C,OAAqB;YACnB,MAAMu7B,IAAcv7B;YAChBu7B,KACFv7B,QAA4Bu7B;;QAIhC,KAAK,MAAMe,KAASt8B,SAClBA,QAA2Bs8B;QAG7Bt8B,UAAmB;;;QAInBA,KAAK0iB,SAASkZ,OAAQI,iBAAiB,UAAU,MAAMh8B,YAEvDA,WAAe;;IAGjBF,GAAoB+Z;QAClB7Z,KAAKu8B,QAAQv8B,SAAwBkM,KAAKC,UAAU0N;;IAGtD/Z;QACE,IAAI08B,IAAgBjgB;QAIpB,OAHAlX,EAAQrF,SAAoB,CAAC6H,GAAKlG;YAChC66B,IAAgBA,KAAwB76B,EAAM+qB;;;IAKlD5sB,GAAoBiK;;;QAGlB,KAAK,MAAM4wB,KAAY36B,SACrB,IAAIA,QAAmBoK,eAAeuwB,MAChC36B,QAAmB26B,GAAUjO,gBAAgBljB,IAAIO,IACnD,QAAO;QAIb,QAAO;;IAGTjK,GAAmB4kB;QACjB1kB,QAA0B0kB,GAAS;;IAGrC5kB,GACE4kB,GACA1H,GACAsG;QAEAtjB,QAA0B0kB,GAAS1H,GAAOsG;;;;QAK1CtjB,QAAyB0kB;;IAG3B5kB,GAAoBiK;QAClB,IAAI0yB,IAA+B;;;gBAInC,IAAIz8B,QAAyB+J,IAAW;YACtC,MAAMmyB,IAAcl8B,KAAK27B,QAAQQ,QAC/BrB,GAAuC96B,KAAKgkB,gBAAgBja;YAG9D,OAAiB;gBACf,MAAM2yB,IAAWC,MACf5yB;gBAGE2yB,MACFD,IAAaC,EAAS1f;;;QAQ5B,OAHAhd,WAAqC+J,IACrC/J;;IAKFF,GAAuBiK;QACrB/J,WAAwC+J,IACxC/J;;IAGFF,GAAmBiK;QACjB,OAAO/J,QAAsB0sB,gBAAgBljB,IAAIO;;IAGnDjK,GAAgBiK;QACd/J,KAAK48B,WACH9B,GAAuC96B,KAAKgkB,gBAAgBja;;IAIhEjK,GACEiK,GACAiT,GACAsG;QAEAtjB,QAA6B+J,GAAUiT,GAAOsG;;IAGhDxjB,GACE8B,GACAqsB,GACAC;QAEAD,EAAgB5oB,QAAQqf;YACtB1kB,QAAyB0kB;YAE3B1kB,KAAKiC,cAAcL,GACnBssB,EAAc7oB,QAAQqf;YACpB1kB,QAAwB0kB;;;IAI5B5kB,GAAey7B;QACbv7B,QAAwBu7B;;IAG1Bz7B;QACME,YACFA,KAAK0iB,SAASkZ,OAAQiB,oBACpB,WACA78B,UAEFA,KAAK48B,WAAW58B;QAChBA,WAAe;;IAIXF,QAAQ+H;QACd,MAAMlG,IAAQ3B,KAAK27B,QAAQQ,QAAQt0B;QAEnC,OADA4W,GArqBY,qBAqqBM,QAAQ5W,GAAKlG,IACxBA;;IAGD7B,QAAQ+H,GAAalG;QAC3B8c,GA1qBY,qBA0qBM,OAAO5W,GAAKlG,IAC9B3B,KAAK27B,QAAQY,QAAQ10B,GAAKlG;;IAGpB7B,WAAW+H;QACjB4W,GA/qBY,qBA+qBM,UAAU5W,IAC5B7H,KAAK27B,QAAQiB,WAAW/0B;;IAG1B/H,GAA8Bw8B;QAC5B,IAAIA,EAAMQ,gBAAgB98B,KAAK27B,SAAS;YAGtC,IAFAld,GArrBU,qBAqrBQ,SAAS6d,EAAMz0B,KAAKy0B,EAAMroB,WAExCqoB,EAAMz0B,QAAQ7H,SAKhB,YAJAka,GACE;YAMJla,WAA4B0wB;gBAC1B,IAAK1wB;oBAKL,IAAkB,SAAds8B,EAAMz0B,KAIV,IAAI7H,QAAsB4G,KAAK01B,EAAMz0B,MAAM;wBACzC,IAAsB,QAAlBy0B,EAAMroB,UAWH;4BACL,MAAM0mB,IAAW36B,QAAkCs8B,EAAMz0B;4BACzD,OAAO7H,QAA4B26B,GAAU;;wBAbnB;4BAC1B,MAAMU,IAAcr7B,QAClBs8B,EAAMz0B,KACNy0B,EAAMroB;4BAER,OACE,OAAOjU,QACLq7B,EAAYV;;2BAQb,IAAI36B,QAAwB4G,KAAK01B,EAAMz0B;wBAC5C,IAAuB,SAAnBy0B,EAAMroB,UAAmB;4BAC3B,MAAM8oB,IAAmB/8B,QACvBs8B,EAAMz0B,KACNy0B,EAAMroB;4BAER,OACE,OAAOjU;;2BAGN,IAAIA,QAAsB4G,KAAK01B,EAAMz0B;wBAC1C,IAAuB,SAAnBy0B,EAAMroB,UAAmB;4BAC3B,MAAM+oB,IAAsBh9B,QAC1Bs8B,EAAMz0B,KACNy0B,EAAMroB;4BAER,OACE,OAAOjU;;2BAGN,IAAIs8B,EAAMz0B,QAAQ7H;wBACvB,IAAuB,SAAnBs8B,EAAMroB,UAAmB;4BAC3B,MAAMsnB,IAAcv7B,QAA+Bs8B,EAAMroB;4BACzD,IAAIsnB,GACF,OAAOv7B,QAA4Bu7B;;2BAGlC,IAAIe,EAAMz0B,QAAQ7H,SAAwB;wBAK/C,MAAM6Z,IAiNhB,SACEojB;4BAEA,IAAIpjB,IAAiBqP;4BACrB,IAAiB,QAAb+T,GACF;gCACE,MAAMC,IAAShxB,KAAK8uB;gCACpBp4B,GACoB,sBAClB,sCAEFiX;8BACA,OAAO0J;gCACPrJ,GAv9BU,qBAu9BQ,kDAAkDqJ;;4BAGxE,OAAO1J;;;;;;GAjOwBsjB,EAA6Bb,EAAMroB;wBACtD4F,MAAmBqP,SACrBlpB,QAA4B6Z;;uBA1D9B7Z,QAAiBuF,KAAK+2B;;;;IAiE9Bc;QACE,OAAOp9B,QAAmBA;;IAG5BF;QACEE,KAAKu8B,QACHv8B,SACAA;;IAIJF,GACE4kB,GACA1H,GACAsG;QAEA,MAAM+Z,IAAgB,OACpBr9B,KAAKiC,aACLyiB,GACA1H,GACAsG,IAEIuX,IAAcD,GAClB56B,KAAKgkB,gBACLhkB,KAAKiC,aACLyiB;QAEF1kB,KAAKu8B,WAAqBc;;IAG5Bv9B,GAA4B4kB;QAC1B,MAAMmW,IAAcD,GAClB56B,KAAKgkB,gBACLhkB,KAAKiC,aACLyiB;QAEF1kB,KAAK48B;;IAGP98B,GAA2By7B;QACzB,MAAMvQ,IAAiC;YACrC2P,UAAU36B;YACVu7B,aAAAA;;QAEFv7B,KAAK27B,QAAQY,QAAQv8B,SAAqBkM,KAAKC;;IAGjDrM,GACEiK,GACAiT,GACAsG;QAEA,MAAMga,IAAYxC,GAChB96B,KAAKgkB,gBACLja,IAEIwzB,IAAiB,OAAwBxzB,GAAUiT,GAAOsG;QAChEtjB,KAAKu8B,WAAmBgB;;;;;WAO1Bz9B,GAAqC+H;QACnC,MAAM21B,IAAQx9B,QAAsB0Q,KAAK7I;QACzC,OAAO21B,IAAQA,EAAM,KAAK;;;;;WAO5B19B,GACE+H,GACAlG;QAEA,MAAMg5B,IAAW36B,QAAkC6H;QAEnD,OAAOu0B,MAAsCzB,GAAUh5B;;;;;WAOzD7B,GACE+H,GACAlG;QAEA,MAAM67B,IAAQx9B,QAAwB0Q,KAAK7I,IAGrC6c,IAAUvZ,OAAOqyB,EAAM,KACvBC,SAAsB14B,MAAby4B,EAAM,KAAmBA,EAAM,KAAK;QACnD,OAAOE,MACL,IAAI79B,EAAK49B,IACT/Y,GACA/iB;;;;;WAQJ7B,GACE+H,GACAlG;QAEA,MAAM67B,IAAQx9B,QAAsB0Q,KAAK7I,IAGnCkC,IAAWoB,OAAOqyB,EAAM;QAC9B,OAAOb,MAAwC5yB,GAAUpI;;;;;WAO3D7B,GAAkC6B;QAChC,OAAOg8B,MAAsCh8B;;IAGvC7B,SACNi7B;QAEA,IAAIA,EAAcn5B,KAAK7B,QAAQC,KAAKiC,YAAYlC,KAQhD,OAAOC,WACL+6B,EAAcrW,SACdqW,EAAc/d,OACd+d,EAAczX;QAVd7E,GAn4BU,qBAq4BR,yCAAyCsc,EAAcn5B,KAAK7B;;IAYlED,GACEy9B;QAEA,OAAOv9B,WACLu9B,EAAexzB,UACfwzB,EAAevgB,OACfugB,EAAeja;;IAInBxjB,GACE66B,GACAU;QAEA,MAAMuC,IAAkB59B;YAGtBA,QAAmB26B,gBAEZ36B,QAAmB26B;QAG5B,MAAMkD,IAAa79B,WAEb89B,IAA2B,IAC3BC,IAA6B;QAcnC,OAZAF,EAAWx4B,QAAQqrB,MAAM3mB;YAClB6zB,EAAgBp0B,IAAIO,MACvB+zB,EAAav4B,KAAKwE;YAItB6zB,EAAgBv4B,QAAQqrB,MAAM3mB;YACvB8zB,EAAWr0B,IAAIO,MAClBg0B,EAAex4B,KAAKwE;YAIjB/J;;IAMTF,GAA+By7B;;;;;;QAMzBv7B,QAAmBu7B,EAAYZ,aACjC36B,QAAyBu7B,EAAYA;;;;;IA6B3Cz7B;QACEE,UAAqB,QACrBA,UAA+D,IAE/DA,UAA6C,MAC7CA,UAAkE,MAClEA,UAEW;;IAEXF,GAAmB4kB;;;IAInB5kB,GACE4kB,GACA1H,GACAsG;;;IAKFxjB,GAAoBiK;QAElB,OADA/J,WAA+B+J,IACxB/J,QAAgB+J,MAAa;;IAGtCjK,GACEiK,GACAiT,GACAsG;QAEAtjB,QAAgB+J,KAAYiT;;IAG9Bld,GAAuBiK;QACrB/J,WAAkC+J;;IAGpCjK,GAAmBiK;QACjB,OAAO/J,QAAgB0sB,gBAAgBljB,IAAIO;;IAG7CjK,GAAgBiK;eACP/J,QAAgB+J;;IAGzBjK;QACE,OAAOE,QAAgB0sB;;IAGzB5sB,GAAoBiK;QAClB,OAAO/J,QAAgB0sB,gBAAgBljB,IAAIO;;IAG7CjK;QAEE,OADAE,UAAkB,QACX6B,QAAQC;;IAGjBhC,GACE8B,GACAqsB,GACAC;;;IAKFpuB,GAAey7B;;;IAIfz7B;IAEAA,GAAoB+Z;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IC7jCpB/Z,YAAoBk+B;;;IAEpBl+B;QAEE,OADAE,WApBW,GAqBJA;;IAGTF;;;;;QAKE,OAAO,OAAsB;;IAG/BA;;QAEE,OAAO,QAAsB;;;;;;;;;;;;;;;;;;;;ICd/BA,YAAmB+H;QAAA7H,WAAA6H;;;;;IAGnB/H,YAAmB+H;QAAA7H,WAAA6H;;;;;;;;;IA4CnB/H,YACUyb;;IAEA0iB;QAFAj+B,aAAAub,gBAfVvb,UAAsC;;;;;;;QAOtCA,WAAkB;;QAGlBA,UAAyBwc;;QAEzBxc,UAAsBwc,MAOpBxc,UAAmB,OAAgBub,KAAoBiO,KAAKjO;;;;;WAO9D2iB;QACE,OAAOl+B;;;;;;;;;;;WAaTF,GACE4b,GACAyiB;QAEA,MAAMC,IAAYD,IACdA,OACA,QACEE,IAAiBF,IACnBA,OACAn+B;QACJ,IAAIs+B,IAAiBH,IACjBA,OACAn+B,SACAu+B,OACAC,KAAc;;;;;;;;;QAWlB,MAAMC,IACJz+B,KAAKub,cAA2B8iB,EAAe74B,SAASxF,KAAKub,MAAMnW,QAC/Di5B,EAAenT,SACf,MACAwT,IACJ1+B,KAAKub,cAA0B8iB,EAAe74B,SAASxF,KAAKub,MAAMnW,QAC9Di5B,EAAehuB,UACf;;QAwFN,IAtFAqL,KACE,CAAC7T,GAAkB82B;YACjB,MAAMC,IAASP,EAAe/7B,IAAIuF;YAClC,IAAIiV,IAAS6hB,aAAuBrrB,SAAyB;kBAS3DwJ,IAAS9c,KAAKub,MAAM/C,iBAA2B;YAGjD,MAAMqmB,MAA4BD,KAC9B5+B,QAAiBwJ,IAAIo1B,EAAO/2B,MAE1Bi3B,MAA4BhiB,MAC9BA;;;YAGC9c,QAAiBwJ,IAAIsT,EAAOjV,QAAQiV,EAAOpJ;YAGhD,IAAIqrB,KAAgB;;wBAGpB,IAAIH,QAAkB;gBACFA,EAAO11B,OAAOvE,QAAQmY,EAAO5T,UAqBpC21B,YACTT,EAAUY,MAAM;oBAAE3jB;oBAA2BhH;oBAC7C0qB,KAAgB,KArBX/+B,kBACHo+B,EAAUY,MAAM;oBACd3jB;oBACAhH;oBAEF0qB,KAAgB,IAGbN,KACCz+B,KAAKub,iBAA8C,KACpDmjB,KACC1+B,KAAKub,iBAA+C;;;;gBAKtDijB,KAAc;8BAQpBJ,EAAUY,MAAM;gBAAE3jB;gBAAwBhH;gBAC1C0qB,KAAgB,KACPH,YACTR,EAAUY,MAAM;gBAAE3jB;gBAA0BhH;gBAC5C0qB,KAAgB,IAEZN;;;;YAIFD,KAAc;uBAMdD,IAAiBA,EAAe90B,QAE9B60B,QAAiBA,EAAe70B,IAAI5B,KAEnBy2B,EAAenqB,OAAOtM,OAGzC02B,IAAiBA,EAAepqB,OAAOtM,IACvCy2B,IAAiBA,EAAenqB,OAAOtM;YAO3C7H,KAAKub,cAA2Bvb,KAAKub,YACvC,MAAOgjB,EAAe/4B,OAAOxF,KAAKub,MAAY,SAAE;YAC9C,MAAMqjB,IAAS5+B,KAAKub,aAChBgjB,EAAerT,SACfqT,EAAeluB;YACnBkuB,IAAiBA,EAAepqB,OAAOyqB,EAAQ/2B,MAC/Cy2B,IAAiBA,EAAenqB,OAAOyqB,EAAQ/2B,MAC/Cu2B,EAAUY,MAAM;gBAAE3jB;gBAA0BhH;;;QAQhD,OAAO;YACL4qB;YACAC,IAAAd;YACAe,IAAAX;YACAY;;;IAIJt/B,GACE8+B,GACA9hB;;;;;;;;QASA,OACE8hB,QACA9hB,EAAOpJ,0BACNoJ;;;;;;;;;;;;;IAeLhd,GACE4b,GACA2jB,GACA1hB;QAMA,MAAMlC,IAAUzb;QAChBA,UAAmB0b,MACnB1b,UAAmB0b;;QAEnB,MAAMJ,IAAUI;QAChBJ,EAAQ1L,KAAK,CAAC0vB,GAAIC,MAsLtB,SAA2BD,GAAgBC;YACzC,MAAMxd,IAAS5G;gBACb;kBACE;oBACE,OAAO;;kBACT;kBAEA;;;;oBAIE,OAAO;;kBACT;oBACE,OAAO;;kBACT;oBACE,OAAOnW,GAAK;;;YAIlB,OAAO+c,OAAYA;;;;;;;;;;;;;;;;;GAvMbyd,EAAkBF,EAAGjkB,MAAMkkB,EAAGlkB,SAC9Brb,KAAKub,SAAoB+jB,EAAGjrB,KAAKkrB,EAAGlrB,OAIxCrU,QAAuB2d;QACvB,MAAM8hB,IAAeJ,IACjBr/B,YACA,IAEE0/B,IADsC,MAA7B1/B,QAAoBwF,QAAcxF,2CAE3C6b,IAAmB6jB,MAAiB1/B;QAG1C,IAFAA,aAEuB,MAAnBsb,EAAQxW,aAGL;YAWL,OAAO;gBACLqzB,UAXyB,OACzBn4B,KAAKub,OACLG,YAGAA,wBACAgkB;gDAE+B;gBAI/BC,IAAAF;;;;QAdF,OAAO;YAAEE,IAAAF;;;;;;WAuBb3/B,GAAuBy7B;QACrB,OAAIv7B,uCAAgBu7B;;;;;QAKlBv7B,WAAe,GACRA,QACL;YACEi/B,IAAaj/B;YACbk/B,IAAW;YACXE,IAAap/B;YACbm/B,KAAa;;qCAEa,MAIvB;YAAEQ,IAAc;;;;;WAO3B7/B,GAAwB+H;;QAEtB,QAAI7H,QAAsBwJ,IAAI3B;;UAIzB7H,QAAiBwJ,IAAI3B,OAOtB7H,QAAiBsC,IAAIuF;;;;;WAW3B/H,GAA0B6d;QACpBA,MACFA,KAA4BtY,QAC1BwC,KAAQ7H,UAAwBA,QAAsByJ,IAAI5B,KAE5D8V,KAA+BtY,QAAQwC,UAMvC8V,KAA8BtY,QAC5BwC,KAAQ7H,UAAwBA,QAAsBmU,OAAOtM;QAE/D7H,UAAe2d;;IAInB7d;;QAEE,KAAKE,SACH,OAAO;;;gBAKT,MAAM4/B,IAAoB5/B;QAC1BA,UAAsBwc,MACtBxc,QAAiBqF,QAAQgP;YACnBrU,QAAqBqU,EAAIxM,SAC3B7H,UAAsBA,QAAoByJ,IAAI4K,EAAIxM;;;QAKtD,MAAMyT,IAAiC;QAWvC,OAVAskB,EAAkBv6B,QAAQwC;YACnB7H,QAAoBwJ,IAAI3B,MAC3ByT,EAAQ/V,KAAK,OAAyBsC;YAG1C7H,QAAoBqF,QAAQwC;YACrB+3B,EAAkBp2B,IAAI3B,MACzByT,EAAQ/V,KAAK,OAAuBsC;;;;;;;;;;;;;;;;;;;;;;;IA0B1C/H,GAA8B+/B;QAC5B7/B,UAAwB6/B,MACxB7/B,UAAsBwc;QACtB,MAAMd,IAAa1b,QAAuB6/B,EAAY9jB;QACtD,OAAO/b,QAAkB0b,8BAAsC;;;;;;;;IASjE5b;QACE,OAAOggC,MACL9/B,KAAKub,OACLvb,SACAA,2BACAA;;;;;;;;;ICxbJF,YACmBspB,GACA2W,GACAC,GACAC;kCADAjgC,sBAAAggC,gBANnBhgC,UAPkB,GAgBhBA,UAAe,OACbA;;oEAMJF;QACEE;;IAGFF;QACEE,WAA2B0wB;YACzB,MAAMzJ,IAAcjnB,cACdkgC,IAAclgC,QAA0BinB;iBAE5CiZ,EACG39B,KAAKkG;gBACJzI,WAAiC,MACxBinB,EACJmS,SACA72B,KAAK;oBACJvC,QAAc8B,QAAQ2G;mBAEvBghB,MAAM0W;oBACLngC;;eAIPypB,MAAM2W;gBACLpgC;;;;IAMVF,GAA6BmnB;QAC3B;YACE,MAAMiZ,IAAclgC,KAAKggC,eAAe/Y;YACxC,QACElQ,QACCmpB,EAAYzW,SACZyW,EAAY39B,YAEbvC,QAAcsmB,OACZjlB,MAAM;YAED;UAGT,OAAOiiB;;YAGP,OADAtjB,QAAcsmB,OAAOhD,IACd;;;IAIXxjB,GAA+BwjB;QACzBtjB,UAAe,KAAKA,QAAiCsjB,MACvDtjB,WAAgB,GAChBA,WAAiC,OAC/BA,WACO6B,QAAQC,eAGjB9B,QAAcsmB,OAAOhD;;IAIzBxjB,GAAoCwjB;QAClC,IAAmB,oBAAfA,EAAM5hB,MAA0B;;;YAGlC,MAAMJ,IAAQgiB,EAAyBhiB;YACvC,OACW,cAATA,KACS,0BAATA,MACCm5B,GAAiBn5B;;QAGtB,QAAO;;;;;;;;;;;;;;;;;;;;;;;;AC3CX;IACExB;;;;IAISyb;;;;;IAKAxR;;;;;;;IAOAs2B;QAZArgC,aAAAub,GAKAvb,gBAAA+J,GAOA/J,YAAAqgC;;;;iCAKX;IACEvgC,YAAmB+H;QAAA7H,WAAA6H;;;;;;;QAQnB7H,WAA4B;;;;;;;;;;;;;;;;;;IAuE5BF,YACUksB,GACA+T;;IAEAO,GACAr+B,GACAs+B;+CADAvgC,mBAAAiC,gBA3CVjC,UAAwD;QAExDA,UAA4B,OAAgCwgC,KAC1DA,EAAEzwB,gBAEJ/P,UAA0B,IAAIoV;;;;;QAK9BpV,UAAkD;;;;;QAKlDA,UAAkC,MAChCwH;;;;;QAMFxH,UAAyC,IAAIoV,KAC7CpV,UAA4B;;QAE5BA,UAAgC;;QAIhCA,UAAiC,IAAIoV,KACrCpV,UAAiCygC;;;;QAKzBzgC,sBAAiC+E,GACjC/E;;;IAYR0gC;QACE,QAA0B,MAAnB1gC,KAAKk6B;;qFAIdp6B,UAAU6gC;QAUR3gC;;;;;;WAQFF,aAAayb;QAGX,IAAIxR,GACA8e;QAHJ7oB,QAAsB;QAKtB,MAAM4gC,IAAY5gC,QAAuBsC,IAAIiZ;QAC7C;;;;;;;QAOExR,IAAW62B,EAAU72B,UACrB/J,WAA2C+J,IAC3C8e,IAAe+X,EAAUP,gBACpB;YACL,MAAMpiB,UAAmBje,WAA+Bub,SAElDuD,IAAS9e,WACbie,EAAWlU;YAEbA,IAAWkU,EAAWlU,UACtB8e,UAAqB7oB,QACnBub,GACAxR,GACW,cAAX+U,IAEE9e,KAAKk6B,aACPl6B,QAAiB6gC;;QAKrB,OADA7gC,WAAuC,QAChC+J;;;;;WAODjK,SACNyb,GACAxR,GACA/C;QAEA,MAAM64B,UAAoB7/B,WACxBub;mCAC0B,IAEtB8kB,IAAO,OAAS9kB,GAAOskB,OACvBiB,IAAiBT,KAAuBR,EAAY9jB,YACpDglB,IAA0BzkB,MAC9BvS,GACA/C,iCAAWhH,KAAKu7B,cAEZ9L,IAAa4Q;qCAE8B,MAAnBrgC,KAAKk6B,eAY7BhxB,IAAO,OAAcqS,GAAOxR,GAAUs2B;QAO5C,OANArgC,QAAuBkU,IAAIqH,GAAOrS,IAC9BlJ,QAAqBwJ,IAAIO,KAC3B/J,QAAqBsC,IAAIyH,GAAWxE,KAAKgW,KAEzCvb,QAAqBkU,IAAInK,GAAU,EAACwR;QAE/BkU,EAAW0I;;;;;;;IAQZr4B,SACN8gC;QAEA,MAAMf,UAAoB7/B,WACxB4gC,EAAUrlB;mCACgB,IAEtBsN,IAAe+X,EAAUP;QAM/B,OAHIrgC,KAAKk6B,aACPl6B,QAAyB4gC,EAAU72B,UAAU8e;;4CAMjD/oB,SAAeyb;QACbvb,QAAsB;QAEtB,MAAM4gC,IAAY5gC,QAAuBsC,IAAIiZ,IAKvCylB,IAAUhhC,QAAqBsC,IAAIs+B,EAAU72B;;;gBACnD,IAAIi3B,EAAQl8B,SAAS,GAMnB,OALA9E,QAAqBkU,IACnB0sB,EAAU72B,UACVi3B,EAAQv6B,OAAO+5B,MAAMA,EAAE77B,QAAQ4W;aAEjCvb,QAAuBmU,OAAOoH;;gBAKhC,IAAIvb,KAAKk6B,WAAW;;;YAGlBl6B,WAA8C4gC,EAAU72B,WAC5B/J,WAC1B4gC,EAAU72B,mBAIJ/J,WACW4gC,EAAU72B,wCAAuC,GAC/DxH,KAAK;gBACJvC,WAAuC4gC,EAAU72B,WACjD/J,WAA0B4gC,EAAU72B,WACpC/J,QAA4B4gC,EAAU72B;eAEvC0f;eAGLzpB,QAA4B4gC,EAAU72B,iBAChC/J,WACJ4gC,EAAU72B;sCACmB;;;;;;;;;;;WAenCjK,YAAYslB,GAAmB6b;QAC7BjhC,QAAsB;QACtB,MAAMyI,UAAezI,WAA2BolB;QAChDplB,WAA0CyI,EAAOic,UACjD1kB,QAAyByI,EAAOic,mBAC1B1kB,QAAqCyI,aACrCzI;;;;;;;;;;;;;;;;;;WAoBRF,eACEspB,GACA4W,GACAC;QAEA,UAEEjgC,SACAggC;;IAKJlgC,SAAuBse;QACrBpe,QAAsB;QACtB;YACE,MAAMsb,UAAgBtb;;wBAEtBoe,KAA0B/Y,QAAQ,CAACsY,GAAc5T;gBAC/C,MAAMm3B,IAAkBlhC,QAAoCsC,IAC1DyH;;;;gBAKAnH,GACE+a,KAA4BnY,OAC1BmY,KAA+BnY,OAC/BmY,KAA8BnY,QAC9B,GACF;gBAEEmY,KAA4BnY,OAAO,IACrC07B,QAAmC,IAC1BvjB,KAA+BnY,OAAO,IAC/C5C,GACEs+B,MACA,4DAEOvjB,KAA8BnY,OAAO,MAC9C5C,GACEs+B,MACA;gBAEFA,QAAmC;sBAMnClhC;UACN,OAAOsjB;kBACD6d,GAAyB7d;;;;;;WAQnCxjB,GACEy7B,GACA6F;;;;;QAMA,IACGphC,KAAKk6B,qCAAakH,MACjBphC,KAAKk6B,2CAAakH,GACpB;YACAphC,QAAsB;YACtB,MAAMqhC,IAAmB;YACzBrhC,QAAuBqF,QAAQ,CAACkW,GAAOqlB;gBACrC,MAAMnR,IAAamR,EAAUP,QAA4B9E;gBAKrD9L,EAAW0I,YACbkJ,EAAiB97B,KAAKkqB,EAAW0I;gBAGrCn4B,WAA6Cu7B,IAC7Cv7B,eAEAA,KAAKu7B,cAAcA,GACfv7B,KAAKk6B,aACPl6B,WAAsCu7B;;;IAK5Cz7B,SAAmBiK,GAAoB2c;QACrC1mB,QAAsB;;QAGtBA,WAAwC+J,GAAU;QAElD,MAAMm3B,IAAkBlhC,QAAoCsC,IAAIyH,IAC1Du3B,IAAWJ,KAAmBA,EAAgBr5B;QACpD,OAAc;;;YAGZ7H,UAA+BA,QAA6B8H,WAG5D9H,QAAoCmU,OAAOpK,IAC3C/J;;;;;;;YASA,IAAIoc,IAAkB,MACpB5U;YAEF4U,IAAkBA,QAEhB,UAAyB3X;YAE3B,MAAM4X,IAAyBG,KAAiB/S,QAC1C6yB,IAAQ,OACZ73B,EAAgBC;iCACK,IAAI0Q;oCACD;YAI1B,OAAOpV,QAAsBs8B;;cAEvBt8B,WACW+J,kCAAwC,GACtDxH,KAAK,MAAMvC,QAA4B+J,OACvC0f;;;IAKP3pB,SACE4kB,GACA6c,GACAje;QAEAtjB,QAAsB;QACtB,MAAM+b,UAAkB/b,WAAwC0kB;QAE9C,SAAd3I,KAYe,cAAfwlB;;;;cAIIvhC,eACkB,mBAAfuhC,KAAgD,eAAfA;;;QAG1CvhC,QAAyB0kB,GAASpB,KAAgB,OAClDtjB,WAAkD0kB,MAElD1f,GAAK,uBAAuBu8B,YAGxBvhC,QAAqC+b;;;;;;;;QAlBzC0C,GAreU,cAqeQ,0CAA0CiG;;IAqBhE5kB,SACE0hC;QAEAxhC,QAAsB;QAEtB,MAAM0kB,IAAU8c,EAAoBpc,MAAMV;;;;;gBAM1C1kB,QAAyB0kB,cAAoB,OAE7C1kB,QAAmC0kB;QAEnC;YACE,MAAMpJ,UAAgBtb;YAGtBA,WAA2C0kB,GAAS,uBAC9C1kB;UACN,OAAOsjB;kBACD6d,GAAyB7d;;;IAInCxjB,SACE4kB,GACApB;QAEAtjB,QAAsB;;;;;QAMtBA,QAAyB0kB,GAASpB,IAElCtjB,QAAmC0kB;QAEnC;YACE,MAAMpJ,UAAgBtb,WAA4B0kB;YAClD1kB,WAA2C0kB,GAAS,YAAYpB,UAC1DtjB;UACN,OAAOsjB;kBACD6d,GAAyB7d;;;;;;WAQnCxjB,SAAoCqmB;QAC7BnmB,gBACHye,GAjjBU,cAmjBR;QAKJ,MAAMgjB,UAAuBzhC;QAC7B,K9BhmB2B,M8BgmBvByhC;;QAGF,YADAtb,EAASrkB;QAIX,MAAM4/B,IAAY1hC,QAA4BsC,UAAuB;QACrEo/B,EAAUn8B,KAAK4gB,IACfnmB,QAA4BkU;;;;;WAO9BpU,GAAsC4kB;SACnC1kB,QAA4BsC,IAAIoiB,MAAY,IAAIrf,QAAQ8gB;YACvDA,EAASrkB;YAGX9B,QAA4BmU,OAAOuQ;;uFAIrC5kB,GAAgDg2B;QAC9C91B,QAA4BqF,QAAQq8B;YAClCA,EAAUr8B,QAAQ8gB;gBAChBA,EAASG,OAAO,IAAIllB,EAAelB,EAAKE;;YAI5CJ,QAA4B2hC;;IAG9B7hC,GACE4kB,GACAyB;QAEA,IAAIyb,IAAe5hC,QAA2BA,KAAKiC;cAEjD2/B,IAAe,YAIjBA,IAAeA,KAAoBld,GAASyB,IAC5CnmB,QAA2BA,KAAKiC;;;;;WAOlCnC,GAA4B4kB,GAAkBpB;QAC5C,IAAIse,IAAe5hC,QAA2BA,KAAKiC;;;gBAInD,OAAkB;YAChB,MAAMkkB,IAAWyb,EAAat/B,IAAIoiB;YAC9ByB,MAKE7C,IACF6C,EAASG,OAAOhD,KAEhB6C,EAASrkB,WAEX8/B,IAAeA,EAAa95B,OAAO4c,KAErC1kB,QAA2BA,KAAKiC;;;IAIpCnC,GACEiK,GACAuZ,IAAsB;QAEtBtjB,WAA8C+J;QAQ9C,KAAK,MAAMwR,KAASvb,QAAqBsC,IAAIyH,IAC3C/J,QAAuBmU,OAAOoH,IAC1B+H,KACFtjB,WAAsCub,GAAO+H;QAMjD,IAFAtjB,QAAqBmU,OAAOpK,IAExB/J,KAAKk6B,WAAW;YAClB,MAAM2H,IAAY7hC,WAAuC+J;YACzD/J,WAA6C+J,IAC7C83B,EAAUx8B,QAAQi8B;gBACKthC;;gBAGnBA;;;;IAMRF,GAA0B+H;;;QAGxB,MAAMi6B,IAAgB9hC,QAA6BsC,IAAIuF;QACjC,SAAlBi6B,MAKJ9hC,eACAA,UAA+BA,QAA6B8H,OAAOD,IACnE7H,QAAoCmU,WACpCnU;;IAGFF,GACEiK,GACA01B;QAEA,KAAK,MAAMsC,QACT,IAAIA,iBACF/hC,WAAoC+hC,EAAYl6B,KAAKkC,IACrD/J,iBACK,IAAI+hC,iBAA6C;YACtDtjB,GA9rBQ,cA8rBU,kCAAkCsjB,EAAYl6B,MAChE7H,WAAuC+hC,EAAYl6B,KAAKkC;YACnC/J,WACnB+hC,EAAYl6B;;YAIZ7H,QAAuB+hC,EAAYl6B;eAGrC7C,GAAK,2BAA2BkH,KAAKC;;IAK3CrM,GAAyBiiC;QACvB,MAAMl6B,IAAMk6B,EAAYl6B;QACnB7H,QAA6BsC,IAAIuF,OACpC4W,GAhtBU,cAgtBQ,4BAA4B5W,IAC9C7H,QAA8BuF,KAAKsC;QACnC7H;;;;;;;;;WAYJF;QACE,MACEE,QAA8B8E,SAAS,KACvC9E,QAA6BwF,OAAOxF,WACpC;YACA,MAAM6H,IAAM7H,QAA8Bq6B,SACpCyH,IAAgB9hC,QAA4BoH;YAClDpH,QAAoCkU,OAElC,OAAoBrM,KAEtB7H,UAA+BA,WAC7B6H,OAGF7H,QAAiB6gC,OACf,OACE7pB,MAAanP,EAAIvB,yCAGjB4iB;;;;IAORppB;QACE,OAAOE;;;IAITF;QACE,OAAOE;;IAGDF,SACNwb,GACA8C;QAEA,MAAM4jB,IAA2B,IAC3BC,IAA2C,IAC3CC,IAAyC;QAE/CliC,QAAuBqF,QAAQ,CAACyY,GAAG8iB;YACjCsB,EAAiB38B,KACf1D,QAAQC,UACLS,KAAK;gBACJ,MAAMu+B,IAAiBF,EAAUP;gBACjC,OAAKS,OAME9gC,WACS4gC,EAAUrlB,kCAAiC,GACxDhZ,KAAK,EAAGwZ,WAAAA,OACA6kB,EAAUP,QACftkB;;;;2BAKPxZ,KAAMu+B;gBACL,MAAMnjB,IACJS,KAAeA,KAA0B9b,IAAIs+B,EAAU72B,WACnD0lB,IAAamR,EAAUP;6CAEoB,MAAnBrgC,KAAKk6B,WACjCvc;gBAMF,IAJA3d,QACE4gC,EAAU72B,UACV0lB,OAEEA,EAAW0I,UAAU;oBACnBn4B,KAAKk6B,aACPl6B,WACE4gC,EAAU72B,UACV0lB,EAAW0I,SAASvc,YAAY,gBAAgB;oBAIpDomB,EAASz8B,KAAKkqB,EAAW0I;oBACzB,MAAMzc,IAAaymB,MACjBvB,EAAU72B,UACV0lB,EAAW0I;oBAEb8J,EAAqB18B,KAAKmW;;;kBAM9B7Z,QAAQ0kB,QACdvmB,qBACMA;;IAGRF,GAAyBsiC;IAOzBtiC,SAA6B8B;QAC3B,MAAMygC,KAAeriC,KAAKiC,YAAY0C,QAAQ/C;QAG9C,IAFA5B,KAAKiC,cAAcL,MAEF;;YAEf5B,QACE;YAGF,MAAMyI,UAAezI,WAAiC4B;;wBAEtD5B,WACE4B,GACA6G,MACAA,aAEIzI,QAAqCyI;;cAGvCzI;;;IAIRF,SAAwBo6B;QACtB,KAAkB,MAAdA,MAAyC,MAAnBl6B,KAAKk6B,WAAoB;YACjDl6B,KAAKk6B,aAAY,SACXl6B,YAAmC;;;;;;;YAQzC,MAAMw8B,IAAgBx8B,cAChBsiC,UAAsBtiC,QAC1Bw8B;YAEF,KAAK,MAAMve,QACTje,QAAiB6gC;eAEd,KAAkB,MAAd3G,MAA0C,MAAnBl6B,KAAKk6B,WAAqB;YAC1Dl6B,KAAKk6B,aAAY;YAEjB,MAAMsC,IAA4B;YAElC,IAAIljB,IAAIzX,QAAQC;YAChB9B,QAAqBqF,QAAQ,CAACyY,GAAG/T;gBAC3B/J,WAA0C+J,KAC5CyyB,EAAcj3B,KAAKwE,KAEnBuP,IAAIA,EAAE/W,KAAK,OACTvC,QAA4B+J,IACrB/J,WACL+J;8CAC6B,MAInC/J,WAA0B+J;sBAEtBuP,SAEAtZ,YACNA,iBACMA,YAAmC;;;;IAK7CF;QACEE,QAAoCqF,QAAQ,CAACyY,GAAG/T;YAC9C/J,WAA0B+J;YAE5B/J,cACAA,UAAsC,IAAIoV,KAC1CpV,UAA+B,MAC7BwH;;;;;;;;IAUI1H,SACNoe;QAEA,MAAMokB,IAA8B,IAC9BjB,IAAmC;QACzC,KAAK,MAAMt3B,QAAqB;YAC9B,IAAIkU;YACJ,MAAM+iB,IAAUhhC,QAAqBsC,IAAIyH;YAEzC,IAAIi3B,KAA8B,MAAnBA,EAAQl8B,QAAc;;;;;sBAK7B9E,WACJ+J;8CAC6B,IAE/BkU,UAAmBje,WACjBghC,EAAQ;gBAGV,KAAK,MAAMzlB,QAAkB;oBAC3B,MAAMqlB,IAAY5gC,QAAuBsC,IAAIiZ,IAGvCkU,UAAmBzvB;oBAGrByvB,EAAW0I,YACbkJ,EAAiB97B,KAAKkqB,EAAW0I;;mBAGhC;;;gBAOL,MAAMxe,UAAe3Z,WAA0B+J;gBAE/CkU,UAAmBje,WAA+B2Z,UAC5C3Z,QACJA,YACA+J;8BACa;;YAIjBu4B,EAAc/8B;;QAIhB,OADAvF;;;;;;;;;;;;;IAeFF,GAAgC6Z;QAC9B,OAAO,IAAI3C,GACT2C,EAAOrT,MACPqT,EAAOnD,iBACPmD,EAAOlD,SACPkD,EAAOjD,SACPiD,EAAOvU,yBAEPuU,EAAOhD,SACPgD,EAAO/C;;;IAKX9W;QACE,OAAOE;;;IAITF,SACEiK,GACAiT,GACAsG;QAEA,IAAItjB,KAAKk6B;;;QAGPzb,GAhgCU,cAggCQ,uDAIpB,IAAIze,QAAqBwJ,IAAIO,IAC3B,QAAQiT;UACN,KAAK;UACL,KAAK;YAAe;gBAClB,MAAM1B,UAAgBtb,cAChBuiC,IAAyBC,MAC7Bz4B,GACU,cAAViT;sBAEIhd;gBAIN;;;UAEF,KAAK;kBACGA,WACJ+J;2CAC8B,IAEhC/J,QAA4B+J,GAAUuZ;YACtC;;UAEF;YACEte,GAAK,8BAA8BgY;;;;IAM3Cld,SACE2iC,GACA1S;QAEA,IAAK/vB,KAAKk6B,WAAV;YAIA,KAAK,MAAMnwB,QAAmB;gBAK5B,MAAM4P,UAAe3Z,WAA0B+J,IAKzCkU,UAAmBje,WAA+B2Z;sBAClD3Z,QACJA,QAA6B2Z,IAC7BsE,EAAWlU;8BACE,IAEf/J,QAAiB6gC;;YAGnB,KAAK,MAAM92B;;;YAGJ/J,QAAqBwJ,IAAIO;;kBAKxB/J,WACW+J,kCAAwC,GACtDxH,KAAK;gBACJvC,WAA0B+J,IAC1B/J,QAA4B+J;eAE7B0f;;;;;IAMP3pB;QAEE,OADAE,YAAkC,IAC3BA,QAAiBg6B;;;;IAK1Bl6B;QAEE,OADAE,YAAkC,IAC3BA,QAAiB0iC;;IAG1B5iC,GAAuBiK;QACrB,MAAMm3B,IAAkBlhC,QAAoCsC,IAAIyH;QAChE,IAAIm3B,KAAmBA,MACrB,OAAO1kB,KAAiB/S,IAAIy3B,EAAgBr5B;QACvC;YACL,IAAI86B,IAASnmB;YACb,MAAMwkB,IAAUhhC,QAAqBsC,IAAIyH;YACzC,QACE;YAEF,KAAK,MAAMwR,QAAkB;gBAC3B,MAAMqlB,IAAY5gC,QAAuBsC,IAAIiZ;gBAE7ConB,IAASA,KAAiB/B,EAAUP;;YAEtC;;;;;;;;;;;;;;;;;;;;;;;;GCxpCN;IAAAvgC;QACEE,UAAgC,MAChCA,gBAAqB,GACrBA,UAA6B;;;;;;;;;IAyB7BF,YAAoB8iC;qBARpB5iC,UAAkB,OAAyCwgC,KACzDA,EAAEzwB,gBAGI/P;QAERA,UAAwD,IAAIg5B,KAG1Dh5B,QAAgB6iC,UAAU7iC;;IAG5BF,OAAOwnB;QACL,MAAM/L,IAAQ+L,EAAS/L;QACvB,IAAIunB,KAAc,GAEdC,IAAY/iC,QAAasC,IAAIiZ;cAE/BunB,KAAc,GACdC,IAAY,QACZ/iC,QAAakU,IAAIqH,QAEnBwnB,KAAoBx9B,KAAK+hB;;QAGLA,KAAgCtnB,KAAKu7B;QAMzD,IAAIwH,MAAoB;YACFzb,KAAwByb,SAE1C/iC;;QAIJ,WACSA,QAAgB6gC,OAAOtlB,GAAOhZ,KAAKwH,MACxCg5B,EAAWh5B,WAAWA,GACfA,MAGFlI,QAAQC,QAAQihC,EAAUh5B;;IAIrCjK,SAAewnB;QACb,MAAM/L,IAAQ+L,EAAS/L;QACvB,IAAIynB,KAAa;QAEjB,MAAMD,IAAY/iC,QAAasC,IAAIiZ;QACnC,OAAe;YACb,MAAM7V,IAAIq9B,KAAoBx8B,QAAQ+gB;YAClC5hB,KAAK,MACPq9B,KAAoBve,UAAU,IAC9Bwe,IAA4C,MAA/BD,KAAoBj+B;;QAIrC,OAEE,OADA9E,QAAamU,OAAOoH,IACbvb,WAAyBub;;IAIpCzb,GAAcmjC;QACZ,IAAIC,KAAc;QAClB,KAAK,MAAMC,QAAuB;YAChC,MAAM5nB,IAAQ4nB,EAAS5nB,OACjBwnB,IAAY/iC,QAAasC,IAAIiZ;YACnC,OAAe;gBACb,KAAK,MAAM+L,KAAYyb,MACjBzb,YACF4b,KAAc;gBAGlBH;;;aAIF/iC;;IAIJF,GAAayb,GAAc+H;QACzB,MAAMyf,IAAY/iC,QAAasC,IAAIiZ;QACnC,OACE,KAAK,MAAM+L,KAAYyb,MACrBzb,EAAS8b,QAAQ9f;;;gBAMrBtjB,QAAamU,OAAOoH;;IAGtBzb,GAAoBy7B;QAClBv7B,KAAKu7B,cAAcA;QACnB,IAAI2H,KAAc;QAClBljC,QAAaqF,QAAQ,CAACyY,GAAGilB;YACvB,KAAK,MAAMzb,KAAYyb;;YAEjBzb,KAAgCiU,OAClC2H,KAAc;iBAKlBljC;;IAIJF,GAA2BujC;QACzBrjC,QAA8ByJ,IAAI45B;;;QAGlCA,EAASj8B;;IAGXtH,GAA8BujC;QAC5BrjC,QAA8BmU,OAAOkvB;;;IAIvCvjC;QACEE,QAA8BqF,QAAQg+B;YACpCA,EAASj8B;;;;;;;;;;;IAmCbtH,YACWyb,GACD+nB,GACRntB;QAFSnW,aAAAub;;;;;QATXvb,WAA6B,GAI7BA,UAAoC,MAE5BA,6CAONA,KAAKmW,UAAUA,KAAW;;;;;;;WAS5BrW,GAAeyjC;QAMb,KAAKvjC,KAAKmW,QAAQqtB,wBAAwB;;YAExC,MAAM9nB,IAAmC;YACzC,KAAK,MAAMgC,KAAa6lB,EAAK7nB,iCACvBgC,EAAUrC,QACZK,EAAWnW;YAGfg+B,IAAO,OACLA,EAAKhoB,OACLgoB,EAAK/nB,MACL+nB,MACA7nB,GACA6nB,MACAA,EAAK3nB,WACL2nB;4CAC+B;;QAGnC,IAAIL,KAAc;QAYlB,OAXKljC,UAKMA,eACTA,QAAmBoH,SACnB87B,KAAc,KANVljC,WAAmCA,KAAKu7B,iBAC1Cv7B;QACAkjC,KAAc,IAOlBljC;;IAIFF,QAAQwjB;QACNtjB,QAAmBsjB,MAAMA;;qDAI3BxjB,GAAuBy7B;QACrBv7B,KAAKu7B,cAAcA;QACnB,IAAI2H,KAAc;QASlB,OAPEljC,YACCA,WACDA,QAA6BA,SAAWu7B,OAExCv7B,QAAuBA,UACvBkjC,KAAc;;;IAKlBpjC,GACEyjC,GACAhI;;QAQA,KAAKgI,EAAK3nB,WACR,QAAO;;;gBAKT,MAAM6nB,gCAAclI;;;gBAGpB,SAAIv7B,KAAKmW,uBASDotB,EAAK/nB,wCAAkB+f;;;IAGjCz7B,GAAyByjC;;;;;QAKvB,IAAIA,EAAK7nB,WAAW5W,SAAS,GAC3B,QAAO;QAGT,MAAM4+B,IACJ1jC,WAAaA,QAAUoW,qBAAqBmtB,EAAKntB;QACnD,UAAImtB,gBAC6C,MAAxCvjC,KAAKmW,QAAQqtB;;;;;IASxB1jC,GAA0ByjC;QAKxBA,IAAOzD,MACLyD,EAAKhoB,OACLgoB,EAAK/nB,MACL+nB,MACAA,EAAK3nB,YAEP5b,WAA0B,GAC1BA,QAAmBoH;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ICtSrBtH,GAAsB6jC;QACpB3jC;;IAGFF,GACEmnB,GACA1L,GACAxB,GACAkW;;;;QAUA,OAAI1U,UAMAxB,EAA6BpV,QAAQF,EAAgBC,OALhD1E,QAA+BinB,GAAa1L,KAS9Cvb,WAAsCinB,MAAyB7f,KACpE2U;YACE,MAAM6nB,IAAkB5jC,QAAgBub,GAAOQ;YAE/C,QACGR,UAA2BA,WAC5Bvb,QACEub,YAGAxB,KAGK/Z,QAA+BinB,GAAa1L,MAGjD+R,QAAiBrK,EAASC,SAC5BzE,GACE,wBACA,yDACA1E,EAA6BtY,YAC7B8Z,EAAM9Z;YAMHzB,WACLinB,GACA1L,GACAxB,GACA3S,KAAKy8B;;;;YAILD,EAAgBv+B,QAAQgP;gBACtBwvB,IAAiBA,KAAsBxvB,EAAIxM,KAAKwM;;;;;;+EAS1DvU,GACEyb,GACAQ;;;QAIA,IAAIqM,IAAe,MAAwB,CAACrS,GAAIC,MAC9CuF;QAOF,OALAQ,EAAU1W,QAAQ,CAACyY,GAAGzK;YAChBA,aAAoBC,MAAYiI,EAAM/C,eACxC4P,IAAeA,EAAa3e;;;;;;;;;;;;;WAiBlC3J,GACEoX,GACA4sB,GACA7T,GACA8T;;;QAIA,IAAI9T,EAAWzqB,SAASs+B,EAAsBt+B,MAC5C,QAAO;;;;;;;;;gBAWT,MAAMw+B,wBACJ9sB,IACI4sB,EAAsB5Y,SACtB4Y,EAAsBzzB;QAC5B,eAKE2zB,EAAe5tB,oBACf4tB,EAAejxB,eAA8C;;IAIjEjT,GACEmnB,GACA1L;QAUA,OARI+R,QAAiBrK,EAASC,SAC5BzE,GACE,wBACA,mDACAlD,EAAM9Z;QAIHzB,WACLinB,GACA1L,GACA9W,EAAgBC;;;;;;;;;;;;;;;;;;;;;;;YCpIa4B;IACjC,IAAImC,IAAS;IACb,KAAK,IAAI/C,IAAI,GAAGA,IAAIY,EAAKxB,QAAQY,KAC3B+C,EAAO3D,SAAS,MAClB2D,IAASw7B,GAAgBx7B,KAE3BA,IAASy7B,GAAc59B,EAAKhE,QAAQmG;IAEtC,OAAOw7B,GAAgBx7B;;;wEAIzB,aAAuBnD,GAAiB6+B;IACtC,IAAI17B;IACJ,MAAM3D,IAASQ,EAAQR;IACvB,KAAK,IAAIY,IAAI,GAAGA,IAAIZ,GAAQY,KAAK;QAC/B,MAAMyB,IAAI7B,EAAQse;QAClB,QAAQzc;UACN,KAAK;YACHsB,KAAU27B;YACV;;UACF,KA7Ba;YA8BX37B,KAAU27B;YACV;;UACF;YACE37B,KAAUtB;;;IAGhB,OAAOsB;;;qDAIT,aAAyBA;IACvB,OAAOA,IAzCU;;;;;;;;gBAkDgBnC;;;IAGjC,MAAMxB,IAASwB,EAAKxB;IAEpB,IADAlC,GAAWkC,KAAU,GAAG,kBAAkBwB,IAC3B,MAAXxB,GAKF,OAJAlC,GAxDe,QAyDb0D,EAAKsd,OAAO,MAxDW,QAwDUtd,EAAKsd,OAAO,IAC7C,oBAAoBtd,IAAO;IAEtBF;;;QAKT,MAAMi+B,IAA4Bv/B,IAAS,GAErCF,IAAqB;IAC3B,IAAI0/B,IAAiB;IAErB,KAAK,IAAI/6B,IAAQ,GAAGA,IAAQzE,KAAU;;;QAGpC,MAAMe,IAAMS,EAAKC,QAzEF,KAyEsBgD;QAMrC,SALI1D,IAAM,KAAKA,UACbb,GAAK,qCAAqCsB,IAAO,MAGtCA,EAAKsd,OAAO/d,IAAM;UAE7B,KA/EuB;YAgFrB,MAAM0+B,IAAej+B,EAAK+rB,UAAU9oB,GAAO1D;YAC3C,IAAIP;YAC0B,MAA1Bg/B,EAAex/B;;;YAGjBQ,SAEAg/B,QACAh/B,OACAg/B,IAAiB,KAEnB1/B,EAASW;YACT;;UACF,KA5Fa;YA6FX++B,KAAkBh+B,EAAK+rB,UAAU9oB,GAAO1D,IACxCy+B,KAAkB;YAClB;;UACF,KA/FgB;;YAiGdA,KAAkBh+B,EAAK+rB,UAAU9oB,GAAO1D,IAAM;YAC9C;;UACF;YACEb,GAAK,qCAAqCsB,IAAO;;QAGrDiD,IAAQ1D,IAAM;;IAGhB,OAAO,IAAIO,EAAaxB;;;;;;;;;;;;;;;;;;;;;;;;;;;ICsExB9E,YAAoB0kC;QAAAxkC,UAAAwkC;;;;;QAMC,SALAC,MAAuBC,QAMxCxqB,GACE;;;;;;;;;WAhMNpa,UACE4B,GACAqR,GACA4xB;QAOA,OADAlmB,GA7CY,YA6CM,qBAAqB/c,IAChC,IAAIwkB,GAA6B,CAACpkB,GAASwkB;;;;;;YAMhD,MAAM8R,IAAUwD,OAAOgJ,UAAUC,KAAKnjC,GAAMqR;YAE5CqlB,EAAQ0M,YAAaxI;gBACnB,MAAMkI,IAAMlI,EAAM3iB,OAA4BlR;gBAC9C3G,EAAQ,OAAa0iC;eAGvBpM,EAAQ2M,YAAY;gBAClBze,EACE,IAAIllB,EACFlB,EAAKW,qBACL;eAMNu3B,EAAQ4M,UAAW1I;gBACjB,MAAMhZ,IAAuBgZ,EAAM3iB,OAA4B2J;gBAC5C,mBAAfA,EAAM5hB,OACR4kB,EACE,IAAIllB,EACFlB,EAAKW,qBACL,2VAQJylB,EAAOhD;eAIX8U,EAAQ6M,kBAAmB3I;gBACzB7d,GAxFQ,YA0FN,eAAe/c,IAAO,oCACtB46B,EAAM4I;gBAER,MAAMV,IAAMlI,EAAM3iB,OAA4BlR;gBAC9Ck8B,EACGQ,gBACCX,GACApM,EAAoB,aACpBkE,EAAM4I,YACNE,IAEDh+B,KAAK;oBACJqX,GAtGI,YAwGF,iCAAiC2mB,KAAiB;;;;;8CAQ9DtlC,cAAc4B;QAEZ,OADA+c,GAjHY,YAiHM,sBAAsB/c,IACjC2jC,GAAkBzJ,OAAOgJ,UAAUU,eAAe5jC;;iFAI3D5B;QACE,IAAsB,sBAAX87B,UAA8C,QAApBA,OAAOgJ,WAC1C,QAAO;QAGT,IAAIH,SACF,QAAO;;;;gBAMT,SAAyB1/B,MAArB62B,OAAO2J,WACT,QAAO;;;;;;;;gBAWT,MAAMC,IAAKd,KAaLe,IAAahB,UACbiB,IAAmB,SAAkBD,IAAa,IAGlDE,IAAiBlB,UACjBmB,IAAuB,SAAsBD,IAAiB;;;;;;;;;gBAEpE,SACEH,EAAGj/B,QAAQ,WAAW,KACtBi/B,EAAGj/B,QAAQ,cAAc,KACzBi/B,EAAGj/B,QAAQ,WAAW;;;;;WAc1BzG;;QACE,OACqB,2CACmB,yBAAtC+lC;;sEAKJ/lC,UACEwsB,GACAwZ;QAEA,OAAOxZ,EAAIwZ,MAA0BA;;;;IAKvChmC,UAAqB0lC;QACnB,MAAMO,IAAkBP,EAAGhI,MAAM,oCAC3BzqB,IAAUgzB,IACZA,EAAgB,GACbv/B,MAAM,KACNrB,MAAM,GAAG,GACTkB,KAAK,OACR;QACJ,OAAO8E,OAAO4H;;;;IAKhBjT,UAAyB0lC;QACvB,MAAMQ,IAAsBR,EAAGhI,MAAM,sBAC/BzqB,IAAUizB,IACZA,EAAoB,GACjBx/B,MAAM,KACNrB,MAAM,GAAG,GACTkB,KAAK,OACR;QACJ,OAAO8E,OAAO4H;;IAmBhBjT,GACEmmC;QAEAjmC,KAAKwkC,GAAG0B,kBAAmB5J,KAClB2J,EAAsB3J;;IAIjCx8B,qBACEgwB,GACAqW,GACAC;QAEA,MAAMC,IAAoB,eAATvW;QACjB,IAAIwW,IAAgB;QAEpB,SAAa;;YAGX,MAAMrf,IAAcsf,GAAoB1B,KACtC7kC,KAAKwkC,IACL6B,IAAW,aAAa;YAG1B;gBACE,MAAMG,IAAsBJ,EAAcnf,GACvCwC,MAAMnG;;gBAEL2D,EAAYwf,MAAMnjB,IAKX4C,GAAmBI,OAAUhD;;;gCAYxC,OANAkjB,EAAoB/c,MAAM;;;;sBAKpBxC;cAEN,OAAO3D;;;;;;gBAOP,MAAMojB,IACW,oBAAfpjB,EAAM5hB,QACN4kC,IA7RsB;gBAqSxB,IAPA7nB,GApSQ,YAsSN,oDACA6E,EAAM/hB;oBAKN,OAAOM,QAAQykB,OAAOhD;;;;IAM9BxjB;QACEE,KAAKwkC,GAAGlN;;;;;;;;;IAaVx3B,YAAoB6mC;qBAHpB3mC,WAAqB,GACrBA,UAAsC;;IAItC4mC;QACE,OAAO5mC;;IAGT6mC;QACE,OAAO7mC;;IAGTgiB,WAAWrgB;QACT3B,UAAgB2B;;;;WAMlB7B;QACEE,WAAkB;;;;;WAOpBF,GAAK+H;QACH7H,UAAe6H;;;;;;WAQjB/H;QACE,OAAOulC,GAAkBrlC,QAAcmU;;;;;;;;IAgDzCrU,YAA6BmnB;QAAAjnB,mBAAAinB,GAfrBjnB,gBAAU;;;;QAKlBA,UAAsC,QAWpCA,KAAKinB,YAAY6f,aAAa;YAC5B9mC,QAAwB8B;WAE1B9B,KAAKinB,YAAY8f,UAAU;YACrB9f,EAAY3D,QACdtjB,QAAwBsmB,OAAOW,EAAY3D,SAE3CtjB,QAAwB8B;WAG5B9B,KAAKinB,YAAY+d,UAAW1I;YAC1B,MAAMhZ,IAAQ0jB,GACX1K,EAAM3iB,OAA4B;YAErC3Z,QAAwBsmB,OAAOhD;;;IAvBnCxjB,YACE0kC,GACA1U,GACAmX;QAEA,OAAO,OAAwBzC,EAAGvd,YAAYggB,GAAkBnX;;IAsBlEoX;QACE,OAAOlnC,QAAwBmpB;;IAGjCrpB,MAAMwjB;QACAA,KACFtjB,QAAwBsmB,OAAOhD,IAG5BtjB,KAAKmnC,YACR1oB,GAhbU,YAkbR,yBACA6E,IAAQA,EAAM/hB,UAAU;QAE1BvB,KAAKmnC,WAAU,GACfnnC,KAAKinB,YAAYwf;;;;;;;;;;WAarB3mC,MACEsnC;QAEA,MAAMtB,IAAQ9lC,KAAKinB,YAAYogB;QAE/B,OAAO,OAAsCvB;;;;;;;;;;;;;;IAkB/ChmC,YAAoBgmC;QAAA9lC,aAAA8lC;;IAWpBhmC,IACEwnC,GACA3lC;QAEA,IAAIy2B;QAQJ,YAPcrzB,MAAVpD,KACF8c,GA3eU,YA2eQ,OAAOze,KAAK8lC,MAAMpkC,SAAkBC,IACtDy2B,IAAUp4B,KAAK8lC,MAAMyB,IAAI5lC,GAAO2lC,OAEhC7oB,GA9eU,YA8eQ,OAAOze,KAAK8lC,MAAMpkC,MAAM;QAC1C02B,IAAUp4B,KAAK8lC,MAAMyB,IAAID,KAEpBjC,GAAkBjN;;;;;;;;WAU3Bt4B,IAAI6B;QAGF,OAFA8c,GA5fY,YA4fM,OAAOze,KAAK8lC,MAAMpkC,MAAMC,GAAOA,IAE1C0jC,GADSrlC,KAAK8lC,MAAMr8B,IAAI9H;;;;;;;;WAWjC7B,IAAI+H;;;QAIF,OAAOw9B,GAHSrlC,KAAK8lC,MAAMxjC,IAAIuF,IAGET,KAAKqB;;aAErB1D,MAAX0D,MACFA,IAAS,OAEXgW,GAjhBU,YAihBQ,OAAOze,KAAK8lC,MAAMpkC,MAAMmG,GAAKY,IACxCA;;IAIX3I,OAAO+H;QAGL,OAFA4W,GAvhBY,YAuhBM,UAAUze,KAAK8lC,MAAMpkC,MAAMmG,IAEtCw9B,GADSrlC,KAAK8lC,MAAM3xB,OAAOtM;;;;;;;WAUpC/H;QAGE,OAFA2e,GAniBY,YAmiBM,SAASze,KAAK8lC,MAAMpkC,OAE/B2jC,GADSrlC,KAAK8lC,MAAM77B;;IAO7BnK,GACE0nC,GACAn+B;QAEA,MAAM2Y,IAAShiB,KAAKgiB,OAAOhiB,KAAKmW,WAAsB9M,KAChDmc,IAAuB;QAC7B,OAAOxlB,QAAmBgiB,GAAQ,CAACna,GAAKlG;YACtC6jB,EAAQjgB,KAAK5D;WACZyF,KAAK,MACCoe;;IAOX1lB,GACE0nC,GACAn+B;QAEAoV,GA/jBY,YA+jBM,cAAcze,KAAK8lC,MAAMpkC;QAC3C,MAAMyU,IAAUnW,KAAKmW,WAAsB9M;QAC3C8M,QAAmB;QACnB,MAAM6L,IAAShiB,KAAKgiB,OAAO7L;QAC3B,OAAOnW,QAAmBgiB,GAAQ,CAACna,GAAKlG,GAAO8lC,MAOtCA,EAAQtzB;;IAuBnBrU,GACE4nC,GACAvhB;QAEA,IAAIhQ;QACCgQ,IAIHhQ,IAAUuxB,KAHVvxB,IAAU,IACVgQ,IAAWuhB;QAIb,MAAM1lB,IAAShiB,KAAKgiB,OAAO7L;QAC3B,OAAOnW,QAAmBgiB,GAAQmE;;;;;;;;;WAWpCrmB,GACEqmB;QAEA,MAAMwhB,IAAgB3nC,KAAKgiB,OAAO;QAClC,OAAO,IAAIkE,GAAmB,CAACpkB,GAASwkB;YACtCqhB,EAAc3C,UAAW1I;gBACvB,MAAMhZ,IAAQ0jB,GACX1K,EAAM3iB,OAA4B;gBAErC2M,EAAOhD;eAETqkB,EAAc7C,YAAaxI;gBACzB,MAAMta,IAA8Bsa,EAAM3iB,OAAsBlR;gBAC3DuZ,IAKLmE,EAASnE,EAAO4lB,YAAuB5lB,EAAOrgB,OAAOyF,KACnDygC;wBAEI7lB,EAAO8lB,aAEPhmC;qBATJA;;;;IAiBRhC,GACE6nC,GACA/hC;QAEA,MAAM4f,IAA2C;QACjD,OAAO,IAAIU,GAAmB,CAACpkB,GAASwkB;YACtCqhB,EAAc3C,UAAW1I;gBACvBhW,EAAQgW,EAAM3iB,OAAsB2J;eAEtCqkB,EAAc7C,YAAaxI;gBACzB,MAAMta,IAA8Bsa,EAAM3iB,OAAsBlR;gBAChE,KAAKuZ,GAEH,YADAlgB;gBAGF,MAAMimC,IAAa,OAAwB/lB,IACrCgmB,IAAapiC,EACjBoc,EAAO4lB,YACP5lB,EAAOrgB,OACPomC;gBAEF,IAAIC,aAAsB9hB,IAAoB;oBAC5C,MAAMga,IAAwC8H,EAAWve,MACvD/C,MACEqhB,EAAWthB,QACJP,GAAmBI;oBAG9Bd,EAAQjgB;;gBAENwiC,OACFjmC,MACkC,SAAzBimC,OACT/lB,EAAO8lB,aAEP9lB,EAAO8lB,SAASC;;WAGnB3gC,KAAK,MACC8e,MAA2BV;;IAI9B1lB,QACN0nC,GACAn+B;QAEA,IAAI4+B,SAAgCljC;QAYpC,YAXqBA,MAAjByiC,MAC0B,uBAC1BS,QAMA5+B,QAGG;YAAE5D;YAAkB4D,OAAAA;;;IAGrBvJ,OAAOqW;QACb,IAAI+L,IAAgC;QAIpC,IAHI/L,EAAQ+xB,YACVhmB,IAAY,SAEV/L,EAAQ1Q,OAAO;YACjB,MAAMA,IAAQzF,KAAK8lC,MAAMrgC,MAAM0Q,EAAQ1Q;YACvC,OAAI0Q,OACK1Q,EAAM0iC,cAAchyB,EAAQ9M,OAAO6Y,KAEnCzc,EAAM2iC,WAAWjyB,EAAQ9M,OAAO6Y;;QAGzC,OAAOliB,KAAK8lC,MAAMsC,WAAWjyB,EAAQ9M,OAAO6Y;;;;;;;GASlD,aAAwBkW;IACtB,OAAO,IAAIlS,GAAsB,CAACpkB,GAASwkB;QACzC8R,EAAQ0M,YAAaxI;YACnB,MAAM7zB,IAAU6zB,EAAM3iB,OAAsBlR;YAC5C3G,EAAQ2G;WAGV2vB,EAAQ4M,UAAW1I;YACjB,MAAMhZ,IAAQ0jB,GACX1K,EAAM3iB,OAA4B;YAErC2M,EAAOhD;;;;;0CAMb;IAAI+kB,MAAmB;;AACvB,YAAmC/kB;IACjC,MAAMmiB,IAAahB,MAAuBC;IAC1C,IAAIe,KAAc,QAAQA,IAAa,IAAI;QACzC,MAAM6C,IACJ;QACF,IAAIhlB,EAAM/hB,QAAQgF,cAAsB,GAAG;;YAEzC,MAAMgiC,IAAW,IAAInnC,EACnB,YACA,6CAA6CknC,wBAC3C;YAWJ,cAPED,MAAmB;;;YAGnBxe,WAAW;gBACT;eACC;;;IAKT,OAAOvG;;;;;;;;;;;;;;;;;;;;IC3uBPxjB;;;;;IAKU29B,GACSvrB,GACAuV,GACA+gB;QAHTxoC,cAAAy9B,GACSz9B,kBAAAkS;;;;;;;;;;;;;QARnBlS,UAAgC;;;;;;WAkBhCF,UACE8B,GACAsQ,GACAuV,GACA+gB;;;;;QAMA5lC,GAAwB,OAAbhB,EAAK7B,KAAY;QAC5B,MAAM09B,IAAS77B,QAAyBA,EAAK7B,MAAO;QACpD,OAAO,OACL09B,GACAvrB;;IAMJpS,GAAWmnB;QACT,IAAIwhB,KAAQ;QACZ,MAAMp/B,IAAQq/B,YAAY7wB,MACxB,EAAC7X,KAAKy9B,QAAQtyB,OAAOw9B,qBACrB,EAAC3oC,KAAKy9B,QAAQtyB,OAAOy9B;QAEvB,OAAOC,GAAe5hB,MAElB;YAAExhB,OAAOqjC,GAAgBC;YAAoB1/B,OAAAA;WAC7C,CAACxB,GAAKlG,GAAO8lC;YACXgB,KAAQ,GACRhB,EAAQhhB;WAGXrf,KAAK,MAAMqhC;;IAGhB3oC,GACEmnB,GACA7B,GACAE;QAEA,OAAOtlB,QAA8BinB,GAAa7f,KAAKs1B;;;QAGrDA,EAASjE,kBAAkBnT,EAAYnV,YAEhC64B,GAAoB/hB,GAAasgB,IAAI7K;;IAIhD58B,GACEmnB;QAEA,OAAOjnB,QAA8BinB,GAAa7f,KAChDs1B,KAAYlxB,EAAWuF,iBAAiB2rB,EAASjE;;IAIrD34B,GACEmnB,GACA3B;QAEA,OAAOtlB,QAA8BinB,GAAa7f,KAAKs1B;;;QAGrDA,EAASjE,kBAAkBnT,EAAYnV,YAChC64B,GAAoB/hB,GAAasgB,IAAI7K;;IAIhD58B,GACEmnB,GACArb,GACA+Y,GACAC;QAEA,MAAMqkB,IAAgBC,GAAuBjiB,IACvCkiB,IAAgBN,GAAe5hB;;;;;;;;;;QAYrC,OAAOkiB,EAAc1/B,IAAI,IAAWrC,KAAKsd;YACvC9hB,GACqB,mBAAZ8hB,GACP;YAGF,MAAMU,IAAQ,OACZV,MAEAC,GACAC,IAEIwkB,IAAUppC,KAAKkS,cAA6BlS,KAAKy9B,QAAQrY,IAEzD2B,IAA4C;YAClD,IAAIsiB,IAAoB,MAA4B,CAAC30B,GAAGC,MACtDvQ,GAAoBsQ,OAAqBC;YAE3C,KAAK,MAAMwL,KAAYyE,GAAW;gBAChC,MAAM0kB,IAAWC,GAAmB1hC,IAClC7H,KAAKy9B,QACLtd,EAAStY,IAAIvB,MACboe;gBAEF2kB,IAAoBA,EAAkB5/B,IAAI0W,EAAStY,IAAIvB,WACvDygB,EAASxhB,KAAK4jC,EAAc5B,SAC5BxgB,EAASxhB,KACP0jC,EAAc1B,OAAcgC,GAAmBC;;YAcnD,OAVAH,EAAkBhkC,QAAQ8b;gBACxB4F,EAASxhB,KACPvF,WAA6CinB,GAAa9F;gBAI9D8F,KAAmC;gBACjCjnB,QAA2B0kB,KAAWU,EAAM1V;gBAGvCwW,SAAqC9e,KAAK,MAAMge;;;IAI3DtlB,GACEmnB,GACAvC;QAEA,OAAOmkB,GAAe5hB,GACnB3kB,IAAIoiB,GACJtd,KAAKgiC,UAEFxmC,GACEwmC,EAAQ3L,WAAWz9B,KAAKy9B,QACxB,oBAAoB2L,EAAQ3L,8BAA8B/Y;QAErD1kB,KAAKkS,oBAEP;;IAIbpS,GACEmnB,GACAvC;QAEA,OAAI1kB,QAA2B0kB,KACtBwB,GAAmBpkB,QACxB9B,QAA2B0kB,MAGtB1kB,QAAyBinB,GAAavC,GAAStd,KAAKge;YACzD,IAAIA,GAAO;gBACT,MAAM1V,IAAO0V,EAAM1V;gBAEnB,OADA1P,QAA2B0kB,KAAWhV,GAC/BA;;YAEP,OAAO;;;IAMf5P,GACEmnB,GACAvC;QAEA,MAAM+kB,IAAc/kB,IAAU,GAExBrb,IAAQq/B,YAAYgB,WAAW,EAAC1pC,KAAKy9B;QAC3C,IAAIkM,IAAmC;QACvC,OAAOd,GAAe5hB,MAElB;YAAExhB,OAAOqjC,GAAgBC;YAAoB1/B,OAAAA;WAC7C,CAACxB,GAAKuhC,GAAS3B;YACT2B,EAAQ3L,WAAWz9B,KAAKy9B,WAC1B76B,GACEwmC,EAAQ1kB,cACR;YAEFilB,IAAa3pC,KAAKkS,mBAEpBu1B,EAAQhhB;WAGXrf,KAAK;;IAGVtH,GACEmnB;QAEA,MAAM5d,IAAQq/B,YAAYjc,WAAW,EACnCzsB,KAAKy9B,QACLtyB,OAAOy9B;QAGT,IAAIlkB,KnChQuB;QmCiQ3B,OAAOmkB,GAAe5hB,MAElB;YAAExhB,OAAOqjC,GAAgBC;YAAoB1/B,OAAAA;YAAO6+B,UAAS;WAC7D,CAACrgC,GAAKuhC,GAAS3B;YACb/iB,IAAU0kB,EAAQ1kB,SAClB+iB,EAAQhhB;WAGXrf,KAAK,MAAMsd;;IAGhB5kB,GACEmnB;QAEA,MAAM5d,IAAQq/B,YAAY7wB,MACxB,EAAC7X,KAAKy9B,SnChRmB,KmCiRzB,EAACz9B,KAAKy9B,QAAQtyB,OAAOy9B;QAEvB,OAAOC,GAAe5hB,MACX6hB,GAAgBC,oBAAoB1/B,GAC5CjC,KAAKwiC,KACJA,EAAU/iC,IAAIuiC,KAAWppC,KAAKkS;;IAIpCpS,GACEmnB,GACAC;;;QAIA,MAAM2iB,IAAcN,GAAmBO,cACrC9pC,KAAKy9B,QACLvW,EAAY5gB,OAERyjC,IAAarB,YAAYgB,eAEzBlkB,IAA2B;QACjC,OAAO0jB,GAAuBjiB,MACnB;YAAE5d;WAAqB,CAACigC,GAAUxrB,GAAG2pB;YAC5C,OAAOuC,GAAQC,GAAavlB,QAStBpe,IAAO4jC;;;;;;;;wBACb,IAAIF,MAAWhqC,KAAKy9B,UAAWvW,EAAY5gB,KAAK3B,QAAQ2B;;YAKxD,OAAOuiC,GAAe5hB,GACnB3kB,IAAIoiB,GACJtd,KAAK+Y;gBACJ,QACE,MAAMnb,GACJ,qDAEE,sBACA0f;gBAGN9hB,GACEud,EAASsd,WAAWz9B,KAAKy9B,QACzB,oBAAoBtd,EAASsd,8BAA8B/Y;gBAE7Dc,EAAQjgB,KAAKvF,KAAKkS;;YAnBpBu1B,EAAQhhB;WAsBXrf,KAAK,MAAMoe;;IAGhB1lB,GACEmnB,GACAG;QAEA,IAAI+iB,IAAiB;QAErB,MAAMpjB,IAA4C;QAiClD,OAhCAK,EAAa/hB,QAAQ6hB;YACnB,MAAM6iB,IAAaR,GAAmBO,cACpC9pC,KAAKy9B,QACLvW,EAAY5gB,OAER+C,IAAQq/B,YAAYgB,eAEpBvgB,IAAU+f,GAAuBjiB,MACrC;gBAAE5d,OAAAA;eACF,CAACigC,GAAUxrB,GAAG2pB;gBACZ,OAAOuC,GAAQC,GAAaG,QAStB9jC,IAAO4jC;;;;;;;;gCACTF,MAAWhqC,KAAKy9B,UAAWvW,EAAY5gB,KAAK3B,QAAQ2B,KAKxD6jC,IAAiBA,EAAe1gC,SAJ9Bg+B,EAAQhhB;;YAQdM,EAASxhB,KAAK4jB;YAGTjD,SAAqC9e,KAAK,MAC/CpH,QAA2BinB;;IAI/BnnB,GACEmnB,GACA1L;QAWA,MAAM8uB,IAAY9uB,EAAMjV,MAClBgkC,IAA0BD,EAAUvlC,SAAS,GAa7C+kC,IAAcN,GAAmBO,cACrC9pC,KAAKy9B,YAGDsM,IAAarB,YAAYgB;;;;QAK/B,IAAIS,IAAiB;QACrB,OAAOjB,GAAuBjiB,MACnB;YAAE5d;WAAqB,CAACigC,GAAUxrB,GAAG2pB;YAC5C,OAAOuC,GAAQC,GAAaG,QACtB9jC,IAAO4jC;YACTF,MAAWhqC,KAAKy9B,UAAW4M,IAAqB/jC;;;;;;YAShDA,EAAKxB,iBAGTqlC,IAAiBA,EAAe1gC,UAX9Bg+B,EAAQhhB;WAaXrf,KAAK,MAAMpH,QAA2BinB;;IAG3CnnB,GACEmnB,GACAsjB;QAEA,MAAM/kB,IAA2B,IAC3BuB,IAA4C;;QAsBlD,OApBAwjB,EAASllC,QAAQqf;YACfqC,EAASxhB,KACPsjC,GAAe5hB,GACZ3kB,IAAIoiB,GACJtd,KAAK+Y;gBACJ,IAAiB,SAAbA,GACF,MAAMnb,GACJ,iEAEE0f;gBAGN9hB,GACEud,EAASsd,WAAWz9B,KAAKy9B,QACzB,oBAAoBtd,EAASsd,8BAA8B/Y;gBAE7Dc,EAAQjgB,KAAKvF,KAAKkS;;YAInBgU,SAAqC9e,KAAK,MAAMoe;;IAGzD1lB,GACEmnB,GACA7B;QAEA,OAAOolB,GACJvjB,MACDjnB,KAAKy9B,QACLrY,GACAhe,KAAKuV,MACLsK,KAAmC;YACjCjnB,QAA8BolB,EAAMV;YAE/BwB,GAAmB7gB,WAEvBwC,KACQ7H,WACLinB,GACApf;;IAOV/H,GAAyB4kB;eAChB1kB,QAA2B0kB;;IAGpC5kB,GACEwsB;QAEA,OAAOtsB,QAAgBssB,GAAKllB,KAAKqhC;YAC/B,KAAKA,GACH,OAAOviB,GAAmBpkB;;;wBAK5B,MAAM2oC,IAAa/B,YAAYgB,WAC7BH,GAAmBmB,cAAc1qC,KAAKy9B,UAElCkN,IAA6C;YACnD,OAAOzB,GAAuB5c,MACnB;gBAAEjjB;eAAqB,CAACxB,GAAKiW,GAAG2pB;gBAEvC,IADe5/B,EAAI,OACJ7H,KAAKy9B,QAGb;oBACL,MAAMn3B,IAAO4jC,GAAmBriC,EAAI;oBACpC8iC,EAA2BplC,KAAKe;uBAJhCmhC,EAAQhhB;eAOXrf,KAAK;gBACJxE,GACwC,MAAtC+nC,EAA2B7lC,QAC3B,gGAEE6lC,EAA2B9jC,IAAIyS,KAAKA;;;;IAMhDxZ,GACEwsB,GACAzkB;QAEA,OAAO+iC,GAAyBte,GAAKtsB,KAAKy9B,QAAQ51B;;;;IAKpD/H,GACEmnB;QAEA,OAAO+hB,GAAoB/hB,GACxB3kB,IAAItC,KAAKy9B,QACTr2B,KAAMs1B,KAEHA,KACA,IAAImO,GACF7qC,KAAKy9B,SnCniBc;6BmCqiBE;;;;;;;GAWjC,aACEnR,GACAmR,GACA51B;IAEA,MAAMyhC,IAAWC,GAAmBO,cAAcrM,GAAQ51B,EAAIvB,OACxD2jC,IAAcX,EAAS,IACvBmB,IAAa/B,YAAYgB;IAC/B,IAAIoB,KAAc;IAClB,OAAO5B,GAAuB5c,MACnB;QAAEjjB;QAAmB0hC,KAAU;OAAQ,CAACljC,GAAKlG,GAAO8lC;QAC3D,OAAOuC,GAAQgB,eAAqBltB,KAAKjW;QACrCmiC,MAAWvM,KAAUuN,YACvBF,KAAc,IAEhBrD,EAAQhhB;OAETrf,KAAK;;;;;;;;YA0BRklB,GACAmR,GACArY;IAEA,MAAM+jB,IAAgB7c,EAAIwZ,MACxBgD,GAAgBhD,QAEZmF,IAAW3e,EAAIwZ,MACnByD,GAAmBzD,QAEf/e,IAA4C,IAE5C1d,IAAQq/B,YAAYwC,KAAK9lB,EAAMV;IACrC,IAAIymB,IAAa;IACjB,MAAMC,IAAgBjC,KACpB;QAAE9/B,OAAAA;OACF,CAACxB,GAAKlG,GAAO8lC,OACX0D,KACO1D,EAAQtzB;IAGnB4S,EAASxhB,KACP6lC,EAAchkC,KAAK;QACjBxE,GACiB,MAAfuoC,GACA,+DACE/lB,EAAMV;;IAId,MAAM/H,IAAkC;IACxC,KAAK,MAAMwD,KAAYiF,EAAMR,WAAW;QACtC,MAAM0kB,IAAWC,GAAmB1hC,IAClC41B,GACAtd,EAAStY,IAAIvB,MACb8e,EAAMV;QAERqC,EAASxhB,KAAK0lC,EAAS92B,YACvBwI,EAAiBpX,KAAK4a,EAAStY;;IAEjC,OAAOqe,SAAqC9e,KAAK;;;;;GAMnD,aACEklB;IAEA,OAAO+e,MACL/e,GACAwc,GAAgBhD;;;;;GAOpB,aACExZ;IAEA,OAAO+e,MAGL/e,GAAKid,GAAmBzD;;;;;GAM5B,aACExZ;IAEA,OAAO+e,MACL/e,GACAue,GAAgB/E;;;;;;;;;;;;;;;;;;;ICppBlBhmC,YACmB0oC,GACTt2B;qBAAAlS,kBAAAkS;;;;;;;;IAUVpS,GACEmnB;QAEA,OAAOjnB,QAAsBinB,GAAa7f,KAAKs1B;YAC7C,MAAM4O,IAAoB,OAAsB5O,EAAS6O;YAEzD,OADA7O,EAAS6O,kBAAkBD,EAAkBlkC,QACtCpH,QAAkBinB,GAAayV,GAAUt1B,KAC9C,MAAMs1B,EAAS6O;;;IAKrBzrC,GACEmnB;QAEA,OAAOjnB,QAAsBinB,GAAa7f,KAAKs1B,KACtCj4B,IACL,IAAIlB,EACFm5B,EAASnN,0BAA0B/rB,SACnCk5B,EAASnN,0BAA0B9rB;;IAM3C3D,GACEmnB;QAEA,OAAOukB,GACJvkB;;IAILnnB,GACEmnB,GACAwkB,GACAlc;QAEA,OAAOvvB,QAAsBinB,GAAa7f,KAAKs1B,MAC7CA,EAAS+O,8BAA8BA,GACnClc,MACFmN,EAASnN,4BAA4BA;QAEnCkc,IAA8B/O,EAAS+O,gCACzC/O,EAAS+O,8BAA8BA,IAElCzrC,QAAkBinB,GAAayV;;IAI1C58B,GACEmnB,GACAhJ;QAEA,OAAOje,QAAoBinB,MAAyB7f,KAAK,MAChDpH,QAAsBinB,GAAa7f,KAAKs1B,MAC7CA,EAASlQ,eAAe,GACxBxsB,WAA8C08B;QACvC18B,QAAkBinB,GAAayV;;IAK5C58B,GACEmnB,GACAhJ;QAEA,OAAOje,QAAoBinB;;IAG7BnnB,GACEmnB,GACAhJ;QAEA,OAAOje,QAAmCinB,GAAahJ,EAAWlU,UAC/D3C,KAAK,MAAMskC,GAAazkB,GAAa9S,OAAO8J,EAAWlU,WACvD3C,KAAK,MAAMpH,QAAsBinB,IACjC7f,KAAKs1B,MACJ95B,GACE85B,EAASlQ,cAAc,GACvB;QAEFkQ,EAASlQ,eAAe,GACjBxsB,QAAkBinB,GAAayV;;;;;;WAS5C58B,GACEwsB,GACAG,GACAC;QAEA,IAAIziB,IAAQ;QACZ,MAAM8c,IAA4C;QAClD,OAAO2kB,GAAapf,MACT,CAACzkB,GAAKlG;YACb,MAAMsc,IAAaje,KAAKkS,cAAwBvQ;YAE9Csc,EAAWpE,kBAAkB4S,KACgB,SAA7CC,EAAgBpqB,IAAI2b,EAAWlU,cAE/BE,KACA8c,EAASxhB,KAAKvF,QAAsBssB;WAGvCllB,KAAK,MAAM8e,UACX9e,KAAK,MAAM6C;;;;WAMhBnK,GACEwsB,GACAzV;QAEA,OAAO60B,GAAapf,MAAa,CAACzkB,GAAKlG;YACrC,MAAMsc,IAAaje,KAAKkS,cAAwBvQ;YAChDkV;;;IAIJ/W,GACEmnB;QAEA,OAAO0kB,GACJ1kB;;IAILnnB,GACEmnB,GACAyV;QAEA,QA6MFpQ,IA7M2BrF,GA+MpBokB,MACL/e,GACAsf,GAAe9F,QAjNuByB,IAAIqE,GAAe/jC,KAAK60B;;;;QA4MlE,IACEpQ;;IA1MAxsB,GACEmnB,GACAhJ;QAEA,OAAOytB,GAAazkB,GAAasgB,IAC/BvnC,KAAKkS;;;;;;WASTpS,GACEme,GACAye;QAEA,IAAImP,KAAU;QAUd,OATI5tB,EAAWlU,WAAW2yB,EAAS6O,oBACjC7O,EAAS6O,kBAAkBttB,EAAWlU,UACtC8hC,KAAU;QAGR5tB,EAAWpE,iBAAiB6iB,EAAS+O,gCACvC/O,EAAS+O,8BAA8BxtB,EAAWpE;QAClDgyB,KAAU,IAELA;;IAGT/rC,GACEmnB;QAEA,OAAOjnB,QAAsBinB,GAAa7f,KACxCs1B,KAAYA,EAASlQ;;IAIzB1sB,GACEmnB,GACAtN;;;;QAKA,MAAM5J,IAAc4J,EAAO5J,eACrB1G,IAAQq/B,YAAY7wB,MACxB,EAAC9H,GAAa5E,OAAOw9B,qBACrB,EAAC54B,GAAa5E,OAAOy9B;QAEvB,IAAIngC,IAA4B;QAChC,OAAOijC,GAAazkB,MAEhB;YAAE5d,OAAAA;YAAO5D,OAAOqmC,GAASC;WACzB,CAAClkC,GAAKlG,GAAO8lC;YACX,MAAM/0B,IAAQ1S,KAAKkS,cAAwBvQ;;;wBAGvCgY,EAAOhV,QAAQ+N,EAAMiH,YACvBlR,IAASiK,GACT+0B,EAAQhhB;WAIbrf,KAAK,MAAMqB;;IAGhB3I,GACEwsB,GACA5c,GACA3F;;;QAIA,MAAMgd,IAA4C,IAC5C+e,IAAQkG,GAAoB1f;QAMlC,OALA5c,EAAKrK,QAAQwC;YACX,MAAMvB,IAAO2lC,GAAmBpkC,EAAIvB;YACpCygB,EAASxhB,KAAKugC,EAAMyB,IAAI,IAAI2E,GAAiBniC,GAAUzD,MACvDygB,EAASxhB,KAAKvF,WAAoCssB,GAAKzkB;YAElDqe;;IAGTpmB,GACEwsB,GACA5c,GACA3F;;;QAIA,MAAM+7B,IAAQkG,GAAoB1f;QAClC,OAAOpG,GAAmB7gB,QAAQqK,GAAO7H;YACvC,MAAMvB,IAAO2lC,GAAmBpkC,EAAIvB;YACpC,OAAO4f,MAA2B,EAChC4f,EAAM3xB,OAAO,EAACpK,GAAUzD,MACxBtG,WAAuCssB,GAAKzkB;;;IAKlD/H,GACEwsB,GACAviB;QAEA,MAAM+7B,IAAQkG,GAAoB1f,IAC5BjjB,IAAQq/B,YAAY7wB,MACxB,EAAC9N,KACD,EAACA,IAAW;wBACG;wBACA;QAEjB,OAAO+7B,EAAM3xB,OAAO9K;;IAGtBvJ,GACEwsB,GACAviB;QAEA,MAAMV,IAAQq/B,YAAY7wB,MACxB,EAAC9N,KACD,EAACA,IAAW;wBACG;wBACA,IAEX+7B,IAAQkG,GAAoB1f;QAClC,IAAI7jB,IAAS+T;QAEb,OAAOspB,KACI;YAAEz8B,OAAAA;YAAO0hC,KAAU;WAAQ,CAACljC,GAAKiW,GAAG2pB;YAC3C,MAAMnhC,IAAO4jC,GAAmBriC,EAAI,KAC9Bgd,IAAS,MAAgBve;YAC/BmC,IAASA,EAAOgB;WAEjBrC,KAAK,MAAMqB;;IAGhB3I,GACEwsB,GACAzkB;QAEA,MAAMvB,IAAO2lC,GAAmBpkC,EAAIvB,OAC9B+C,IAAQq/B,YAAY7wB,MACxB,EAACvR,KACD,EAAC6lC,GAAmB7lC;wBACL;wBACA;QAEjB,IAAI2D,IAAQ;QACZ,OAAO+hC,SAEH;YACEvmC,OAAOymC,GAAiBE;YACxBrB,KAAU;YACV1hC,OAAAA;WAEF,EAAEU,GAAUzD,IAAOwX,GAAG2pB;;;;YAIH,MAAb19B,MACFE,KACAw9B,EAAQhhB;WAIbrf,KAAK,MAAM6C,IAAQ;;IAGxBnK,GACEmnB,GACAld;QAEA,OAAO2hC,GAAazkB,GACjB3kB,IAAIyH,GACJ3C,KAAKsL,KACAA,IACK1S,KAAKkS,cAAwBQ,KAE7B;;;;;;GASjB,aACE4Z;IAEA,OAAO+e,MACL/e,GACAwf,GAAShG;;;AAgBb,YACExZ;IAMA,OAJoBmY,MAClBnY,GACAsf,GAAe9F,OAEExjC,IAAIspC,GAAe/jC,KAAKT,KAAKs1B,MAC9C95B,GAAwB,SAAb85B,GAAmB;IACvBA;;;YAKTpQ;IAEA,OAAOqf,GAAiBrf,GAAKllB,KAC3BilC,KAAgBA,EAAaZ;;;;;gBAQ/Bnf;IAEA,OAAO+e,MACL/e,GACA4f,GAAiBpG;;;;;;;;;;;;;;;;;;;;;;;IClYnBhmC,YACWoS,GACQuV;QADRznB,kBAAAkS;;;;;;;WAUXpS,GACEmnB,GACApf,GACAwM;QAGA,OADsBi4B,GAAqBrlB,GACtBsgB,IAAIgF,GAAM1kC,IAAMwM;;;;;;;WASvCvU,GACEmnB,GACAC;QAEA,MAAM4e,IAAQwG,GAAqBrlB,IAC7Bpf,IAAM0kC;QACZ,OAAOzG,EAAM3xB,OAAOtM;;;;;;;WASd/H,eACNmnB,GACAulB;QAEA,OAAOxsC,KAAKysC,YAAYxlB,GAAa7f,KAAKs1B,MACxCA,EAASgQ,eACF1sC,QAAiBinB,GAAayV;;IAIzC58B,GACEmnB,GACAC;QAEA,OAAOolB,GAAqBrlB,GACzB3kB,IAAIiqC,OACJnlC,KAAKulC,KACG3sC;;;;;;;WAUbF,GACEmnB,GACAC;QAEA,OAAOolB,GAAqBrlB,GACzB3kB,IAAIiqC,OACJnlC,KAAKulC;YACJ,MAAMt4B,IAAMrU;YACZ,OAAOqU,IACH;gBACEu4B,IAAev4B;gBACf7O,MAAMqnC;gBAER;;;IAIV/sC,WACEmnB,GACAG;QAEA,IAAI5B,IAAUoC;QACd,OAAO5nB,QACLinB,MAEA,CAACpf,GAAK8kC;YACJ,MAAMt4B,IAAMrU;YACZwlB,IAAUA,KAAe3d,GAAKwM;WAEhCjN,KAAK,MAAMoe;;;;;;;;;WAWf1lB,GACEmnB,GACAG;QAEA,IAAI5B,IAAUoC,MACVklB,IAAU,MAAmCtlC;QACjD,OAAOxH,QACLinB,MAEA,CAACpf,GAAK8kC;YACJ,MAAMt4B,IAAMrU;YACRqU,KACFmR,IAAUA,KAAe3d,GAAKwM,IAC9By4B,IAAUA,KAAejlC,GAAKglC,WAE9BrnB,IAAUA,KAAe3d,GAAK,OAC9BilC,IAAUA,KAAejlC,GAAK;WAGlCT,KAAK,OACE;YAAE2lC,IAAgBvnB;YAASwnB,IAAAF;;;IAItChtC,GACEmnB,GACAG,GACAjB;QAEA,IAAIiB,OACF,OAAOlB,GAAmBpkB;QAG5B,MAAMuH,IAAQq/B,YAAY7wB,MACxBuP,EAAa/W,QAAS/J,UACtB8gB,EAAa8D,OAAQ5kB,WAEjB2mC,IAAU7lB;QAChB,IAAI8lB,IAA8BD;QAElC,OAAOX,GAAqBrlB,MACjB;YAAE5d,OAAAA;WAAS,CAAC8jC,GAAiBR,GAAalF;YACjD,MAAM2F,IAAe5lC;;wBAGrB,MAAO0lC,KAAW1lC,YAAiD,KACjE2e,KAAmB,OACnB+mB,IAAUD;YAGRC,KAAWA,EAASvoC;;YAEtBwhB,SACA+mB,IAAUD,SAAoBA,SAAoB;;gBAKlDxF,KAAayF,EAAS5mC,YAEtBmhC,EAAQhhB;WAGXrf,KAAK;;;YAGJ,WACE+e,KAAmB,OACnB+mB,IAAUD,SAAoBA,SAAoB;;;IAK1DntC,GACEmnB,GACA1L,GACAyM;QAMA,IAAIxC,IAAU7K;QAEd,MAAM0yB,IAA8B9xB,EAAMjV,KAAKxB,SAAS,GAElDwoC,IAAmC;QACzC,IAAItlB,EAAcrjB,QAAQF,EAAgBC,MAAM;;;YAG9C,MAAM4D,IAAWiT,EAAMjV;YACvBgnC,EAAiBjkC,QAAQq/B,YAAYgB;eAChC;;;;YAIL,MAAM6D,IAAgBhyB,EAAMjV,UACtBknC,IAAcxtC,KAAKkS;YACzBo7B,EAAiBjkC,QAAQq/B,YAAYgB,WACnC;yBACY,IAEd4D,EAAiB7nC,QAAQgoC,GAAiBC;;QAG5C,OAAOpB,GAAqBrlB,SACC,CAACpf,GAAK8kC,GAAalF;;;;;;YAM5C,IAAI5/B,EAAI/C,cACN;YAGF,MAAMuO,IAAWrT,KAAKkS;YACjBqJ,EAAMjV,OAAgB+M,EAASxL,IAAIvB,QAE7B+M,aAAoBC,MAAYiI,EAAM/C,eAC/CgN,IAAUA,KAAenS,EAASxL,WAFlC4/B,EAAQhhB;WAKXrf,KAAK,MAAMoe;;IAGhB1lB,GACEmnB,GACAe;QAKA,IAAImH,IAAc7U,MAEdqzB,IAAe3tC,KAAKkS;QAExB,MAAM07B,IAAiBtB,GAAqBrlB,IACtC5d,IAAQq/B,YAAYgB,eAAyB;QACnD,OAAOkE,KAEH;YAAEnoC,OAAOgoC,GAAiBI;YAAexkC,OAAAA;WACzC,CAACyU,GAAG6uB;;;YAGF,MAAMt4B,IAAMrU,KAAKkS;YACjBid,IAAcA,KAAmB9a,EAAIxM,KAAKwM,IAC1Cs5B,IAAehB,EAAqB;WAGvCvlC,KAAK,OACG;YACLqpB,IAAAtB;YACAzP,UAAU1f,KAAKkS;;;IAKvBpS,GACEmnB;QAEA,MAAM2mB,IAAiBtB,GAAqBrlB;;gBAG5C,IAAIvH,IAAWjb,EAAgBC;QAE/B,OAAOkpC,KAEH;YAAEnoC,OAAOgoC,GAAiBI;YAAe3F,UAAS;WAClD,CAACrgC,GAAK8kC,GAAalF;YACbkF,EAAYjtB,aACdA,IAAW1f,KAAKkS,cAA8By6B,EAAYjtB,YAE5D+nB,EAAQhhB;WAGXrf,KAAK,MAAMsY;;IAGhB5f,GAAgBqW;QAGd,OAAO,IAAI23B,MACT9tC,QACEmW,KAAWA;;IAIjBrW,GAAQwsB;QACN,OAAOtsB,KAAKysC,YAAYngB,GAAKllB,KAAKs1B,KAAYA,EAASgQ;;IAGjD5sC,YACNwsB;QAEA,OAAOyhB,GAAoBzhB,GACxBhqB,IAAI0rC,GAAuBnmC,KAC3BT,KAAKs1B,MACJ95B,KAAa85B,GAAU;QAChBA;;IAIb58B,GACEwsB,GACAoQ;QAEA,OAAOqR,GAAoBzhB,GAAKib,IAAIyG,GAAuBnmC,KAAK60B;;;;;WAOlE58B,GACE6sC;QAEA,OAAiB;YACf,MAAMt4B,IAAMrU,KAAKkS;YACjB,OACEmC,mBACAA,EAAItB,QAAQpO,QAAQF,SAIb,OAGF4P;;QAET,OAAO;;;;;;;;;;GAqIX,aACEiY;IAEA,OAAO+e,MAGL/e,GAAK0hB,GAAuBlI;;;;;GAMhC,aACExZ;IAEA,OAAO+e,MACL/e,GACAmhB,GAAiB3H;;;AAIrB,YAAejhB;IACb,OAAOA,EAAOve;;;;;gBAMe+N;IAC7B,IAAI1S;IACJ,IAAI0S,EAAIgK,UACN1c,IAAQ0S,EAAIgK,eACP,IAAIhK,EAAI45B,iBACbtsC,IAAQ0S,EAAI45B,sBACP;QAAA,KAAI55B,EAAI65B,YAGb,MAAMlpC,GAAK;QAFXrD,IAAQ0S,EAAI65B;;IAId,OAAOhiC,KAAKC,UAAUxK,GAAOmD;;;;;;;;;;;;;;;;;;;;;GAlK7BgpC,SAA4C,cAAcK;;;;;;IAYxDruC,YACmBsuC,GACAC;QAEjB7sC;;QAdFxB,UAGI,OAAc6H,KAAOA,EAAIpG;;IAc7B3B,GACEmnB;QAEA,MAAMF,IAA4C;QAElD,IAAIylB,IAAY,GAEZnD,IAAoB,MAA4B,CAAC30B,GAAGC,MACtDvQ,GAAoBsQ,OAAqBC;QAsD3C,OAnDA3U,QAAaqF,QAAQ,CAACwC,GAAKmf;YACzB,MAAMsnB,IAAetuC,QAAmBsC,IAAIuF;YAK5C,OAAmB;gBAKjB,MAAMwM,IAAMrU,QAAmBkS,iBAE7BlS,KAAK0f;gBAEP2pB,IAAoBA,EAAkB5/B,IAAI5B,EAAIvB;gBAE9C,MAAMd,IAAOqnC,GAAex4B;gBAC5Bm4B,KAAahnC,OACbuhB,EAASxhB,KAAKvF,WAA4BinB,GAAapf,GAAKwM;mBAG5D,IADAm4B,QACIxsC,SAAoB;;;;;gBAKtB,MAAMuuC,IAAavuC,QAAmBkS,cACpC,OAAerK,GAAKpD,QACpBzE,KAAK0f;gBAEPqH,EAASxhB,KACPvF,WAA4BinB,GAAapf;mBAG3Ckf,EAASxhB,KAAKvF,WAA+BinB,GAAapf;YAKhEwhC,EAAkBhkC,QAAQ8b;YACxB4F,EAASxhB,KACPvF,cACEinB,GACA9F;YAKN4F,EAASxhB,KAAKvF,QAAmBwuC,eAAevnB,QAEzCf;;IAGTpmB,GACEmnB,GACAC;;QAGA,OAAOlnB,WACUinB,MACd7f,KAAKqnC,KACc,SAAdA,KACFzuC,QAAmBkU,OAAiB,IAC7B,SAEPlU,QAAmBkU,OAAiBu6B,EAAUjpC;QACvCipC;;IAKf3uC,GACEmnB,GACAG;;;QAIA,OAAOpnB,WACYinB,MAChB7f,KAAK,EAAG2lC,IAAA2B,GAAgB1B,IAAAF;;;;QAIvBA,EAAQznC,QAAQ,CAAC6hB,GAAa1hB;YAC5BxF,QAAmBkU,OAAiB1O;;;;;;IC/ehD1F;QACEE,UAAgC;;IAEhCF,GACEmnB,GACA0nB;QAGA,OADA3uC,QAA2ByJ,IAAIklC,IACxBzoB,GAAmBpkB;;IAG5BhC,GACEmnB,GACA5f;QAEA,OAAO6e,GAAmBpkB,QACxB9B,QAA2B8nB,WAAWzgB;;;;;;;;;IAU5CvH;QACUE,aAAQ;;;IAKhBF,IAAI6uC;QAEF,MAAMtnC,IAAesnC,OACfC,IAAaD,OACbE,IACJ7uC,KAAKyF,MAAM4B,MACX,MAA4BjB,MACxBq8B,KAASoM,EAAgBrlC,IAAIolC;QAEnC,OADA5uC,KAAKyF,MAAM4B,KAAgBwnC,EAAgBplC,IAAImlC;;IAIjD9uC,IAAI6uC;QACF,MAAMtnC,IAAesnC,OACfC,IAAaD,OACbE,IAAkB7uC,KAAKyF,MAAM4B;QACnC,OAAOwnC,KAAmBA,EAAgBrlC,IAAIolC;;IAGhD9uC,WAAWuH;QAIT,QAFErH,KAAKyF,MAAM4B,MACX,MAA4BjB;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;GC1B3B,OAAMg/B,KAAiB;;6DAGjB0J;IACXhvC,YAA6BoS;QAAAlS,kBAAAkS;;;;;;;;WAS7BpS,gBACE0kC,GACAlY,GACA9M,GACAiB;QAEA7d,GACE4c,IAAciB,KACZjB,KAAe,KACfiB,KAAa2kB,IACf,mCAAmC5lB,SAAmBiB;QAGxD,MAAMsuB,IAAsB,OAAwBziB;QAEhD9M,IAAc,KAAKiB,KAAa,MAsSxC,SAAkC+jB;YAChCA,EAAGwK,kBAAkBC,GAAgBnJ;;;;;;;GAtSjCoJ,EAAyB1K,IAsZ/B,SAA6BA;YAC3BA,EAAGwK,kBAAkBnE,GAAgB/E,OAAO;gBAC1CkF,SAASH,GAAgBG;gBAGExG,EAAGwK,kBAAkBlG,GAAgBhD,OAAO;gBACvEkF,SAASlC,GAAgBkC;gBACzBmE,gBAAe;eAEIC,YACnBtG,GAAgBC,oBAChBD,GAAgBuG,sBAChB;gBAAEC,SAAQ;gBAGZ9K,EAAGwK,kBAAkBzF,GAAmBzD;;;;;GApapCyJ,EAAoB/K,IACpBgL,GAAiBhL,IAmgBvB,SAAmCA;YACjCA,EAAGwK,kBAAkBvB,GAAiB3H;;;;;GAngBlC2J,EAA0BjL;;;gBAM5B,IAAIlrB,IAAI4M,GAAmBpkB;QA+D3B,OA9DI0d,IAAc,KAAKiB,KAAa;;;QAGd,MAAhBjB,OA03BV,SAAwBglB;YACtBA,EAAGkL,kBAAkBxD,GAAiBpG,QACtCtB,EAAGkL,kBAAkB5D,GAAShG,QAC9BtB,EAAGkL,kBAAkB9D,GAAe9F;SA53B9B6J,CAAenL,IACfgL,GAAiBhL,KAEnBlrB,IAAIA,EAAElS,KAAK;;;;;;QAu4BjB,SACEklB;YAEA,MAAMsjB,IAActjB,EAAIwZ,MACtB8F,GAAe9F,QAEXpJ,IAAW,IAAIkP;iCACE;0CACS,GAC9BnnC,EAAgBC;6BACC;YAEnB,OAAOkrC,EAAYrI,IAAIqE,GAAe/jC,KAAK60B;;;;;GAn5BtBmT,QAGfrwB,IAAc,KAAKiB,KAAa,MACd,MAAhBjB;;;;;;;QAOFlG,IAAIA,EAAElS,KAAK,MAgZnB,SACEo9B,GACAlY;YAKA,OAHyBA,EAAIwZ,MAC3BgD,GAAgBhD,YAEgB1+B,KAAK0oC;gBACrCtL,EAAGkL,kBAAkB5G,GAAgBhD,QAEdtB,EAAGwK,kBAAkBlG,GAAgBhD,OAAO;oBACjEkF,SAASlC,GAAgBkC;oBACzBmE,gBAAe;mBAEFC,YACbtG,GAAgBC,oBAChBD,GAAgBuG,sBAChB;oBAAEC,SAAQ;;gBAGZ,MAAMS,IAAmBzjB,EAAIwZ,MAC3BgD,GAAgBhD,QAEZkK,IAAWF,EAAkBjpC,IAAIsZ,KACrC4vB,EAAiBxI;gBAGnB,OAAOrhB;;;;;;;;;GA1aD+pB,EAAyCzL,SAI7ClrB,IAAIA,EAAElS,KAAK;aAu7BjB,SAAmCo9B;gBACjCA,EAAGwK,kBAAkBkB,GAAiBpK,OAAO;oBAC3CkF,SAASkF,GAAiBlF;;;kCAx7BtBmF;aAA0B3L;aAI1BhlB,IAAc,KAAKiB,KAAa,MAClCnH,IAAIA,EAAElS,KAAK,MAAMpH,KAAKowC;QAGpB5wB,IAAc,KAAKiB,KAAa,MAClCnH,IAAIA,EAAElS,KAAK,OAilBjB,SAAmCo9B;YACjCA,EAAGwK,kBAAkBhB,GAAuBlI;;;;;;;;;;GAjlBtCuK,EAA0B7L,IACnBxkC,KAAKswC,yBAIZ9wB,IAAc,KAAKiB,KAAa,MAClCnH,IAAIA,EAAElS,KAAK,MAAMpH,KAAKuwC;QAGpB/wB,IAAc,KAAKiB,KAAa,MAClCnH,IAAIA,EAAElS,KAAK,MACTpH,KAAKwwC,4BAA4BhM,SAIjChlB,IAAc,KAAKiB,KAAa,MAClCnH,IAAIA,EAAElS,KAAK;;;;aAi1BjB,SAAwCo9B;gBAClCA,EAAGyC,iBAAiB3R,SAAS,4BAC/BkP,EAAGkL,kBAAkB;aA/0BjBe,CAA+BjM,IA22BvC,SAA2ClY;gBACzC,MAAMokB,IAAsBpkB,EAAI+a,YAAYoG,GAAiB3H;gBAC7D4K,EAAoBtB,YAClB3B,GAAiBI,eACjBJ,GAAiBkD,mBACjB;oBAAErB,SAAQ;oBAEZoB,EAAoBtB,YAClB3B,GAAiBC,yBACjBD,GAAiBmD,6BACjB;oBAAEtB,SAAQ;;;;;;;;GAp3BNuB,EAAkCvkB;aAIlC9M,IAAc,MAAMiB,KAAa,OACnCnH,IAAIA,EAAElS,KAAK,MAAMpH,KAAK8wC,0BAEjBx3B;;IAGDxZ,kBACNwsB;QAEA,IAAIykB,IAAY;QAChB,OAAOzkB,EACJwZ,MAA6C2H,GAAiB3H,UACtD,CAAChoB,GAAGzJ;YACX08B,KAAalE,GAAex4B;WAE7BjN,KAAK;YACJ,MAAMs1B,IAAW,IAAIsR;YACrB,OAAO1hB,EACJwZ,MACCkI,GAAuBlI,OAExByB,IAAIyG,GAAuBnmC,KAAK60B;;;IAIjC58B,4BACNwsB;QAEA,MAAM0kB,IAAc1kB,EAAIwZ,MACtB+E,GAAgB/E,QAEZ+C,IAAiBvc,EAAIwZ,MACzBgD,GAAgBhD;QAGlB,OAAOkL,OAAsB5pC,KAAK6pC,KACzB/qB,GAAmB7gB,WAAiBqxB;YACzC,MAAMrtB,IAAQq/B,YAAY7wB,MACxB,EAAC6e,EAAM+G,SvC7Jc,KuC8JrB,EAAC/G,EAAM+G,QAAQ/G,EAAMwa;YAGvB,OAAOrI,KACIC,GAAgBC,oBAAoB1/B,GAC5CjC,KAAKwiC,KACG1jB,GAAmB7gB,WAEvB+jC;gBACCxmC,GACEwmC,EAAQ3L,WAAW/G,EAAM+G,QACzB,wBAAwB2L,EAAQ1kB;gBAElC,MAAMU,IAAQplB,KAAKkS;gBAEnB,OAAOs4B,GACLle,GACAoK,EAAM+G,QACNrY,GACAhe,KAAK;;;;;;;WAYbtH,sBACNwsB;QAEA,MAAM0f,IAAsB1f,EAAIwZ,MAG9BoG,GAAiBpG,QACb8H,IAAiBthB,EAAIwZ,MACzB2H,GAAiB3H;QAGnB,OAAO0F,GAA+Blf,GAAKllB,KAAK+pC;YAC9C,MAYMpqB,IAA4C;YAClD,OAAO6mB,KACI,CAAC/lC,GAAKwM;gBACb,MAAM/N,IAAO,IAAIF,EAAayB,IACxBupC,IA4EhB,SAAqB9qC;oBACnB,OAAO,EAAC,GAAG2lC,GAAmB3lC;;;;GA7EC+qC,EAAY/qC;gBACnCygB,EAASxhB,KACPymC,EAAoB1pC,OAAoB8E,KAAKkqC,SAIlCprB,GAAmBpkB,YAtBX,CACvBwE,KAEO0lC,EAAoBzE,IACzB,IAAI2E,GACF,GACAD,GAAmB3lC,QAcRirC,CAAiBjrC;eAO/Bc,KAAK,MAAM8e;;;IAIVpmB,4BACN0kC,GACAlY;;QAGAkY,EAAGwK,kBAAkBwC,GAAmB1L,OAAO;YAC7CkF,SAASwG,GAAmBxG;;QAG9B,MAAMyG,IAAyBnlB,EAAIwZ,MAGjC0L,GAAmB1L,QAGf4L,IAAQ,QACRC,IACJhD;YAEA,IAAI+C,EAAMjoC,IAAIklC,IAAiB;gBAC7B,MAAMtnC,IAAesnC,OACfC,IAAaD;gBACnB,OAAO8C,EAAuBlK,IAAI;oBAChClgC,cAAAA;oBACA8Z,QAAQ8qB,GAAmB2C;;;;;;QAMjC,OAAOtiB,EACJwZ,MAA6C2H,GAAiB3H,UACtD;YAAEiF,KAAU;WAAQ,CAAC6G,GAAc9zB;YAC1C,MAAMxX,IAAO,IAAIF;YACjB,OAAOurC,EAASrrC;WAEjBc,KAAK,MAEGklB,EACJwZ,MACCyD,GAAmBzD,UAEZ;YAAEiF,KAAU;WAAQ,EAAEf,GAAQC,GAAavlB,IAAU5G;YAC5D,MAAMxX,IAAO4jC;YACb,OAAOyH,EAASrrC;;;IAKlBxG,oBACNwsB;QAEA,MAAMulB,IAAcvlB,EAAIwZ,MAA6BgG,GAAShG;QAC9D,OAAO+L,KAAoB,CAAChqC,GAAKiqC;YAC/B,MAAMC,IAAqB/xC,KAAKkS,kBAC1B8/B,IAAkBhyC,KAAKkS;YAC7B,OAAO2/B,EAAYtK;;;;;MAYZ0K;IACXnyC,YAAmB0D,GAAwBC;QAAxBzD,eAAAwD,GAAwBxD,mBAAAyD;;;;;;;;;;;;UAkBhCwrC;IAgBXnvC,YACSoyC;;IAEAC,GACAC;QAHApyC,eAAAkyC,GAEAlyC,+BAAAmyC,GACAnyC,wBAAAoyC;;;;;;;;;;GAZFnD,YAAQ;;;;;AAMRA,SAAM;;MAuBFpE;IAOX/qC;;;;IAIS29B;;;;;;;;;IASAyT;;;;;;;;;;IAUAzY;QAnBAz4B,cAAAy9B,GASAz9B,+BAAAkxC,GAUAlxC,uBAAAy4B;;;;2CA5BFoS,YAAQ;;AAGRA,aAAU;;;;;;;;;MAuCN/B;IAaXhpC;;;;IAIS29B;;;;IAIA/Y;;;;;IAKA2tB;;;;;;;;;;;;;IAaA1tB;;;;;;IAMAC;QA5BA5kB,cAAAy9B,GAIAz9B,eAAA0kB,GAKA1kB,wBAAAqyC,GAaAryC,qBAAA2kB;QAMA3kB,iBAAA4kB;;;;2CA3CFkkB,YAAQ;;AAGRA,aAAU;;AAGVA,wBAAqB;;AAGrBA,0BAAuB,EAAC,UAAU;;MAyG9BS;IA0CXzpC;;;;WAnCAA,qBAAqB29B;QACnB,OAAO,EAACA;;;;;WAOV39B,qBACE29B,GACAn3B;QAEA,OAAO,EAACm3B,GAAQwO,GAAmB3lC;;;;;WAOrCxG,WACE29B,GACAn3B,GACAoe;QAEA,OAAO,EAAC+Y,GAAQwO,GAAmB3lC,IAAOoe;;;;AA9BrC6kB,WAAQ;;;;;;;AAuCRA,iBAAc,IAAIA;;MAmBd+I;IACXxyC,YAAmBwG,GAAuBoZ;QAAvB1f,YAAAsG,GAAuBtG,gBAAA0f;;;;;;;UAO/B6yB;IACXzyC,YAAmBwG,GAAuByM;QAAvB/S,YAAAsG,GAAuBtG,eAAA+S;;;;;;;;;;;;;;;;UAgB/B06B;;;;;;IA8BX3tC;;;;;;IAMSmuC;;;;;IAKAC;;;;;IAKA7vB;;;;;;;IAOA3K;;;;;IAMAgM;;;;;IAMAkvB;QA7BA5uC,uBAAAiuC,GAKAjuC,kBAAAkuC,GAKAluC,gBAAAqe,GAOAre,6BAAA0T;QAMA1T,gBAAA0f,GAMA1f,kBAAA4uC;;;;AAhEFnB,WAAQ;;;;;;;AAQRA,mBAAgB,iBAEhBA,uBAAoB;;;;;;;;AASpBA,6BAA0B,2BAE1BA,iCAA8B,EAAC,cAAc;;;;;MAkDzCO;;;;;IASXluC,YAAmB4sC;QAAA1sC,gBAAA0sC;;;;AARZsB,WAAQ,wBAERA,SAAM;;MAoCFlC;IAgBXhsC;;;;;;;;;IASSiK;;;;IAIAgG;;;;;;IAMA2P;;;;;;;;;;;;;;;;;;IAkBA1F;;;;;;;;;;;;;;;IAeAw4B;;;;;;IAMAz4B;;;;;;;;IAQAwB;QAzDAvb,gBAAA+J,GAIA/J,mBAAA+P,GAMA/P,gBAAA0f,GAkBA1f,mBAAAga;QAeAha,gCAAAwyC,GAMAxyC,oCAAA+Z,GAQA/Z,aAAAub;;;;AAjFFuwB,WAAQ;;AAGRA,aAAU;;AAGVA,2BAAwB;;;;;;AAOxBA,yBAAsB,EAAC,eAAe;;;;;;;;;;;;MAwFlCI;IAaXpsC;;;;IAISiK;;;;IAIAzD;;;;;;IAMAuT;QAVA7Z,gBAAA+J,GAIA/J,YAAAsG,GAMAtG,sBAAA6Z;;;;2CAzBFqyB,YAAQ;;AAGRA,aAAU,EAAC,YAAY;;AAGvBA,0BAAuB;;AAGvBA,4BAAyB,EAAC,QAAQ;;;;;;;;MAoC9BN;IAQX9rC;;;;;;IAMSyrC;;;;;;IAMAE;;;;;;;;;IASAlc;;;;IAIA/C;QAnBAxsB,uBAAAurC,GAMAvrC,mCAAAyrC,GASAzrC,iCAAAuvB;QAIAvvB,mBAAAwsB;;;;;;;GA5BFof,UAAM,mBACNA,WAAQ;;;;;;;;MA4CJ4F;IAOX1xC;;;;IAISuH;;;;;IAKA8Z;QALAnhB,oBAAAqH,GAKArH,cAAAmhB;;;;0CAIX,aAA0BqjB;IACKA,EAAGwK,kBAAkB9C,GAAiBpG,OAAO;QACxEkF,SAASkB,GAAiBlB;OAEPoE,YACnBlD,GAAiBE,sBACjBF,GAAiBuG,wBACjB;QAAEnD,SAAQ;;;IAGQ9K,EAAGwK,kBAAkBlD,GAAShG,OAAO;QACvDkF,SAASc,GAASd;OAIRoE,YACVtD,GAASC,uBACTD,GAAS4G,qBACT;QAAEpD,SAAQ;QAEZ9K,EAAGwK,kBAAkBpD,GAAe9F;;;AAtC7B0L,WAAQ;;AAGRA,aAAU,EAAC,gBAAgB;;MA8FvBtB;IAOXpwC;;;;IAKS66B;;IAEAS;;IAEAjL;;IAEAwiB;QANA3yC,gBAAA26B,GAEA36B,oBAAAo7B,GAEAp7B,sBAAAmwB,GAEAnwB,oBAAA2yC;;;;0CAhBFzC,YAAQ;;AAGRA,aAAU;;AA2BZ,MAqCM0C,KAXY,KAJA,KAJA,KAlBA,EACvB/H,GAAgB/E,OAChBgD,GAAgBhD,OAChByD,GAAmBzD,OACnB2H,GAAiB3H,OACjBgG,GAAShG,OACTmJ,GAAgBnJ,OAChB8F,GAAe9F,OACfoG,GAAiBpG,SAUqBoK,GAAiBpK,SAIjBkI,GAAuBlI,SAIvB0L,GAAmB1L;;;;;;;;;;;;;;;;;;;;;;;;IC1iC3DhmC;;;;;;;;QAQEE,UAAiC;;;;;;;;WASjCF,GACEmnB,GACA0nB;QAGA,KAAK3uC,QAA4BwJ,IAAImlC,IAAiB;YACpD,MAAMtnC,IAAesnC,OACfC,IAAaD;YAEnB1nB,KAAmC;;;gBAGjCjnB,QAA4ByJ,IAAIklC;;YAGlC,MAAMkE,IAAuC;gBAC3CxrC,cAAAA;gBACA8Z,QAAQ8qB,GAAmB2C;;YAE7B,OAAO6C,GAAuBxqB,GAAasgB;;QAE7C,OAAOrhB,GAAmBpkB;;IAG5BhC,GACEmnB,GACA5f;QAEA,MAAMyrC,IAAc,IACdzpC,IAAQq/B,YAAY7wB,MACxB,EAACxQ,GAAc,MACf,EAAC8kC,GAAmB9kC,IAAe;wBACpB;wBACA;QAEjB,OAAOoqC,GAAuBxqB,MACnB5d,GACRjC,KAAKoO;YACJ,KAAK,MAAMwV,KAASxV,GAAS;;;;;gBAK3B,IAAIwV,EAAM3jB,iBAAiBA,GACzB;gBAEFyrC,EAAYvtC,KAAK2kC,GAAmBlf,EAAM7J;;YAE5C;;;;;;;;GASR,aACEmL;IAEA,OAAO+e,MAGL/e,GAAKklB,GAAmB1L;;;;;;;;;;;;;;;;;;;6DCtEfiN;IACXjzC,YAAoBkzC;;;4EAGpBlzC,GAAqBwwB;QACnB,IAAIA,EAAUjS,UACZ,OAAOre,WACLswB,EAAUjS,YACRiS,EAAU5c;QAET,IAAI4c,EAAU4d,YAAY;YAC/B,MAAMrmC,IAAML,KAAyB8oB,EAAU4d,WAAW5nC,OACpDyM,IAAU/S,QAAqBswB,EAAU4d,WAAWxuB;YAC1D,OAAO,OAAe7X,GAAKkL,GAAS;gBAClCW,yBAAyB4c,EAAU5c;;;QAEhC,IAAI4c,EAAU2d,iBAAiB;YACpC,MAAMpmC,IAAML,KAAyB8oB,EAAU2d,gBAAgB3nC,OACzDyM,IAAU/S,QAAqBswB,EAAU2d,gBAAgBl7B;YAC/D,OAAO,OAAoBlL,GAAKkL;;QAEhC,OAAO/N,GAAK;;sDAKhBlF,GACEuT,GACAqM;QAEA,MAAMuzB,IAAajzC,QAAsB0f,IACnCkvB,IAAav7B,EAASxL,IAAIvB;QAChC,IAAI+M,aAAoBC,IAAU;YAChC,MAAMe,IAAMrU,eACN0T,IAAwBL,EAASK;YACvC,OAAO,IAAI+5B;mCACc;8BACL,MAClBp5B,GACAX,MAEAk7B;;QAEG,IAAIv7B,iBAAgC;YACzC,MAAM/M,IAAO+M,EAASxL,IAAIvB,UACpBoZ,IAAW1f,QAAmBqT,EAASN,UACvCW,IAAwBL,EAASK;YACvC,OAAO,IAAI+5B;mCACc,MACvB,IAAI6E,GAAahsC,GAAMoZ;4BACP,MAChBhM,MAEAk7B;;QAEG,IAAIv7B,iBAAqC;YAC9C,MAAM/M,IAAO+M,EAASxL,IAAIvB,UACpBoZ,IAAW1f,QAAmBqT,EAASN;YAC7C,OAAO,IAAI06B,GACT,IAAI8E,GAAkBjsC,GAAMoZ;8BACV;4BACF;0CACa,MAE7BkvB;;QAGF,OAAO5pC,GAAK;;IAIhBlF,GAAiBga;QACf,MAAMtV,IAAYsV;QAClB,OAAO,EAACtV,EAAUhB,SAASgB,EAAUf;;IAGvC3D,GAAmBozC;QACjB,MAAM1uC,IAAY,IAAIjB,EAAU2vC,EAAe,IAAIA,EAAe;QAClE,OAAOzuC,IAA8BD;;IAGvC1E,GAAsBga;QACpB,MAAMtV,IAAYsV;QAClB,OAAO,IAAIm4B,GAAYztC,EAAUhB,SAASgB,EAAUf;;IAGtD3D,GAAwBqzC;QACtB,MAAM3uC,IAAY,IAAIjB,EACpB4vC,EAAY3vC,SACZ2vC,EAAY1vC;QAEd,OAAOgB,IAA8BD;;qFAIvC1E,GAAkB29B,GAAgBrY;QAChC,MAAMguB,IAA0BhuB,EAAMT,cAAc9d,IAAIqe,KACtDllB,gBAEIqzC,IAAsBjuB,EAAMR,UAAU/d,IAAIqe,KAC9CllB;QAEF,OAAO,IAAI8oC,GACTrL,GACArY,EAAMV,SACNU,KAAqBlhB;;6DAOzBpE,GAAoBspC;QAClB,MAAMzkB,KAAiBykB,EAAQzkB,iBAAiB,IAAI9d,IAAIqe,KACtDllB,gBAEI4kB,IAAYwkB,EAAQxkB,UAAU/d,IAAIqe,KACtCllB,gBAEIwE,IAAYjB,EAAUG,WAAW0lC,EAAQiJ;QAC/C,OAAO,OACLjJ,EAAQ1kB,SACRlgB,GACAmgB,GACAC;;iDAKJ9kB,GAAawzC;QACX,MAAMvgC,IAAU/S,QAAqBszC,EAAS5zB,WACxC3F,SACsChV,MAA1CuuC,EAASv5B,+BACL/Z,QAAqBszC,EAASv5B,gCAC9BtV,EAAgBC;QAEtB,IAAIiV;QAMJ,OAJEA,SAwDkD5U,MAzDhCuuC,EAAS/3B,MAyDSQ,YAxD3B/b,WAA0CszC,EAAS/3B,SAEnDvb,WAAsCszC,EAAS/3B;QAEnD,OACL5B,GACA25B,EAASvpC,2BAETupC,EAASd,0BACTz/B,GACAgH,GACAvO,EAAWuF,iBAAiBuiC,EAASt5B;;sEAKzCla,GAAWme;QAQT,MAAMk1B,IAAcnzC,QAAmBie,OACjCs1B,IAA2BvzC,QAC/Bie,EAAWlE;QAEb,IAAIy5B;QAEFA,IADEv1B,EAAWtE,cACA3Z,WAAwCie,EAAWtE,UAEnD3Z,WAAoCie,EAAWtE;;;gBAK9D,MAAMK,IAAciE,EAAWjE,YAAY7J;;gBAG3C,OAAO,IAAI27B,GACT7tB,EAAWlU,UACXkU,EAAWtE,OAAO5J,kBAElBiK,GACAiE,EAAWpE;;;;;;;;;;;;;;;;;;;;;;;ACtJjB,MAyBM45B,KACJ;;;;;qBAYwCC;IACxC5zC,YACWivC,GACAoC;QAET3vC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;IA2IF1B,YACmBqyC,GACAnuB,GACA2W,GACjBjY,GACAixB,GACiBjd,GACjBxkB,GACiB4W;QAejB,IAtBiB9oB,+BAAAmyC,GACAnyC,sBAAAgkB,GACAhkB,gBAAA26B;kCAhCnB36B,WAAmB,GACXA,kBAAY,GACZA,uBAAiB;;QAIzBA,UAAmD,MAC3CA,qBAAe;;QAKvBA,UAAkE;;QAGlEA,UAAkE;;QAGlEA,UAAoCmL,OAAOw9B;;QAG3C3oC,UAAqD8d,KAAKjc,QAAQC,WAkBhE9B,UAAyB,OAAyBA,UAClDA,UAAcgkB,IAAiBqnB;QAC/BrrC,KAAKkS,aAAa,IAAI6gC,GAAgB7gC,IACtClS,KAAKqe,WAAWqE,EAASrE,UACzBre,UAAmB,OACjBA,SACAA,KAAKkS;QAEPlS,UAAoB,QACpBA,UAA2B,OACzBA,KAAKkS,YACLlS,WAEE0iB,EAASkZ,WAAUlZ,EAASkZ,OAAOC,cAIrC,MAAM,IAAIz6B,EACRlB,EAAKc,eACL;QALFhB,KAAK47B,SAASlZ,EAASkZ,QACvB57B,UAAkBA,KAAK47B,OAAOC;;IAjHlC/7B,UACEwsB,GACAwZ;QAEA,IAAIxZ,iBACF,OAAOmY,MAA8BnY,MAAyBwZ;QAE9D,MAAM9gC,GACJ;;IAWNlF,gBAAwCqW;QAUtC,KAAKk1B,SACH,MAAM,IAAIjqC,EACRlB,EAAKc,eA/FX;QAoGE,MAAMusB,IAAc,OAClBpX,EAAQg8B,yBACRh8B,EAAQ6N,gBACR7N,EAAQwkB,UACRxkB,EAAQuM,UACRvM,MACAA,MACAA,EAAQjE,YACRiE;QAGF,aADMoX,EAAYhkB,SACXgkB;;;;;;WAgFDztB;QAIN,OAAO2kC,MACLzkC,SACAolC,IACA,IAAI0J,GAAgB9uC,KAAKkS,aAExB3P,KAAKiiC,MACJxkC,UAAgBwkC,GAGTxkC,YAERuC,KAAK,OACJvC;QACAA,WAEAA,WAEOA,QAAc6tB,eACnB,YACA,EAAC+d,GAAe9F,SAChBxZ,KAAOkf,GAA+Blf,MAGzC/pB,KAAKkpC;YACJzrC,UAAsB,OACpByrC,GACAzrC;WAGHuC,KAAK;YACJvC,WAAgB;WAEjBypB,MAAMK,MACL9pB,WAAiBA,QAAcs3B,SACxBz1B,QAAQykB,OAAOwD;;IAI5BhqB,GACE8zC;QAOA,OALA5zC,UAA4B0wB,MAAMmjB;YAChC,IAAI7zC,SACF,OAAO4zC;WAGJA,EAAqB5zC,KAAKk6B;;IAGnCp6B,GACEg0C;QAEA9zC,WAAuC0wB,MAAM4L;;YAElB,SAArBA,EAAMyX,oBACFD;;;IAKZh0C,GAAkBqwB;QACZnwB,KAAKmwB,mBAAmBA,MAC1BnwB,KAAKmwB,iBAAiBA;;;QAGtBnwB,WAA4B0wB;YACtB1wB,iBACIA;;;;;;;;WAYdF;QACE,OAAOE,QACJ6tB,eAAe,aAAa+kB,IAAYtmB,KACjB0nB,GAAoB1nB,GAEvCib,IACC,IAAI2I,GACFlwC,KAAK26B,UACLh3B,KAAKC,OACL5D,KAAKmwB,gBACLnwB,KAAK2yC,eAGRvrC,KAAK;YACJ,IAAIpH,KAAKk6B,WACP,OAAOl6B,QAAwBssB,GAAKllB,KAAKkzB;sBAErCt6B,KAAKk6B,aAAY,GACjBl6B,WAA4B,MAC1BA,SAA0B;;WAMnCoH,KAAK,MAAMpH,QAAqBssB,IAChCllB,KAAK6sC,KACAj0C,KAAKk6B,kBACAl6B,QAA+BssB,GAAKllB,KAAK,OAAM,YAE/CpH,QAAiCssB,GAAKllB,KAAK,OAAM,KAM/DqiB,MAAMlG;YACL,KAAKvjB,KAAKmyC,yBACR,MAAM5uB;YAQR,OALA9E,GAzVQ,wBA2VN,0DACA8E;8BAEsB;WAEzBhhB,KAAK23B;YACAl6B,KAAKk6B,cAAcA,KACrBl6B,WAA4B,MAC1BA,QAA0Bk6B,KAG9Bl6B,KAAKk6B,YAAYA;;;IAIvBp6B,GACEwsB;QAGA,OADc4nB,GAAmB5nB,GACpBhqB,IAAI2sC,GAAgBpnC,KAAKT,KAAK+sC,KAClCjuB,GAAmBpkB,QAAQ9B;;IAItCF,GACEwsB;QAGA,OADsB0nB,GAAoB1nB,GACrBnY,OAAOnU,KAAK26B;;;;;;WAQ3B76B;QACN,IACEE,KAAKk6B,cACJl6B,QAAiBA,SA5XE,OA6XpB;YACAA,UAAiC2D,KAAKC;;;;;;mBAER5D,KAAK6tB,eACjC,uCACA,qBACAvB;gBACE,MAAM8nB,IAAgB/I,MAGpB/e,GAAK4jB,GAAiBpK;gBAExB,OAAOsO,OAAwBhtC,KAAK60B;oBAClC,MAAMoY,IAASr0C,WA1YD,OA8YRs0C,IAAWrY,EAAgBx1B,OAC/B8tC,MAAsC,MAA5BF,EAAO9tC;;oBAInB,OAAO2f,GAAmB7gB,WAEvBmvC,KACCJ,EAAcjgC,OAAOqgC,EAAe7Z,WACtCvzB,KAAK;;eAGXqiB,MAAM,MAKC,KAQOpkB,QAAQmvC;gBACtBx0C,KAAK47B,OAAOC,aAAae,WACvB58B,QAAkCw0C,EAAe7Z;;;;;;;WAUzD76B;QACEE,UAA+BA,mEAnaS,KAsatC,MACSA,UACJuC,KAAK,MAAMvC,WACXuC,KAAK,MAAMvC;;2DAMpBF,GAAsBy0C;QACpB,SAAOA,KAASA,EAAOrC,YAAYlyC,KAAK26B;;;;;;;;WAU1C76B,GACEwsB;QAGA,OADc4nB,GAAmB5nB,GAE9BhqB,IAAI2sC,GAAgBpnC,KACpBT,KAAKqtC;;;;;;;;;YAiBJ,IAfqB,SAAnBA,KACAz0C,QACEy0C,EAAerC,kBA9cS,SAidzBpyC,QAAqBy0C,EAAevC,UAUd;gBACvB,IAAIlyC,cAAsCA,KAAKmwB,gBAC7C,QAAO;gBAGT,KAAKnwB,YAAoC;oBACvC,KAAKy0C,EAAgBtC;;;;;;;;;;;;oBAanB,MAAM,IAAI/wC,EACRlB,EAAKW;oBAKT,QAAO;;;YAIX,UAAIb,KAAKmwB,mBAAkBnwB,KAAK2yC,iBAIzBqB,GAAoB1nB,QAExBllB,KAAK60B,UAwB0Bl3B,MArBH/E,WAjgBH,KAogBtBmO,KAAKumC;gBACL,IAAI10C,KAAK26B,aAAa+Z,EAAY/Z,UAAU;oBAC1C,MAAMga,KACH30C,KAAKmwB,kBAAkBukB,EAAYvkB,gBAChCykB,KACH50C,KAAK2yC,gBAAgB+B,EAAY/B,cAC9BkC,IACJ70C,KAAKmwB,mBAAmBukB,EAAYvkB;oBACtC,IACEwkB,KACCC,QAGD,QAAO;;gBAGX,QAAO;;WAKdxtC,KAAK6sC,MACAj0C,KAAKk6B,mBACPzb,GAxiBM,wBA0iBJ,UACEw1B,IAAkB,OAAO;;;IAQrCn0C;;;QAGEE,WAAgB,GAEhBA,WACIA,YACFA,QAA6BisB,UAC7BjsB,UAA+B,OAEjCA;QACAA,iBACMA,QAAc6tB,eAClB,aACA,EAACohB,GAAgBnJ,OAAOoK,GAAiBpK,SACzCxZ,KACStsB,QAA+BssB,GAAKllB,KAAK,MAC9CpH,QAA0BssB;QAIhCtsB,QAAcs3B;;;QAIdt3B;;;;;WAOFF,GACEg1C,GACAC;QAEA,OAAOD,EAAQruC,OACb8tC,KACEv0C,QAAiBu0C,EAAOnZ,qBACvBp7B,QAAqBu0C,EAAO5Z;;IAInC76B;QACE,OAAOE,QAAc6tB,eACnB,YACA,EAACqiB,GAAiBpK,SAClBxZ,KACS0nB,GAAoB1nB,QAExBllB,KAAK0tC,KACJ90C,WAhmBc,MAgmBuC6G,IACnDmuC,KAAkBA,EAAera;;IAO7C76B,8BAA8BkkB;QAC5B,KAAKqnB,SACH,OAAOxpC,QAAQC;QAEjB,MAAMmzC,IAASjxB,IAAiBqnB;cAC1B5G,GAAStwB;;IAGjB+X;QACE,OAAOlsB;;IAGTF,GAAiB8B;QAKf,OAAOszC,MACLtzC,GACA5B,KAAKkS,YACLlS,SACAA;;IAIJF;QAKE,OAAOE;;IAGTF;QAKE,OAAOE;;IAGTF;QAKE,OAAOE;;IAGTF,eACEoI,GACA4nB,GACAqlB;QAIA12B,GAtqBY,wBAsqBM,yBAAyBvW;QAE3C,MAAMktC,IAAwB,eAATtlB,IAAsB,aAAa;QAExD,IAAIulB;;;gBAIJ,OAAOr1C,QACJ6tB,kBAA6B+kB,IAAY0C,MACxCD,IAAyB,UAEvBr1C,QAAoBoH;QAGT,wBAAT0oB,IAMK9vB,WACJoH,KAAKmuC,YAIGv1C,YAERoH,KAAKmuC;YACJ,QAQE,MAPAr7B,GACE,8CAA8ChS,QAEhDlI,KAAKk6B,aAAY;YACjBl6B,WAA4B,MAC1BA,SAA0B,KAEtB,IAAIoB,EACRlB,EAAKW;YAIT,OAAOs0C;WAER/tC,KAAKqB,KACGzI,WAA8CoH,KACnD,MAAMqB,MAILzI,WAAgDoH,KAAK,MAC1D+tC,QAIL5yC,KAAKkG,MACJ4sC;QACO5sC;;;;;;;;IAUb3I,GACEwsB;QAGA,OADc4nB,GAAmB5nB,GACpBhqB,IAAI2sC,GAAgBpnC,KAAKT,KAAKqtC;YASzC,IAPqB,SAAnBA,KACAz0C,QACEy0C,EAAerC,kBApuBW,SAuuB3BpyC,QAAqBy0C,EAAevC,aAEXlyC,eACrBy0C,EAAgBtC,yBACnB,MAAM,IAAI/wC,EACRlB,EAAKW;;;;;;WAYff,GACEwsB;QAEA,MAAMkpB,IAAa,IAAIvG,GACrBjvC,KAAK26B,UACL36B,KAAKmyC,yBACLxuC,KAAKC;QAEP,OAAOswC,GAAmB5nB,GAAKib,IAAI0H,GAAgBpnC;;IAGrD/H;QACE,OAAO2kC;;;;;WAOT3kC,UAA0B21C;;;;;;QAQxB,IAAItkC,IAAWskC,KAAwBvkC;QAKvC,OAJKukC,YACHtkC,KAAY,MAAMskC,KAAwBtkC,WAGrC,eAAeskC,EAAazxB,iBAAiB,MAAM7S,IAAW;;qFAIvErR,GACEwsB;QAEA,MAAMwZ,IAAQoO,GAAmB5nB;QACjC,OAAOwZ,EAAMxjC,IAAI2sC,GAAgBpnC,KAAKT,KAAK+sC,KACrCn0C,cACFye,GA/yBQ,wBA+yBU;QACXqnB,EAAM3xB,OAAO86B,GAAgBpnC,QAE7Bqe,GAAmBpkB;;iEAMhChC,GAAoBs7B,GAAsBsa;QACxC,MAAM9xC,IAAMD,KAAKC;QAGjB,SAAIw3B,IAFkBx3B,aAIXw3B,IAHWx3B,OAIpBsW,GACE,kDAAkDkhB,OALhCx3B;SAOb;;IAMX9D;QAEsB,SAAlBE,KAAKqe,YACqC,qBAAnCre,KAAKqe,SAAS2d,qBAErBh8B,UAAiC;YAC/BA,WAA4B,OAC1BA,KAAK2yC,eAAkD,cAAnC3yC,KAAKqe,SAAUs3B;YAC5B31C;WAIXA,KAAKqe,SAAS2d,iBACZ,oBACAh8B,UAGFA,KAAK2yC,eAAiD,cAAlC3yC,KAAKqe,SAASs3B;;IAItC71C;QACME,YAMFA,KAAKqe,SAASwe,oBACZ,oBACA78B,UAEFA,UAAiC;;;;;;;;;;;WAcrCF;QAC8C,qBAAjCE,KAAK47B,OAAOI,qBACrBh8B,UAA2B;;;;YAIzBA,WAEAA,WAA4B,MAGnBA;WAGXA,KAAK47B,OAAOI,iBAAiB,UAAUh8B;;IAI3CF;QACME,YAKFA,KAAK47B,OAAOiB,oBAAoB,UAAU78B,UAC1CA,UAA2B;;;;;;WAS/BF,GAAwB66B;QACtB;YACE,MAAMib,IAEJ,SADA51C,QAAgBm8B,QAAQn8B,QAAkC26B;YAQ5D,OANAlc,GA75BU,wBA+5BR,WAAWkc,MACTib,IAAY,OAAO;;UAIvB,OAAOryB;;YAGP,OADArJ,GAt6BU,wBAs6BQ,oCAAoCqJ,KAC/C;;;;;;WAQXzjB;QACE;YACEE,QAAgBu8B,QACdv8B,QAAkCA,KAAK26B,WACvCr2B,OAAOX,KAAKC;UAEd,OAAO2f;;YAEPrJ,GAAS,mCAAmCqJ;;;6DAKhDzjB;QACE;YACEE,QAAgB48B,WACd58B,QAAkCA,KAAK26B;UAEzC,OAAOpX;;;;IAKXzjB,GAAqC66B;QACnC,OAAO,oBAAiC36B,KAAKgkB,kBAAkB2W;;;;;;;;;;;AAOnE,YACErO;IAEA,OAAOA,EAAIwZ,MAA2CmJ,GAAgBnJ;;;;;GAMxE,aACExZ;IAEA,OAAOA,EAAIwZ,MACToK,GAAiBpK;;;4DA52BZuF,SAAgB;;;IAs3BvBvrC,YAA6B0kC,GAA0BnY;QAA1BrsB,UAAAwkC,GAJ7BxkC,UAA4C,MAK1CA,UAAwB,OAAwBA;;IAGlDF,GACEwsB;QAEA,MAAMupB,IAAkB71C,QAA0BssB;QAElD,OAD2BtsB,KAAKwkC,WAAmClY,GACzCllB,KAAKolB,KAC7BqpB,EAAgBzuC,KAAK0uC,KAAYtpB;;IAIrC1sB,GACEwsB;QAEA,IAAIypB,IAAgB;QACpB,OAAO/1C,QAA2CssB,GAAKxO;YACrDi4B;WACC3uC,KAAK;;IAGVtH,GACEwsB,GACAzV;QAEA,OAAO7W,KAAKwkC,WAAkClY,GAAKzV;;IAGrD/W,GACEwsB,GACAzV;QAEA,OAAO7W,QAA6BssB,GAAK,CAACzH,GAAQhL,MAChDhD,EAAEgD;;IAIN/Z,GAAgBk2C;QACdh2C;;IAGFF,GACEwsB,GACAzkB;QAEA,OAAO0pC,GAAiBjlB,GAAKzkB;;IAG/B/H,GACEwsB,GACAzkB;QAEA,OAAO0pC,GAAiBjlB,GAAKzkB;;IAG/B/H,GACEwsB,GACAG,GACAC;QAEA,OAAO1sB,KAAKwkC,WAEKlY,GAAKG,GAAYC;;IAGpC5sB,GACEwsB,GACAzkB;QAEA,OAAO0pC,GAAiBjlB,GAAKzkB;;;;;;;WAS/B/H,GACEwsB,GACAzH;QAEA,OAAI7kB,gBACKkmB,GAAmBpkB,SAAiB,cPhiB/CwqB,GACAzH;YAEA,IAAInS,KAAQ;YACZ,OAAOs2B,GAAoB1c,MACVmR,KACNmN,GAAyBte,GAAKmR,MAAgBr2B,KAAK0jC,YAEtDp4B,KAAQ,IAEHwT,GAAmBpkB,eAG7BsF,KAAK,MAAMsL;SOqhBHujC,CAAyB3pB;;IAIpCxsB,GACEwsB,GACAG;QAEA,MACMypB,IADgBl2C,KAAKwkC,cAGrBzd,IAA4C;QAClD,IAAIovB,IAAgB;QAsBpB,OApBkBn2C,QAChBssB,GACA,CAACzH,GAAQhL;YACP,IAAIA,KAAkB4S,GAAY;gBAChC,MAAMnT,IAAItZ,QAAcssB,MAAallB,KAAKgvC;oBACxC;;;oBAIE,OAHAD,KAGOD,KAAsB5pB,MAAallB,KAAK,OAC7C8uC,SACOlK,GAAoB1f,GAAKnY,OAoFvC,EAAC,GAAG83B,KAAuB3lC;;gBAhF1BygB,EAASxhB,KAAK+T;;WAMjBlS,KAAK,MAAM8e,UACX9e,KAAK,MAAM8uC,EAAatkC,MAAM0a,IAC9BllB,KAAK;;IAGVtH,aACEwsB,GACArO;QAEA,MAAM4tB,IAAU5tB,KAA8BqO;QAC9C,OAAOtsB,KAAKwkC,WAAqClY,GAAKuf;;IAGxD/rC,GACEwsB,GACAzkB;QAEA,OAAO0pC,GAAiBjlB,GAAKzkB;;;;;;;WAS/B/H,GACEwsB,GACAzV;QAEA,MAAMivB,IAAQkG,GAAoB1f;QAClC,IACI+pB,GADAC,IAAqCptB;QAEzC,OAAO4c,KAEH;YACErgC,OAAOymC,GAAiBE;WAE1B,EAAEriC,GAAU8a,KAAWve,MAAAA,GAAMuT,gBAAAA;YACV,MAAb9P;;;YAGEusC,MAAiBptB,SACnBrS,EAAE,MAAgBqzB;;;;;YAMpBoM,OACAD,IAAW/vC;;;YAIXgwC,IAAeptB;WAIpB9hB,KAAK;;;;YAIAkvC,MAAiBptB,SACnBrS,EAAE,MAAgBqzB;;;IAK1BpqC,GAAawsB;QACX,OAAOtsB,KAAKwkC,WAAoClY;;;;AAmBpD,YACEA,GACAzkB;IAEA,OAAOmkC,GAAoB1f,GAAKib;;;;;IAXlC,SACE1/B,GACAgS;QAEA,OAAO,IAAIqyB,GAAiB,GAAGD,GAAmBpkC,EAAIvB,OAAOuT;KAQ3D08B,CAAY1uC,GAAKykB;;;;;;;;;;;;;;;;;;;ICntCnBxsB,YACmB2nB,GACA+gB;;;;;;QAhBnBxoC,UAAyC;;QAGzCA,UAA+B;;;;;QAMvBA,uBAA8BwL;;QAGtCxL,UAA+B,MAAc2lB;;IAO7C7lB,GAAWmnB;QACT,OAAOf,GAAmBpkB,QAAsC,MAA9B9B,QAAmB8E;;IAGvDhF,GACEmnB,GACA7B,GACAE;QAEA,MAAMZ,IAAUU,EAAMV,SAChB8xB,IAAax2C,QAA4B0kB,GAAS;QACxD9hB,GACiB,MAAf4zC,GACA;;QAIYx2C;QAUd,OADAA,KAAKy4B,kBAAkBnT,GAChBY,GAAmBpkB;;IAG5BhC,GACEmnB;QAEA,OAAOf,GAAmBpkB,QAAQ9B,KAAKy4B;;IAGzC34B,GACEmnB,GACA3B;QAGA,OADAtlB,KAAKy4B,kBAAkBnT,GAChBY,GAAmBpkB;;IAG5BhC,GACEmnB,GACArb,GACA+Y,GACAC;QAIA,MAAMF,IAAU1kB;QAGhB,IAFAA,WAEIA,QAAmB8E,SAAS,GAAG;YACnB9E,QAAmBA,QAAmB8E,SAAS;;QAO/D,MAAMsgB,IAAQ,OACZV,MAEAC,GACAC;QAEF5kB,QAAmBuF,KAAK6f;;QAGxB,KAAK,MAAMjF,KAAYyE,GACrB5kB,UAA4BA,QAA0ByJ,IACpD,OAAiB0W,EAAStY,KAAK6c,KAGjC1kB,WACEinB,GACA9G,EAAStY,IAAIvB;QAIjB,OAAO4f,GAAmBpkB,QAAQsjB;;IAGpCtlB,GACEmnB,GACAvC;QAEA,OAAOwB,GAAmBpkB,QAAQ9B,QAAuB0kB;;IAG3D5kB,GACEmnB,GACAvC;QAEA,MAAMqW,IAAgB/6B,QAAuB0kB;QAE7C,OAAOwB,GAAmBpkB,QACxBi5B,EAAcrrB;;IAIlB5P,GACEmnB,GACAvC;QAEA,MAAM+kB,IAAc/kB,IAAU,GAIxB+xB,IAAWz2C,YACXyF,IAAQgxC,IAAW,IAAI;;;gBAC7B,OAAOvwB,GAAmBpkB,QACxB9B,QAAmB8E,SAASW,IAAQzF,QAAmByF,KAAS;;IAIpE3F;QACE,OAAOomB,GAAmBpkB,QACM,MAA9B9B,QAAmB8E,U3CnJM,I2CmJ2B9E,UAAmB;;IAI3EF,GACEmnB;QAEA,OAAOf,GAAmBpkB,QAAQ9B,QAAmBmF;;IAGvDrF,GACEmnB,GACAC;QAEA,MAAM3d,IAAQ,UAA8B,IACtC1D,IAAM,UAA8BsF,OAAOy9B,oBAC3CngC,IAA0B;QAchC,OAbAzI,WAAyC,EAACuJ,GAAO1D,KAAM+f;YAKrD,MAAMR,IAAQplB,QAAuB4lB;YAKrCnd,EAAOlD,KAAK6f;YAGPc,GAAmBpkB,QAAQ2G;;IAGpC3I,GACEmnB,GACAG;QAEA,IAAI+iB,IAAiB;QAerB,OAbA/iB,EAAa/hB,QAAQ6hB;YACnB,MAAM3d,IAAQ,UAA8B,IACtC1D,IAAM,UAA8BsF,OAAOy9B;YACjD5oC,WAAyC,EAACuJ,GAAO1D,KAAM+f;gBAMrDukB,IAAiBA,EAAe1gC,IAAImc;;YAIjCM,GAAmBpkB,QAAQ9B;;IAGpCF,GACEmnB,GACA1L;;;QAQA,MAAMm7B,IAASn7B,EAAMjV,MACf+mC,IAA8BqJ,EAAO5xC,SAAS;;;;;QAMpD,IAAI6xC,IAAYD;QACXlvC,YACHmvC,IAAYA,EAAUzhC,MAAM;QAG9B,MAAM3L,IAAQ,OAAiB,UAA4B;;;gBAI3D,IAAI4gC,IAAiB;QAmBrB,OAjBAnqC,WAAuC4lB;YACrC,MAAMgxB,IAAahxB,EAAI/d,IAAIvB;YAC3B,SAAKowC;;;;;;YAQCE,EAAW9xC,iBACbqlC,IAAiBA,EAAe1gC,IAAImc,SAE/B;WAERrc,IAEI2c,GAAmBpkB,QAAQ9B;;IAGpCF,GAA4ByqC;;;QAG1B,MAAM9hC,IAA0B;QAOhC,OANA8hC,EAASllC,QAAQqf;YACf,MAAMU,IAAQplB,QAAuB0kB;YACvB,SAAVU,KACF3c,EAAOlD,KAAK6f;YAGT3c;;IAGT3I,GACEmnB,GACA7B;QAIAxiB,GACiB,MAFE5C,QAA4BolB,EAAMV,SAAS,YAG5D;QAEF1kB,QAAmBq6B;QAEnB,IAAIwc,IAAa72C;QACjB,OAAOkmB,GAAmB7gB,QAAQ+f,EAAMR,WAAYzE;YAClD,MAAMyF,IAAM,OAAiBzF,EAAStY,KAAKud,EAAMV;YAEjD,OADAmyB,IAAaA,EAAW1iC,OAAOyR,IACxB5lB,WACLinB,GACA9G,EAAStY;WAEVT,KAAK;YACNpH;;;IAIJF,GAAyB4kB;;;IAIzB5kB,GACEwsB,GACAzkB;QAEA,MAAM+d,IAAM,OAAiB/d,GAAK,IAC5Bme,IAAWhmB,WAA4C4lB;QAC7D,OAAOM,GAAmBpkB,QAAQ+F,EAAIlD,QAAQqhB,KAAYA,EAASne;;IAGrE/H,GACEwsB;QAQA,OANItsB,QAAmB8E,QAMhBohB,GAAmBpkB;;;;;;;;;WAW5BhC,GAA+B4kB,GAAkBxc;QAM/C,OALclI,QAAoB0kB;;;;;;;;;;WAiBpC5kB,GAAuB4kB;QACrB,IAAkC,MAA9B1kB,QAAmB8E;;QAErB,OAAO;;;;;gBAQT,OAAO4f,IADc1kB,QAAmB,GAAG0kB;;;;;WAQ7C5kB,GAA0B4kB;QACxB,MAAMjf,IAAQzF,QAAoB0kB;QAClC,OAAIjf,IAAQ,KAAKA,KAASzF,QAAmB8E,SACpC,OAGK9E,QAAmByF;;;;;;;;;;;;;;;;;;;;;;;;IC7UnC3F,YACmB2nB,GACAqvB;;;QAXX92C,YAPD,MACLwH;;QASMxH,YAAO;;;;;;;WAiBfF,GACEmnB,GACA5S,GACAqL;QAOA,MAAM7X,IAAMwM,EAAIxM,KACVmjB,IAAQhrB,KAAKwb,KAAKlZ,IAAIuF,IACtBymC,IAAetjB,IAAQA,EAAMxlB,OAAO,GACpCuxC,IAAc/2C,QAAWqU;QAU/B,OARArU,KAAKwb,OAAOxb,KAAKwb,QAAY3T,GAAK;YAChC+kC,IAAev4B;YACf7O;YACAka,UAAAA;YAGF1f,KAAKwF,QAAQuxC,OAEN/2C,WACLinB,GACApf,EAAIvB;;;;;;;WAURxG,GAAoBonB;QAClB,MAAM8D,IAAQhrB,KAAKwb,KAAKlZ;cAEtBtC,KAAKwb,OAAOxb,KAAKwb,KAAK1T,WACtB9H,KAAKwF,QAAQwlB,EAAMxlB;;IAIvB1F,GACEmnB,GACAC;QAEA,MAAM8D,IAAQhrB,KAAKwb,KAAKlZ;QACxB,OAAO4jB,GAAmBpkB,QAAQkpB,IAAQA,OAAsB;;IAGlElrB,WACEmnB,GACAG;QAEA,IAAI5B,IAAUoC;QAKd,OAJAR,EAAa/hB,QAAQ6hB;YACnB,MAAM8D,IAAQhrB,KAAKwb,KAAKlZ;YACxBkjB,IAAUA,QAA4BwF,IAAQA,OAAsB;YAE/D9E,GAAmBpkB,QAAQ0jB;;IAGpC1lB,GACEmnB,GACA1L,GACAyM;QAMA,IAAIxC,IAAU7K;;;gBAId,MAAM+7B,IAAS,MAAgBn7B,EAAMjV,KAAK4O,MAAM,MAC1C8hC,IAAWh3C,KAAKwb,QAAqBk7B;QAC3C,MAAOM,UAAoB;YACzB,OAAMnvC,KACJA,GACAlG,QAAOirC,IAAE5lB,GAAatH,UAAEA,MACtBs3B;YACJ,KAAKz7B,EAAMjV,OAAgBuB,EAAIvB,OAC7B;YAEEoZ,UAAqC,KAGrCsH,aAAyB1T,MAAYiI,EAAM/C,eAC7CgN,IAAUA,KAAewB,EAAcnf;;QAG3C,OAAOqe,GAAmBpkB,QAAQ0jB;;IAGpC1lB,GACEmnB,GACApQ;QAEA,OAAOqP,GAAmB7gB,QAAQrF,KAAKwb,MAAO3T,KAAqBgP,EAAEhP;;IAGvE/H,GACEmnB,GACAe;QAKA,MAAM,IAAI3mB,MACR;;IAIJvB,GACEmnB;QAEA,OAAOf,GAAmBpkB,QAAQ2C,EAAgBC;;IAGpD5E,GAAgBqW;;;QAKd,OAAO,IAAI8gC,MAAqDj3C;;IAGlEF,GAAQwsB;QACN,OAAOpG,GAAmBpkB,QAAQ9B,KAAKwF;;;;;;GAMzCyxC,SAA4C,cAAc9I;IACxDruC,YAA6BsuC;QAC3B5sC;;IAGF1B,GACEmnB;QAEA,MAAMF,IAA4C;QAUlD,OATA/mB,QAAaqF,QAAQ,CAACwC,GAAKwM;YACrBA,IACF0S,EAASxhB,KACPvF,WAA4BinB,GAAa5S,GAAKrU,KAAK0f,aAGrD1f,WAA+B6H;YAG5Bqe;;IAGTpmB,GACEmnB,GACAC;QAEA,OAAOlnB,WAA4BinB;;IAGrCnnB,GACEmnB,GACAG;QAEA,OAAOpnB,QAAmB8nB,WAAWb;;;;;;;;;;;;;;;;;;;;;IC3LzCnnB,YAA6BytB;QAAAvtB,mBAAAutB;;;;QAlB7BvtB,UAAkB,OAAkC0tB,KAAKA,EAAE3d;;QAGnD/P,iCAA4ByE,EAAgBC;;QAE5C1E,uBAA4B;;QAEpCA,UAAsD;;;;;QAKtDA,UAAqB,QAEbA,mBAAc,GAEtBA,UAA4BygC;;IAI5B3gC,GACEwsB,GACAzV;QAGA,OADA7W,QAAaqF,QAAQ,CAACyY,GAAGG,MAAepH,OACjCqP,GAAmBpkB;;IAG5BhC,GACEmnB;QAEA,OAAOf,GAAmBpkB,QAAQ9B,KAAKuvB;;IAGzCzvB,GACEmnB;QAEA,OAAOf,GAAmBpkB,QAAQ9B;;IAGpCF,GACEmnB;QAGA,OADAjnB,KAAKurC,kBAAkBvrC,QAAuBoH,QACvC8e,GAAmBpkB,QAAQ9B,KAAKurC;;IAGzCzrC,GACEmnB,GACAwkB,GACAlc;QAQA,OANIA,MACFvvB,KAAKuvB,4BAA4BA,IAE/Bkc,IAA8BzrC,YAChCA,UAA6ByrC;QAExBvlB,GAAmBpkB;;IAG5BhC,GAAuBme;QACrBje,QAAakU,IAAI+J,EAAWtE;QAC5B,MAAM5P,IAAWkU,EAAWlU;QACxBA,IAAW/J,KAAKurC,oBAClBvrC,UAAyB,OAAsB+J,IAC/C/J,KAAKurC,kBAAkBxhC,IAErBkU,EAAWpE,iBAAiB7Z,YAC9BA,UAA6Bie,EAAWpE;;IAI5C/Z,GACEmnB,GACAhJ;QAQA,OAFAje,YACAA,KAAKwsB,eAAe,GACbtG,GAAmBpkB;;IAG5BhC,GACEmnB,GACAhJ;QAOA,OADAje,YACOkmB,GAAmBpkB;;IAG5BhC,GACEmnB,GACAhJ;QAUA,OAHAje,QAAamU,OAAO8J,EAAWtE,SAC/B3Z,WAAsCie,EAAWlU,WACjD/J,KAAKwsB,eAAe;QACbtG,GAAmBpkB;;IAG5BhC,GACEmnB,GACAwF,GACAC;QAEA,IAAIziB,IAAQ;QACZ,MAAMitC,IAA4C;QAalD,OAZAl3C,QAAaqF,QAAQ,CAACwC,GAAKoW;YAEvBA,EAAWpE,kBAAkB4S,KACgB,SAA7CC,EAAgBpqB,IAAI2b,EAAWlU,cAE/B/J,QAAamU,OAAOtM,IACpBqvC,EAAS3xC,KACPvF,QAAmCinB,GAAahJ,EAAWlU;YAE7DE;YAGGic,SAAqC9e,KAAK,MAAM6C;;IAGzDnK,GACEmnB;QAEA,OAAOf,GAAmBpkB,QAAQ9B,KAAKwsB;;IAGzC1sB,GACEmnB,GACAtN;QAEA,MAAMsE,IAAaje,QAAasC,IAAIqX,MAAW;QAC/C,OAAOuM,GAAmBpkB;;IAG5BhC,GACEmnB,GACAld;;;QAIA,OAAO/E,GAAK;;IAGdlF,GACEwsB,GACA5c,GACA3F;QAEA/J,WAA8B0P,GAAM3F;QACpC,MAAMy+B,IAAoBxoC,KAAKutB,gBACzBxG,IAA4C;QAMlD,YAJErX,EAAKrK,QAAQwC;YACXkf,EAASxhB,KAAKijC,KAA+Blc,GAAKzkB;YAG/Cqe;;IAGTpmB,GACEwsB,GACA5c,GACA3F;QAEA/J,WAAiC0P,GAAM3F;QACvC,MAAMy+B,IAAoBxoC,KAAKutB,gBACzBxG,IAA4C;QAMlD,YAJErX,EAAKrK,QAAQwC;YACXkf,EAASxhB,KAAKijC,KAAkClc,GAAKzkB;YAGlDqe;;IAGTpmB,GACEwsB,GACAviB;QAGA,OADA/J,WAAsC+J,IAC/Bmc,GAAmBpkB;;IAG5BhC,GACEwsB,GACAviB;QAEA,MAAMotC,IAAen3C,WAAgC+J;QACrD,OAAOmc,GAAmBpkB;;IAG5BhC,GACEwsB,GACAzkB;QAEA,OAAOqe,GAAmBpkB,QAAQ9B,WAA4B6H;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;ICzKhE/H,YACmB66B,GACjByc;QADiBp3C,gBAAA26B,GAhBnB36B,UAAkE,IAGlEA,UAAkC,OAAmB,IAErDA,WAAmB,GAcjBA,WAAgB;QAChBA,UAAyBo3C,EAAyBp3C,OAClDA,UAAmB,OAAsBA;QAGzCA,UAAoB,QACpBA,UAA2B,OACzBA,SAJaqU,KACbrU,WAAoCqU;;IAQxCvU;;QAGE,OADAE,WAAgB,GACT6B,QAAQC;;IAGjBoqB;QACE,OAAOlsB;;IAGTF;QACE,OAAO,EAACE,KAAK26B;;IAGf76B,GACE8zC;;QAGA,OAAOA,GAAqB;;IAG9B9zC;;;IAIAA,GAAkBqwB;;;IAIlBrwB;QACE,OAAOE;;IAGTF,GAAiB8B;QACf,IAAI80B,IAAQ12B,QAAoB4B;QAQhC,aANE80B,IAAQ,OACN12B,SACAA,UAEFA,QAAoB4B;;IAKxB9B;QACE,OAAOE;;IAGTF;QACE,OAAOE;;IAGTF,eACEoI,GACA4nB,GACAqlB;QAIA12B,GAzGY,qBAyGM,yBAAyBvW;QAC3C,MAAMokB,IAAM,OAAsBtsB,QAAoBoH;QAEtD,OADApH,cACOm1C,EAAqB7oB,GACzBllB,KAAKqB,KACGzI,WACmBssB,GACvBllB,KAAK,MAAMqB,SAGflG,KAAKkG,MACJ6jB;QACO7jB;;IAIb3I,GACEmnB,GACApf;QAEA,OAAOqe,MACLhc,OAAOyD,OAAO3N,SAAqB6G,IAAI6vB,KAAS,MAC9CA,KAAkBzP,GAAapf;;;;;;;qBAUA6rC;IACrC5zC,YAAqBqxC;QACnB3vC;;;;;IAcF1B,YAAqCytB;QAAAvtB,mBAAAutB,GAHrCvtB,UAA4C,MAC5CA,UAAsD;;IAItDF,UAAeytB;QACb,OAAO,OAAwBA;;IAGjC8pB;QACE,IAAKr3C,SAGH,OAAOA;QAFP,MAAMgF,GAAK;;IAMflF,GAAgBk2C;QACdh2C;;IAGFF,GACEwsB,GACAzkB;QAGA,OADA7H,QAAuBmU,OAAOtM,IACvBqe,GAAmBpkB;;IAG5BhC,GACEwsB,GACAzkB;QAGA,OADA7H,QAAuByJ,IAAI5B,IACpBqe,GAAmBpkB;;IAG5BhC,GACEwsB,GACAzkB;QAGA,OADA7H,QAAuByJ,IAAI5B,IACpBqe,GAAmBpkB;;IAG5BhC,aACEwsB,GACArO;QAEA,MAAMyzB,IAAQ1xC,KAAKutB;QACnB,OAAOmkB,KACuBplB,GAAKrO,EAAWlU,UAC3C3C,KAAKsI;YACJA,EAAKrK,QAAQwC,KAAO7H,QAAuByJ,IAAI5B;WAEhDT,KAAK,MAAMsqC,KAAuBplB;;IAGvCxsB;QACEE,UAA0B,IAAIg5B;;IAGhCl5B,GACEwsB;;QAGA,MACM4pB,IADQl2C,KAAKutB;QAEnB,OAAOrH,GAAmB7gB,QACxBrF,SACC6H,KACQ7H,QAAkBssB,GAAKzkB,GAAKT,KAAKkwC;iBAEpCpB,KAAyBruC;YAI/BT,KAAK,OACLpH,UAA0B,MACnBk2C,EAAatkC,MAAM0a;;IAI9BxsB,GACEwsB,GACAzkB;QAEA,OAAO7H,QAAkBssB,GAAKzkB,GAAKT,KAAKkwC;gBAEpCt3C,QAAuBmU,OAAOtM,KAE9B7H,QAAuByJ,IAAI5B;;;IAKjC/H,GAAauU;;QAEX,OAAO;;IAGTvU,GACEwsB,GACAzkB;QAEA,OAAOqe,MAAsB,EAC3B,MAAMlmB,KAAKutB,oBAAyCjB,GAAKzkB,IACzD,MAAM7H,KAAKutB,eAAqCjB,GAAKzkB,IACrD,MAAMqe,GAAmBpkB,QAAQ9B,WAA+B6H;;;;;;;;;;;;;;;;;;;;;;;IC/NpE/H,iBACEspB,GACAqsB,GACA/yB,GACAqW,GACA4B,GACAlN,GACA8S,GACAgX;QAQA,MAAMvzB,IAAiBqnB,UAIjBn5B,IAAawQ,KAAuB+yB;QAC1C,KAAKha,MAAwC/Y,IAC3C,MAAM,IAAIthB,EACRlB,EAAKc,eACL;QAIJhB,UAAyBu3C,EAAoBC,kBACzC,UAEE90B,GACAsB,GACA2W,QAGF,QACJ36B,aAA4Cu7B,KAC1Cv7B,WACEu7B;QAIJv7B,KAAKutB,oBAAoB8d,MAAgD;YACvE8G,yBAAyBoF,EAAoBC;YAC7CxzB,gBAAAA;YACA2W,UAAAA;YACAjY,UAAAA;YACA+0B;YACAvlC,YAAAA;YACAwlC,IAAW5rB,MAAwByrB,EAAoBI;YACvDC,IAAsB53C;;QAGxB,MAAM+rB,IAAmB/rB,KAAKutB;QAG9BvtB,UAAmB,cACnBA,UAAkB,OAChBA,KAAKutB,aACL,YAGFvtB,UAAmB,OACjBA,eAGAu7B,KACEv7B,WACEu7B,yBAGJ7Y;QAEF1iB,UAAkB,OAChBA,SACAA,SACAA,gBAIFA,UAAoB,OAAiBA,UAErCA,aAA8BA;QAC9BA,aAAoCA,eAE9BA,QAAuBuJ,eACvBvJ,QAAiBuJ,eACjBvJ,QAAgBuJ;;;cAIhBvJ,KAAKutB,eAAoCmD,MAAMwJ;kBAC7Cl6B,WAAkCk6B,IACpCA,MAAcl6B,aAChBA,QAAkBuJ,MAAMvJ,WACdk6B,KACVl6B,QAAkBi6B;;;IAKxBn6B,iBAAiB21C;QACf,MAAMzxB,IAAiBqnB;QAGvB,OAAOA,GAAqBwM,iBAAiB7zB;;;;AAIjD,MAAM8zB,KACJ;;;;;IAgBAh4C,YACWs3C,IAEsBW;;;IAGjCj4C,iBACEspB,GACAqsB,GACA/yB,GACAqW,GACA4B,GACAlN,GACA8S,GACAgX;QAEA,IAAIA,MACF,MAAM,IAAIn2C,EACRlB,EAAKW;QAKTb,KAAKutB,cAAc,OACjBoN,GACA36B,UAEFA,UAAmB,MACnBA,UAAyB,QACzBA,UAAkB,OAChBA,KAAKutB,aACL;QAGFvtB,UAAmB,OACjBA,eAGAu7B,KACEv7B,WACEu7B,yBAGJ7Y;QAEF1iB,UAAkB,OAChBA,SACAA,SACAA,gBAIFA,UAAoB,OAAiBA,UAErCA,aAA8BA;cAExBA,QAAiBuJ,eACjBvJ,YAAmC,UACnCA,YAAkC;;IAG1CF;QACE,MAAM,IAAIsB,EACRlB,EAAKW;;;;;;;;;;;;;;;;;;;;;;;;;;ICtLTf,YACU4iB,GACA+yB,GACAxd;;;;;;;;;IASA7O;QAXAppB,gBAAA0iB,gBAEA1iB,mBAAAi4B,gBALOj4B,gBAAWg4C;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;WAqD5Bl4C,MACEm4C,GACAV;QAEAv3C;;;;;;;QAQA,MAAMk4C,IAAqB,QAQrBC,IAAoB;;;;;;;gBAE1B,IAAIC,KAAc;;;;QA4BlB,OA3BAp4C,KAAKi4B,cAA8Br2B;YACjC,QAKE,OAJAw2C,KAAc,GAEd35B,GAxHQ,mBAwHU,uBAAuB7c,EAAK7B,MAEvCC,cAGL4B,MAEAW,KAAK21C,EAAmBp2C,SAASo2C,EAAmB5xB;YAEtDtmB,WAAiC,MACxBA,QAA4B4B;;;QAMzC5B,WAAiC,MACxBk4C,EAAmB/uB,UAMrBgvB,EAAkBhvB;;kFAI3BrpB;QAEE,OADAE,WACOA,QAAgBiqB,QAAQ,MACtBjqB,QAAgBg6B;;;;;;;;;;;;;;;;;;;;;WAwBnBl6B,SACNm4C,GACAV,GACA31C,GACAu2C;QAEA;;;;YAKE,MAAM/gB,UAAmBp3B,KAAK0iB,YAAwB1iB,UAChDkS,IAAalS,KAAK0iB,YACtB1iB,aAEI+4B,IAAY,OAChB/4B,YAEAA,KAAKi4B,aACL/lB;kBAGI+lC,EAAkBI,WACtBr4C,SACAA,SACAA,KAAK0iB,aAEL1iB,KAAK26B,UACL/4B,GAzMiC;YA8MnC5B,KAAKutB,cAAc0qB,EAAkB1qB,aACrCvtB,UAAyBi4C,MACzBj4C,UAAkBi4C,MAClBj4C,UAAmBi4C;YACnBj4C,UAAkBi4C,MAClBj4C,UAAmBi4C,MACnBj4C,UAAgBi4C;;;YAIhBj4C,KAAKutB,eAAuCmD;sBACpC1wB,KAAKs4C;gBAGbH,EAAkBr2C;UAClB,OAAOwhB;;YAMP;;;YAHA60B,EAAkB7xB,OAAOhD,KAGpBtjB,QAAiBsjB,IACpB,MAAMA;YAOR,OALAi1B,QAAQC,KACN,+EAEEl1B;YAEGtjB,QACL,QACA;gBAAEy4C,KAAS;eACX72C;;;;;;WAUN9B,GAAoBwjB;QAClB,OAAmB,oBAAfA,EAAM5hB,OAEN4hB,EAAMhiB,SAASpB,EAAKW,uBACpByiB,EAAMhiB,SAASpB,EAAKc,kBAGE,sBAAjB03C,gBACPp1B,aAAiBo1B;;;;QA3Pc,OAwQ7Bp1B,EAAMhiB,QAzQgB,OA0QtBgiB,EAAMhiB;;;QA3QsB,OA8Q5BgiB,EAAMhiB;;;;;WAWZxB;QACE,IAAIE,YACF,MAAM,IAAIoB,EACRlB,EAAKW,qBACL;;IAKNf,GAA+B8B;QAI7B,OAHA5B,cAEAye,GAzSY,mBAySM,uCAAuC7c,EAAK7B;QACvDC,WAAuC4B;;qFAIhD9B;QAEE,OADAE,WACOA,QAAgBiqB,QAAQ,MACtBjqB,QAAgB0iC;;IAI3B5iC;QACE,OAAOE,WAA2C0wB;;YAE5C1wB,WACFA,QAAiBi6B,cAGbj6B,oBACAA,oBACAA,KAAKutB;;;;YAKXvtB,KAAKi4B;;;;;;;WASTn4B;QACEE;QAEA,MAAMigC,IAAW;QAIjB,OAHAjgC,WAAiC,MACxBA,gBAEFigC,EAAS9W;;IAGlBrpB,OACEyb,GACA8nB,GACAltB;QAEAnW;QACA,MAAMsnB,IAAW,OAAkB/L,GAAO8nB,GAAUltB;QAIpD,OAHAnW,WAAiC,MACxBA,QAAc6gC,OAAOvZ,KAEvBA;;IAGTxnB,GAASwnB;;;QAGHtnB,WAGJA,WAAiC,MACxBA,WAAuBsnB;;IAIlCxnB,GAA0B+kB;QAExB,OADA7kB,WACOA,QACJiqB,QAAQ,MACAjqB,eAERuC,KAAM8Q;YACL,IAAIA,aAAoBC,IACtB;YACK,IAAID,iBACT,OAAO;YAEP,MAAM,IAAIjS,EACRlB,EAAKgB,aACL;;;IASVpB,GAA2Byb;QAEzB,OADAvb,WACOA,QAAgBiqB,QAAQyG;YAC7B,MAAMmP,UAAoB7/B,WACxBub;uCAC0B,IAEtB8kB,IAAO,OAAS9kB,GAAOskB,OACvBiB,IAAiBT,KAAuBR,EAAY9jB;YAC1D,OAAOskB;yCAEuB,GAC5BlI;;;IAINr4B,MAAM8kB;QACJ5kB;QACA,MAAMigC,IAAW;QAIjB,OAHAjgC,WAAiC,MAC/BA,QAAgBi5B,MAAMrU,QAEjBqb,EAAS9W;;IAGlBrpB;QACE,OAAOE;;IAGTF,GAA2BujC;QACzBrjC,WACAA,WAAiC,OAC/BA,WAAyCqjC,IAClCxhC,QAAQC;;IAInBhC,GAA8BujC;;;QAGxBrjC,WAGJA,WAA4CqjC;;IAG9CsV;;;;QAIE,OAAO34C;;IAGTF,YACEkgC;QAEAhgC;QACA,MAAMigC,IAAW;QAKjB,OAJAjgC,WAAiC,OAC/BA,QAAgB6tB,eAAe7tB,SAAiBggC,OACzCn+B,QAAQC;QAEVm+B,EAAS9W;;;;;;;;;;;;;;;;;;;;;;;;;ICtdlBrpB,YAAoBujC;QAAArjC,gBAAAqjC;;;;;QAFZrjC,cAAQ;;IAIhBF,KAAK6B;QACH3B,QAAmBA,KAAKqjC,SAASj8B,MAAMzF;;IAGzC7B,MAAMwjB;QACJtjB,QAAmBA,KAAKqjC,SAAS/f,OAAOA;;IAG1CxjB;QACEE,KAAK44C,SAAQ;;IAGf94C,GAAyB+4C,GAA+Bvc;QACjDt8B,KAAK44C,SACR/uB,WAAW;YACJ7pB,KAAK44C,SACRC,EAAavc;WAEd;;;;;;;;;;;;;;;;;;;gBCfyBtyB;;;;;IAChC,OAOF,SAA8BA,GAAc8uC;QAC1C,IAAmB,mBAAR9uC,KAA4B,SAARA,GAC7B,QAAO;QAGT,MAAM+uC,IAAS/uC;QACf,KAAK,MAAMgvC,QACT,IAAIA,KAAUD,KAAoC,qBAAnBA,EAAOC,IACpC,QAAO;QAGX,QAAO;;;;;;;;;;;;;;;;;;;;;GAlBAC,EAAqBjvC,GAAK,EAAC,QAAQ,SAAS;;;;ICanDlK,YACmBo5C,GACAC,GACAC,GACAC;QAHAr5C,iBAAAk5C,GACAl5C,6BAAAm5C,gBAEAn5C,iBAAAq5C;;IAGnBv5C,GAAa6B;QACX,QAAQ0K,EAAU1K;UAChB;YACE,OAAO;;UACT;YACE,OAAOA,EAAM2K;;UACf;YACE,OAAOS,GAAgBpL,EAAMyL,gBAAgBzL,EAAM2M;;UACrD;YACE,OAAOtO,QAAsB2B,EAAqB;;UACpD;YACE,OAAO3B,QAA4B2B;;UACrC;YACE,OAAOA,EAAMgK;;UACf;YACE,OAAO,IAAIonB,GAAKnmB,GAAoBjL,EAAiB;;UACvD;YACE,OAAO3B,QAAsB2B,EAAqB;;UACpD;YACE,OAAO,IAAI2yB,GACT3yB,EAAMqL,cAAeC,UACrBtL,EAAMqL,cAAeE;;UAEzB;YACE,OAAOlN,QAAkB2B,EAAiB;;UAC5C;YACE,OAAO3B,QAAmB2B,EAAe;;UAC3C;YACE,MAAMqD,GAAK,yBAAyBkH,KAAKC,UAAUxK;;;IAIzD7B,GAAsB2L;QACpB,MAAMhD,IAAiC;QAIvC,OAHApD,EAAQoG,EAASC,UAAU,IAAI,CAAC7D,GAAKlG;YACnC8G,EAAOZ,KAAO7H,QAAkB2B;YAE3B8G;;IAGT3I,GAAqB4N;QACnB,QAAQA,EAAWC,UAAU,IAAI9G,IAAIlF,KAAS3B,QAAkB2B;;IAGlE7B,GAA+B6B;QAC7B,QAAQ3B;UACN,KAAK;YACH,MAAMqR,e1EpBmB1P;gBAC/B,MAAM0P,IAAgB1P,EAAM8J,SAAUC;gBAEtC,OAAIO,EAAkBoF,KACbioC,EAAiBjoC,KAEnBA;a0EcqBioC,CAAiB33C;YACvC,OAAqB,QAAjB0P,IACK,OAEFrR,QAAkBqR;;UAC3B,KAAK;YACH,OAAOrR,QAAsBuM,EAAkB5K;;UACjD;YACE,OAAO;;;IAIb7B,GAAyB6B;QACvB,MAAM43C,IAAkB1tC,GAAmBlK,IACrC6C,IAAY,IAAIjB,EACpBg2C,EAAgB/1C,SAChB+1C,EAAgBztC;QAElB,OAAI9L,KAAKm5C,wBACA30C,IAEAA,EAAUg1C;;IAIrB15C,GAAyB4B;QACvB,MAAM+3C,IAAerzC,IAAwB1E;QAC7CkB,GACEyc,OACA,iCAAiC3d;QAEnC,MAAMuP,IAAa,OAAewoC,EAAan3C,IAAI,IAAIm3C,EAAan3C,IAAI,KAClEuF,IAAM,MAAgB4xC,IAAsB;QAclD,OAZKxoC,EAAWtM,QAAQ3E,KAAKk5C;;QAE3Bh/B,GACE,YAAYrS,2BACV,4CACA,GAAGoJ,EAAWC,aAAaD,EAAWE,4BACtC,iEACA,aAAanR,KAAKk5C,aAAsBhoC,aAAalR,KAAKk5C,aAAsB/nC,eAChF;QAIC,IAAIuoC,GAAkB7xC,GAAK7H,KAAKk5C,WAAWl5C,KAAKq5C;;;;;;;;;;;;;;;;;;;;uBCjD3D;MAUaM,KAAuB7tB;;;;;;;AAyBpC;IAiBEhsB,YAAY85C;;QACV,SAAsB70C,MAAlB60C,EAAS31B,MAAoB;YAC/B,SAAqBlf,MAAjB60C,EAAS11B,KACX,MAAM,IAAI9iB,EACRlB,EAAKI,kBACL;YAGJN,KAAKikB,OA5DU,4BA6DfjkB,KAAKkkB,OA5DS;eA8DdmN,GAAkB,YAAY,oBAAoB,QAAQuoB,EAAS31B,OACnEjkB,KAAKikB,OAAO21B,EAAS31B,MAErB41B,GAA0B,YAAY,WAAW,OAAOD,EAAS11B;QACjElkB,KAAKkkB,oBAAM01B,EAAS11B;QAgDtB,IA9CA41B,GAAoB,YAAYF,GAAU,EACxC,QACA,OACA,eACA,yBACA,kBACA;QAGFC,GACE,YACA,UACA,eACAD,EAAS3hB,cAEXj4B,KAAKi4B,cAAc2hB,EAAS3hB;QAE5B4hB,GACE,YACA,WACA,yBACAD,EAAST;;;SAK4B,MAAnCS,EAAST,wBACXj/B,GACE,6FAG0C,MAAnC0/B,EAAST,yBAClBj/B,GACE;QAIJla,KAAKm5C,sCACHS,EAAST;QAEXU,GACE,YACA,UACA,kBACAD,EAASjC,sBAEqB5yC,MAA5B60C,EAASjC,gBACX33C,KAAK23C,iBAAiB7rB,YACjB;YACL,IACE8tB,EAASjC,mBAAmBgC,MAC5BC,EAASjC,iBAAiB7rB,OAE1B,MAAM,IAAI1qB,EACRlB,EAAKI,kBACL,mCAAmCwrB;YAGrC9rB,KAAK23C,iBAAiBiC,EAASjC;;QAInCkC,GACE,YACA,WACA,gCACAD,EAASG;QAEX/5C,KAAKmkB,wBACuCpf,MAA1C60C,EAASG,gCAELH,EAASG;;IAGjBj6C,QAAQqE;QACN,OACEnE,KAAKikB,SAAS9f,EAAM8f,QACpBjkB,KAAKkkB,QAAQ/f,EAAM+f,OACnBlkB,KAAKm5C,0BAA0Bh1C,EAAMg1C,yBACrCn5C,KAAKi4B,gBAAgB9zB,EAAM8zB,eAC3Bj4B,KAAK23C,mBAAmBxzC,EAAMwzC,kBAC9B33C,KAAKmkB,qBAAqBhgB,EAAMggB;;;;;;UAQzB61B;;;;IA4BXl6C,YACEm6C,GACAj4C,GACAk4C,IAAyC;QAEzC,IAzBFl6C,UAAoD;;;QAapDA,UAAkB,QAkRlBA,gBAAW;YACTmU,QAAQuc;;;gBAGN1wB,iBACMA,QAAuBs4C;;WA3QyB,mBAA5C2B,EAAgC9jC,SAAsB;;;YAGhE,MAAMgkC,IAAMF;YACZj6C,UAAoBm6C,GACpBn6C,UAAmBg6C,MAA4BG,IAC/Cn6C,UAAuBm6C,EAAIz4C,MAC3B1B,UAAoB;eACf;YACL,MAAMo6C,IAAWH;YACjB,KAAKG,EAASlpC,WACZ,MAAM,IAAI9P,EACRlB,EAAKI,kBACL;YAIJN,UAAmB,OAAeo6C,EAASlpC,WAAWkpC,EAASjpC;;YAE/DnR,UAAuB,aACvBA,UAAoB;;QAGtBA,aACAA,UAAiB,OAAsB,KACvCA,UAAmBA,QAAsBA;;IAG3CF,SAASu6C;QACPnnB,GAA0B,sBAAsBC,WAAW,IAC3DhC,GAAgB,sBAAsB,UAAU;QAEhD,MAAMmpB,IAAc;QACpB,IAAIt6C,YAA0BA,QAAe2E,YAC3C,MAAM,IAAIvD,EACRlB,EAAKW,qBACL;QAMJb,kBACgC+E,MAA5Bu1C,EAAYriB,gBACdj4B,mBrFMJi4B;YAEA,KAAKA,GACH,OAAO;YAGT,QAAQA,EAAY5c;cAClB,KAAK;gBACH,MAAMk5B,IAAStc;;gCAWf,OATAr1B,KAEsB,wBACP,SAAX2xC,MACAA,EAAa,SACbA,EAAa,KAAmC,kCAElD;gBAEK,SAELtc,OAA4B;;cAGhC,KAAK;gBACH,OAAOA;;cAET;gBACE,MAAM,IAAI72B,EACRlB,EAAKI,kBACL;;;;;;;;;;;;;;;;;;;qFqFpCkBi6C;SAAwBD,EAAYriB;;IAI5Dn4B;QAEE,OADAE,WACOA,QAAuBg6B;;IAGhCl6B;QAEE,OADAE,WACOA,QAAuB0iC;;IAGhC5iC,kBAAkB85C;;QAChB,IAAI55C,SACF,MAAM,IAAIoB,EACRlB,EAAKW,qBACL;QAMJ,IAAI22C,KAAkB;QActB,OAZIoC,WAC8C70C,MAA5C60C,EAASY,kCACXtgC,GACE;QAGJs9B,gCACEoC,EAASpC,uCACToC,EAASY;QAINx6C,QAAqBA,SAAyB;YACnDy4C,KAAS;YACTd,gBAAgB33C,QAAe23C;YAC/BH,iBAAAA;;;IAIJ13C;QACE,SAC4BiF,MAA1B/E,YACCA,YAED,MAAM,IAAIoB,EACRlB,EAAKW,qBACL;QAIJ,MAAMo/B,IAAW;QAUjB,OATAjgC,WAA8C0wB;YAC5C;gBACE,MAAM+kB,IAAez1C;sBACfA,QAAwB63C,qBAC9B5X,EAASn+B;cACT,OAAOyhB;gBACP0c,EAAS3Z,OAAO/C;;YAGb0c,EAAS9W;;IAGlBrpB;QAEE,OADCE,KAAKm6C,IAAqBM,uBAAuB,cAC3Cz6C,KAAKiB,SAASkT;;IAGvBumC;QAEE,OADA16C,WACOA;;IAGTF;QAEE,OADAE,WACOA,QAAuB26C;;IAKhC76C,kBAAkB86C;QAGhB,IAFA56C,WAEI66C,GAAkBD,IACpB,OAAO56C,QAA+B46C;QACjC;YACLzpB,GAAgB,+BAA+B,YAAY,GAAGypB;YAC9D,MAAMvX,IAAkC;gBACtCj8B,MAAMwzC;;YAER,OAAO56C,QAA+BqjC;;;IAI1CvjC,GACEujC;QAEA,MAGMyX,IAAgB,OAAwB;YAC5C1zC,MAAM;gBACAi8B,EAASj8B,QACXi8B,EAASj8B;;YAGbkc,OATkBoD;gBAClB,MAAM1hB,GAAK;;;QAWb,OADAhF,eACO;YACL86C,QACA96C;;;IAIJF;QAQE,OAPKE;;;QAGHA,QAAqB,QAA+B;YAClDy4C,KAAS;YAGNz4C;;IAGTF;QACE,OAAO,OACLE,SACAA,SACAA,QAAeikB,MACfjkB,QAAekkB,KACflkB,QAAemkB;;IAInBrkB,GACEm4C,GACAV;QASA,MAAM9B,IAAez1C;QASrB,OAPAA,UAAwB,OACtBwK,YAEAxK,SACAA,UAGKA,QAAsBuJ;;IAG/BzJ,GAAyBmR;QACvB,MAiBMiB,IAAa,UAAoC;YACrD6oC,IAAevwC;;QAEjB,OAAO,OAAmB0H,GApBJvQ;YACpB,IAAIA,aAAiB+3C,IAAmB;gBACtC,MAAMsB,OACAC,IAAUt5C,EAAMu3C;gBACtB,KAAK+B,EAAQt2C,YACX,MAAM,IAAIvD,EACRlB,EAAKI,kBACL,wCACE,GAAG26C,EAAQ/pC,aAAa+pC,EAAQ9pC,4BAChC,gBAAgB6pC,EAAO9pC,aAAa8pC,EAAO7pC;gBAGjD,OAAO,UAAqCxP;;YAE5C,OAAOA;;;IASL7B,UAAyBq6C;QAC/B,IAi/DcnwC,IAj/DAmwC,EAAIhkC,SAi/DStO,IAj/DA,cAk/DtBqC,OAAOC,UAAUC,eAAeC,KAAKL,GAAKnC,IAj/D7C,MAAM,IAAIzG,EACRlB,EAAKI,kBACL;QA8+DR,IAAkB0J,GAAanC;;;;;gBA1+D3B,MAAMqJ,IAAYipC,EAAIhkC,QAAQjF;QAC9B,KAAKA,KAAkC,mBAAdA,GACvB,MAAM,IAAI9P,EACRlB,EAAKI,kBACL;QAGJ,OAAO,OAAe4Q;;IAGxBipC;QACE,KAAKn6C,SACH,MAAM,IAAIoB,EACRlB,EAAKW,qBACL;QAIJ,OAAOb;;IAYTF,WAAWo7C;QAIT,OAHAhoB,GAA0B,wBAAwBC,WAAW,IAC7DhC,GAAgB,wBAAwB,oBAAoB;QAC5DnxB,WACO,IAAIm7C,GAAoB/0C,QAAqCpG;;IAGtEF,IAAIo7C;QAIF,OAHAhoB,GAA0B,iBAAiBC,WAAW,IACtDhC,GAAgB,iBAAiB,oBAAoB;QACrDnxB,WACO05C,MAA0BtzC,QAAqCpG;;IAGxEF,gBAAgBuH;QAQd,IAPA6rB,GAA0B,6BAA6BC,WAAW,IAClEhC,GACE,6BACA,oBACA,GACA9pB;QAEEA,EAAad,QAAQ,QAAQ,GAC/B,MAAM,IAAInF,EACRlB,EAAKI,kBACL,0BAA0B+G,2BACxB;QAIN,OADArH,WACO,IAAIgX,GACT,OAAkB5Q,KAAyBiB,IAC3CrH;;IAIJF,eACEkgC;QAIA,OAFA9M,GAA0B,4BAA4BC,WAAW,IACjEhC,GAAgB,4BAA4B,YAAY,GAAG6O;QACpDhgC,UAA8BinB,YAClCA,KACQ+Y,EAAe,IAAIlH,GAAY94B,MAAMinB;;IAKlDnnB;QAGE,OAFAE,WAEO,IAAIo7C,GAAWp7C;;IAGxB6iB;QACE,QAAQyK;UACN,KAAKrK,EAASC;YACZ,OAAO;;UACT,KAAKD,EAASo4B;YACZ,OAAO;;UACT;;YAEE,OAAO;;;IAIbv7C,mBAAmBw7C;QAGjB,QAFApoB,GAA0B,yBAAyBC,WAAW,IAC9DhC,GAAgB,yBAAyB,oBAAoB,GAAGmqB;QACxDA;UACN,KAAK;YACHx4B,GAAYG,EAASC;YACrB;;UACF,KAAK;YACHJ,GAAYG,EAASI;YACrB;;UACF,KAAK;YACHP,GAAYG,EAASo4B;YACrB;;UACF;YACE,MAAM,IAAIj6C,EACRlB,EAAKI,kBACL,wBAAwBg7C;;;;;IAOhCx7C;QACE,OAAOE,QAAem5C;;;;;;UAObrgB;IACXh5B,YACUy7C,GACAC;;;IAGV17C,IACE27C;QAEAvoB,GAA0B,mBAAmBC,WAAW;QACxD,MAAMvN,IAAM81B,GACV,mBACAD,GACAz7C;QAEF,OAAOA,WACG,EAAC4lB,QACRrjB,KAAMiZ;YACL,KAAKA,KAAwB,MAAhBA,EAAK1W,QAChB,OAAOE,GAAK;YAEd,MAAMqP,IAAMmH,EAAK;YACjB,IAAInH,iBACF,OAAO,IAAIsnC,GACT37C,SACA4lB,MACA;8BACiB;qCACO,GACxBA;YAEG,IAAIvR,aAAef,IACxB,OAAO,IAAIqoC,GACT37C,SACA4lB,MACAvR;8BACiB;qCACO,GACxBuR;YAGF,MAAM5gB,GACJ,+DAA+DqP,EAAIke,YAAY7wB;;;IAMzF5B,IACE27C,GACA95C,GACAwU;QAEAylC,GAA4B,mBAAmBzoB,WAAW,GAAG;QAC7D,MAAMvN,IAAM81B,GACV,mBACAD,GACAz7C;QAEFmW,IAAU0lC,GAAmB,mBAAmB1lC;QAChD,OAAO2lC,GAAgBnrB,KAAgBorB,GACrCn2B,MACAjkB,GACA,oBAEIu7B,IACJ/mB,EAAQ6lC,SAAS7lC,EAAQ8lC,cACrBj8C,cACE2wB,MAEAxa,EAAQ8lC,eAEVj8C,cACE2wB;QAIR,OADA3wB,QAAkBkU,IAAI0R,UACf5lB;;IAaTF,OACE27C,GACAS,GACAv6C,MACGg0B;QAEH,IAAI/P,GACAsX;QAgCJ,OA7B+B,wBAC7Bgf,mBAEAjoB,GAA4B,sBAAsBd,WAAW;QAC7DvN,IAAM81B,GACJ,sBACAD,GACAz7C,UAEFk9B,IAASl9B,cACP,yBAEA2B,GACAg0B,OAGFzC,GAA0B,sBAAsBC,WAAW;QAC3DvN,IAAM81B,GACJ,sBACAD,GACAz7C,UAEFk9B,IAASl9B,cACP;QAKJA,QAAkBogB,OAAOwF,UAClB5lB;;IAGTF,OAAO27C;QACLvoB,GAA0B,sBAAsBC,WAAW;QAC3D,MAAMvN,IAAM81B,GACV,sBACAD,GACAz7C;QAGF,OADAA,QAAkBmU,OAAOyR,OAClB5lB;;;;MAIEo7C;IAIXt7C,YAAoBy7C;qBAHpBv7C,UAAqB,IACrBA,WAAqB;;IAIrBF,IACE27C,GACA95C,GACAwU;QAEAylC,GAA4B,kBAAkBzoB,WAAW,GAAG,IAC5DnzB;QACA,MAAM4lB,IAAM81B,GACV,kBACAD,GACAz7C;QAEFmW,IAAU0lC,GAAmB,kBAAkB1lC;QAC/C,OAAO2lC,GAAgBnrB,KAAgBorB,GACrCn2B,MACAjkB,GACA,mBAEIu7B,IACJ/mB,EAAQ6lC,SAAS7lC,EAAQ8lC,cACrBj8C,cACE2wB,MAEAxa,EAAQ8lC,eAEVj8C,cACE2wB;QAMR,OAHA3wB,UAAkBA,QAAgB2X,OAChCulB,KAAmBtX,MAAU3S,GAAauN,QAErCxgB;;IAaTF,OACE27C,GACAS,GACAv6C,MACGg0B;QAIH,IAAI/P,GACAsX;QAkCJ,OArCAl9B,WAM+B,wBAC7Bk8C,mBAEAjoB,GAA4B,qBAAqBd,WAAW;QAC5DvN,IAAM81B,GACJ,qBACAD,GACAz7C,UAEFk9B,IAASl9B,cACP,wBAEA2B,GACAg0B,OAGFzC,GAA0B,qBAAqBC,WAAW;QAC1DvN,IAAM81B,GACJ,qBACAD,GACAz7C,UAEFk9B,IAASl9B,cACP;QAKJA,UAAkBA,QAAgB2X,OAChCulB,KAAmBtX,MAAU3S,GAAaE,QAAO,MAE5CnT;;IAGTF,OAAO27C;QACLvoB,GAA0B,qBAAqBC,WAAW,IAC1DnzB;QACA,MAAM4lB,IAAM81B,GACV,qBACAD,GACAz7C;QAKF,OAHAA,UAAkBA,QAAgB2X,OAChC,OAAmBiO,MAAU3S,GAAauN,QAErCxgB;;IAGTF;QAGE,OAFAE,WACAA,WAAkB,GACdA,QAAgB8E,SAAS,IACpB9E,aAAyCi5B,MAAMj5B,WAGjD6B,QAAQC;;IAGjBhC;QACE,IAAIE,SACF,MAAM,IAAIoB,EACRlB,EAAKW,qBACL;;;;;;UAUK64C;IAIX55C,YACSq8C,GACEjD,GACAkD;qBADAp8C,iBAAAk5C,gBAGTl5C,UAAwBA,KAAKk5C;;IAG/Bp5C,UACEwG,GACA4yC,GACAG;QAEA,IAAI/yC,EAAKxB,SAAS,KAAM,GACtB,MAAM,IAAI1D,EACRlB,EAAKI,kBACL,+FAEE,GAAGgG,aAA8BA,EAAKxB;QAG5C,OAAO,IAAI40C,GAAkB,MAAgBpzC,IAAO4yC,GAAWG;;IAGjE/0B;QACE,OAAOtkB,QAAUsG;;IAGnB6a;QACE,OAAO,IAAIg6B,GACTn7C,QAAUsG,UACVtG,KAAKk5C,WACLl5C;;IAIJsG;QACE,OAAOtG,QAAUsG;;IAGnBxG,WACEo7C;QASA,IAPAhoB,GAA0B,gCAAgCC,WAAW,IACrEhC,GACE,gCACA,oBACA;YAIA,MAAM,IAAI/vB,EACRlB,EAAKI,kBACL;QAGJ,MAAMgG,IAAOF;QACb,OAAO,IAAI+0C,GAAoBn7C,QAAUsG,KAAK4O,MAAM5O,IAAOtG,KAAKk5C;;IAGlEp5C,QAAQqE;QACN,MAAMA,aAAiBu1C,KACrB,MAAMrmB,GAAkB,WAAW,qBAAqB,GAAGlvB;QAE7D,OACEnE,KAAKk5C,cAAc/0C,EAAM+0C,aACzBl5C,QAAU2E,QAAQR,SAClBnE,YAAoBmE;;IAQxBrE,IAAI6B,GAAUwU;QACZylC,GAA4B,yBAAyBzoB,WAAW,GAAG,IACnEhd,IAAU0lC,GAAmB,yBAAyB1lC;QACtD,OAAO2lC,GAAgBnrB,KAAgBorB,GACrC/7C,SACA2B,GACA,0BAEIu7B,IACJ/mB,EAAQ6lC,SAAS7lC,EAAQ8lC,cACrBj8C,KAAKk5C,gBACHvoB,MAEAxa,EAAQ8lC,eAEVj8C,KAAKk5C,gBAAmCvoB;QAC9C,OAAO3wB,QAAsBi5B,MAC3BiE,KAAmBl9B,SAAWiT,GAAauN;;IAU/C1gB,OACEo8C,GACAv6C,MACGg0B;QAEH,IAAIuH;QAqBJ,OAlB+B,wBAC7Bgf,mBAEAjoB,GAA4B,4BAA4Bd,WAAW;QACnE+J,IAASl9B,KAAKk5C,gBACZ,+BAEAv3C,GACAg0B,OAGFzC,GAA0B,4BAA4BC,WAAW;QACjE+J,IAASl9B,KAAKk5C,gBACZ,iCAKGl5C,QAAsBi5B,MAC3BiE,KAAmBl9B,SAAWiT,GAAaE,QAAO;;IAItDrT;QAEE,OADAozB,GAA0B,4BAA4BC,WAAW,IAC1DnzB,QAAsBi5B,MAAM,EACjC,OAAmBj5B,SAAWiT,GAAauN;;IAuB/C1gB,cAAcqjB;QACZy4B,GACE,gCACAzoB,WACA,GACA;QAEF,IAGIkQ,GAHAltB,IAA2C;YAC7CqtB,yBAAwB;WAGtB6Y,IAAU;QAEa,mBAAlBl5B,QACN03B,GAAkB13B,UAEnBhN,IAAUgN,MACV22B,GAAoB,gCAAgC3jC,GAAS,EAC3D;QAEF0jC,GACE,gCACA,WACA,0BACA1jC,EAAQqtB;QAEV6Y;QAGF,MAAMC,IAAkB;YACtB9Y,wBAAwBrtB,EAAQqtB;;QAgClC,OA7BIqX,GAAkB13B,QACpBkgB,IAAWlgB,QAIXgO,GACE,gCACA,eAEAhO;QAEFo5B,GACE,gCACA,YACAF,IAAU,GACVl5B,EAAKk5B,IAAU,KAEjBE,GACE,gCACA,YACAF,IAAU,GACVl5B,EAAKk5B,IAAU;QAEjBhZ,IAAW;YACTj8B,MAAM+b;YACNG,OAAOH,EAAKk5B,IAAU;YACtBG,UAAUr5B,EAAKk5B,IAAU;YAGtBr8C,WAAyCqjC;;IAGlDvjC,GACEqW,GACAktB;QAEA,IAAIoZ,IAAc/1B;YAChB6xB,QAAQj1B,MAAM;;QAEZ+f,EAAS/f,UACXm5B,IAAapZ,EAAS/f,MAAMkG,KAAK6Z;QAGnC,MAAMyX,IAAgB,OAAgC;YACpD1zC,MAAM+wB;gBACJ,IAAIkL,EAASj8B,MAAM;oBAKjB,MAAMiN,IAAM8jB,EAAS3c,KAAKlZ,IAAItC;oBAE9BqjC,EAASj8B,KACP,IAAIu0C,GACF37C,KAAKk5C,WACLl5C,SACAqU,GACA8jB,EAASvc,WACTuc,EAAS/hB,kBACTpW;;;YAKRsjB;YAEIo5B,IAAmB18C,QAAsB6gC,OAC7C8b,MAAqB38C,QAAUsG,UAE/B6P;QAGF,OAAO;YACL2kC,QACA96C;;;IAIJF,IAAIqW;QAGF,OAFAylC,GAA4B,yBAAyBzoB,WAAW,GAAG,IACnEypB,GAAmB,yBAAyBzmC;QACrC,IAAItU,QACT,CAACC,GAAkDwkB;YAC7CnQ,KAA8B,YAAnBA,EAAQirB,SACrBphC,KAAKk5C,kBAEwBl5C,SAC1BuC,KAAK8R;gBACJvS,EACE,IAAI65C,GACF37C,KAAKk5C,WACLl5C,SACAqU;gCACe,GACfA,aAAef,MAAWe,MAC1BrU;eAGHsmB,KAELtmB,QAA4B8B,GAASwkB,GAAQnQ;;;IAMrDrW,GACEgC,GACAwkB,GACAnQ;QAEA,MAAM0mC,IAAW78C,QACf;YACEwjC,yBAAwB;YACxBsZ,KAAuB;WAEzB;YACE11C,MAAOm8B;;;gBAGLsZ,MAEKtZ,EAAKpwB,UAAUowB,EAAK7G,SAAS9gB;;;;;;;;gBAQhC0K,EACE,IAAIllB,EACFlB,EAAKgB,aACL,4DAIJqiC,EAAKpwB,UACLowB,EAAK7G,SAAS9gB,aACdzF,KACmB,aAAnBA,EAAQirB,SAER9a,EACE,IAAIllB,EACFlB,EAAKgB,aACL,gLAOJY;;YAGJwhB,OAAOgD;;;IAKbxmB,cACEu5C;QAEA,OAAO,IAAIK,GAAqB15C,SAAWA,KAAKk5C,WAAWG;;;;AAI/D,MAAM0D;IACJj9C,YACWsW,GACAwF;QADA5b,wBAAAoW,GACApW,iBAAA4b;;IAGX9b,QAAQqE;QACN,OACEnE,KAAKoW,qBAAqBjS,EAAMiS,oBAChCpW,KAAK4b,cAAczX,EAAMyX;;;;MAWlB+/B;IAEX77C,YACUy7C,GACAY,GACDa,GACCC,GACAC,GACSd;;;IAGnBt8C,KAAKqW;QAGH,IAFAylC,GAA4B,yBAAyBzoB,WAAW,GAAG,IACnEhd,IAAUgnC,GAAwB,yBAAyBhnC;QACtDnW,SAEE;;;YAGL,IAAIA,SAAiB;gBACnB,MAAMm4B,IAAW,IAAIilB,GACnBp9C,SACAA,SACAA,SACAA,SACAA;gBAEF,OAAOA,QAAgBq9C,cAAcllB,GAAUhiB;;YAQ/C,OANuB,OACrBnW,SACAA,cACAmW,EAAQmnC;kCACSv4C,MAEgB/E;;;IAKzCF,IACE2S,GACA0D;QAIA,IAFAylC,GAA4B,wBAAwBzoB,WAAW,GAAG,IAClEhd,IAAUgnC,GAAwB,wBAAwBhnC;QACtDnW,SAAgB;YAClB,MAAM2B,IAAQ3B,QACXkJ,OACA2J,MAAM+iB,GAAsB,wBAAwBnjB;YACvD,IAAc,SAAV9Q,GAAgB;gBAOlB,OANuB,OACrB3B,SACAA,cACAmW,EAAQmnC,kBACRt9C,YAEiC2B;;;;IAMzC2iB;QACE,OAAOtkB,QAAUsG;;IAGnBsf;QACE,OAAO,IAAI8zB,GACT15C,SACAA,SACAA;;IAIJmT;QACE,OAA0B,SAAnBnT;;IAGT08B;QACE,OAAO,IAAIqgB,GAAiB/8C,SAAwBA;;IAGtDF,QAAQqE;QACN,MAAMA,aAAiBw3C,KACrB,MAAMtoB,GAAkB,WAAW,oBAAoB,GAAGlvB;QAE5D,OACEnE,YAAoBmE,QACpBnE,YAAoBmE,QACpBnE,QAAU2E,QAAQR,UACE,SAAnBnE,UACuB,SAApBmE,OACAnE,QAAe2E,QAAQR,UAC3BnE,YAAoBmE;;;;MAKbi5C,WACHzB;IAER77C,KAAKqW;QAMH,OALa3U,MAAM0H,KAAKiN;;;;MASfa;IACXlX,YACSy9C,GACErE,GACUkD;qBADVp8C,iBAAAk5C;;IAIXp5C,MACE+S,GACA2qC,GACA77C;QAEAuxB,GAA0B,eAAeC,WAAW,IACpDsqB,GAAgB,eAAe,GAAG97C;QAelC,IAAI+7C;kBxCzoCN/sB,GACAgtB,GACAtlC,GACA2Y;YAEA,KAAK2sB,EAAM5rC,KAAKC,KAAWA,UACzB,MAAM,IAAI5Q,EACRlB,EAAKI,kBACL,iBAAiBmxB,gCACf,GAAGd,eAA0BO,GAAQ7Y,6BACrC,WAAWslC,EAAMt3C,KAAK;SwC6nC1Bu3C,CAAmB,eAVQ,EACzB,KACA,MACA,MACA,MACA,KACA,kBACA,MACA,wBAEoD,GAAGJ;QAGzD,MAAM/qC,IAAYmjB,GAAsB,eAAe/iB,IACjDgrC,IAAWplC,KAAoB+kC;QACrC,IAAI/qC,OAAwB;YAC1B,IACEorC,MAAaplC,GAASM,kBACtB8kC,MAAaplC,GAASQ,oBAEtB,MAAM,IAAI7X,EACRlB,EAAKI,kBACL,qCAAqCu9C,EAASp8C,iBAC5C;YAEC,IAAIo8C,MAAaplC,GAASO,IAAI;gBACnChZ,QAAuC2B,GAAOk8C;gBAC9C,MAAMC,IAA6B;gBACnC,KAAK,MAAMpwC,KAAc/L,GACvBm8C,EAAcv4C,KAAKvF,QAA0B0N;gBAE/CgwC,IAAa;oBAAEhwC,YAAY;wBAAEC;;;mBAE7B+vC,IAAa19C,QAA0B2B;eAIvCk8C,MAAaplC,GAASO,MACtB6kC,MAAaplC,GAASQ,sBAEtBjZ,QAAuC2B,GAAOk8C,IAEhDH,IAAa19C,KAAKk5C,gBAChB,eACAv3C;;6BAEqBk8C,MAAaplC,GAASO;QAG/C,MAAMvS,IAASuR,GAAYmK,OAAO1P,GAAWorC;QAE7C,OADA79C,QAAuByG,IAChB,IAAIuQ,GACThX,WAAsByG,IACtBzG,KAAKk5C,WACLl5C;;IAIJF,QACE+S,GACAkrC;QASA,IAAI77B;QACJ,IARA05B,GAA4B,iBAAiBzoB,WAAW,GAAG,IAC3DopB,GACE,iBACA,oBACA,GACAwB;aAGmBh5C,MAAjBg5C,KAA+C,UAAjBA,GAChC77B,IAAY1K,GAAUC,gBACjB;YAAA,IAAqB,WAAjBsmC,GAGT,MAAM,IAAI38C,EACRlB,EAAKI,kBACL,mDAAmDy9C,SACjD;YALJ77B,IAAY1K,GAAUY;;QAQxB,IAA4B,SAAxBpY,QAAY2W,SACd,MAAM,IAAIvV,EACRlB,EAAKI,kBACL;QAIJ,IAA0B,SAAtBN,QAAY4W,OACd,MAAM,IAAIxV,EACRlB,EAAKI,kBACL;QAIJ,MAAMmS,IAAYmjB,GAAsB,iBAAiB/iB,IACnD4D,IAAU,OAAYhE,GAAWyP;QAEvC,OADAliB,QAAwByW,IACjB,IAAIO,GACThX,WAAuByW,IACvBzW,KAAKk5C,WACLl5C;;IAIJF,MAAM8I;QAIJ,OAHAsqB,GAA0B,eAAeC,WAAW,IACpDhC,GAAgB,eAAe,UAAU,GAAGvoB,IAC5Co1C,GAAuB,eAAe,GAAGp1C;QAClC,IAAIoO,GACThX,WAA6B4I,IAC7B5I,KAAKk5C,WACLl5C;;IAIJF,YAAY8I;QAIV,OAHAsqB,GAA0B,qBAAqBC,WAAW,IAC1DhC,GAAgB,qBAAqB,UAAU,GAAGvoB;QAClDo1C,GAAuB,qBAAqB,GAAGp1C,IACxC,IAAIoO,GACThX,WAA4B4I,IAC5B5I,KAAKk5C,WACLl5C;;IAIJF,QACEm+C,MACGvyC;QAEHuoB,GAA4B,iBAAiBd,WAAW;QACxD,MAAMtb,IAAQ7X,QACZ,oBAEA0L;qBACY;QAEd,OAAO,IAAIsL,GACThX,WAAwB6X,IACxB7X,KAAKk5C,WACLl5C;;IAIJF,WACEm+C,MACGvyC;QAEHuoB,GAA4B,oBAAoBd,WAAW;QAC3D,MAAMtb,IAAQ7X,QACZ,uBAEA0L;qBACY;QAEd,OAAO,IAAIsL,GACThX,WAAwB6X,IACxB7X,KAAKk5C,WACLl5C;;IAIJF,UACEm+C,MACGvyC;QAEHuoB,GAA4B,mBAAmBd,WAAW;QAC1D,MAAMtb,IAAQ7X,QACZ,sBAEA0L;qBACY;QAEd,OAAO,IAAIsL,GACThX,WAAsB6X,IACtB7X,KAAKk5C,WACLl5C;;IAIJF,MACEm+C,MACGvyC;QAEHuoB,GAA4B,eAAed,WAAW;QACtD,MAAMtb,IAAQ7X,QACZ,kBAEA0L;qBACY;QAEd,OAAO,IAAIsL,GACThX,WAAsB6X,IACtB7X,KAAKk5C,WACLl5C;;IAIJF,QAAQqE;QACN,MAAMA,aAAiB6S,KACrB,MAAMqc,GAAkB,WAAW,SAAS,GAAGlvB;QAEjD,OACEnE,KAAKk5C,cAAc/0C,EAAM+0C,aAAal5C,QAAY2E,QAAQR;;IAI9DrE,cACEu5C;QAEA,OAAO,IAAIriC,GAAShX,SAAaA,KAAKk5C,WAAWG;;0EAInDv5C,GACE40B,GACAupB,GACAvyC,GACA4M;QAGA,IADAmlC,GAAgB/oB,GAAY,OACxBupB,aAAsBtC,IAAkB;YAC1C,IAAIjwC,EAAO5G,SAAS,GAClB,MAAM,IAAI1D,EACRlB,EAAKI,kBACL,kCAAkCo0B;YAGtC,MAAM6O;YACN,KAAKA,EAAKpwB,QACR,MAAM,IAAI/R,EACRlB,EAAKM,WACL,yDACE,GAAGk0B;YAGT,OAAO10B,QAAuBujC,EAAe,IAAEjrB;;QAC1C;YACL,MAAM4lC,IAAY,MAAavmC,OAAOjM;YACtC,OAAO1L,QAAqB00B,MAAuBpc;;;;;;;;;;;;;WAevDxY,GAA0BuU,GAAeiE;QACvC,MAAM6lC,IAA0B;;;;;;;;gBAShC,KAAK,MAAM1nC,KAAWzW,QAAYyW,SAChC,IAAIA,EAAQ5D,WACVsrC,EAAW54C,KAAK64C,GAASp+C,KAAKk5C,cAAuB7kC,EAAIxM,YACpD;YACL,MAAMlG,IAAQ0S,EAAIxB,MAAM4D,EAAQ5D;YAChC,IAAI5G,EAAkBtK,IACpB,MAAM,IAAIP,EACRlB,EAAKI,kBACL,iGAEEmW,EAAQ5D,QACR;YAGC,IAAc,SAAVlR,GAEJ;gBACL,MAAMkR,IAAQ4D,EAAQ5D;gBACtB,MAAM,IAAIzR,EACRlB,EAAKI,kBACL,mEACE,iCAAiCuS,qBACjC;;YAPJsrC,EAAW54C,KAAK5D;;QAYtB,OAAO,OAAUw8C,GAAY7lC;;;;WAM/BxY,GACE40B,GACA/mB,GACA2K;;QAGA,MAAM7B,IAAUzW;QAChB,IAAI2N,EAAO7I,SAAS2R,EAAQ3R,QAC1B,MAAM,IAAI1D,EACRlB,EAAKI,kBACL,kCAAkCo0B,UAChC;QAKN,MAAMypB,IAA0B;QAChC,KAAK,IAAIz4C,IAAI,GAAGA,IAAIiI,EAAO7I,QAAQY,KAAK;YACtC,MAAM24C,IAAW1wC;YAEjB,IADyB8I,KACJ5D,WAAoB;gBACvC,IAAwB,sBACtB,MAAM,IAAIzR,EACRlB,EAAKI,kBACL,yDACE,GAAGo0B;gBAGT,KACG10B,iBAC0B,MAA3Bq+C,EAAS93C,QAAQ,MAEjB,MAAM,IAAInF,EACRlB,EAAKI,kBACL,uFACE,uBAAuBo0B,0CACvB,IAAI2pB;gBAGV,MAAM/3C,IAAOtG,QAAYsG,KAAK4O,MAAM9O;gBACpC,KAAKoB,KAA0BlB,IAC7B,MAAM,IAAIlF,EACRlB,EAAKI,kBACL,qEACE,+CAA+Co0B,0BAC/C,6BAA6BpuB,iDAC7B;gBAGN,MAAMuB,IAAM,MAAgBvB;gBAC5B63C,EAAW54C,KAAK64C,GAASp+C,KAAKk5C,cAAuBrxC;mBAChD;gBACL,MAAMy2C,IAAUt+C,KAAKk5C,gBACnBxkB;gBAGFypB,EAAW54C;;;QAIf,OAAO,OAAU44C,GAAY7lC;;IAsB/BxY,cAAcqjB;QACZy4B,GAA4B,oBAAoBzoB,WAAW,GAAG;QAC9D,IACIkQ,GADAltB,IAA2C,IAE3CkmC,IAAU;QAyCd,OAvC2B,mBAAlBl5B,QACN03B,GAAkB13B,UAEnBhN,IAAUgN,MACV22B,GAAoB,oBAAoB3jC,GAAS,EAC/C;QAEF0jC,GACE,oBACA,WACA,0BACA1jC,EAAQqtB;QAEV6Y,MAGExB,GAAkB13B,QACpBkgB,IAAWlgB,QAEXgO,GAAgB,oBAAoB,eAAqBhO,OACzDo5B,GACE,oBACA,YACAF,IAAU,GACVl5B,EAAKk5B,IAAU;QAEjBE,GACE,oBACA,YACAF,IAAU,GACVl5B,EAAKk5B,IAAU,KAEjBhZ,IAAW;YACTj8B,MAAM+b;YACNG,OAAOH,EAAKk5B,IAAU;YACtBG,UAAUr5B,EAAKk5B,IAAU;YAG7Br8C,QAA8CA,UACvCA,QAAwBmW,GAASktB;;IAG1CvjC,GACEqW,GACAktB;QAEA,IAAIoZ,IAAc/1B;YAChB6xB,QAAQj1B,MAAM;;QAEZ+f,EAAS/f,UACXm5B,IAAapZ,EAAS/f,MAAMkG,KAAK6Z;QAGnC,MAAMyX,IAAgB,OAAgC;YACpD1zC,MAAOqB;gBACD46B,EAASj8B,QACXi8B,EAASj8B,KACP,IAAIm3C,GACFv+C,KAAKk5C,WACLl5C,SACAyI,GACAzI;;YAKRsjB;YAGIk7B,IAAkBx+C,KAAKk5C,gBACvBwD,IAAmB8B,EAAgB3d,OACvC7gC,YAEAmW;QAEF,OAAO;YACL2kC,QACA0D;;;IAIJ1+C,GAAiDyb;QAC/C,IAAIA,UAA2D,MAAjCA,KAAsBzW,QAClD,MAAM,IAAI1D,EACRlB,EAAKc,eACL;;IAKNlB,IAAIqW;QAIF,OAHAylC,GAA4B,aAAazoB,WAAW,GAAG,IACvDypB,GAAmB,aAAazmC,IAChCnW,QAA8CA,UACvC,IAAI6B,QACT,CAACC,GAA+CwkB;YAC1CnQ,KAA8B,YAAnBA,EAAQirB,SACrBphC,KAAKk5C,kBAEyBl5C,SAC3BuC,KAAM4gC;gBACLrhC,EACE,IAAIy8C,GACFv+C,KAAKk5C,WACLl5C,YAEAA;eAGHsmB,KAELtmB,QAA4B8B,GAASwkB,GAAQnQ;;;IAMrDrW,GACEgC,GACAwkB,GACAnQ;QAEA,MAAM0mC,IAAW78C,QACf;YACEwjC,yBAAwB;YACxBsZ,KAAuB;WAEzB;YACE11C,MAAOqB;;;gBAGLo0C,KAGEp0C,EAAOi0B,SAAS9gB,aAChBzF,KACmB,aAAnBA,EAAQirB,SAER9a,EACE,IAAIllB,EACFlB,EAAKgB,aACL,mLAOJY,EAAQ2G;;YAGZ6a,OAAOgD;;;;;;;WAUbxmB,GAA6B2+C;QAC3B,IAA+B,sBAAU;YACvC,IAAwB,OAApBA,GACF,MAAM,IAAIr9C,EACRlB,EAAKI,kBACL;YAIJ,KACGN,iBACiC,MAAlCy+C,EAAgBl4C,QAAQ,MAExB,MAAM,IAAInF,EACRlB,EAAKI,kBACL,oHAEE,IAAIm+C;YAGV,MAAMn4C,IAAOtG,QAAYsG,KAAK4O,MAC5B9O;YAEF,KAAKoB,KAA0BlB,IAC7B,MAAM,IAAIlF,EACRlB,EAAKI,kBACL,yIAEE,QAAQgG,uDAA0DA,EAAKxB;YAG7E,OAAOs5C,GAASp+C,KAAKk5C,cAAuB,MAAgB5yC;;QACvD,IAAIm4C,aAA2B/E,IAAmB;YACvD,MAAM9zB,IAAM64B;YACZ,OAAOL,GAASp+C,KAAKk5C,cAAuBtzB;;QAE5C,MAAM,IAAIxkB,EACRlB,EAAKI,kBACL,mIAEE,GAAGmxB;;;;;WASX3xB,GACE6B,GACAk8C;QAEA,KAAKrsB,MAAMpgB,QAAQzP,MAA2B,MAAjBA,EAAMmD,QACjC,MAAM,IAAI1D,EACRlB,EAAKI,kBACL,sDACE,IAAIu9C,EAASp8C;QAGnB,IAAIE,EAAMmD,SAAS,IACjB,MAAM,IAAI1D,EACRlB,EAAKI,kBACL,mBAAmBu9C,EAASp8C,mCAC1B;QAGN,IAAIE,EAAM4E,QAAQ,SAAS,GACzB,MAAM,IAAInF,EACRlB,EAAKI,kBACL,mBAAmBu9C,EAASp8C,+CAC1B;QAGN,IAAIE,EAAM8E,OAAOuL,KAAW7G,OAAOoC,MAAMyE,IAAUlN,SAAS,GAC1D,MAAM,IAAI1D,EACRlB,EAAKI,kBACL,mBAAmBu9C,EAASp8C,8CAC1B;;IAKR3B,GAA0B2G;QACxB,IAAIA,aAAkBuR,IAAa;YACjC,MAAM0mC,IAAW,EAACjmC,GAASM,gBAAgBN,GAASQ,sBAC9C0lC,IAAiB,EAAClmC,GAASO,IAAIP,GAASQ,sBACxC2lC,IAAYF,EAASn4C,QAAQE,EAAOyR,OAAO,GAC3C2mC,IAAkBF,EAAep4C,QAAQE,EAAOyR,OAAO;YAE7D,IAAIzR,QAAuB;gBACzB,MAAMq4C,IAAgB9+C;gBACtB,IAAsB,SAAlB8+C,MAA2BA,EAAcn6C,QAAQ8B,EAAOoM,QAC1D,MAAM,IAAIzR,EACRlB,EAAKI,kBACL,kHAEE,2BAA2Bw+C,EAAcr9C,gBACzC,SAASgF,EAAOoM,MAAMpR;gBAI5B,MAAM2V,IAAoBpX;gBACA,SAAtBoX,KACFpX,QACEyG,EAAOoM;mBAIN,IAAIgsC,QAA8B;;;gBAGvC,IAAIE,IAAiC;gBAOrC,UALEA,IAAgB/+C,gBAEI,SAAlB++C,WACFA,IAAgB/+C,gBAEG,QAAjB++C;;gBAEF,MAAIA,MAAkBt4C,EAAOyR,KACrB,IAAI9W,EACRlB,EAAKI,kBACL,iDACE,IAAImG,EAAOyR,GAAGzW,yBAGZ,IAAIL,EACRlB,EAAKI,kBACL,kCAAkCmG,EAAOyR,GAAGzW,yBAC1C,SAASs9C,EAAct9C;;;;IAQrC3B,GAA2B2W;QACzB,IAA2C,SAAvCzW,cAA6C;;YAE/C,MAAMmX,IAAkBnX;YACA,SAApBmX,KACFnX,WAAwDyW,EAAQ5D;;;IAKtE/S,GACEk/C,GACAvoC;QAEA,KAAKA,EAAQ9R,YACX,MAAM,IAAIvD,EACRlB,EAAKI,kBACL,+DACE,+BAA+B0+C,EAAWv9C,iBAC1C,6BAA6Bu9C,EAAWv9C,iBACxC,mEACA,gBAAgBgV,EAAQhV;;;;MAMrB88C;IAOXz+C,YACmBy7C,GACA0D,GACAC,GACA9C;4DATnBp8C,UAAoE,MACpEA,UAA+D;QAU7DA,KAAK08B,WAAW,IAAIqgB,GAClBmC,EAAU9oC,kBACV8oC,EAAUtjC;;IAIdJ;QACE,MAAM/S,IAAoD;QAE1D,OADAzI,KAAKqF,QAAQgP,KAAO5L,EAAOlD,KAAK8O,KACzB5L;;IAGTggC;QACE,OAAOzoC,QAAewb;;IAGxBhW;QACE,OAAOxF,QAAewb,KAAKhW;;IAG7B1F,QACEqmB,GACAg5B;QAEAvD,GAA4B,yBAAyBzoB,WAAW,GAAG,IACnEhC,GAAgB,yBAAyB,YAAY,GAAGhL;QACxDnmB,QAAewb,KAAKnW,QAAQgP;YAC1B8R,EAAS9b,KAAK80C,GAASn/C,QAA2BqU;;;IAItDkH;QACE,OAAO,IAAIvE,GAAMhX,SAAqBA,SAAiBA;;IAGzDF,WACEqW;QAEIA,MACF2jC,GAAoB,4BAA4B3jC,GAAS,EACvD,6BAEF0jC,GACE,4BACA,WACA,0BACA1jC,EAAQqtB;QAIZ,MAAMA,OACJrtB,MAAWA,EAAQqtB;QAGrB,IAAIA,KAA0BxjC,YAC5B,MAAM,IAAIoB,EACRlB,EAAKI,kBACL;QAkBJ,OAZGN,WACDA,YAA8CwjC,MAE9CxjC;;;;;;iBAmNJk5C,GACA1V,GACArL,GACAkhB;YAEA,IAAIlhB,UAA4B;;;gBAG9B,IAAIinB,GACA35C,IAAQ;gBACZ,OAAO0yB,EAASzc,WAAW7U,IAAIsU;oBAC7B,MAAM9G,IAAM,IAAI+oC,GACdlE,GACA/9B,EAAO9G,IAAIxM,KACXsT,EAAO9G,KACP8jB,EAASvc,WACTuc,KAAqB3uB,IAAI2R,EAAO9G,IAAIxM,MACpCwxC;oBAWF,OADA+F,IAAUjkC,EAAO9G,KACV;wBACLgH,MAAM;wBACNhH,KAAAA;wBACAgrC,WAAW;wBACXC,UAAU75C;;;;YAGT;;;gBAGL,IAAI85C,IAAepnB;gBACnB,OAAOA,EAASzc,WACbjV,OACC0U,KAAUqoB,0BAA0BroB,EAAOE,MAE5CxU,IAAIsU;oBACH,MAAM9G,IAAM,IAAI+oC,GACdlE,GACA/9B,EAAO9G,IAAIxM,KACXsT,EAAO9G,KACP8jB,EAASvc,WACTuc,KAAqB3uB,IAAI2R,EAAO9G,IAAIxM,MACpCwxC;oBAEF,IAAIgG,KAAY,GACZC,KAAY;oBAUhB,yBATInkC,EAAOE,SACTgkC,IAAWE,EAAah5C,QAAQ4U,EAAO9G,IAAIxM,MAE3C03C,IAAeA,EAAaprC,OAAOgH,EAAO9G,IAAIxM;wCAE5CsT,EAAOE,SACTkkC,IAAeA,EAAa91C,IAAI0R,EAAO9G,MACvCirC,IAAWC,EAAah5C,QAAQ4U,EAAO9G,IAAIxM,OAEtC;wBAAEwT,MAAMmkC,GAAiBrkC,EAAOE;wBAAOhH,KAAAA;wBAAKgrC,UAAAA;wBAAUC,UAAAA;;;;SAlRzCG,CACpBz/C,SACAwjC,GACAxjC,SACAA,UAEFA,UAA4CwjC,IAGvCxjC;;kEAITF,QAAQqE;QACN,MAAMA,aAAiBo6C,KACrB,MAAMlrB,GAAkB,WAAW,iBAAiB,GAAGlvB;QAGzD,OACEnE,YAAoBmE,QACpBnE,QAAoB2E,QAAQR,SAC5BnE,QAAe2E,QAAQR,SACvBnE,YAAoBmE;;IAIxBrE,GAA8BuU;QAC5B,OAAO,IAAI+oC,GACTp9C,SACAqU,EAAIxM,KACJwM,GACArU,KAAK08B,SAAS9gB,WACd5b,WAA2BwJ,IAAI6K,EAAIxM,MACnC7H;;;;MAKOm7C,WAAwDnkC;IAEnElX,YACW4/C,GACTxG,GACAkD;QAGA,IADA56C,MAAMm7C,UAA6BzD,oBAC/BwG,EAAM56C,SAAS,KAAM,GACvB,MAAM,IAAI1D,EACRlB,EAAKI,kBACL,kGAEE,GAAGo/C,aAA+BA,EAAM56C;;IAKhDwf;QACE,OAAOtkB,QAAYsG;;IAGrB6a;QACE,MAAMytB,IAAa5uC,QAAYsG;QAC/B,OAAIsoC,QACK,OAEA,IAAI8K,GACT,MAAgB9K,IAChB5uC,KAAKk5C;;IAKX5yC;QACE,OAAOtG,QAAYsG;;IAGrBxG,IAAIo7C;QAaF,IAZAU,GAA4B,2BAA2BzoB,WAAW,GAAG;;;QAG5C,MAArBA,UAAUruB,WACZo2C,IAAalD,UAEf7mB,GACE,2BACA,oBACA;QAGiB,OAAf+pB,GACF,MAAM,IAAI95C,EACRlB,EAAKI,kBACL;QAGJ,MAAMgG,IAAOF;QACb,OAAOszC,MACL15C,QAAYsG,KAAK4O,MAAM5O,IACvBtG,KAAKk5C,WACLl5C;;IAIJF,IAAI6B;QACFuxB,GAA0B,2BAA2BC,WAAW,IAIhEhC,GAAgB,2BAA2B,UAAU,GAH9BnxB,UACnBA,QAAgB2/C,YAAYh+C,KAC5BA;QAEJ,MAAMi+C,IAAS5/C,KAAKqU;QACpB,OAAOurC,EAAO1rC,IAAIvS,GAAOY,KAAK;;IAGhCzC,cACEu5C;QAEA,OAAO,IAAI8B,GAAuBn7C,SAAYA,KAAKk5C,WAAWG;;;;AAIlE,YACE3kB,GACAve;IAEA,SAAgBpR,MAAZoR,GACF,OAAO;QACL6lC,QAAO;;IAeX,IAXAlC,GAAoBplB,GAAYve,GAAS,EAAC,SAAS,kBACnD0jC,GAA0BnlB,GAAY,WAAW,SAASve,EAAQ6lC,QAClE6D,GACEnrB,GACA,eACA,2BACAve,EAAQ8lC,aACRjqC,KACqB,mBAAZA,KAAwBA;SAGPjN,MAAxBoR,EAAQ8lC,oBAA+Cl3C,MAAlBoR,EAAQ6lC,OAC/C,MAAM,IAAI56C,EACRlB,EAAKI,kBACL,sCAAsCo0B,0CACpC;IAIN,OAAOve;;;AAGT,YACEue,GACAve;IAEA,YAAgBpR,MAAZoR,IACK,MAGT2jC,GAAoBplB,GAAYve,GAAS,EAAC,uBAC1C2pC,GACEprB,GACA,GACA,oBACAve,EAAQmnC,kBACR,EAAC,YAAY,YAAY;IAEpBnnC;;;AAGT,YACEue,GACAve;IAEAomC,GAAwB7nB,GAAY,UAAU,GAAGve,IAC7CA,MACF2jC,GAAoBplB,GAAYve,GAAS,EAAC,aAC1C2pC,GACEprB,GACA,GACA,UACAve,EAAQirB,QACR,EAAC,WAAW,UAAU;;;AAK5B,YACE1M,GACA+mB,GACAvC;IAEA,IAAMuC,aAAuB/B,IAEtB;QAAA,IAAI+B,EAAYvC,cAAcA,GACnC,MAAM,IAAI93C,EACRlB,EAAKI,kBACL;QAGF,OAAOm7C;;IAPP,MAAMpoB,GAAkBqB,GAAY,qBAAqB,GAAG+mB;;;AAqFhE,YAA0BpgC;IACxB,QAAQA;MACN;QACE,OAAO;;MACT;MACA;QACE,OAAO;;MACT;QACE,OAAO;;MACT;QACE,OAAOrW,GAAK,0BAA0BqW;;;;;;;;;;;;GAa5C,aACEg+B,GACA13C,GACAgvB;IAEA,IAAImrB;IAOJ,OANIzC,KACFyC,IAAiBzC,EAAUsG,YAAYh+C,IACvCgvB,IAAe,sBAAsBA,KAErCmrB,IAAiBn6C,GAEZ,KAAiBgvB;;;AAYnB,MAAMovB,KAAkBxsB,GAC7BymB,IACA,sCAEWgG,KAAoBzsB,GAC/BuF,IACA,uDAEWmnB,KAAmB1sB,GAC9B6nB,IACA,8CAEW8E,KAA0B3sB,GACrCmmB,IACA,4CAEWyG,KAAyB5sB,GAAuBooB,KAChDyE,KAA8B7sB,GACzC6pB,KAEWiD,KAAc9sB,GAAuBvc,KACrCspC,KAAsB/sB,GAAuBgrB,KAC7CgC,KAA4BhtB,GACvC4nB,IACA,mDCz/EIqF,KAAqB;IACzBxG;IACA1lB,UAAAA;IACA/wB,WAAAA;IACAwvB;IACA+F;IACAsiB;IACA1B;IACAiC;IACA3kC;IACAomC;IACAmB;IACApD;eACAx0C;IACA85C;IACA39B,aAAak3B,GAAUl3B;IACvB62B,sBAAAA;;;;;;;;;;;;;;;;;;;;ICpCA75C,GAAYqmB;;;IAIZrmB;;;;;;;;;;;;;;;;;;;;;;;;;ICYAA;QANAE,UAA4C,MAC1CA,WACFA,UAA8C,MAC5CA,WACFA,UAAmD,IAGjDA;;IAGFF,GAAYqmB;QACVnmB,QAAeuF,KAAK4gB;;IAGtBrmB;QACE87B,OAAOiB,oBAAoB,UAAU78B,UACrC47B,OAAOiB,oBAAoB,WAAW78B;;IAGxCF;QACE87B,OAAOI,iBAAiB,UAAUh8B,UAClC47B,OAAOI,iBAAiB,WAAWh8B;;IAGrCF;QACE2e,GA/BY,uBA+BM;QAClB,KAAK,MAAM0H,KAAYnmB,SACrBmmB;;IAIJrmB;QACE2e,GAtCY,uBAsCM;QAClB,KAAK,MAAM0H,KAAYnmB,SACrBmmB;;;;;IAOJrmB;QACE,OACoB,sBAAX87B,eACqB72B,MAA5B62B,OAAOI,yBACwBj3B,MAA/B62B,OAAOiB;;;;;;;;;;;;;;;;;;;;;;;;;ICxCX/8B,YAAYqjB;QACVnjB,UAAcmjB,MACdnjB,UAAemjB;;IAGjBrjB,GAAOqmB;QAELnmB,UAAqBmmB;;IAGvBrmB,GAAQqmB;QAENnmB,UAAsBmmB;;IAGxBrmB,UAAUqmB;QAERnmB,UAAwBmmB;;IAG1BrmB;QACEE;;IAGFF,KAAKkjB;QACHhjB,QAAYgjB;;IAGdljB;QAKEE;;IAGFF,GAAY4mB;QAKV1mB;;IAGFF,GAAckjB;QAKZhjB,QAAsBgjB;;;;;;;;;;;;;;;;;;;GChC1B,OASM09B,KAAmD;IACzDC,mBAA6C;IAC7CC,QAAkC;GAK5BC,KAA0B,iBAAiBlhD;;;IAS/CG,YAAYghD;QACV9gD,UAAkB8gD;QAClB,MAAMjsC,IAAQisC,EAAK58B,MAAM,UAAU;QACnClkB,UAAe6U,IAAQ,QAAQisC,EAAK78B,MACpCjkB,KAAKmkB,mBAAmB28B,EAAK38B;;;;;WAO/BrkB,GACEsD,GACAw0B;QAEA,IAAIA,GACF,KAAK,MAAMmpB,KAAUnpB,KACfA,IAAkBxtB,sBACpBhH,OAAkBw0B;QAIxBx0B,EAAQ;;IAGVtD,GACE+4B,GACAT,GACAR;QAEA,MAAMopB,IAAMhhD;QAEZ,OAAO,IAAI6B,QAAQ,CAACC,GAAyBwkB;YAC3C,MAAM26B,IAAM,IAAIC;YAChBD,EAAIE,WAAWC,EAAUC,UAAU;gBACjC;oBACE,QAAQJ,EAAIK;sBACV,KAAKC,EAAUC;wBACb,MAAMC,IAAOR,EAAIS;wBACjBjjC,GAhEE,cAgEgB,iBAAiBvS,KAAKC,UAAUs1C,KAClD3/C,EAAQ2/C;wBACR;;sBACF,KAAKF,EAAUI;wBACbljC,GApEE,cAoEgB,cAAoB,gBACtC6H,EACE,IAAIllB,EAAelB,EAAKK,mBAAmB;wBAE7C;;sBACF,KAAKghD,EAAUK;wBACb,MAAM9iC,IAASmiC,EAAIY;wBAQnB,IAPApjC,GA3EE,cA6EA,cAAoB,yBACpBK,GACA,kBACAmiC,EAAIa;wBAEFhjC,IAAS,GAAG;4BACd,MAAMijC,IAAiBd,EAAIS,kBACxBp+B;4BACH,SAEIy+B,EAAcjjC,UACdijC,EAAcxgD,SAChB;gCACA,MAAMygD,atEwK2BljC;oCACjD,MAAMmjC,IAAcnjC,EAAOojC,cAAcn7C,QAAQ,KAAK;oCACtD,OAAOmD,OAAOyD,OAAOzN,GAAMqG,QAAQ07C,MAAwB,IACtDA,IACD/hD,EAAKG;iCsE5KkC8hD,CACzBJ,EAAcjjC;gCAEhBwH,EACE,IAAIllB,KAEF2gD,EAAcxgD;mCAIlB+kB,EACE,IAAIllB,EACFlB,EAAKG,SACL,kCAAkC4gD,EAAIY;;;;wBAO5CpjC,GA9GA,cA8GkB,cAAoB,aACtC6H,EACE,IAAIllB,EAAelB,EAAKgB,aAAa;wBAGzC;;sBACF;wBACE8D,GACE,cAEE,kDAEAi8C,EAAIK,qBACJ,OACAL,EAAImB,iBACJ;;;oBAIR3jC,GAjIM,cAiIY,cAAoB;;;;;;YAO1C,MAAM4jC,IAAWn4C,kBAAKkuB;mBACfiqB,EAAQlxC;YAEf,MAAMmxC,IAAgBp2C,KAAKC;YAC3BsS,GA5IU,cA4IQ,iBAAiBuiC,IAAM;;;;;;YAMzC,MAAM59C,IAAqB;gBAAEm/C,gBAAgB;;YAE7CviD,QAA6BoD,GAASw0B,IAEtCqpB,EAAIzpB,KAAKwpB,GAAK,WAAuB59C,GApIlB;;;IAwIvBtD,GACE+4B,GACAT,GACAR;;;QAIA,OAAO53B,WAAqCo4B,GAASR;;IAGvD93B,GACE+4B,GACAjB;QAEA,MAAM4qB,IAAW,EACfxiD,SACA,KAxKqB,iCA0KrB,QAEA,cAEIyiD,IAAsBC,KACtBtqB,IAA6B;;;YAGjCuqB,oBAAoB;YACpBC,oBAAoB;YACpBC,kBAAkB;;;gBAGhB1xC,UAAU,YAAYnR,QAAgBkR,uBAAuBlR,QAAgBmR;;YAE/E2xC,cAAa;YACbC,yBAAwB;YACxBC,uBAAuB;;;;;;;gBAOrBC,gCAAgC;;YAElC9+B,kBAAkBnkB,KAAKmkB;;QAGzBnkB,QAA6Bo4B,EAA2B,oBAAER;;;;;;;;;;;;;;;;QAoBvDsrB,OACAC,OACAC,OACAC,OACAC,OACAC,QAEDnrB,EAAQorB,4BAA4B;QAGtC,MAAMxC,IAAMwB,EAASn8C,KAAK;QAC1BoY,GAxOY,cAwOM,0BAA0BuiC,IAAM,MAAM5oB;QACxD,MAAMqrB,IAAUhB,EAAoBiB,iBAAiB1C,GAAK5oB;;;;;;gBAO1D,IAAIurB,KAAS,GAKTC,KAAS;;;;gBAEb,MAAMC,IAAe,OAA4B;YAC/CC,IAAS9gC;gBACF4gC,IASHnlC,GAlQM,cAkQY,6CAA6CuE,YAP7DvE,GA3PI,cA2Pc;gBAClBglC,EAAQ5e,QACR8e,KAAS,IAEXllC,GA/PM,cA+PY,uBAAuBuE,IACzCygC,EAAQjsB,KAAKxU;;YAKjB+gC,IAAS,MAAMN,EAAQnsB;YAOnB0sB,IAAuB,CAC3B3oC,GACAzV;;;YAIA69C,EAAQ5iB,OAAOxlB,GAAO4oC;gBACpB;oBACEr+C,EAAGq+C;kBACH,OAAO1gC;oBACPsG,WAAW;wBACT,MAAMtG;uBACL;;;;;;;;gBAuFT,OAlFAygC,EAAqBE,EAAW9C,UAAU+C,MAAM;YACzCP,KACHnlC,GA/RQ,cA+RU;YAItBulC,EAAqBE,EAAW9C,UAAUgD,OAAO;YAC1CR,MACHA,KAAS,GACTnlC,GAtSQ,cAsSU,gCAClBolC;YAIJG,EAA4BE,EAAW9C,UAAU/9B,OAAOqD;YACjDk9B,MACHA,KAAS,GACTnlC,GA9SQ,cA8SU,qCAClBolC,KACE,IAAIziD,EACFlB,EAAKgB,aACL;YAaR8iD,EACEE,EAAW9C,UAAUiD,SACrBrhC;;YACE,KAAK4gC,GAAQ;gBACX,MAAMU,IAAUthC,EAAK9Z,KAAK;gBAC1BtG,QAAsB;;;;;;gBAMtB,MAAM2hD,OACAjhC,IACJihC,EAAejhC,wBACdihC,EAAqC,iCAAIjhC;gBAC5C,IAAIA,GAAO;oBACT7E,GA/UI,cA+Uc,8BAA8B6E;;oBAEhD,MAAMxE,IAAiBwE,EAAMxE;oBAC7B,IAAIxd,atEvRqBwd;;;wBAGnC,MAAMxd,IAAgB6Y,GAAQ2E;wBAC9B,SAAa/Z,MAATzD,GAIJ,OAAOyd,GAAmBzd;qBsE+QLkjD,CAAqB1lC,IAC5Bvd,IAAU+hB,EAAM/hB;yBACPwD,MAATzD,MACFA,IAAOpB,EAAKe,UACZM,IACE,2BACAud,IACA,mBACAwE,EAAM/hB;;oBAGVqiD,KAAS,GACTC,KAAyB,IAAIziD,EAAeE,GAAMC,KAClDkiD,EAAQnsB;uBAER7Y,GAjWI,cAiWc,4BAClBolC;;YAMRh6B,WAAW;;;;;YAKTg6B;WACC;;;IAKL/jD,GAAQ+4B;QACN,MAAM4rB,IAAa/D;QAKnB,OACE1gD,UACA,kBAGAA,QAAgBkR,YAChB,gBACAlR,QAAgBmR,WAChB;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;YCrZ4B6P;;;;;;;;;aLmChCphB,GACA8kD;QAKC9kD,EAAgCqB,SAAS0jD,kBACxC,IAAIC,EACF,aACAC;YACE,MAAM1K,IAAM0K,EAAUC,YAAY,OAAO3iD;YACzC,OAAOuiD,EAAiBvK,GAAK0K,EAAUC,YAAY;kCAGrDC;KKhDJC,CACEhkC,GACA,CAACm5B,GAAKj4C,MAAS,IAAI83C,GAAUG,GAAKj4C,GAAM,UAE1C8e,EAASikC;;;;;;;;;;;;;;;;;;;;;;;;;;ACVXz6C,MAA4B;ICI1B1K;QAHAE,WAAyB,GAIvBA,UAAuC,sBAATyK;;IAGhC4T;QACE,OAA2B,sBAAbA,WAA2BA,WAAW;;IAGtDud;QACE,OAAyB,sBAAXA,SAAyBA,SAAS;;IAGlD97B,GAAe21C;QACb,OAAO5zC,QAAQC,QAAQ;;IAGzBhC;QACE,OAAIolD,UACK,SAEA;;IAIXplD,GAAcmR;QACZ,OAAO,UAAoC;YAAE8pC,KAAe;;;IAG9Dj7C,GAAW6B;QACT,OAAOuK,KAAKC,UAAUxK;;IAGxB7B,KAAKqlD;QACH,OAAO16C;;IAGT3K,KAAKslD;QACH,OAAOv6C,KAAKu6C;;IF5BhBC,GAAkBzlD;;"}